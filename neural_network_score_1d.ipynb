{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b4113ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy as dc\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "import math\n",
    "import pickle\n",
    "#from graphviz import Digraph\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def get_signature(x):\n",
    "    return_string = ''\n",
    "    for ele in list_entite:\n",
    "        return_string = return_string + str(int(x[ele]))\n",
    "    return return_string\n",
    "\n",
    "\n",
    "def simulation(ini_d_s, ini_c_s, nb_ite):\n",
    "    \"\"\"\n",
    "    initial_discrete_state = '100'\n",
    "    initial_domain = [0.1,0.2,0.3]\n",
    "    \"\"\"\n",
    "    nb_dim = len(ini_c_s)\n",
    "    return_series = np.zeros((1, nb_dim))\n",
    "    times = np.zeros((1, 1))\n",
    "    count = 0\n",
    "    for dim_i in range(nb_dim):\n",
    "        return_series[0][dim_i] = int(ini_d_s[dim_i]) + ini_c_s[dim_i]\n",
    "    times[0][0] = 0\n",
    "    d_s = ini_d_s\n",
    "    c_s = ini_c_s.copy()\n",
    "    for num_ite in range(nb_ite):\n",
    "        # instant transition\n",
    "        instant_transition = True\n",
    "        current_d_s = dc(d_s)\n",
    "        c_count = 0\n",
    "        while instant_transition:\n",
    "            instant_transition = False\n",
    "            for dim_i in range(nb_dim):\n",
    "                if c_s[dim_i] == 1 and classify_boundary(d_s, dim_i, 1) == 'output':\n",
    "                    instant_transition = True\n",
    "                    c_s[dim_i] = 0\n",
    "                    d_s = d_s[0:dim_i] + str(int(d_s[dim_i]) + 1) + d_s[dim_i + 1:]\n",
    "                    break\n",
    "                elif c_s[dim_i] == 0 and classify_boundary(d_s, dim_i, -1) == 'output':\n",
    "                    instant_transition = True\n",
    "                    c_s[dim_i] = 1\n",
    "                    d_s = d_s[0:dim_i] + str(int(d_s[dim_i]) - 1) + d_s[dim_i + 1:]\n",
    "                    break\n",
    "            c_count = c_count + 1\n",
    "            #             print(d_s)\n",
    "            if c_count > 1 and current_d_s == d_s:\n",
    "                return (return_series, times)\n",
    "        delta_t = math.inf\n",
    "        first_touch_dim = nb_dim\n",
    "        first_touch_sign = 0\n",
    "        one_return_series = np.zeros((1, nb_dim))\n",
    "        one_times = np.zeros((1, 1))\n",
    "        set_att = []\n",
    "        for dim_i in range(nb_dim):\n",
    "            if c_s[dim_i] == 1 and classify_boundary(d_s, dim_i, 1) == 'attractif':\n",
    "                set_att = set_att + [dim_i]\n",
    "            elif c_s[dim_i] == 0 and classify_boundary(d_s, dim_i, -1) == 'attractif':\n",
    "                set_att = set_att + [dim_i]\n",
    "        if len(set_att) == nb_dim:\n",
    "            return (return_series, times)\n",
    "        for dim_i in range(nb_dim):\n",
    "            if dim_i not in set_att:\n",
    "                speed = get_celerity(d_s, dim_i)\n",
    "                if speed > 0:\n",
    "                    delta = (1 - c_s[dim_i]) / speed\n",
    "                    sign = 1\n",
    "                elif speed < 0:\n",
    "                    delta = (0 - c_s[dim_i]) / speed\n",
    "                    sign = 0\n",
    "                elif speed == 0:\n",
    "                    delta = math.inf\n",
    "                if delta < delta_t:\n",
    "                    delta_t = delta\n",
    "                    first_touch_dim = dim_i\n",
    "                    first_touch_sign = sign\n",
    "        # check if two boundary are reached at the same time\n",
    "        for dim_i in range(nb_dim):\n",
    "            if dim_i not in set_att:\n",
    "                speed = get_celerity(d_s, dim_i)\n",
    "                if speed > 0:\n",
    "                    delta = (1 - c_s[dim_i]) / speed\n",
    "                    sign = 1\n",
    "                elif speed < 0:\n",
    "                    delta = (0 - c_s[dim_i]) / speed\n",
    "                    sign = 0\n",
    "                elif speed == 0:\n",
    "                    delta = math.inf\n",
    "                if delta == delta_t and dim_i != first_touch_dim:\n",
    "                    print('reach two new boundaries at the same time!')\n",
    "\n",
    "        c_s[first_touch_dim] = first_touch_sign\n",
    "        count = count + delta_t\n",
    "        for dim_i in range(nb_dim):\n",
    "            if dim_i not in set_att and dim_i != first_touch_dim:\n",
    "                speed = get_celerity(d_s, dim_i)\n",
    "                c_s[dim_i] = c_s[dim_i] + delta_t * speed\n",
    "            one_return_series[0][dim_i] = int(d_s[dim_i]) + c_s[dim_i]\n",
    "        #         print('discrete state:',d_s)\n",
    "        #         print('continuous state:',c_s)\n",
    "        #         print('***********************')\n",
    "        one_times[0][0] = count\n",
    "        return_series = np.vstack([return_series, one_return_series])\n",
    "        times = np.vstack([times, one_times])\n",
    "    return (return_series, times)\n",
    "\n",
    "\n",
    "def classify_boundary(state, dim, domain):\n",
    "    \"\"\"\n",
    "    state: '010'\n",
    "    dim: 2\n",
    "    domain: 1/0/-1\n",
    "    \"\"\"\n",
    "    current_row = celerities.query('signature == @state')\n",
    "    speed = current_row['c_' + list_entite[dim]].values[0]\n",
    "    if domain == 0:\n",
    "        return 'interior'\n",
    "    elif domain == 1:\n",
    "        if speed > 0:\n",
    "            if int(state[dim]) == max_level[list_entite[dim]]:\n",
    "                return 'attractif'\n",
    "            else:\n",
    "                upper_discrete_state = state\n",
    "                upper_discrete_state = list(upper_discrete_state)\n",
    "                upper_discrete_state[dim] = str(int(upper_discrete_state[dim]) + 1)\n",
    "                upper_discrete_state = \"\".join(upper_discrete_state)\n",
    "                upper_speed = celerities.query('signature == @upper_discrete_state')['c_' + list_entite[dim]].values[0]\n",
    "                if upper_speed <= 0:\n",
    "                    return 'attractif'\n",
    "                elif upper_speed > 0:\n",
    "                    return 'output'\n",
    "        elif speed == 0:\n",
    "            return 'neutral'\n",
    "        elif speed < 0:\n",
    "            return 'input'\n",
    "    elif domain == -1:\n",
    "        if speed < 0:\n",
    "            if int(state[dim]) == 0:\n",
    "                return 'attractif'\n",
    "            else:\n",
    "                lower_discrete_state = state\n",
    "                lower_discrete_state = list(lower_discrete_state)\n",
    "                lower_discrete_state[dim] = str(int(lower_discrete_state[dim]) - 1)\n",
    "                lower_discrete_state = \"\".join(lower_discrete_state)\n",
    "                lower_speed = celerities.query('signature == @lower_discrete_state')['c_' + list_entite[dim]].values[0]\n",
    "                if lower_speed >= 0:\n",
    "                    return 'attractif'\n",
    "                elif lower_speed < 0:\n",
    "                    return 'output'\n",
    "        elif speed == 0:\n",
    "            return 'neutral'\n",
    "        elif speed > 0:\n",
    "            return 'input'\n",
    "\n",
    "\n",
    "def get_celerity(state, dim):\n",
    "    current_row = celerities.query('signature == @state')\n",
    "    speed = current_row['c_' + list_entite[dim]].values[0]\n",
    "    return speed\n",
    "\n",
    "\n",
    "def get_transition_matrix(state, first_domain, second_domain):\n",
    "    \"\"\"\n",
    "    state: '0101'\n",
    "    first_domain(second_domain): [0,-1,1,0]\n",
    "    \"\"\"\n",
    "    # get first reach dimension\n",
    "    first_reach_dim = len(second_domain) + 1\n",
    "    for num_dim in range(len(second_domain)):\n",
    "        if second_domain[num_dim] in [-1, 1] and first_domain[num_dim] != second_domain[num_dim]:\n",
    "            first_reach_dim = num_dim\n",
    "            break\n",
    "    # Calculate delta t\n",
    "    speed = get_celerity(state, first_reach_dim)\n",
    "    if first_domain[first_reach_dim] in [1, -1]:\n",
    "        if second_domain[first_reach_dim] == 1:\n",
    "            delta_cons = 1 / speed\n",
    "            delta_var = 0\n",
    "        elif second_domain[first_reach_dim] == -1:\n",
    "            delta_cons = (-1) / speed\n",
    "            delta_var = 0\n",
    "    else:\n",
    "        if second_domain[first_reach_dim] == 1:\n",
    "            delta_cons = 1 / speed\n",
    "            delta_var = (-1) / speed\n",
    "        elif second_domain[first_reach_dim] == -1:\n",
    "            delta_cons = 0\n",
    "            delta_var = (-1) / speed\n",
    "    # calculate transition matrix\n",
    "    nb_dim = len(second_domain)\n",
    "    # the supplementary dimension is 1\n",
    "    t_m = np.zeros((nb_dim + 1, nb_dim + 1))\n",
    "    t_m[nb_dim][nb_dim] = 1\n",
    "    delta1 = time.time()\n",
    "    for num_dim in range(nb_dim):\n",
    "        if num_dim == first_reach_dim:\n",
    "            # for first reached dimension\n",
    "            if second_domain[first_reach_dim] == 1:\n",
    "                t_m[first_reach_dim][nb_dim] = 1\n",
    "            elif second_domain[first_reach_dim] == -1:\n",
    "                t_m[first_reach_dim][nb_dim] = 0\n",
    "        else:\n",
    "            # slide\n",
    "            if second_domain[num_dim] in [-1, 1] and second_domain[num_dim] == first_domain[num_dim]:\n",
    "                t_m[num_dim][num_dim] = 1\n",
    "            else:\n",
    "                # normal tranform x_new = x + c * delta_t\n",
    "                current_speed = get_celerity(state, num_dim)\n",
    "                t_m[num_dim][num_dim] = 1\n",
    "                t_m[num_dim][first_reach_dim] = current_speed * delta_var\n",
    "                t_m[num_dim][nb_dim] = current_speed * delta_cons\n",
    "    return t_m\n",
    "\n",
    "\n",
    "def get_transition_cross_state(state1, state2):\n",
    "    \"\"\"\n",
    "    state1: '0101'\n",
    "    state2: '0100'\n",
    "    \"\"\"\n",
    "    nb_dim = len(state1)\n",
    "    # initialize transiton matrix\n",
    "    t_m = np.zeros((nb_dim + 1, nb_dim + 1))\n",
    "    t_m[nb_dim][nb_dim] = 1\n",
    "    for dim_i in range(nb_dim):\n",
    "        t_m[dim_i][dim_i] = 1\n",
    "        if state2[dim_i] > state1[dim_i]:\n",
    "            t_m[dim_i][nb_dim] = -1\n",
    "        elif state2[dim_i] < state1[dim_i]:\n",
    "            t_m[dim_i][nb_dim] = 1\n",
    "    return t_m\n",
    "\n",
    "\n",
    "def get_fixed_point(A):\n",
    "    nb_dim = A.shape[0]\n",
    "    iden = np.zeros((nb_dim, nb_dim))\n",
    "    for i_dim in range(nb_dim):\n",
    "        iden[i_dim][i_dim] = 1\n",
    "    X = np.subtract(A, iden)\n",
    "    b = np.zeros(nb_dim)\n",
    "    fixed_point = np.linalg.solve(X, b)\n",
    "    return fixed_point\n",
    "\n",
    "\n",
    "def get_constraint1(discrete_domain):\n",
    "    dim_free = []\n",
    "    for one_dim in range(len(discrete_domain)):\n",
    "        if discrete_domain[one_dim] not in [-1, 1]:\n",
    "            dim_free = dim_free + [one_dim]\n",
    "    last_constraint_a = np.zeros((2 * len(dim_free), len(discrete_domain)))\n",
    "    last_constraint_b = np.zeros((2 * len(dim_free), 1))\n",
    "    for one_dim in range(len(dim_free)):\n",
    "        last_constraint_a[one_dim * 2][dim_free[one_dim]] = 1\n",
    "        last_constraint_a[one_dim * 2 + 1][dim_free[one_dim]] = -1\n",
    "        last_constraint_b[one_dim * 2][0] = 1\n",
    "        last_constraint_b[one_dim * 2 + 1][0] = 0\n",
    "    return last_constraint_a, last_constraint_b\n",
    "\n",
    "\n",
    "def get_stable_zone(one_trajectory):\n",
    "    len_state = len(one_trajectory)\n",
    "    nb_dim = len(list_entite)\n",
    "    t_m = np.zeros((nb_dim + 1, nb_dim + 1))\n",
    "    cons_a = np.zeros((1, nb_dim))\n",
    "    cons_b = np.ones((1, 1))\n",
    "    for dim_i in range(nb_dim + 1):\n",
    "        t_m[dim_i][dim_i] = 1\n",
    "    for i_state in range(len_state):\n",
    "        current_discrete_state = list(one_trajectory[i_state].keys())[0]\n",
    "        if i_state < len_state - 1:\n",
    "            post_discrete_state = list(one_trajectory[i_state + 1].keys())[0]\n",
    "        current_discrete_trajectory = one_trajectory[i_state][current_discrete_state]\n",
    "        len_domain = len(current_discrete_trajectory)\n",
    "        for i_domain in range(len_domain):\n",
    "            # calculate current constraints\n",
    "            current_cons_a, current_cons_b = get_constraint1(current_discrete_trajectory[i_domain])\n",
    "            new_cons_a = np.matmul(current_cons_a, t_m[:-1, :-1])\n",
    "            temp_b = np.matmul(current_cons_a, t_m[:-1, -1])\n",
    "            new_cons_b = current_cons_b - temp_b.reshape(temp_b.shape[0], 1)\n",
    "            cons_a = np.vstack([cons_a, new_cons_a])\n",
    "            cons_b = np.vstack([cons_b, new_cons_b])\n",
    "            # calculate next transition matrix\n",
    "            if i_domain < len_domain - 1:\n",
    "                current_transition_matrix = get_transition_matrix(current_discrete_state,\n",
    "                                                                  current_discrete_trajectory[i_domain],\n",
    "                                                                  current_discrete_trajectory[i_domain + 1])\n",
    "                t_m = np.matmul(current_transition_matrix, t_m)\n",
    "            elif i_domain == len_domain - 1 and i_state < len_state - 1:\n",
    "                current_transition_matrix = get_transition_cross_state(current_discrete_state, post_discrete_state)\n",
    "                t_m = np.matmul(current_transition_matrix, t_m)\n",
    "    # regularise the constrains in the first discrete domain\n",
    "    first_discrete_state = list(one_trajectory[0].keys())[0]\n",
    "    first_domain = one_trajectory[0][first_discrete_state][0]\n",
    "    for num_dim in range(len(first_domain)):\n",
    "        if first_domain[num_dim] == -1:\n",
    "            cons_a[:, num_dim] = 0\n",
    "        elif first_domain[num_dim] == 1:\n",
    "            cons_b = cons_b - cons_a[:, num_dim].reshape(cons_a[:, num_dim].shape[0], 1)\n",
    "            cons_a[:, num_dim] = 0\n",
    "    c = np.zeros((cons_a.shape[1],))\n",
    "    res = linprog(c, cons_a, cons_b)\n",
    "    if res.success == False:\n",
    "        return False, [cons_a, cons_b]\n",
    "    else:\n",
    "        return True, [cons_a, cons_b]\n",
    "\n",
    "\n",
    "def dfs(graph, trace, start):\n",
    "    global cycles\n",
    "    global reached\n",
    "    trace = dc(trace)\n",
    "    if start in trace:\n",
    "        index = trace.index(start)\n",
    "        tmp = [i for i in trace[index:]]\n",
    "        temp_bool = False\n",
    "        for ele in cycles:\n",
    "            if same(ele, tmp) == True:\n",
    "                temp_bool = True\n",
    "        if temp_bool == False:\n",
    "            cycles = cycles + [tmp]\n",
    "        return\n",
    "    if start not in reached:\n",
    "        reached = reached + [start]\n",
    "    trace.append(start)\n",
    "    for i in graph[start]:\n",
    "        dfs(graph, trace, i)\n",
    "\n",
    "\n",
    "def same(list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        return False\n",
    "    elif list1[0] not in list2:\n",
    "        return False\n",
    "    else:\n",
    "        length = len(list1)\n",
    "        first = list2.index(list1[0])\n",
    "        for i in range(length):\n",
    "            if list1[i] != list2[(first + i) % length]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "def get_next_state(cycle, state):\n",
    "    len_cycle = len(cycle)\n",
    "    i_c = cycle.index(state)\n",
    "    if i_c < len_cycle - 1:\n",
    "        return cycle[i_c + 1]\n",
    "    elif i_c == len_cycle - 1:\n",
    "        return cycle[0]\n",
    "\n",
    "\n",
    "def dfs_discrete_all(domain, s_domain, state, cycle, t_m, s_z):\n",
    "    \"\"\"\n",
    "    domain: [1,-1,1]\n",
    "    s_domain: current discrete trajectory without domain [{'01':[[-1,1],[0,-1]]},{}]\n",
    "    state: discrete state of domain\n",
    "    cycle: the cycle of discrete state\n",
    "    t_m: transition matrix without considering domain\n",
    "    s_z: stable zone without considering domain\n",
    "    \"\"\"\n",
    "    global list_discrete_trajectory\n",
    "    global list_transition_matrix\n",
    "    global list_stable_zone\n",
    "    global list_cycle\n",
    "    s_domain = dc(s_domain)\n",
    "    t_m = dc(t_m)\n",
    "    s_z = dc(s_z)\n",
    "    cycle = dc(cycle)\n",
    "    domain = dc(domain)\n",
    "    state = dc(state)\n",
    "    #     print('s_domain',s_domain)\n",
    "    #     print('domain',domain)\n",
    "    #     print('state',state)\n",
    "    #     print('cycle',cycle)\n",
    "    #     print('t_m',t_m)\n",
    "    #     print('s_z',s_z)\n",
    "\n",
    "    if len(cycle) > 1 and state == cycle[0]:\n",
    "        list_discrete_trajectory = list_discrete_trajectory + [s_domain]\n",
    "        list_transition_matrix = list_transition_matrix + [t_m]\n",
    "        list_stable_zone = list_stable_zone + [s_z]\n",
    "        list_cycle = list_cycle + [cycle]\n",
    "        return\n",
    "    elif len(cycle) > 1 and state in cycle[:-1] and state != cycle[0]:\n",
    "        return\n",
    "    # step1: add domain to s_domain\n",
    "    if len(s_domain) == 0:\n",
    "        new_dict = dict()\n",
    "        new_dict[state] = [dc(domain)]\n",
    "        s_domain = [new_dict]\n",
    "        s_z_a, s_z_b = get_constraint1(domain)\n",
    "        s_z = [s_z_a, s_z_b]\n",
    "        cycle = cycle + [dc(state)]\n",
    "\n",
    "        # instant transition\n",
    "        instant = False\n",
    "        for i_dim in range(len(domain)):\n",
    "            if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                next_domain = dc(domain)\n",
    "                next_domain[i_dim] = -1\n",
    "                next_state = dc(state)\n",
    "                next_state = list(next_state)\n",
    "                next_state[i_dim] = str(int(next_state[i_dim]) + 1)\n",
    "                next_state = \"\".join(next_state)\n",
    "                dfs_discrete_all(next_domain, s_domain, next_state, cycle, t_m, s_z)\n",
    "                instant = True\n",
    "                break\n",
    "            elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                next_domain = dc(domain)\n",
    "                next_domain[i_dim] = 1\n",
    "                next_state = dc(state)\n",
    "                next_state = list(next_state)\n",
    "                next_state[i_dim] = str(int(next_state[i_dim]) - 1)\n",
    "                next_state = \"\".join(next_state)\n",
    "                dfs_discrete_all(next_domain, s_domain, next_state, cycle, t_m, s_z)\n",
    "                instant = True\n",
    "                break\n",
    "\n",
    "        # non instant transition\n",
    "        if instant == False:\n",
    "            for i_dim in range(len(domain)):\n",
    "                if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'input':\n",
    "                    domain[i_dim] = 0\n",
    "                elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'input':\n",
    "                    domain[i_dim] = 0\n",
    "            for i_dim in range(len(domain)):\n",
    "                if domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = 1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "                elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = -1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "                elif domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'attractif':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = 1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "                elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'attractif':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = -1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "    else:\n",
    "        # calculate new transition matrix\n",
    "        current_state = list(s_domain[-1].keys())[0]\n",
    "        if current_state == state:\n",
    "            last_domain = s_domain[-1][current_state][-1]\n",
    "            temp_t_m = get_transition_matrix(state, last_domain, domain)\n",
    "        elif current_state != state:\n",
    "            temp_t_m = get_transition_cross_state(current_state, state)\n",
    "        #         print('temp_t_m',temp_t_m)\n",
    "        new_t_m = np.matmul(temp_t_m, t_m)\n",
    "        # calculate new constraint\n",
    "        c_a, c_b = get_constraint1(domain)\n",
    "        new_a = np.matmul(c_a, new_t_m[:-1, :-1])\n",
    "        temp_b = np.matmul(c_a, new_t_m[:-1, -1])\n",
    "        new_b = c_b - temp_b.reshape(temp_b.shape[0], 1)\n",
    "        # regulate the constraint considering the first domain\n",
    "        first_state = cycle[0]\n",
    "        first_domain = s_domain[0][first_state][0]\n",
    "        for num_dim in range(len(first_domain)):\n",
    "            if first_domain[num_dim] == -1:\n",
    "                new_a[:, num_dim] = 0\n",
    "            elif first_domain[num_dim] == 1:\n",
    "                new_b = new_b - new_a[:, num_dim].reshape(new_a[:, num_dim].shape[0], 1)\n",
    "                new_a[:, num_dim] = 0\n",
    "        #         print('new_a',new_a)\n",
    "        #         print('new_b',new_b)\n",
    "        #         print('************')\n",
    "        new_s_z_a = np.vstack([s_z[0], new_a])\n",
    "        new_s_z_b = np.vstack([s_z[1], new_b])\n",
    "        c = np.zeros((new_s_z_a.shape[1],))\n",
    "        try:\n",
    "            res = linprog(c, new_s_z_a, new_s_z_b)\n",
    "            add_bool = res.success\n",
    "        except:\n",
    "            add_bool = False\n",
    "        if add_bool == False:\n",
    "            # path end without returning a discrete trajectory\n",
    "            return\n",
    "        else:\n",
    "            # add domain to s_domain\n",
    "            if current_state == state:\n",
    "                s_domain[-1][state] = s_domain[-1][state] + [dc(domain)]\n",
    "            elif current_state != state:\n",
    "                new_dict = dict()\n",
    "                new_dict[state] = [dc(domain)]\n",
    "                s_domain = s_domain + [new_dict]\n",
    "                cycle = cycle + [dc(state)]\n",
    "            # choose all possible next domain\n",
    "\n",
    "            # instant transition\n",
    "            instant = False\n",
    "            for i_dim in range(len(domain)):\n",
    "                if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                    next_domain = dc(domain)\n",
    "                    next_domain[i_dim] = -1\n",
    "                    next_state = dc(state)\n",
    "                    next_state = list(next_state)\n",
    "                    next_state[i_dim] = str(int(next_state[i_dim]) + 1)\n",
    "                    next_state = \"\".join(next_state)\n",
    "                    dfs_discrete_all(next_domain, s_domain, next_state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    instant = True\n",
    "                    break\n",
    "                elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                    next_domain = dc(domain)\n",
    "                    next_domain[i_dim] = 1\n",
    "                    next_state = dc(state)\n",
    "                    next_state = list(next_state)\n",
    "                    next_state[i_dim] = str(int(next_state[i_dim]) - 1)\n",
    "                    next_state = \"\".join(next_state)\n",
    "                    dfs_discrete_all(next_domain, s_domain, next_state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    instant = True\n",
    "                    break\n",
    "\n",
    "            # non instant transition\n",
    "            if instant == False:\n",
    "                for i_dim in range(len(domain)):\n",
    "                    if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'input':\n",
    "                        domain[i_dim] = 0\n",
    "                    elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'input':\n",
    "                        domain[i_dim] = 0\n",
    "                for i_dim in range(len(domain)):\n",
    "                    if domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = 1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = -1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    elif domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'attractif':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = 1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'attractif':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = -1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18131aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABX20lEQVR4nO3dd3iOZ/vA8e+VPSUiQUgIsWOLvdUuQZXSmqVKi+rQPfRt3/76dtcordasWrVrq1LESEJsMUMiRggRspPr98cdbUTIup+RPNfnOHJInnudbvKcz32N8xJSShRFURTLZWXqABRFURTTUolAURTFwqlEoCiKYuFUIlAURbFwKhEoiqJYOBtTB1AYnp6e0s/Pz9RhKIqiFCthYWE3pJReOV8vlonAz8+P0NBQU4ehKIpSrAghLub2umoaUhRFsXAqESiKolg4lQgURVEsnEoEiqIoFk4lAkVRFAunEoGiKIqFU4lAURTFwqlEYAIhV0MIvx5u6jAURVGAYjqhrDiLS45j4vaJlLIrxcb+G7ESKhcrimJa6l3IyGYdnsXdtLvE3Ish7FqYqcNRFEVRicCYLsRfYHnEcvr498HZ1pm159aaOiRFURR9EoEQYo4Q4roQ4tgjtncQQsQLIcKzvj7Mtq27ECJCCHFWCPG2HvGYq2/CvsHexp5Xm7xK18pd2RK5hcS0RFOHpSiKhdPriWAe0D2PfXZJKRtmff0HQAhhDcwAegB1gMFCiDo6xWRWQq6GsCNqB6PrjaaMYxl6+/cmMT2R7VHbTR2aoigWTpdEIKX8G4grxKHNgLNSyvNSylRgCdBHj5jMSabM5MuQL/F29mZI7SEANCnXhIouFVl7VjUPKYpiWsbsI2gphDgshNgohAjIeq0iEJVtn+is1x4ihBgjhAgVQoTGxsYaOlZdrT+/npNxJ5nYeCIONg4AWAkrelXtxb4r+7h275qJI1QUxZIZKxEcBCpLKRsA04DVWa+LXPaVuZ1ASvmTlDJQShno5fXQugpmKyk9ie8Pfk9AmQB6Vun5wLYg/yAkkj/O/2Gi6BRFUYyUCKSUd6SUd7O+3wDYCiE80Z4AfLPt6gPEGCMmY1l4YiHXEq/xRuAbD80ZqFSqEg29GrLu3DqkzDX/KYqiGJxREoEQorwQQmR93yzrujeBEKC6EKKKEMIOGASUmEbzG0k3+OXoL3Ty7URg+cBc9wmqFsS5+HOciDth5OgURVE0eg0fXQzsBWoKIaKFEKOEEGOFEGOzdnkaOCaEOAxMBQZJTTowHtgMnASWSSmP6xGTOfgh/AdSM1J5tcmrj9ynm1837KzsVKexoigmo0uJCSnl4Dy2TwemP2LbBmCDHnGYk7O3zrLizAoG1xqMn5vfI/crZVeKjpU6svHCRt4IfANba1vjBakoioKaWWwwX4d9jbOtM2Prj81z3yD/IG6l3GLX5V1GiExRFOVBKhEYQHBMMLsv7+bF+i/i7uCe5/6tKrTCw8GDdefWGT44RVGUHFQi0FlGZgZfh35NRZeKDK712Bazf9hY2fBk1SfZEb2D28m3DRugoihKDioR6GztubWcvnWaSU0mYWdtl+/jgvyDSM9MZ1PkJgNGpyiK8jCVCHSUmJbItEPTaODVgG6VuxXo2FoetahRuoaqSKooitGpRKCjecfnEZsUyxuBb5A1baJAgvyDOHrjKOfjzxsgOkVRlNypRKCT64nXmXd8Hl0rd6Vh2YaFOseTVZ/ESljxxzlVckJRFONRiUAn0w9NJz0znUlNJhX6HJ6OnrSq0Ip159eRKTP1C05RFOUxVCLQQURcBKvPrubZWs/i6+qb9wGP0ce/D1fvXSXkaohO0SmKojyeSgRFJKXkq9CvKGVfihfqv1Dk83Xw7YCrravqNFYUxWhUIiiiXZd3se/KPsY1GIebvVuRz+dg40BXv65svbhVLWOpKIpRqERQBOmZ6XwT+g2VXCsxsMZA3c4b5B9EUnoS2y5t0+2ciqIoj6ISQRGsPLOSc/HneK3Ja7oWi2tUthE+Lj6qeUhRFKNQiaCQ7qbeZUb4DBqXbUynSp10PbcQgiD/IA5cOcDVe1d1PbeiKEpOKhEU0pxjc4hLjmNy08mFmjyWl17+vdQyloqiGIVKBIVw9d5VFpxYQM8qPanrWdcg1/B19aVx2casObum5C9jeTsKSvrfUVHMmEoEhTD14FSklLzS+BWDXifIP4jIO5Ecu3HMoNcxqZPr4Lu68PdXpo5EUSyWSgQFdPzmcdadX8fQOkOp4FLBoNfq6tcVe2v7kttpfCsSVr8Mwgp2fa09GSiKYnQqERSAlJKvQr7Cw8GD0fVGG/x6rnaudPLtxMbIjaRmpBr8ekaVngrLR2rfD89akGfrh6aLR1EsmF6L188RQlwXQuTahiGEeE4IcSTrK1gI0SDbtkghxFEhRLgQIlSPeAzlr6i/CL0WyrgG43CxczHKNYOqBRGfEs+u6BK2jOW2KRBzEPpMB7820GYSHF8JkbtNHZmiWBy9ngjmAd0fs/0C0F5KWR/4BPgpx/aOUsqGUspAneLRXVpmGt+GfUsVtyo8XeNpo123hXcLPB09WXNujdGuaXCn1sO+GdDsRagTpL3W+hVwqwQb34KMdNPGpygWRpdEIKX8G4h7zPZgKeWtrB/3AT56XNeYlkcsJ/JOJK83eR0bKxujXdfGyoZeVXuxK3oXt5Jv5X2Aubt9CVaPA++G0PWTf1+3ddR+vnYMDs4zVXSKYpFM0UcwCtiY7WcJbBFChAkhxjzqICHEGCFEqBAiNDY21uBBZncn9Q4zD8+kefnmtPNpZ9RrA/T27026TGfDhQ1Gv7auMtLg9+e1oaID5oKN/YPb6/QBv7aw/VNIfOTnCkVRdGbURCCE6IiWCN7K9nJrKWVjoAfwshAi13daKeVPUspAKWWgl5eXEaL9189HfiY+JZ43mhZu5bGiqlG6BrU9arPu3DqjX1tXf34M0SEQNBU8qj68XQjo8T9Ijoe/PjN+fIpioYyWCIQQ9YGfgT5Sypv3X5dSxmT9eR1YBTQzVkz5cfnuZX49+Su9/XtTy6OWyeLo7d+b4zePc+72OZPFUCSnN0PwNAgcBQH9Hr1fuQBoOhpCf4Frx40Xn6JYMKMkAiFEJWAlMFRKeTrb685CCNf73wNdAbOaPfV92PdYC2smNppo0jh6VOmBtbAunnMK4qNh1YtQvh50y8cn/Q7vgIO71nGsZhwrisHpNXx0MbAXqCmEiBZCjBJCjBVCjM3a5UOgDPBDjmGi5YDdQojDwAFgvZRykx4x6eFI7BE2Rm5keMBwyjmXM2ksno6etKnYhj/O/0FGZoZJYymQ+/0CGWkwYD7YOuR9jJMHdHofInfBiRI0WkpRzJQuw1+klIPz2D4aeGgGlpTyPNDg4SNMT0rJlyFfUsahDM/Xfd7U4QBa89DO6J3sv7qfVhVamTqc/Nn+KUTth/6/QBn//B/XZASEzoUt70P1rmDnZLAQFcXSqZnFj7Dt0jbCY8MZ32g8Trbm8SbUwbcDrnauxafT+MxW2POd9qZer4BzL6ystY7j+CgInmqI6BRFyWK8AfHFSFqGNnmsmns1+lV7TMemkdlb29Pdrzt/nP+De2n3cLZ1NnVIj3YnRusXKFcXun9euHP4tYaAp2D3t9DwWXCvpG+MipIf6amwsC9Y2YBvM/BtDj6B4Fja1JHpRj0R5GLxqcVEJUTxRuAbWFtZmzqcB9xfxnLrxa2mDuXRMtLh91GQlgwD5mmTxQqr6yeA0JqIFMUUInfBxT3aZMhdX8Oip+F/fjCjOaydAId+hRtnivXABvVEkEN8Sjw/HvmR1hVa07pia1OH85AGXg2oXKoya8+tpW+1vqYOJ3c7/g8uBcNTs8GzetHO5eYDbV+Dv/4LF/6GKsaf0KdYuIgNYOsEL+2FzAytRlbUfog6oA1mOLhA28/RI+uJIeupoULjYtO3pRJBDrMOz+Ju2l1eD3zd1KHkSghB76q9mR4+nZi7MQYvhV1gZ//UPjU1Ggr1B+pzzlYT4NBCbTjpi7vAWv23VYxESojYCP6d/n2yrdLu3w8kmZlw80xWYshKDqezBj5a2WhDpn2b/5sc3Myzuo76jcrm0p1LLIlYQr9q/aheuoifZA2ol38vpodPZ925dbzY4EVTh/OvO1dg5RgoWxt6fKHfeW0doet/YdlQCJsLzV7Q79yK8jhXDsOdy9Dx3dy3W1mBV03tq/Ew7bXEOG0G/f3EcHAB7J+lbStV8d+k4NsMytcHa1vj/F0eQyWCbL47+B22VraMbzTe1KE8VkWXijQt35R159cxpv4Yk5S9eEhmBqx8AdIStX4BvR+Ja/eGKu214ah1+2tzDRTF0CI2aAsn1XhcceUcnDygRjftC7Q5NNeOaUnhfnI4vkrbZuMIFRtn64RuBs5l9P975EElgiwHrx1k68WtvNzwZTwdPU0dTp56V+3Nh8EfcuTGERp4mcFUjJ3/0zrV+s7UPh3p7X4dopmttWTQ6xv9r6EoOZ3aoL1BOxfhPcHaFio00r6aZz3Bx1+G6AP/Jofg6ZD5rbatTLUHm5M8a2pPHgakEgGQKTP5KvQryjqWZXjAcFOHky9dKnfhs/2fsfbsWtMngvM7YOcX0OBZbZinoZStrTULHfgJAkdq7a+KYii3LsK1o9Dlk7z3LSi3iuDW79+6W2lJEBOerZ9hM4Qv0rbZu4Fv03+Tg09TsNN36LgaPgpsjtzM0RtHmdB4Ao42RRjqaEQudi48UfkJ0y9jmXANVrwAnjXgSSMsQN/hbVWHSDGO+52+tZ40/LVsHaFyS22lvsG/weSzMOEg9J0FdZ/S+t/++gwW9IHzO3W/vMUngpSMFL4L+45aHrUI8g8ydTgFElQ1iITUBHZE7TBNAJkZsHI0pCTAwPm6f0rJlWNpeOJDbVz38ZWGv55iuU6t1z7gFKQ0il6E0K7bcDD0/g5eCoa3L8KQldpES51ZfCJYdHIRMfdieCPwDaxE8bodzb2bU9axrOlKTvz9lTa2v+eXWrONsTQepo222PIhpN4z3nUVy5F0W/uwUbOnqSP5l4MbVHtC+1NnxeudT2dxyXHMPjKb9j7tae7d3NThFJi1lTVP+j/J7su7uZl0M+8D9HRhF+z8HOo/A42GGPfaVtba8NQ70bD7O+NeW7EMZ7ZCZrpxmoXMgEUngpnhM0lKT+K1Jq+ZOpRCC6oaRLpMZ+OFjXnvrJe7sbBiNHj4w5PfaI+xxla5JdR9GvZ8D7cijX99pWSLWA/OXlAx0NSRGIXFJoIL8RdYfno5T9d4mqruuSybWExUK12NOmXqGG/BmsxMWDUGkm9r8wXsXYxz3dx0+Y/2dKDqECl6Sk+FM9u0uQMGHrZpLizjb5mLb8K+wcHGgXENxpk6lCIL8g/iZNxJTt86nffORbX7Gzi3XRvTX76u4a/3OG4VtTpEJ9dpQ1gVRQ+RuyA1wWKahcBCE0HI1RB2RO1gdL3RlHE0/iw+vfWo0gMbYWP4TuPIPVrxt7pPQ2MzmW/RcgK4V4aNb2tVTxWlqO4XmavawdSRGI3FJYJMmcmXIV/i7ezNkNpG7uQ0EA8HD9r4aMtYpmca6M3w3g1YMQpKV9GGs5lDWQvQlr7s9hnEntQWvFeUosityJwFsLhEsP78ek7GnWRi44k42ORj/dxioo9/H24k3WD/lf36nzwzU1tkJjEuq1/AVf9rFEWtJ6FqR+1p5d4NU0ejFGdXwrUic+Y0bNQI9Fq8fo4Q4roQ4tgjtgshxFQhxFkhxBEhRONs27oLISKytr2tRzyPkpSexPcHvyegTAA9q5Ssf+h2Pu0oZVeKNecMsNh78Pdwdht0/wy86+t//qISQlsFLeWuVodIUQorYmNWkblupo7EqPR6IpgHPK48Xw+getbXGGAmgBDCGpiRtb0OMFgIUUenmB6y8MRCriVeY3LTycVu8lhe7Kzt6FGlB9svbedu6l39TnxpH/z5CdTpC4Gj9Duv3srW0gp6hc3TSgcrSmHoUWSuGNLl3VBK+TcQ95hd+gALpGYf4C6E8AaaAWellOellKnAkqx9DaKSayWeqfkMTco1MdQlTCrIP4iUjBS2XNyizwkT4+D357W1goOmmk+/wKO0fwucyqg6RErh3C8yZ2HNQmC8PoKKQFS2n6OzXnvU6w8RQowRQoQKIUJjY2MLFUT3Kt15v0XJHXNez7MefqX89JlTkJkJq8bCvVitX8AA09p15+iu1SG6tBeOrTB1NEpxE5E1KdOCho3eZ6xEkNtHSfmY1x9+UcqfpJSBUspALy8vXYMrKYQQBPkHEXYtjOiE6KKdbO90OLNZWxmsQkNd4jOKRkPAuwFs+UDVIVIKJmKDVvvfFEXmTMxYiSAa8M32sw8Q85jXlULqVbUXAsG680WYUxAVAn9+rK0KVtyWhbxfhyghBnapxWuUfPqnyFwPU0diEsZKBGuBYVmjh1oA8VLKK0AIUF0IUUUIYQcMytpXKSRvF2+alW/GunPrkIVpJ0+Mg99HamurBk03/36B3FRqAfUGQvA0iLtg6miU4sDCiszlpNfw0cXAXqCmECJaCDFKCDFWCDE2a5cNwHngLDAbeAlASpkOjAc2AyeBZVLK43rEZMmCqgURlRBFeGx4wQ6UEta8DAlXYcBcrc29uOryMVjZqDpESv5ErAfnshZTZC4nXZaqlFIOzmO7BF5+xLYNaIlC0UnnSp351OZT1p5bS6OyjfJ/4L6ZWjtp98+hYjEfWVWqArR7Hf78j1Ybyb+TqSNSzFV6ilZkrm4/iykyl5Nl/q1LOCdbJzpX6szmC5tJTk/O30HRYbD1Q6jVC5qPzXv/4qDFy1pJjI1vQ0aaqaNRzFXkbq3InAUOG71PJYISKqhaEAlpCeyI3pH3zkm34fcR4OoNfYppv0Bu7tchuhEBIT+bOhrFXFlgkbmcVCIooZqWa0o5p3KsPZtH3/v9foE7MVn9AqWNE6Cx1OwB/k/AX/+n6hApD7PQInM5qURQQllbWdPbvzfBMcHcSHrMG+CBn+DUH9B5CviUwI6y+3WI0u5p/QWKkp2FFpnLSSWCEqy3f28yZAbrz6/PfYfLB7VRNTW6Q8vxxg3OmLxqaP0eBxdAzCFTR6OYk1MbLLLIXE4qEZRgVd2qUs+zXu4L1mSka+sOO5eFvjNLTr/Ao7R/UyskpuoQKdlFbLTIInM5qURQwvX2703ErQgi4iIe3HBiNcSdg55fgJOHSWIzKgc3eOIjiNoPR5ebOholHzJlJgevHST8erhhFlyy4CJzOekyj0AxXz38evBFyBesPbeWyR6TtRelhOCpUKYa1LCgKfUNn9NWMdv6ofbLb+9i6oiUXNxOvs2ac2tYfno5F+9cBMDVzpUW3i1oWaElrSq0oqJLrrUpC8aCi8zlpBJBCefu4E57n/asP7+eV5u8io2VjTZu+sph6PWdZU2gsbLS6hD90gV2fQ2dPzJ1REoWKSWHYw+z/PRyNl3YRGpmKo3KNuLF+i9iZ23H3pi97InZw9aLWwGoXKoyrSq0olWFVjQt3xRnW+eCXzRivcUWmctJJQILEOQfxJ+X/iQ4Jph2Pu20GjxOntBgkKlDMz7fZlB/kFZdtfFQ8Khq6ogs2r20e6w/v55lEcuIuBWBs60z/ar3Y0CNAdT0qPnPft38uiGl5MKdC+yN2UtwTDCrz65m8anF2AgbGpRtQKsKrWhdoTW1PGphbWX9+Asn3YLIPdB6ooH/hsWDSgQWoG3Ftrjbu7Pu3Dra2ZfTykt3eNdyx013nqINmd38HgxebOpoLFJEXATLIpbxx/k/SExPpJZHLT5s+SE9q/R85Kd7IQRV3apS1a0qz9V+jtSMVMKvhxMcE0xwTDDTDk1j2qFpuNu708K7Ba0qtKJlhZaUdy7/8MnObAOZofoHsqhEYAFsrW3pUaUHK06v4M6tBErZOEDT0aYOy3RKeUO7N2DbFG0t5mqdTR2RRUjJSGFL5BaWRizlcOxh7K3t6e7XnYE1B1LPsx6igCPX7KztaObdjGbezZjUZBI3k26y78o+gmOC2Ruzl02RmwDwd/P/p2+hSbkmONk6WXyRuZxEoUoVm1hgYKAMDQ01dRjFyvEbxxm0fhAf3Yzn6RpPQy8Lr9WfngI/tNAqlI4LBmtbU0dUYl28c5HlEctZfW418Snx+JXyY2DNgQT5B+Fmb5iV76SUnL199p+nhbBrYaRkpGBrZUvjso1oFbGDVj5tqdFvTolbv/xxhBBhUsqHsp9KBBZCSknf39rgdjeWBU9vVB1kABGbYPEzWj2ilrkWx1UKKS0zjR1RO1gWsYx9V/ZhI2zoVKkTz9R8hqblmxb4039RJacnc/D6QYIvBxMcuYUziVcAKONQ5p+nhZYVWuLpWLLnEzwqEaimIQsh0hIJuhXLd672RNnaPbAsnMWq0Q2qdYEdn0O9AeBS1tQRFXtX713l99O/s/LMSmKTYvF29mZCown0q9YPLyfTLTHrYOPwzygjrl/h+tnj7Hvqe4KvhxIcE8wf5/8AoEbpGrSu0JqWFVrSuFxj7K3tTRazMaknAktxYDZXN79F10o+vNjgRV5uqD4BA3DjjNZE1GCwVnlVKbBMmUlwTDBLI5byd/TfSClpU7ENz9R8hjYV2+Q9gseYpIRvA6BCIxi0CNDij4iL+Kdv4eD1g6RlpmFvbU9guUBaVmhJ6wqt8Xf3N/qTjN5U05Aly8yAaU3A2ZMxlapyKeESG57aYFFto4+15X0Ing4vbIeKjU0dTbFxM+kmq8+uZvnp5Vy+exkPBw/6V+9P/xr99ZnwZQgxh+CnDtDnB2j0XK67JKYlEnot9J9hqufjzwPaMOwpLadgW4z7k1TTkCU7tR5uXYAuH9Pb3op3d7/LwWsHCSyvRkwA0O5NOLwUNr4JIzaAjZ2pIzJbUkrCroWx7PQytl7cSnpmOk3LN2VSk0k84fuE+b9J/lNkrvsjd3GydaKdTzttzg1ac9eyiGXMPjqbG0k3+KbDN4WbwGbGVCKwBMHToLQf1OrFExkpONk4se78OpUI7nMoBV3+A6vHwvRA6PAO1B8I5tSkYWIJqQmsPbeW5RHLORd/Dlc7VwbVHMSAmgOo6laMJuVFbADfFuBcJt+HlHcuz8TGE/F19eXjvR8zctNIfuj8Q4nqWNZr8fruQogIIcRZIcTbuWyfLIQIz/o6JoTIEEJ4ZG2LFEIczdqm2nv0dmk/RB/Qlm20ssbJ1okulbuwObIAy1hagoaD4bnfteJ0q8fCzFZwYo3FVyo9fvM4HwV/xBPLn+DzA5/jZOvEf1r9hz8H/Mlbzd4qXkng1kW4dkxbrKgQ+lXvx9ROU4m8E8mQDUOIjI/UNz4TKnIiEEJYAzOAHkAdYLAQok72faSUX0opG0opGwLvADullHHZdumYtV19RNVb8FRwcH+gPbRPtT7cS7vH9kvbTReXOareBcbshAHzQWbCsmFae/LZbRaXEEKvhjLoj0EM+mMQGy9spGeVnizptYTfnvyNftX74WhTDGel61Bkrp1PO37p+guJaYkM2ziMI7FHdArOtPR4ImgGnJVSnpdSpgJLgD6P2X8woOb1G8PNc1r/QNPRYPdvm2aTck3wdvZm7fk8lrG0RFZWENAXxu3V1mlIjINf+8PcnnAx2NTRGUV6Zjrv7X6PuOQ43mn2Dn8O+JMpraYQUCbA1KEVjU5F5up51ePXnr/ibOvMqM2j2Bm1U6cATUePRFARiMr2c3TWaw8RQjgB3YEV2V6WwBYhRJgQYsyjLiKEGCOECBVChMbGxuoQtgXY94M2Y7bZg7fVSljRq2ov9sbs5XridRMFZ+asbaDhszAhFHp+pa3dMLeHlhRK+Cpn2y5uI+ZeDO80e4dnaz+Lq52rqUMquvtF5mrpU1uoUqlKLOy5EH93fyb+NZEVp1fkfZAZ0yMR5Daw9lHP0b2BPTmahVpLKRujNS29LIRol9uBUsqfpJSBUspALy/TTUwpNu7dhEOLoP4z4Fruoc1B/kFkykxWnVllguCKERt7aPYCTAyHzh/D5TCtuWjZMIiNyOvoYkdKydzjc/Er5Ud73/amDkc/Z7ZmFZnTb+0BT0dP5nSbQ8sKLZmydwozw2dSHIfjgz6JIBoemKjqA8Q8Yt9B5GgWklLGZP15HViF1tSkFFXoL5Ce9Mi1iP3c/Ojg24Gfj/78z+IfymPYOUGbSfDKYWj/Fpz9U5uItmoc3Io0dXS6Cb0WyombJxgWMKxkzTOJ2JBVZK6Jrqd1snViWqdpBPkH8cPhH/h478eGWU3NwPT4lw4Bqgshqggh7NDe7B9qfBZCuAHtgTXZXnMWQrje/x7oChzTISbLlpYM+3+E6l2hbK1H7vZBiw+wtbblwz0fkikzjRhgMebgBh3f1RJCi5fg+EqYFgjrX4c7V0wdXZHNPz4fDwcPelftbepQ9JOeopWdrtndIAsx2VrZ8mnrT3mh3gusOLOCV/96laT0JN2vY0hFvitSynRgPLAZOAksk1IeF0KMFUKMzbZrP2CLlPJettfKAbuFEIeBA8B6KeWmosZk8Y4sgcQb0GrCY3cr61SWt5q+xcHrB/nt5G9GCq6EcPaEbv+FiYe0BW7C5sHUhrDlA62DuRg6f/s8O6N3MqjmIBxsHEwdjn4id0Fqgq7NQjkJIZjYeCLvNX+PndE7Gb15NLeSbxnsenpTJSZKmsxMmNFMa8oYsxPyqI0ipWT89vEcuHKAFUErqFSqkpECLWHiLmjF644sBTsXaDVee2JwKGXqyPJtSvAU/jj/B1ue3oKHg4epw9HPH6/B4cXw5nmjLMb058U/eWvXW5R3Ls+szrPwcfUx+DXz61ElJkpQI6ACaKuP3TwDrSbmmQRA+yTzYYsPsbWy5YM9H6gmosLyqAJP/Qgv7QX/DrDj/+D7BrBnKqSZfzPBjaQbrD23lj7+fUpWEpBSmz/g38loK/I9UfkJZnedza3kWwzZMIQTN08Y5bpFoRJBSRM8Hdx8oc7jpnI8qJxzOd5qpjURLT6lpngUSdna8Myv8MJfWoXLrR/A1EYQ8jOkp5o6ukdafGox6ZnpDK0z1NSh6OtKOCTEGH1JykZlG7Gwx0LsrO0YuWkkwTHmPQdFJYKS5HIYXNwNLcYVeMWtIP8g2vm047uw77h055KBArQgFRvD0JVaEbvSflpn8vRACF+sVYM1I0npSSyNWEpH3474ufmZOhx95aPInKFUda/Kwh4L8XH14eVtL7Pu3Dqjx5BfFpUIVh6M5rVl4cQnpZk6FMMIng72btB4WIEPVU1EBuLXGkZuNOs6RmvOriE+JZ4RdUeYOhT9FaLInJ7KOZdjXvd5NC7XmHd3v8ucY3PMcq6BRSWC6wkprAmPocd3f7Pn7A1Th6OvWxfhxGpoMhzsCzcTtJxzOd5s9qZqItKbEGZbxygjM4MFJxZQ36s+Db0amiwOg7gVqRWZ02k2cWG52rkys/NMevj14Nuwb/n8wOdkmNlToUUlgrHt/VkxrhUOdtY89/N+pqw9TlKqef2DFNq+mdojcPOxee/7GH38+9C2Ylu+P/g9UXei8j5Ayb+cdYySTF/H6K+ov4hKiGJEwIhiv/rWQyKyRqIbuX8gN3bWdnze7nOG1RnGb6d+Y/Lfk0nJSDF1WP+wqEQA0NDXnfUT2jKilR/zgiN5ctouwqNumzqsokm6BQcXQN2nwa1oK0MJIfio5UfYCBs+CFZNRAZxv47R+DCT1zGad3wePi4+dPLtZNTrGoVOReb0YiWsmNx0Mm8EvsHWi1t5ceuLxKfEmzoswAITAYCjnTVTggJYNLo5yakZ9J8ZzDdbIkjLKKZvemHzIO2eNnZdB+WcyzG56WTCroWpJiJDsrH7t45Rl//8W8do1TijNBeFXw/ncOxhhgUMM691hfWgc5E5PQ0PGM4X7b7gcOxhRmwawdV7V00dkmUmgvtaV/Nk06vt6NOwAlO3n6XfD3s4cy3B1GEVTHoq7JsFVTtC+Xq6nbZvtb60qdhGNREZg50TtH5FK1vRfCwc/k2rZWRg847Pw83ejT7++R9qXGwYoMicnnpU6cGszrO4eu8qz214jjO3zpg0HotOBAClHGz5ZmBDZg1pQsztZJ6ctpufd50nM9P8evZzdex3uHs1z3ISBZW9iejDYFWLyCgc3KDLJ+BaQVtQyIAu3rnI9kvbeabmMzjZOhn0WiZxar1Biszpqbl3c+Z1n4eUkuEbhxNyNcRksVh8Irive93ybJ7UjnbVvfh0/UkGz95HVFyiqcN6PCm19YjLBmgzJ3VW3rk8k5tOJvRaKEtOLdH9/EoubOyg+YtwYSdcMdzqVwtPLMTGyobBtQYb7Bomk56iPVEZqMicnmp61OTXnr/i5eTFi1tfZHPkZpPEYd53yci8XO2ZPawJXz5dn+Mxd+jx/S6WhUSZ5bhfAM79CddPaH0DBhrx0bdaX1pXbM13B78jKkE1ERlFkxFavaK90w1y+rjkOFafXU1v/94lagH2fxihyJyeKrhUYEGPBdT1rMvknZNZdHKR0WNQiSAHIQQDAn3ZNKktdSuW4s0VR3hhQSixCeYz1OsfwdPA1VsbLWQgQgimtJyCtbBW5aqNxdEdGg+HYysg/rLup18asZSUjBSG1Sn4xMNi4dQGsHWCqsVnYR03ezd+6vITHX078vmBz/km7Buj/q6pRPAIPqWd+G10Cz7oVYe/z9yg23d/s/GoGdWbv3oUzu/QmhFs7Ax6qfLO5Xmz6ZuEXgtlacRSg15LydJirNb0t3+WrqdNTk9myakltPNph7+7eQyr1JUJiszpxcHGgW86fMMzNZ9h7rG5vLv7XdIyjFMFQSWCx7CyEoxqU4X1E9pQ0d2RcYsO8tpSMylRETxdaz5oMtIol7vfRPRt2LeqicgY3Ctpk8/C5kHyHd1Ou+78OuKS4xgRMEK3c5qVmENakblaxaNZKCdrK2vea/4eExtNZP359bz050vcTb1r8OuqRJAP1cu5svKlVrzyRHXWHI6h+3d/s/uMCUtUxF/WRgs1HqY1IxhB9iaij4I/Uk1ExtByPKTc0SYL6iBTZrLg+ALqlKlDYLmHStKXDBEbtRn21buZOpJCE0LwQv0X+KT1J4RcDWHk5pHcSDLs+41KBPlka23Fq11qsHJcK5zsrBnyiwlLVOyfpT0CF7GcREHdH0UUcjWEZRHLjHpti1SxMVRuo/1769BE8Hf030TeiSyZ5STuM3GROT31rdaX6U9M5+KdiwzZMIQL8RcMdi2VCAqoga876ye25fnWVbQSFVN3ceiSEZekS76jNRfU6QOlKxvvuln6VetH6wqt+SbsG6IToo1+fYvTagLER2nVSoto3vF5eDt706Vyl8fud+xyPAN/3Mugn/aSml6MnvzMpMicntpUbMPcbnNJSk9i2MZhHI49bJDrqERQCA621nzYuw6/jW5OSnom/WcG8/WWCOP80hxcoDUX6DyBLL+EEExpNQUrYaUmmhlD9a5Qpro2wawIw5iPxh4l7FoYQ+sMxcbKJtd9biem8v7qowRN303E1QT2nY/j660Rhb6m0UVs1P40gyJzegrwDODXHr/iaufK6M2j2Xdln+7X0CURCCG6CyEihBBnhRBv57K9gxAiXggRnvX1YX6PNWetqnmycVJbnmrsw7SsEhWnDVmiIiNNayao3EZrNjCR8s7lmRyomoiMwspKmydy5TBE7i70aeafmI+rrStPVX/qoW0ZmZLFBy7R8asd/Lb/EsNa+vH3mx15tnklftx53rT9YQURscGsiszpybeULwt7LKSdTzuquVfT/fxFTgRCCGtgBtADqAMMFkLUyWXXXVLKhllf/yngsWarlIMtXw1owI9Dm3A1Pple03Yz++/zZBiiRMWJNVozgYmeBrJ7qvpTtKrQSjURGUP9QeDspc0bKYTohGi2XtzKgJoDcLZ1fmBbeNRt+v2wh3dWHqV6WVfWT2zLlKAA3Bxt+eDJOvh7OfPasnDi7pnvMpuAWReZ00sZxzJ83eFrg0wC1OOJoBlwVkp5XkqZCiwB8lvFqijHmpVuAeXZ/Go72tfw4r8bDFCiQkqtecCzhtZcYGL3RxFZCSs1isjQbB2g6QtwZjPEFryp5teTv2IlrHi21rP/vHbzbgpv/X6EvjP2cDU+me8HNWTpiy2o7V3qn30c7ayZOrgRtxPTePP3w+Y7wx7MvsicudMjEVQEsg8sj856LaeWQojDQoiNQoiAAh6LEGKMECJUCBEaGxtbuEgjNsL6NyAjvXDH58HTxZ6fhjbhqwENOBlzh+7f/c3SkEv6/AJF7tKaB1qON5v6Kd4u3kwOnMyBqwdYHrHc1OGUbE1Hg41DgctOxKfEs/LMSnpW6Uk553KkZ2SyYG8kHb/awYqD0bzYrirb3+hAn4YVcx1JFFDBjbd61GLbyev8uu+iXn8b/Z1aDy7lzLrInDnT4x0lt3FoOd/5DgKVpZQNgGnA6gIcq70o5U9SykApZaCXl1fhIo05BCGzYcmzkGKYSRpCCJ5u4sPGSW2p7+POWyuOMnp+KNcTkot24uBpWvNA/Wf0CVQn95uIvg77mst39S+HoGRxLqMtZnN4Cdy9nu/Dlp9eTlJ6EsMDhhMSGUfv6Xv4cM1x6vm4sWlSW97pWRsX+9w7j+97vrUfHWpqxRgjrpphmfb0FG3JzxrmX2TOXOlx16IB32w/+wAx2XeQUt6RUt7N+n4DYCuE8MzPsbrq+C48+TWc3QrzekKC4RaE8CntxKLRzfmwVx12n71Bt2+LUKLi+ik4swWajdGaCczIA01Ee1QTkUG1eFkbMHBgdr52T81IZdHJRQSWbcHMLYkMmLWX+MRUZj7XmF9HNada2fytbS2E4MunG+DqYMPExYdITjOz5V0jd0Hq3RI3WsiY9EgEIUB1IUQVIYQdMAhYm30HIUR5kfXcKYRolnXdm/k5VndNR8PgpXDjLPzcGa6fNNilrKwEz7epwvqJbfD1cGLcooO8WpgSFXung40jBI4yTKBF5O3izRuBb7D/6n5+P/27qcMpuTyraaUTQmZDat79T2vP/cGNpBuEHK7P+iNXGN+xGtteb0+Pet4FnlDm5WrPVwMaEHEtgc83nirs38AwimGROXNT5EQgpUwHxgObgZPAMinlcSHEWCHE/amvTwPHhBCHganAIKnJ9diixpSnGl1h5Abt09UvXbXibQZUrawrK8a1YlLn6qw9HEO3b/9m3/mb+Ts44RocWQqNnjPr2ZL9q/enpXdLvg5VTUQG1XK8NkIm/PGlivecieXTXTPJSC5PYLlmbHm1HW90q4mT3eObgR6nQ82y/0yk/PPktUKfR1fFuMicORFmPRLgEQIDA2VoaGjRT3Q7ChYNgJtnIGia1gZrYEeibzNpaTjX4pNZM74N1cq6PP6APz+BXV/DhDCzHx995e4V+q3tR13PuszuMrvkljEwJSm1J9mkOBgfCjnWGo65ncR/N5xk07kdOFWay7NV3uKddkN0u3xKegZ9ZwRz7U4ym15pS9lSJm6qvHwQZneEvjON8vtb3AkhwqSUDxWasuyeFXdfGLUZKreG1ePgr/8z+KLh9X3cWTS6OQ621oz9NYy7KY8ZwZR6D0J+htq9zD4JgNZE9Hrg6+y/sp/lp9UoIoMQQptHEndem0CVJSU9gxl/neWJr3ey7cQ1qlUPpaxjWd5ore/gAnsba6YNbkhiajqvLz9s+iVdIzYU+yJz5sCyEwFo68Q+9zs0fA52fq4lhHTDTp7xdnNk2rONOB979/Hjsw8tguTb0GqiQePR09PVn6aFdwvVRGRItXuDe+V/JpjtiLhO9+928eXmCNrV8OTHUeWJSTnKkDpDsLW21f3y1cq68mGvAHaducEvuw1XCC1fIjaWmCJzpqQSAWgLu/SZAR3fg8OLYVF/SLpt0Eu28vfkre612HD0Kj/vyuWXKTMD9s0An2bg28ygsehJCMHHrT5GCMFHwR+Z9ySk4srKGlq+DFH7+b+f5jNibggCmP98M34cGsim6KU42zrzdA3DrVw3uJkv3QLK8cXmUxy7HG+w6zxWCSwyZyoqEdwnBLR/E/r9CBf3wpxucPuSQS85pl1VetQtz+ebTrH3XI7O41N/aP/RzaCcREFVcKnwTxPR72fUKCK9JadlMP1Wc+KlM40vL+LtHrXYNEmb1X713lU2XdhE/+r9cbXL3/DQwhBC8PlT9SnjbM/ExYe497gmTkMpoUXmTEElgpwaDIIhK+DOFa1TLuaQwS4lhODLAQ3wK+PE+N8OciU+SdsgJeyZCqWrFNuVlu43EX0V8hUxdw03NcSSSCnZcvwqnb/ZyVc7LrO/TF+6igOMrSews9F+lX898SsAQ2rr10H8KKWd7fjmmQZcuHmP/6w7YfDrPeTUevCqVSz6z8ydSgS5qdoeRm0Ba3uY2xMiNhnsUi72Nvw4tAnJaRm8tOggKekZELUfLodqj/85RoUUF/ebiADVRKSDCzfuMXJeCGMWhuFkZ83iF1rQdeSHCCsb2DcTgITUBH4/8zvd/Lrh7eJtlLha+Xsyrr0/S0OjWH/EiGt6J8bBxWCo2cN41yzBVCJ4lLK1YPQ2rcjbksH5ns1ZGNXKuvLlgAYcunSbT/84qXUCOnpoHdjF2P0mon1X9qkmokJKTE3ni02n6Pbt34RF3uKDXnVYP7EtLf3LgGt5qD8QDv0KiXGsOL2Ce2n3GB4w3KgxvtqlBg183Xln5REu304yzkXPblNF5nRU+NkllsC1nDbx7PdRsOENuH0ROv/HIPVMetbz5sV2Vdmyaw/Sfj2i3WSwc9L9OsY2oMYAtlzcwlchX9G6QmsquFQwdUi5Co+6zWfrtVnmrg42uDjY4Opgg6uDLS72NpTK+t7VwQYX+3+/v/+zjbW+/yeklGw4epVP15/gSnwy/Rv78FaPmpR1zTFuv+V4CF9EWshsFl7fQvPyzalTxriV3G2trZg6qCE9v9/Fq0vCWTymBdZWBp5DoorM6UolgrzYOcOgRbDxLe2T+u1LWoeyAWYxTu5Wk8Bjn5B6z4YLlZ6hlu5XML77TURPrXmKKcFT+LHLj2Y30ezizXuMmheCtZWgiqczV+8kk3A9nYTkNBKS00nPx1h5JzvrrATxYJJwtbd9IKm4Ztvn39e1/RxsrRBCcOZaAh+tPU7wuZvU8S7FtMGNCPTzyP3C5epAtc5sOjyH6252TGk5Rd+bk0+VyzjzSd+6vLbsMDP+OsvEJ6ob7mL3i8zV7a+KzOlEJYL8sLKGnl9CaT/Y8r7WkTx4MTjru0CETXIcnVP/ZK11e75aeYl14yvh7mSn6zVMoaJLRV4PfJ1P9n3CijMrDDqssaBuJ6Yycm4IGVKyfExLqno9ONNbSklKeiZ3ktO4m5xOQtbX3ZQ07tz/PvnfpJGQkvbPPjG3k7ibon2fmJp3oTYbK4Grgw13ktNxsbfhk751ebZZpTw/XcsWLzN/+zj87cvQpmKbIt2PoujXqCI7T8fy/Z9naF2tDE0qPyJ5FdWFrCJzxXQghTlSiSC/hNCWDHT3hZVj4Jcu2kQ0PUcshPyCSE+m+lNvc3VpLJOWhjNneFOsDP2YbQQDagxgS+QWvgrVmoiM1Zn5OMlpGYxZEEb0rSR+Hd38oSQA2hONg601DrbW5LNYZ67SMzK5l5LBnayEoSWI+8nj3+/vJqfj4mDDC22r4uGcvw8B+xwdibC34z/xCbnWdTcWIQSf9K1L2MVbvLIknA2vtKWUg/4T2ojIKjJXpZ3+57ZQll1rqLCiDsDiQdowz8GLoVKLop8zLQm+rQs+gfDsUn7dd5H3Vx/jlSeq82qXGkU/vxm4fPcyT615igZeDUzeRJSZKXllaTjrDscwdXAjghqYZ99FfozdOpZT18PZcuYkds/9DtW7mDSesIu3GPjjXp6s5833gxrq++8sJXxTR1uze9DjC+8pD1O1hvTk2wxGbQXH0jA/CI6tLPo5Dy+BxBv/TCB7rnkl+jf24fs/z7D9lJlUeiyi+01Ee6/sZeUZHe5ZEXy1JYJ1h2N4s3vNYp0EIuIi2BOzh+cCRmDnWkFbztTEmlQuzaQntEq7qw7pXGYk5hAkxKhmIZ2pRFBYZfy14aUVGsHvI2H3d4UvWJeZqa05UKGRVgAP7TH7v/3qUse7FJOWhHPx5j39Yjehp2s8TfPyzfky9Euu3DXiuPNsFh+4xA87zjG4WSXGtS/ek5EWnFiAo40jA2sPhhZj4cLf2pKmJvZSx2o08/Pgg9XHiLyh4/9dVWTOIFQiKAonDxi2BgL6wbaPYP1rhVsP+fQmuHlWexrI9hjtYGvNj0ObIIRg7K8HScpHh6O5sxJWTGk1hUyZyZS9U4w+0WxHxHXeX32M9jW8+KRPgNmNYCqI64nX2XBhA/2q9cPN3g0aDwc7Fwgu2LrGhmBtJfh2UEOsrQSvLDlEWoZOK9ed2gCVWqoiczpTiaCobB2g/xxoPQlC52iTzwq6HvLe6eBWCWr3eWiTr4cT3w1qyKmrd3hv1dESMUPXx9WH15u8TnBMMKvOrjLadY/HxPPyooPULOfKjOca6z7239h+O/kbmTKTIXWyykk4umvJ4PhKiI82aWwAFd0d+bx/fQ5Hx/Pt1tNFP+GtSLh+XM0mNoDi/ZtgLqysoMvH0OtbbXzz3B7aENP8iA6Di3ugxTiwzn0QV8eaZZn0RA1WHrrMwn0XdQzcdAbUHECz8s34MuRLrt4z3NrR912JT+L5eSGUcrRlzoimeS7Ybu7upd1j2elldK7UGV/XbMt+txirNVHun2W64LLpWc+bQU19mbnzHMHnbhTtZKrInMGoRKCnwOe19ZBvntMK1l3LRyGuvdPA3g0aD33sbhM6VaNTrbL8Z90Jwi7G6RSw6VgJKz5u9TEZMoMpwYZtIkpITmPk3BDupWQwZ0RTyruZeFUtHaw6s4qE1ISHy0m4V4KAvhA2H5LvmCS2nD7sXYcqZZx5belhbt0rwlofqsicwahEoLcaXeH5jZCZrpWyftx6yLci4cQaCBwJ9o8fpG5lJfh2YEMquDvy0qKDXE9I1jVsU/Bx9eG1Jq+xJ2YPPxz+wSDJIC0jk5cWHeTs9bvMHNKY2t6ldL+GsaVnprPwxEIal21Mfa/6D+/Qcjyk3IGDC4wfXC6c7GyYOrgRN++l8NaKI4X7d/6nyJx6GjAEXRKBEKK7ECJCCHFWCPF2LtufE0IcyfoKFkI0yLYtUghxVAgRLoQw4eQAHXk3gBf+BDcf+LW/ttJYbvbNBGENzV/M12ndnGz5cWgT4pPSGP+bjh1wJjSw5kD6VuvLrMOz+DbsW12TgZSS91cdY9eZG3zWrx5tq3vpdm5T2nZxGzH3YhgRMCL3HSo2hspttP9fGWlGje1R6lZ0481utdhy4hq/HSjEOh9ntmYVmVOJwBCKnAiEENbADKAHUAcYLITIWfXqAtBeSlkf+AT4Kcf2jlLKhrlNdCi23Hzg+U3g1wbWvAR/ffbg8NKkW3BwIdQbAKXyP469tncp/u+pehy4EMf/Np4yQODGdb+JaFDNQcw9PpfP9n9GptQnwf2w4xxLQ6OY0KkaA5v65n1AMSClZO7xufiV8qO9b/tH79hqAtyJhuOrjRZbXka1qULb6p588scJzlxLKNjBERtUkTkD0uOJoBlwVkp5XkqZCiwBHhj+IqUMllLeyvpxH+Cjw3XN3z/rIQ+Bnf+DVWP/XQ85dC6k3dPWHCigfo18GN6yMj/vvsAfR4r/oi9Wwop3m7/LyLojWRKxhA/3fEhGZtGGyq4Jv8yXmyPo16gir5WQmdkAoddCOXHzBMMChmElHvPrW72rVkJ977TCz2/RmZWV4OuBDXC2s2HiknCS0/L5b3y/yFyN7qrInIHocVcrAlHZfo7Oeu1RRgEbs/0sgS1CiDAhxJhHHSSEGCOECBVChMbGxhYpYKOytoU+06Hj+3BkCfz6FNyNhf0/gn8nKF+3UKd978k6NKlcmjd/P8Lpgn66MkNCCF5t/CovN3yZNefW8Naut0jLLFyzxr7zN5m8/Agtqnrwef96xXquQE7zj8/Hw8GD3lV7P35HKyvtQ8aVwxC5yzjB5UNZVwe+HFCfk1fu8MWmiPwdpIrMGZweiSC337JcP4IIITqiJYK3sr3cWkrZGK1p6WUhRK6VpKSUP0kpA6WUgV5exaytVwhoPxn6/QSX9sH0QLh7tUjrEdvZWPHDc41xsrNh7MIwEpLNoy24KIQQjG0wljcC32Bz5GZe++s1UjJSCnSOs9cTGLMglEplnPhxSCD2NsVzhbfcnL99np3ROxlUcxAONvkY+VR/EDh7aeXTzUinWuUY0cqPOXsu8FfE9bwPiFifVWTuMU1hSpHokQiigewNsD7AQ+0VQoj6wM9AHynlPyu1Syljsv68DqxCa2oqmRo8A0NXARLK14eqHYt0unKlHJjxbCMuxiXyxvLDJWKyGcDwgOF80OIDdkTvYMKfE0hMS8zXcbEJKYyYG4KdjRVzRzTFzckAlS9NaMGJBdhb2/NMrWfyd4CtAzQbA2e2wHXz6k96u0ctapZzZfLyw8QmPCbZZ2Zq8wf8O2l/H8Ug9EgEIUB1IUQVIYQdMAhYm30HIUQlYCUwVEp5OtvrzkII1/vfA12BYzrEZL6qtIXxYTB09QPlJAqredUyvNOjFpuPX2PWzvNFj89MDKw5kP+2+S/7r+5n3LZx3E19/GztpNQMRs8P4ebdVH4Z3hRfj+K/ult2N5JusPbcWvr498HDoQB1/gNHgY2jNnvdjDjYWjN1cCMSktN5Y/lhMh+1+M+VcEi4opqFDKzIiUBKmQ6MBzYDJ4FlUsrjQoixQoixWbt9CJQBfsgxTLQcsFsIcRg4AKyXUhpupXhz4eKla62UUW2q0Ku+N19uPsWes0WcvWlGgvyD+KLdFxyJPcLoLaOJT4nPdb+MTMnEJYc4cjmeqYMb0cDX3biBGsHiU4tJz0xnaJ3HTzx8iHMZaPgsHFkKCeZVxbZmeVfef7I2O0/HMjc4MvedVJE5o9ClC15KuUFKWUNK6S+l/G/Wa7OklLOyvh8tpSydNUT0n2GiWSONGmR9Bdw/VikYIQT/61+famVdmLD4kPEWEDeCbn7d+K7jd5y5dYaRm0dyI+nhRPfp+hNsPXGNj3rVoUudciaI0rAS0xJZGrGUjr4d8XPzK/gJWr6szScIma17bEU1pEVlOtcux/82nuJ4TI5EHxuhzcFRReYMTo3FKiGc7W2YNaQJqemZvPRrWP6H5hUD7X3bM6PzDKITohm5aeQDtYnm7L7A3D2RjGpThRGtq5gwSsNZc24N8SnxjKg7onAnKOOvNa2E/Ayp5lXOXAjBF0/Xx93JlomLD5GYmlW999R6mP0EZKZBl09MG6QFUImgBKnq5cLXAxtwODqej9flo85RMdLCuwU/dvmRG0k3GLFpBFEJUWw6dpVP1p+ge0B53utZ29QhGkRGZgYLTyykvld9Gno1LPyJWk3QJjGG/6ZbbHrxcLbj22cacv7GPT5ddxz++j9Y8ix4VoMxO8BHTSIzNJUISphuAeV5qYM/iw9cYllIVN4HFCONyjbi564/czftLs+tH86klZtp4OPOt880LBHrOufmr6i/iEqIYkTAiKLNh/BtDhUDYe8MKOJkPUNoXc2T8a3K0TH8Vdj5OTR4FkZu1GboKwZXvGvxZpOWlkZ0dDTJyeZbjM3BwQEfHx9sbQ07rPH1rjU5Eh3P+2uOUdu7FPV83Ax6PWMK8Azgs+Y/8PJfY7Hz+ZF3uv2Eo13JmSuQ07zj8/Bx8aGTb6einUgI7alg+XCt2aVOkD4B6uXGWV6LHEem9Vn+x0iGdfwMb1tHU0dlMUrM4vUXLlzA1dWVMmXKmOVMUiklN2/eJCEhgSpVDN+WHXcvld7TdgPwx4Q2lHa2M/g1jeF2YipPzQzmZsplSvvPIS0zmR+7/Ehdz8LN0DZn4dfDGbpxKO82f5fBtQYX/YSZGTC1EbiWh1Fbin4+vZzeDCtGg7UtV7rO4omVmdT3cWPR6BZYl9AnPVMp8YvXJycnm20SAK1TrEyZMkZ7YvFwtuOH5xoTm5DCxCWHyHjUOO1iJCU9gzELw4iOS2L24B4senIBpexKMXrLaMKuhZk6PN3NOz4PN3s3+vg/vHJdoVhZayOIovbDpf36nLMopIS/v4TfnoHSfjBmB94Nu/JxUAD7zscxa+c5U0doMUpMIgDMNgncZ+z4Gvi6858+Aew6c0OfpQJNKDNTMnn5EQ5ciOOrgQ1oVsWDii4Vmdd9HmWdyjJ261iCY4JNHaZuLt65yPZL23mm5jM42eo4Oa7hc+DgrhWjM6WUu7BsGGz/FOr2h+c3a4vqAE838aFXfW++2XqaQ5du5XEiRQ8lKhEoDxvUrBLPBPoy/a+zbD1hXhOKCuLrrRGsPRzDm91rEtTg37Ld5ZzLMbfbXCqXqsz4P8ezI2qHyWLU08ITC7GxstGnSSg7exdtJb2Tf0CciWaix52HX7rAqT+g66fQ/2ew+zfZCSH4b796lC/lwCtLwktEHS1zpxKBBfi4TwD1Krrx2tJwLtwwr3Hk+bH4wCVm/HWOwc0qMa79w8sUlnEswy/dfqGWRy1e/etVNl0o3pPT45LjWH12Nb39e+Pp6Kn/BZq/CFY2sPcH/c+dl7Pb4KcOcCcGhqzQOrBzeVJ2c7Tl+0ENib6VyOTlR0pE06Y5U4nAAjjYWjNzSGNsrAVjF4b9O2mnGNh5Opb3Vx+jfQ0vPukT8MjmNTd7N37q8hMNyjbgrV1vserMKiNHqp+lEUtJyUhhWJ1hhrmAa3mo/wyEL9KWgDQGKWHP97BoAJTy0eYH+D9+JFSgnwfv9qzNpuNX+WjtsRJTVNEclZjho9l9vO44J2L0Xbi7ToVSfNQ7IM/9+vbtS1RUFMnJybzyyiuMGfPIJRaMyqe0E1MHN2L4nAO8veIo3w9qaPZ9Kidi7vDSr2HULOfKjOcaY2P9+M8tLnYuzOw8k0l/TeLD4A9JzkjWv2nFwJLTk1lyagntfNrh727ARdpbvgzhv0LoL9BusuGuA9ps5rUT4NgKqNMX+v4Ads75OnR026rE3k3hx53n8XSxZ1LnkrPIkDlRTwQ6mzNnDmFhYYSGhjJ16lRu3ryZ90FG0ra6F693rcnawzHMe1SRLzNxJT6J5+eFUMrRljkjmuJin7/PLI42jkzrNI2Ovh35bP9nzD0218CR6iMxLZFNkZuYtGMScclxj16PWC/l6kC1zrD/J0gz4Ei2Wxfhl25wbCU88REMmJfvJHDf291r0b+xD99tO8Ov+y4aJk4LVyKfCPLzyd1Qpk6dyqpVWrNEVFQUZ86coUwZ8ymYNa69P+FRt/nv+pPUrehGU78ClDQ2koTkNEbODeFuSjrLx7akvFvB6tDbWdvxdYeveW/Xe3wT9g2J6Ym81OAls3sCupd2j51RO9lycQu7L+8mJSOFMg5lGFN/DIHljLB8d6sJsKAPHF0OjQtY1TQ/zu+A5SO1+QvPLYfqXQp1GiEEn/evx63EVD5YcwwPZzt61vPWN1YLVyITgans2LGDbdu2sXfvXpycnOjQoYPZzXS+v25sn+l7eGnRQWYNaYK/lzNujrZm8UaZlpHJS4sOcvb6XeaObEpt71KFOo+tlS3/1/b/cLBxYNbhWSSlJfF64Osm/zsmpCawM3onWyK3sOfyHlIzU/Fy9OKp6k/RtXJXGpVthLWVkWZKV2kP5eppK5g1fE6/9YClhH0zYcv74FkdBv2mFb4rAltrK2Y825ghv+xn0pJw3B1taVXNAB3pFkolAh3Fx8dTunRpnJycOHXqFPv27TN1SLkq5WDLrCFN6PfDHvrP1Mbeu9rb4OPhhG9pR3yz/+nhhE9pR5zsDP9fRUrJB6uPsevMDb7oX5+21Yu2JKm1lTVTWk3B0caR+Sfmk5yRzLvN3338ou8GcCf1DjuidrA1cit7YvaQlplGWaeyDKw5kC6Vu9CwbEOjxwT8W3Zi1ZisxeG7Fv2caUmw7hVt/YNavaDfLLB3Lfp5AUc7a34ZHsjAH/cyZmEYS8a0oG7FklM+xZRUItBR9+7dmTVrFvXr16dmzZq0aNHC1CE9Us3yrvz5enuORMcTFZdI9K0kouISibx5j11nbpCUo4y1p4sdPqWdHkwSpZ3w9XCkgrsjtnl05ObHDzvOsSQkigmdqjGwqW/eB+SDlbDi7WZv42DjwJxjc0hKT+LjVh9jY2XY//rxKfH8FfUXWyK3sPfKXtIz0ynvXJ5BtQbRtXJX6nvVN82bf051n4JtU7QJZkVNBLejYOlzcOUwdHwP2r6h31NGFncnO+Y/34z+PwQzYu4Bfh/bCj/PgvU5KA9TiUBH9vb2bNy40dRh5Ju3myPebg8X9pJScuNuKlG3Eh9IElG3EjkcdZuNR6+Qnm1ct5XQzuVT2pFKWU8Rvh6OWYnCCS8X+zyrg64Jv8yXmyPo16gir3XRd2SIEIJJjSfhZOPE9PDpJKcn83nbz7G11rf43+3k22yP2s6Wi1vYH7OfdJlOBecKPFfrObr6daWuZ13zePPPztoWWoyFrR9CTDhUaFi480Tu0WYKp6fA4CVQs4eeUT7A282RBaOaM2BWMMPmHOD3cS0p66rWMy4KlQiUhwgh8HK1x8vVnsaVSj+0PT0jk6t3komKSyLqViLRcYlEZSWLv8/Ecu3Og4uR29lY4VPa8Z8nCN9/niy0nyOuJjB5+RFaVPXg8/71DNKOL4TgxQYv4mjjyJehX5Kckcw3Hb7B3tq+SOeNS45j+6XtbIncwoGrB8iQGVR0qcjQgKF0rdyVgDKPnvtgNpqMgJ1fausa9/+5YMdKCQdmw+Z3tHpBgxaDl+GHeFYr68KcEU15dvZ+hs8JYemLLSjlYNiqviWZSgRKgdlYW+FT2gmf0k605OERUclpGVy+ncSluAeTRNStRMKjbhOf9HDJAH8vZ34cEoi9jWE7SocFDMPBxoFP933Ky3++zNSOUwtcy+dm0k3+vPQnWy5uIfRqKBkyA19XX0YEjKCrX1dqe9Q2/zf/7BzcoPEw2D8LOk/J/xoAacmw4XU49CvU6A5P/aSdy0gaVSrNrKFNGDUvhBfmhzL/+WY42JbckuSGpEsiEEJ0B74HrIGfpZSf59gusrb3BBKBEVLKg/k5Vil+HGyt8fdywd/LJdftd5LTtMQQl0T0rURuJabyXPPKuDkZ5xPdwJoDcbRx5P097zN221hmPDEDV7vHd2jeSLrBtovb2HpxK6HXQsmUmVQuVZnn6z5PV7+u1Cxds3i9+efUYqyWCPbNhG75WDr8TgwsHQKXw6Ddm9DhHd37A/KjfQ0vvhrQgElLw5m0JJwZzzUu0aWrD166RSNfd93/rxU5EQghrIEZQBcgGggRQqyVUmZfK7EHUD3rqzkwE2iez2OVEqaUgy0BFdwIqGC6ER+9/Xtjb23PW3+/xegto/mx84+4O7g/sM/1xOtsu7iNLRe3cPDaQSSSKm5VeKHeC3Sp3IUapWsU7zf/7NwrQUA/CJsP7d98/Cf7S/tg6VBIS4SBC02+yE3fRhW5eS+VT/44wfurj/FZv7ol598lS0p6Bp+tP8n8vReZ8Wxjnqyv7zwKPZ4ImgFnpZTnAYQQS4A+QPY38z7AAqkVC9knhHAXQngDfvk4VlEMoqtfVxxsHHj1r1cZuXkks7vOJj0z/Z9P/oeuH0IiqeZejbENxtK1cleqla5m6rANp9V4OPY7HFygDSvNTehc2DAZ3H1h+Fooax5rRY9qU4Ubd1OYueMcXi52vNa1pqlD0s3Fm/d4+beDHLt8h1FtqtClTjndr6FHIqgIZF8cNxrtU39e+1TM57EACCHGAGMAKlWqVLSIFSVLO592/ND5ByZsn0DQqiAS0hIAqF66Oi81fImulbtS1b2qiaM0kgqNwK+t1jzUfKw2oui+9FTY+CaEzdVKU/T/GRwfHkhgSm92q8nNuylM3X6WMi72DG/lZ+qQimz9kSu8veIIQsBPQ5vQNaC8Qa6jRyLI7RksZ5nAR+2Tn2O1F6X8CfgJtKUqCxKgsURGRtKrVy+OHTtm6lCUAmju3ZyfuvzE3GNzCfAMoEvlLlRxM/xyomap1QT4bSAcXw31B2ivJVzVhoZG7Yc2r0KnD7TVzsyMEILP+tUj7l4aU9Ydp4yLHb3qV8j7QDOUnJbBZxtOsmDvRRr6ujNtcCN8PXRcoCgHPRJBNJB99o8PEJPPfezycayiGFzDsg35vtP3pg7D9Kp1Ac8aEDwV6j2tdQYvHQLJ8fD0XG0CmhmzsbZi+rONGPrLfl5dGo67ox1tqhevUhSRN7SmoOMxd3ihbRUmd6uFnY1hO+L1SAQhQHUhRBXgMjAIeDbHPmuB8Vl9AM2BeCnlFSFEbD6OLbiNb8PVo0U+zQPK14MeeQ9oSk9PZ/jw4Rw6dIgaNWqwYMECnJwMl8kVRVdWVtByPKybqPUFHJwPrt4waiuUr2vq6PLFwdaan4c1ZeCPe3lxYSiLx7Sgvo+7qcPKlz+OxPD2iqNYWwlmDws0SH9AboqcZqSU6cB4YDNwElgmpTwuhBgrhBibtdsG4DxwFpgNvPS4Y4sakylFREQwZswYjhw5QqlSpfjhBxOsAqUoRVH/GXD2gpDZULmVtohMMUkC97k52bJgVDPcnewYOTfE7FfmS07L4P3VRxn/2yGql3Nh/cQ2RksCAKI4rvoTGBgoQ0NDH3jt5MmT1K5t2hEMkZGRtGvXjkuXLgGwfft2pk6dyurVq//ZxxziVJQ8ndoANyKg5QSwLr7zTs/H3uXpWXtxsrNmxbhWlCtlfqUoLty4x8uLDnLiyh3GtKvK5G41dandlRshRJiU8qEa52ZW+KT4yzl+uaSNZ1YsRK2eWsdwMU4CAFW9XJg7oilx91IZPudArrPaTWnd4Rh6T9tNTHwSvwwP5N2etQ2WBB5HJQKdXbp0ib179wKwePFi2rRpY+KIFMWyNfB158ehTTgXe5cX5oeSnKOyrikkp2Xw3qqjTFh8iBrlXFg/sS1P1DZeU1BOKhHorHbt2syfP5/69esTFxfHuHHjTB2Soli8ttW9+HpgQ0IuxjFh8SHSMzJNFsv52Lv0+yGYRfsv8WK7qix9sSUV3R+uAmxMxfu5z8z4+flx4oSaFK0o5iioQQXi7qYwZd0J3lt1zGCVbh9nTfhl3l15FFsbK+aMCKRTLdM9BWSnEoGiKBZjROsq3LibyvS/zuLpasfkbrWMct3ktAw+XneCxQcu0aRyaaYNbkQFEz8FZKcSgaIoFuX1rjW4eS+FGX+dw9PFnpGtDTuL/FzsXV5edJBTVxN4sX1V3uhquFFBhaUSgaIoFkUIwSd96nLzbiofrzuBh7MdfRpWNMi17jcF2dlYMXdEUzrWKmuQ6xSVeaUlRVEUI7CxtmLq4EY0q+LBG8sP8/fpWF3Pn5yWwTsrj/LKknBqe5di/cS2ZpsEQCUCRVEslIOtNbOHBeLv5cLYX8M4HHVbl/Oei71L3xl7WHzgEuM6+LN4TAuz6g/IjUoEiqJYLDdHWxY834wyLnaMnBfCudi7RTrf6kOX6T1tN9fuJDN3ZFPe6l7L7PoDcmP+ESqKohhQ2VIOLHi+OQIY9ssBrt1JLvA5ktMyeHvFESYtDSegQik2vNKWjjXNtykoJ5UIFEWxeFU8nZk3shm3E1MZ9ssB4hPzX4ri7HWtKWhJSBQvdfBn8Qst8HYz76agnErkqKH/Hfgfp+JO6XrOWh61eKvZW4/dZ8GCBXz11VcIIahfvz4LFy7UNQZFUQynno8bPw0LZOTcEEYvCGHhqOY42D5+AZ5Vh6J5b9UxHGytmTeyKR2K0VNAdiUyEZjC8ePH+e9//8uePXvw9PQkLi7O1CEpilJArat58u0zDRm/+CDjfzvIrCFNsMmljT8pNYMpa4+zNDSKZn4eTB3ciPJu5lfZNL9KZCLI65O7IWzfvp2nn34aT09tNSQPDw+jx6AoStE9Wd+buHsBfLDmOO+uOsr/+td/oBTF2esJvLzoEBHXEhjfsRqTOlfPNVkUJyUyEZiClFKVnFaUEmJoSz9i76Yy9c8zlHGx563uWimKFWHRvL/6GI521sx/vhnta3iZOFJ9qESgkyeeeIJ+/frx6quvUqZMGeLi4tRTgaIUY692rs6NuynM3HEOVwcbIm/cY1loNM2qeDB1UPFuCspJJQKdBAQE8N5779G+fXusra1p1KgR8+bNM3VYiqIU0v1SFLfupfLFpgiEgAmdqvHKE8W/KSgnlQh0NHz4cIYPH27qMBRF0Ym1leDbZxpSqcxp2lTzpG31ktEUlFOR0poQwkMIsVUIcSbrz9K57OMrhPhLCHFSCHFcCPFKtm1ThBCXhRDhWV89ixKPoiiK3hxsrXmnR+0SmwSg6BPK3gb+lFJWB/7M+jmndOB1KWVtoAXwshCiTrbt30opG2Z9bShiPIqiKEoBFTUR9AHmZ30/H+ibcwcp5RUp5cGs7xOAk4BBar5KKQ1xWt2Ye3yKolimoiaCclLKK6C94QOPnVYnhPADGgH7s708XghxRAgxJ7empWzHjhFChAohQmNjHy4Z6+DgwM2bN832zVZKyc2bN3FwKDkjDRRFKRlEXm+cQohtQPlcNr0HzJdSumfb95aUMtc3cyGEC7AT+K+UcmXWa+WAG4AEPgG8pZTP5xV0YGCgDA0NfeC1tLQ0oqOjSU4ueMEoY3FwcMDHxwdbW1tTh6IoigUSQoRJKQNzvp7nqCEpZefHnPSaEMJbSnlFCOENXH/EfrbACmDR/SSQde5r2faZDfyRVzyPYmtrS5Uqhl1yTlEUpSQqatPQWuD+eMnhwJqcOwhtuu0vwEkp5Tc5tnln+7EfcKyI8SiKoigFVNRE8DnQRQhxBuiS9TNCiApCiPsjgFoDQ4FOuQwT/UIIcVQIcQToCLxaxHgURVGUAirShDIp5U3giVxejwF6Zn2/G8i1CI+UcmhRrq8oiqIUXZ6dxeZICBELXCzk4Z5oHdTFUXGOHYp3/Cp201Cx66uylPKhmXHFMhEUhRAiNLde8+KgOMcOxTt+FbtpqNiNo2RVTlIURVEKTCUCRVEUC2eJieAnUwdQBMU5dije8avYTUPFbgQW10egKIqiPMgSnwgURVGUbFQiUBRFsXAlNhEIIboLISKEEGeFEA+tkyA0U7O2HxFCNDZFnLnJR+wdhBDx2WZqf2iKOHOTVUX2uhAi13IhZn7f84rdnO/7IxeAyraPWd77fMZulvdeCOEghDgghDicFfvHuexjlvf9AVLKEvcFWAPngKqAHXAYqJNjn57ARrRZzy2A/aaOuwCxdwD+MHWsj4i/HdAYOPaI7WZ53/MZuznfd2+gcdb3rsDpYvR/Pj+xm+W9z7qXLlnf26KV2G9RHO579q+S+kTQDDgrpTwvpUwFlqAtopNdH2CB1OwD3HMUwTOV/MRutqSUfwNxj9nFXO97fmI3WzJ/C0CZ5b3PZ+xmKete3s360TbrK+cIHLO879mV1ERQEYjK9nM0D//Hys8+ppDfuFpmPY5uFEIEGCc0XZjrfc8vs7/vj1gACorBvX9M7GCm914IYS2ECEcrw79VSlns7nuRis6ZsdyK3OXM0vnZxxTyE9dBtJohd7Mqua4Gqhs6MJ2Y633PD7O/70JbAGoFMElKeSfn5lwOMZt7n0fsZnvvpZQZQEMhhDuwSghRV0qZvZ/JrO87lNwngmjAN9vPPkBMIfYxhTzjklLeuf84KqXcANgKITyNF2KRmOt9z5O533fxiAWgsjHbe59X7OZ+7wGklLeBHUD3HJvM9r7fV1ITQQhQXQhRRQhhBwxCW0Qnu7XAsKwe/RZAvMxaf9nE8oxdCFFeCCGyvm+G9u940+iRFo653vc8mfN9z4or1wWgsjHLe5+f2M313gshvLKeBBBCOAKdgVM5djPL+55diWwaklKmCyHGA5vRRuHMkVIeF0KMzdo+C9iA1pt/FkgERpoq3uzyGfvTwDghRDqQBAySWcMTTE0IsRhthIenECIa+AitA82s7zvkK3azve/8uwDU0az2aoB3gUpg9vc+P7Gb6733BuYLIazRktMyKeUfxeG9JjtVYkJRFMXCldSmIUVRFCWfVCJQFEWxcCoRKIqiWDiVCBRFUSycSgSKoigWTiUCRVEUC6cSgaIoioX7f/ahYIYpnXLIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_entite = ['a','b','c']\n",
    "max_level = dict()\n",
    "max_level['a'] = 1\n",
    "max_level['b'] = 1\n",
    "max_level['c'] = 1\n",
    "\n",
    "list_colums = []\n",
    "list_colums = list_colums + list_entite\n",
    "for one_ele in list_entite:\n",
    "    list_colums = list_colums + ['c_'+one_ele]\n",
    "celerities = pd.DataFrame(columns=list_colums)\n",
    "\n",
    "sca = 0.2\n",
    "scmax = 1\n",
    "sab = 0.3\n",
    "samax = 1\n",
    "sbc = 0.9\n",
    "sbmax = 1\n",
    "\n",
    "vac0a0=1\n",
    "vac0a1=1.9\n",
    "vac1a0=1.3\n",
    "vac1a1=0.4\n",
    "vba0b0=3.8\n",
    "vba0b1=2.5\n",
    "vba1b0=2.7\n",
    "vba1b1=3.3\n",
    "vcb0c0=1.5\n",
    "vcb0c1=0.8\n",
    "vcb1c0=1.9\n",
    "vcb1c1=1.5\n",
    "\n",
    "num = 20\n",
    "initial_state  = (0.5,0.7,0.8)\n",
    "nb = 10\n",
    "\n",
    "noise1 = 0.2\n",
    "noise2 = 0.2\n",
    "noise3 = 0.2\n",
    "\n",
    "cac0a0=vac0a0/(sab - 0)\n",
    "cac0a1=vac0a1/(samax - sab)\n",
    "cac1a0=vac1a0/(sab - 0)\n",
    "cac1a1=vac1a1/(samax - sab)\n",
    "cba0b0=vba0b0/(sbc - 0)\n",
    "cba0b1=vba0b1/(sbmax - sbc)\n",
    "cba1b0=vba1b0/(sbc - 0)\n",
    "cba1b1=vba1b1/(sbmax - sbc)\n",
    "ccb0c0=vcb0c0/(sca - 0)\n",
    "ccb0c1=vcb0c1/(scmax -sca)\n",
    "ccb1c0=vcb1c0/(sca - 0)\n",
    "ccb1c1=vcb1c1/(scmax -sca)\n",
    "\n",
    "df1 = pd.DataFrame([[0,0,0,cac0a0,cba0b0,ccb0c0]],columns=list_colums)\n",
    "df2 = pd.DataFrame([[0,0,1,-cac1a0,cba0b0,ccb0c1]],columns=list_colums)\n",
    "df3 = pd.DataFrame([[0,1,0,cac0a0,cba0b1,-ccb1c0]],columns=list_colums)\n",
    "df4 = pd.DataFrame([[0,1,1,-cac1a0,cba0b1,-ccb1c1]],columns=list_colums)\n",
    "df5 = pd.DataFrame([[1,0,0,cac0a1,-cba1b0,ccb0c0]],columns=list_colums)\n",
    "df6 = pd.DataFrame([[1,0,1,-cac1a1,-cba1b0,ccb0c1]],columns=list_colums)\n",
    "df7 = pd.DataFrame([[1,1,0,cac0a1,-cba1b1,-ccb1c0]],columns=list_colums)\n",
    "df8 = pd.DataFrame([[1,1,1,-cac1a1,-cba1b1,-ccb1c1]],columns=list_colums)\n",
    "\n",
    "celerities=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8])\n",
    "celerities['signature'] = celerities.apply(get_signature,axis=1)\n",
    "\n",
    "ini_discrete = ''\n",
    "ini_fractional = []\n",
    "if initial_state[0]>=sab:\n",
    "    ini_discrete = ini_discrete+'1'\n",
    "    ini_fractional = ini_fractional + [(initial_state[0]-sab)/(samax - sab)]\n",
    "elif initial_state[0]<sab:\n",
    "    ini_discrete = ini_discrete+'0'\n",
    "    ini_fractional = ini_fractional + [initial_state[0]/sab]\n",
    "    \n",
    "if initial_state[1]>=sbc:\n",
    "    ini_discrete = ini_discrete+'1'\n",
    "    ini_fractional = ini_fractional + [(initial_state[1]-sbc)/(sbmax - sbc)]\n",
    "elif initial_state[1]<sbc:\n",
    "    ini_discrete = ini_discrete+'0'\n",
    "    ini_fractional = ini_fractional + [initial_state[1]/sbc]\n",
    "    \n",
    "if initial_state[2]>=sca:\n",
    "    ini_discrete = ini_discrete+'1'\n",
    "    ini_fractional = ini_fractional + [(initial_state[2]-sca)/(scmax - sca)]\n",
    "elif initial_state[2]<sca:\n",
    "    ini_discrete = ini_discrete+'0'\n",
    "    ini_fractional = ini_fractional + [initial_state[2]/sca]\n",
    "    \n",
    "data,t = simulation(ini_discrete,ini_fractional,num)\n",
    "real_data = dc(data)\n",
    "for i in range(data.shape[0]):\n",
    "    if data[i][0] < 1:\n",
    "        real_data[i][0] = data[i][0]*sab\n",
    "    elif data[i][0] >= 1:\n",
    "        real_data[i][0] = (data[i][0] - 1)*(samax - sab) + sab\n",
    "    if data[i][1] < 1:\n",
    "        real_data[i][1] = data[i][1]*sbc\n",
    "    elif data[i][1] >= 1:\n",
    "        real_data[i][1] = (data[i][1] - 1)*(sbmax - sbc) + sbc\n",
    "    if data[i][2] < 1:\n",
    "        real_data[i][2] = data[i][2]*sca\n",
    "    elif data[i][2] >= 1:\n",
    "        real_data[i][2] = (data[i][2] - 1)*(scmax - sca) + sca\n",
    "noise_data = np.zeros((nb+1,3))\n",
    "delta_t = t[-1][0]/nb\n",
    "new_t = np.zeros((nb+1,1))\n",
    "for i in range(nb+1):\n",
    "    new_t[i][0] = i*delta_t\n",
    "    for j in range(t.shape[0]-1):\n",
    "        if t[j][0] <= new_t[i][0] and t[j+1][0] >= new_t[i][0]:\n",
    "            noise_data[i][0] = random.gauss(0,noise1) + real_data[j][0] + (real_data[j+1][0] - real_data[j][0])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "            noise_data[i][1] = random.gauss(0,noise2) + real_data[j][1] + (real_data[j+1][1] - real_data[j][1])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "            noise_data[i][2] = random.gauss(0,noise3) + real_data[j][2] + (real_data[j+1][2] - real_data[j][2])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "            break\n",
    "plt.plot(new_t[0:nb],noise_data[0:nb,0],label='a')\n",
    "plt.plot(new_t[0:nb],noise_data[0:nb,1],label='b')\n",
    "plt.plot(new_t[0:nb],noise_data[0:nb,2],label='c')\n",
    "plt.legend()\n",
    "plt.savefig('simu1',dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59ac7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, SimpleRNN, concatenate, LSTM, Conv2D, Activation, MaxPooling2D\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9fd9868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_sc(nb_data,num,nb, noise):\n",
    "\n",
    "    X,Y=[],[]\n",
    "    initial_state  = (np.random.random_sample(1)[0],np.random.random_sample(1)[0],np.random.random_sample(1)[0])\n",
    "\n",
    "    noise1 = random.uniform(0, noise)\n",
    "    noise2 = random.uniform(0, noise)\n",
    "    noise3 = random.uniform(0, noise)\n",
    "\n",
    "    for k in range(nb_data):\n",
    "        print(k)\n",
    "        list_entite = ['a','b','c']\n",
    "        max_level = dict()\n",
    "        max_level['a'] = 1\n",
    "        max_level['b'] = 1\n",
    "        max_level['c'] = 1\n",
    "\n",
    "        list_colums = []\n",
    "        list_colums = list_colums + list_entite\n",
    "        for one_ele in list_entite:\n",
    "            list_colums = list_colums + ['c_'+one_ele]\n",
    "        celerities = pd.DataFrame(columns=list_colums)\n",
    "\n",
    "        sca = np.random.random_sample(1)[0]\n",
    "        scmax = 1\n",
    "        sab = np.random.random_sample(1)[0]\n",
    "        samax = 1\n",
    "        sbc = np.random.random_sample(1)[0]\n",
    "        sbmax = 1\n",
    "\n",
    "        vac0a0=10*np.random.random_sample(1)[0]\n",
    "        vac0a1=10*np.random.random_sample(1)[0]\n",
    "        vac1a0=10*np.random.random_sample(1)[0]\n",
    "        vac1a1=10*np.random.random_sample(1)[0]\n",
    "        vba0b0=10*np.random.random_sample(1)[0]\n",
    "        vba0b1=10*np.random.random_sample(1)[0]\n",
    "        vba1b0=10*np.random.random_sample(1)[0]\n",
    "        vba1b1=10*np.random.random_sample(1)[0]\n",
    "        vcb0c0=10*np.random.random_sample(1)[0]\n",
    "        vcb0c1=10*np.random.random_sample(1)[0]\n",
    "        vcb1c0=10*np.random.random_sample(1)[0]\n",
    "        vcb1c1=10*np.random.random_sample(1)[0]\n",
    "\n",
    "        Y.append([sca,sab,sbc])\n",
    "\n",
    "        cac0a0=vac0a0/(sab - 0)\n",
    "        cac0a1=vac0a1/(samax - sab)\n",
    "        cac1a0=vac1a0/(sab - 0)\n",
    "        cac1a1=vac1a1/(samax - sab)\n",
    "        cba0b0=vba0b0/(sbc - 0)\n",
    "        cba0b1=vba0b1/(sbmax - sbc)\n",
    "        cba1b0=vba1b0/(sbc - 0)\n",
    "        cba1b1=vba1b1/(sbmax - sbc)\n",
    "        ccb0c0=vcb0c0/(sca - 0)\n",
    "        ccb0c1=vcb0c1/(scmax -sca)\n",
    "        ccb1c0=vcb1c0/(sca - 0)\n",
    "        ccb1c1=vcb1c1/(scmax -sca)\n",
    "\n",
    "        df1 = pd.DataFrame([[0,0,0,cac0a0,cba0b0,ccb0c0]],columns=list_colums)\n",
    "        df2 = pd.DataFrame([[0,0,1,-cac1a0,cba0b0,ccb0c1]],columns=list_colums)\n",
    "        df3 = pd.DataFrame([[0,1,0,cac0a0,cba0b1,-ccb1c0]],columns=list_colums)\n",
    "        df4 = pd.DataFrame([[0,1,1,-cac1a0,cba0b1,-ccb1c1]],columns=list_colums)\n",
    "        df5 = pd.DataFrame([[1,0,0,cac0a1,-cba1b0,ccb0c0]],columns=list_colums)\n",
    "        df6 = pd.DataFrame([[1,0,1,-cac1a1,-cba1b0,ccb0c1]],columns=list_colums)\n",
    "        df7 = pd.DataFrame([[1,1,0,cac0a1,-cba1b1,-ccb1c0]],columns=list_colums)\n",
    "        df8 = pd.DataFrame([[1,1,1,-cac1a1,-cba1b1,-ccb1c1]],columns=list_colums)\n",
    "\n",
    "        celerities=pd.concat([df1,df2,df3,df4,df5,df6,df7,df8])\n",
    "        celerities['signature'] = celerities.apply(get_signature,axis=1)\n",
    "\n",
    "        ini_discrete = ''\n",
    "        ini_fractional = []\n",
    "        if initial_state[0]>=sab:\n",
    "            ini_discrete = ini_discrete+'1'\n",
    "            ini_fractional = ini_fractional + [(initial_state[0]-sab)/(samax - sab)]\n",
    "        elif initial_state[0]<sab:\n",
    "            ini_discrete = ini_discrete+'0'\n",
    "            ini_fractional = ini_fractional + [initial_state[0]/sab]\n",
    "\n",
    "        if initial_state[1]>=sbc:\n",
    "            ini_discrete = ini_discrete+'1'\n",
    "            ini_fractional = ini_fractional + [(initial_state[1]-sbc)/(sbmax - sbc)]\n",
    "        elif initial_state[1]<sbc:\n",
    "            ini_discrete = ini_discrete+'0'\n",
    "            ini_fractional = ini_fractional + [initial_state[1]/sbc]\n",
    "\n",
    "        if initial_state[2]>=sca:\n",
    "            ini_discrete = ini_discrete+'1'\n",
    "            ini_fractional = ini_fractional + [(initial_state[2]-sca)/(scmax - sca)]\n",
    "        elif initial_state[2]<sca:\n",
    "            ini_discrete = ini_discrete+'0'\n",
    "            ini_fractional = ini_fractional + [initial_state[2]/sca]\n",
    "\n",
    "        data,t = simulation(ini_discrete,ini_fractional,num)\n",
    "        real_data = dc(data)\n",
    "        for i in range(data.shape[0]):\n",
    "            if data[i][0] < 1:\n",
    "                real_data[i][0] = data[i][0]*sab\n",
    "            elif data[i][0] >= 1:\n",
    "                real_data[i][0] = (data[i][0] - 1)*(samax - sab) + sab\n",
    "            if data[i][1] < 1:\n",
    "                real_data[i][1] = data[i][1]*sbc\n",
    "            elif data[i][1] >= 1:\n",
    "                real_data[i][1] = (data[i][1] - 1)*(sbmax - sbc) + sbc\n",
    "            if data[i][2] < 1:\n",
    "                real_data[i][2] = data[i][2]*sca\n",
    "            elif data[i][2] >= 1:\n",
    "                real_data[i][2] = (data[i][2] - 1)*(scmax - sca) + sca\n",
    "        noise_data = np.zeros((nb+1,3))\n",
    "        delta_t = t[-1][0]/nb\n",
    "        new_t = np.zeros((nb+1,1))\n",
    "        for i in range(nb+1):\n",
    "            new_t[i][0] = i*delta_t\n",
    "            for j in range(t.shape[0]-1):\n",
    "                if t[j][0] <= new_t[i][0] and t[j+1][0] >= new_t[i][0]:\n",
    "                    noise_data[i][0] = random.gauss(0,noise1) + real_data[j][0] + (real_data[j+1][0] - real_data[j][0])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                    noise_data[i][1] = random.gauss(0,noise2) + real_data[j][1] + (real_data[j+1][1] - real_data[j][1])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                    noise_data[i][2] = random.gauss(0,noise3) + real_data[j][2] + (real_data[j+1][2] - real_data[j][2])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                    break\n",
    "\n",
    "        X.append(noise_data)\n",
    "    return np.array(X),np.array(Y)\n",
    "\n",
    "def seuil_grid_search1d(X, nb_points, step=0.1, min=0, max=1):\n",
    "    xx = np.arange(min, max+step, step)\n",
    "    score_vect=[]\n",
    "    for i in range(len(xx)):\n",
    "        score = 0\n",
    "        sab = xx[i]\n",
    "        for j in range(nb_points, len(X)-nb_points):\n",
    "            s=0\n",
    "            for k in range(1,nb_points+1): #nb de points à considérer de part et d'autre\n",
    "                s_temp = (X[j+k,1]-X[j-k,1])/(2*k) #Concentration B pour le seuil A\n",
    "                s+= np.abs(s_temp)*int(int(s_temp>0) == int(X[j,0]<sab)) #vaut abs(s) si le signe correspond, 0 sinon\n",
    "            #s+= score_saturation(X, sab, j) #on augmente le score si la concentration est à un maximum ou un minimum\n",
    "            score += s\n",
    "        score_vect.append(score)\n",
    "    return np.array(score_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53b997",
   "metadata": {},
   "source": [
    "Réseau avec le score 1d et les observations 2 à 2 *model_ab_1d*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c17d6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "n_sim = 1000\n",
    "num = 20\n",
    "nb = 100\n",
    "noise = 0.2\n",
    "dataset = create_dataset_sc(n_sim, num, nb, noise)\n",
    "dataset_score = dataset[0]\n",
    "y = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5beba3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ab = np.zeros((n_sim, nb-1, 2, 2))\n",
    "\n",
    "for k1 in range(n_sim):\n",
    "    for k2 in range(nb-1):\n",
    "        dataset_ab[k1, k2, 0, 0] = dataset_score[k1, k2, 0]\n",
    "        dataset_ab[k1, k2, 1, 0] = dataset_score[k1, k2+1, 0]\n",
    "        dataset_ab[k1, k2, 0, 1] = dataset_score[k1, k2, 1]\n",
    "        dataset_ab[k1, k2, 1, 1] = dataset_score[k1, k2+1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d7086e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "step = 0.1\n",
    "score_1d = []\n",
    "for k in range(n_sim):\n",
    "    print(k)\n",
    "    X = dataset_score[k, :]\n",
    "    score_1d += [seuil_grid_search1d(X, 1, step, min=0, max=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bf5f0da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dataset_ab_1d = [0]*n_sim\n",
    "for s in range(n_sim):\n",
    "    liste_dataset_ab_1d[s] = [score_1d[s]]\n",
    "    liste_dataset_ab_1d[s] += [dataset_ab[s, :, :, :]]\n",
    "       \n",
    "X_train_ab_1d, X_test_ab_1d, y_train_ab_1d, y_test_ab_1d = train_test_split(liste_dataset_ab_1d, y[:, 1], train_size = 0.7, shuffle = False)  \n",
    "\n",
    "X_train_ab_1d_2 = [0]*nb\n",
    "X_train_ab_1d_2[0] = np.zeros((len(X_train_ab_1d), int(1/step)+1))\n",
    "for s in range(len(X_train_ab_1d)):\n",
    "    X_train_ab_1d_2[0][s] = X_train_ab_1d[s][0]\n",
    "    \n",
    "for k in range(1, nb):\n",
    "    X_train_ab_1d_2[k] = np.zeros((len(X_train_ab_1d), 2, 2))\n",
    "    for s in range(len(X_train_ab_1d)):\n",
    "        X_train_ab_1d_2[k][s] = X_train_ab_1d[s][1][k-1]\n",
    "\n",
    "X_test_ab_1d_2 = [0]*nb\n",
    "X_test_ab_1d_2[0] = np.zeros((len(X_test_ab_1d), int(1/step)+1))\n",
    "for s in range(len(X_test_ab_1d)):\n",
    "    X_test_ab_1d_2[0][s] = X_test_ab_1d[s][0]\n",
    "    \n",
    "for k in range(1, nb):\n",
    "    X_test_ab_1d_2[k] = np.zeros((len(X_test_ab_1d), 2, 2))\n",
    "    for s in range(len(X_test_ab_1d)):\n",
    "        X_test_ab_1d_2[k][s] = X_test_ab_1d[s][1][k-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3ad6e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_input = []\n",
    "list_output = []\n",
    "\n",
    "\n",
    "input_score_1d = Input(shape = (int(1/step)+1,)) # score 1d\n",
    "\n",
    "x = Dense(32, activation='relu')(input_score_1d)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Model(inputs=input_score_1d, outputs=x)\n",
    "\n",
    "list_output += [x.output]\n",
    "list_input += [x.input]\n",
    "\n",
    "for k in range (nb-1):\n",
    "    input_k = Input(shape = (2, 2,))\n",
    "    x = Dense(32)(input_k)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Model(inputs=input_k, outputs=x)\n",
    "    list_output += [x.output]\n",
    "    list_input += [x.input]\n",
    "\n",
    "output_N1 = concatenate(list_output)\n",
    "\n",
    "z = Dense(4, activation=\"relu\")(output_N1)\n",
    "z = Dense(2, activation=\"relu\")(z)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model_ab_1d = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "model_ab_1d.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a99cd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 55s 2s/step - loss: 0.4563 - mean_absolute_error: 0.4590 - val_loss: 0.4862 - val_mean_absolute_error: 0.4765\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.4485 - mean_absolute_error: 0.4493 - val_loss: 0.4783 - val_mean_absolute_error: 0.4686\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.4408 - mean_absolute_error: 0.4418 - val_loss: 0.4705 - val_mean_absolute_error: 0.4609\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.4333 - mean_absolute_error: 0.4354 - val_loss: 0.4630 - val_mean_absolute_error: 0.4536\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.4260 - mean_absolute_error: 0.4260 - val_loss: 0.4558 - val_mean_absolute_error: 0.4466\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.4189 - mean_absolute_error: 0.4194 - val_loss: 0.4488 - val_mean_absolute_error: 0.4397\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.4122 - mean_absolute_error: 0.4129 - val_loss: 0.4420 - val_mean_absolute_error: 0.4330\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.4058 - mean_absolute_error: 0.4079 - val_loss: 0.4353 - val_mean_absolute_error: 0.4265\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.3996 - mean_absolute_error: 0.4017 - val_loss: 0.4289 - val_mean_absolute_error: 0.4203\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.3936 - mean_absolute_error: 0.3956 - val_loss: 0.4225 - val_mean_absolute_error: 0.4142\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.3877 - mean_absolute_error: 0.3897 - val_loss: 0.4164 - val_mean_absolute_error: 0.4082\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3818 - mean_absolute_error: 0.3828 - val_loss: 0.4104 - val_mean_absolute_error: 0.4024\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.3762 - mean_absolute_error: 0.3723 - val_loss: 0.4044 - val_mean_absolute_error: 0.3966\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3706 - mean_absolute_error: 0.3678 - val_loss: 0.3988 - val_mean_absolute_error: 0.3912\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3653 - mean_absolute_error: 0.3617 - val_loss: 0.3933 - val_mean_absolute_error: 0.3858\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.3602 - mean_absolute_error: 0.3606 - val_loss: 0.3878 - val_mean_absolute_error: 0.3804\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3552 - mean_absolute_error: 0.3529 - val_loss: 0.3826 - val_mean_absolute_error: 0.3753\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3504 - mean_absolute_error: 0.3539 - val_loss: 0.3778 - val_mean_absolute_error: 0.3705\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.3460 - mean_absolute_error: 0.3440 - val_loss: 0.3730 - val_mean_absolute_error: 0.3658\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.3416 - mean_absolute_error: 0.3421 - val_loss: 0.3684 - val_mean_absolute_error: 0.3612\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.3372 - mean_absolute_error: 0.3384 - val_loss: 0.3639 - val_mean_absolute_error: 0.3567\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3329 - mean_absolute_error: 0.3323 - val_loss: 0.3594 - val_mean_absolute_error: 0.3522\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.3288 - mean_absolute_error: 0.3276 - val_loss: 0.3550 - val_mean_absolute_error: 0.3478\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.3246 - mean_absolute_error: 0.3245 - val_loss: 0.3507 - val_mean_absolute_error: 0.3436\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.3205 - mean_absolute_error: 0.3216 - val_loss: 0.3465 - val_mean_absolute_error: 0.3395\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.3165 - mean_absolute_error: 0.3153 - val_loss: 0.3426 - val_mean_absolute_error: 0.3356\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3127 - mean_absolute_error: 0.3085 - val_loss: 0.3390 - val_mean_absolute_error: 0.3320\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.3091 - mean_absolute_error: 0.3080 - val_loss: 0.3354 - val_mean_absolute_error: 0.3284\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.3055 - mean_absolute_error: 0.3063 - val_loss: 0.3319 - val_mean_absolute_error: 0.3250\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.3022 - mean_absolute_error: 0.3030 - val_loss: 0.3285 - val_mean_absolute_error: 0.3216\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2990 - mean_absolute_error: 0.2969 - val_loss: 0.3253 - val_mean_absolute_error: 0.3184\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2960 - mean_absolute_error: 0.2958 - val_loss: 0.3222 - val_mean_absolute_error: 0.3154\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2931 - mean_absolute_error: 0.2938 - val_loss: 0.3193 - val_mean_absolute_error: 0.3126\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2904 - mean_absolute_error: 0.2870 - val_loss: 0.3165 - val_mean_absolute_error: 0.3098\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2878 - mean_absolute_error: 0.2873 - val_loss: 0.3138 - val_mean_absolute_error: 0.3071\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2852 - mean_absolute_error: 0.2849 - val_loss: 0.3113 - val_mean_absolute_error: 0.3047\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.2829 - mean_absolute_error: 0.2844 - val_loss: 0.3089 - val_mean_absolute_error: 0.3022\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.2807 - mean_absolute_error: 0.2821 - val_loss: 0.3065 - val_mean_absolute_error: 0.2998\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 66ms/step - loss: 0.2786 - mean_absolute_error: 0.2778 - val_loss: 0.3041 - val_mean_absolute_error: 0.2974\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2766 - mean_absolute_error: 0.2765 - val_loss: 0.3018 - val_mean_absolute_error: 0.2951\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2747 - mean_absolute_error: 0.2757 - val_loss: 0.2997 - val_mean_absolute_error: 0.2930\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2730 - mean_absolute_error: 0.2706 - val_loss: 0.2977 - val_mean_absolute_error: 0.2911\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2713 - mean_absolute_error: 0.2720 - val_loss: 0.2958 - val_mean_absolute_error: 0.2892\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2698 - mean_absolute_error: 0.2671 - val_loss: 0.2940 - val_mean_absolute_error: 0.2875\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2682 - mean_absolute_error: 0.2693 - val_loss: 0.2924 - val_mean_absolute_error: 0.2859\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2668 - mean_absolute_error: 0.2654 - val_loss: 0.2907 - val_mean_absolute_error: 0.2842\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2653 - mean_absolute_error: 0.2638 - val_loss: 0.2892 - val_mean_absolute_error: 0.2827\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2640 - mean_absolute_error: 0.2631 - val_loss: 0.2876 - val_mean_absolute_error: 0.2811\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2628 - mean_absolute_error: 0.2648 - val_loss: 0.2861 - val_mean_absolute_error: 0.2796\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2616 - mean_absolute_error: 0.2616 - val_loss: 0.2847 - val_mean_absolute_error: 0.2782\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2603 - mean_absolute_error: 0.2614 - val_loss: 0.2833 - val_mean_absolute_error: 0.2769\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2592 - mean_absolute_error: 0.2590 - val_loss: 0.2820 - val_mean_absolute_error: 0.2757\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2582 - mean_absolute_error: 0.2588 - val_loss: 0.2808 - val_mean_absolute_error: 0.2745\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2572 - mean_absolute_error: 0.2580 - val_loss: 0.2796 - val_mean_absolute_error: 0.2733\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2563 - mean_absolute_error: 0.2571 - val_loss: 0.2785 - val_mean_absolute_error: 0.2723\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2555 - mean_absolute_error: 0.2575 - val_loss: 0.2774 - val_mean_absolute_error: 0.2712\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2548 - mean_absolute_error: 0.2566 - val_loss: 0.2764 - val_mean_absolute_error: 0.2702\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2541 - mean_absolute_error: 0.2532 - val_loss: 0.2753 - val_mean_absolute_error: 0.2692\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2534 - mean_absolute_error: 0.2543 - val_loss: 0.2744 - val_mean_absolute_error: 0.2683\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2528 - mean_absolute_error: 0.2537 - val_loss: 0.2734 - val_mean_absolute_error: 0.2674\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2522 - mean_absolute_error: 0.2529 - val_loss: 0.2725 - val_mean_absolute_error: 0.2665\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2516 - mean_absolute_error: 0.2522 - val_loss: 0.2716 - val_mean_absolute_error: 0.2656\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2510 - mean_absolute_error: 0.2494 - val_loss: 0.2707 - val_mean_absolute_error: 0.2647\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2505 - mean_absolute_error: 0.2516 - val_loss: 0.2699 - val_mean_absolute_error: 0.2640\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2500 - mean_absolute_error: 0.2520 - val_loss: 0.2691 - val_mean_absolute_error: 0.2631\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2495 - mean_absolute_error: 0.2514 - val_loss: 0.2684 - val_mean_absolute_error: 0.2624\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2491 - mean_absolute_error: 0.2462 - val_loss: 0.2676 - val_mean_absolute_error: 0.2616\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2487 - mean_absolute_error: 0.2468 - val_loss: 0.2668 - val_mean_absolute_error: 0.2609\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2482 - mean_absolute_error: 0.2486 - val_loss: 0.2662 - val_mean_absolute_error: 0.2603\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2478 - mean_absolute_error: 0.2482 - val_loss: 0.2654 - val_mean_absolute_error: 0.2595\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2474 - mean_absolute_error: 0.2463 - val_loss: 0.2648 - val_mean_absolute_error: 0.2589\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2471 - mean_absolute_error: 0.2473 - val_loss: 0.2640 - val_mean_absolute_error: 0.2581\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2467 - mean_absolute_error: 0.2488 - val_loss: 0.2634 - val_mean_absolute_error: 0.2576\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2464 - mean_absolute_error: 0.2462 - val_loss: 0.2628 - val_mean_absolute_error: 0.2569\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2461 - mean_absolute_error: 0.2459 - val_loss: 0.2622 - val_mean_absolute_error: 0.2563\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2457 - mean_absolute_error: 0.2471 - val_loss: 0.2616 - val_mean_absolute_error: 0.2557\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2454 - mean_absolute_error: 0.2465 - val_loss: 0.2611 - val_mean_absolute_error: 0.2552\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 1s 86ms/step - loss: 0.2452 - mean_absolute_error: 0.2455 - val_loss: 0.2605 - val_mean_absolute_error: 0.2546\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2449 - mean_absolute_error: 0.2442 - val_loss: 0.2598 - val_mean_absolute_error: 0.2540\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2446 - mean_absolute_error: 0.2467 - val_loss: 0.2594 - val_mean_absolute_error: 0.2535\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2444 - mean_absolute_error: 0.2437 - val_loss: 0.2589 - val_mean_absolute_error: 0.2530\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2442 - mean_absolute_error: 0.2450 - val_loss: 0.2584 - val_mean_absolute_error: 0.2525\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2441 - mean_absolute_error: 0.2422 - val_loss: 0.2579 - val_mean_absolute_error: 0.2520\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2439 - mean_absolute_error: 0.2439 - val_loss: 0.2575 - val_mean_absolute_error: 0.2517\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2438 - mean_absolute_error: 0.2436 - val_loss: 0.2573 - val_mean_absolute_error: 0.2514\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2437 - mean_absolute_error: 0.2443 - val_loss: 0.2570 - val_mean_absolute_error: 0.2512\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2436 - mean_absolute_error: 0.2428 - val_loss: 0.2568 - val_mean_absolute_error: 0.2510\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2435 - mean_absolute_error: 0.2422 - val_loss: 0.2565 - val_mean_absolute_error: 0.2508\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2434 - mean_absolute_error: 0.2427 - val_loss: 0.2563 - val_mean_absolute_error: 0.2505\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2433 - mean_absolute_error: 0.2436 - val_loss: 0.2561 - val_mean_absolute_error: 0.2504\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2433 - mean_absolute_error: 0.2430 - val_loss: 0.2559 - val_mean_absolute_error: 0.2502\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2432 - mean_absolute_error: 0.2431 - val_loss: 0.2557 - val_mean_absolute_error: 0.2501\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2431 - mean_absolute_error: 0.2416 - val_loss: 0.2556 - val_mean_absolute_error: 0.2500\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2431 - mean_absolute_error: 0.2440 - val_loss: 0.2553 - val_mean_absolute_error: 0.2498\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2431 - mean_absolute_error: 0.2410 - val_loss: 0.2551 - val_mean_absolute_error: 0.2496\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2430 - mean_absolute_error: 0.2421 - val_loss: 0.2550 - val_mean_absolute_error: 0.2495\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2429 - mean_absolute_error: 0.2421 - val_loss: 0.2548 - val_mean_absolute_error: 0.2494\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2429 - mean_absolute_error: 0.2444 - val_loss: 0.2546 - val_mean_absolute_error: 0.2492\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2428 - mean_absolute_error: 0.2447 - val_loss: 0.2545 - val_mean_absolute_error: 0.2491\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2428 - mean_absolute_error: 0.2418 - val_loss: 0.2544 - val_mean_absolute_error: 0.2491\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2428 - mean_absolute_error: 0.2446 - val_loss: 0.2543 - val_mean_absolute_error: 0.2490\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2427 - mean_absolute_error: 0.2431 - val_loss: 0.2541 - val_mean_absolute_error: 0.2488\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2427 - mean_absolute_error: 0.2433 - val_loss: 0.2539 - val_mean_absolute_error: 0.2487\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2427 - mean_absolute_error: 0.2428 - val_loss: 0.2538 - val_mean_absolute_error: 0.2486\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2427 - mean_absolute_error: 0.2427 - val_loss: 0.2537 - val_mean_absolute_error: 0.2485\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2426 - mean_absolute_error: 0.2433 - val_loss: 0.2537 - val_mean_absolute_error: 0.2485\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2426 - mean_absolute_error: 0.2438 - val_loss: 0.2536 - val_mean_absolute_error: 0.2484\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.2426 - mean_absolute_error: 0.2434 - val_loss: 0.2535 - val_mean_absolute_error: 0.2483\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.2426 - mean_absolute_error: 0.2431 - val_loss: 0.2534 - val_mean_absolute_error: 0.2483\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.2426 - mean_absolute_error: 0.2442 - val_loss: 0.2533 - val_mean_absolute_error: 0.2482\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2425 - mean_absolute_error: 0.2426 - val_loss: 0.2532 - val_mean_absolute_error: 0.2481\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2425 - mean_absolute_error: 0.2430 - val_loss: 0.2531 - val_mean_absolute_error: 0.2481\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.2425 - mean_absolute_error: 0.2412 - val_loss: 0.2530 - val_mean_absolute_error: 0.2480\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2425 - mean_absolute_error: 0.2435 - val_loss: 0.2530 - val_mean_absolute_error: 0.2480\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2425 - mean_absolute_error: 0.2417 - val_loss: 0.2529 - val_mean_absolute_error: 0.2479\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2425 - mean_absolute_error: 0.2413 - val_loss: 0.2528 - val_mean_absolute_error: 0.2479\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2424 - mean_absolute_error: 0.2435 - val_loss: 0.2528 - val_mean_absolute_error: 0.2478\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2424 - mean_absolute_error: 0.2435 - val_loss: 0.2527 - val_mean_absolute_error: 0.2478\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2424 - mean_absolute_error: 0.2421 - val_loss: 0.2527 - val_mean_absolute_error: 0.2478\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2424 - mean_absolute_error: 0.2431 - val_loss: 0.2526 - val_mean_absolute_error: 0.2477\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2424 - mean_absolute_error: 0.2415 - val_loss: 0.2525 - val_mean_absolute_error: 0.2476\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2424 - mean_absolute_error: 0.2412 - val_loss: 0.2524 - val_mean_absolute_error: 0.2476\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2424 - mean_absolute_error: 0.2419 - val_loss: 0.2524 - val_mean_absolute_error: 0.2475\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2423 - mean_absolute_error: 0.2444 - val_loss: 0.2523 - val_mean_absolute_error: 0.2475\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2423 - mean_absolute_error: 0.2414 - val_loss: 0.2523 - val_mean_absolute_error: 0.2475\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2423 - mean_absolute_error: 0.2422 - val_loss: 0.2522 - val_mean_absolute_error: 0.2474\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2423 - mean_absolute_error: 0.2412 - val_loss: 0.2522 - val_mean_absolute_error: 0.2474\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2423 - mean_absolute_error: 0.2403 - val_loss: 0.2522 - val_mean_absolute_error: 0.2474\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2423 - mean_absolute_error: 0.2430 - val_loss: 0.2521 - val_mean_absolute_error: 0.2473\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2423 - mean_absolute_error: 0.2431 - val_loss: 0.2521 - val_mean_absolute_error: 0.2473\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2423 - mean_absolute_error: 0.2408 - val_loss: 0.2520 - val_mean_absolute_error: 0.2473\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2423 - mean_absolute_error: 0.2418 - val_loss: 0.2520 - val_mean_absolute_error: 0.2472\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2423 - mean_absolute_error: 0.2419 - val_loss: 0.2519 - val_mean_absolute_error: 0.2472\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2423 - mean_absolute_error: 0.2427 - val_loss: 0.2519 - val_mean_absolute_error: 0.2472\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2423 - mean_absolute_error: 0.2418 - val_loss: 0.2518 - val_mean_absolute_error: 0.2471\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2518 - val_mean_absolute_error: 0.2471\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2518 - val_mean_absolute_error: 0.2471\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2446 - val_loss: 0.2517 - val_mean_absolute_error: 0.2471\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2422 - mean_absolute_error: 0.2445 - val_loss: 0.2517 - val_mean_absolute_error: 0.2470\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2516 - val_mean_absolute_error: 0.2470\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2516 - val_mean_absolute_error: 0.2470\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2516 - val_mean_absolute_error: 0.2470\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2516 - val_mean_absolute_error: 0.2469\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2516 - val_mean_absolute_error: 0.2469\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2515 - val_mean_absolute_error: 0.2469\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2515 - val_mean_absolute_error: 0.2469\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2515 - val_mean_absolute_error: 0.2469\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2515 - val_mean_absolute_error: 0.2468\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2438 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2438 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.2422 - mean_absolute_error: 0.2401 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 0.2422 - mean_absolute_error: 0.2456 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2422 - mean_absolute_error: 0.2448 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 0.2422 - mean_absolute_error: 0.2447 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2398 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2403 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.2422 - mean_absolute_error: 0.2439 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2438 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2404 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2441 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 1s 77ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2399 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2423 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2449 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2443 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2402 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2445 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 1s 90ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2423 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2438 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2402 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2445 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2447 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2422 - mean_absolute_error: 0.2441 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2438 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2394 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2402 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2404 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2404 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2441 - val_loss: 0.2515 - val_mean_absolute_error: 0.2469\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 1s 88ms/step - loss: 0.2422 - mean_absolute_error: 0.2396 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 1s 85ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2451 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2400 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2442 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2442 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2423 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2439 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 1s 76ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 1s 136ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 1s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2438 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2439 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 1s 87ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2510 - val_mean_absolute_error: 0.2465\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2510 - val_mean_absolute_error: 0.2465\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2510 - val_mean_absolute_error: 0.2465\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2510 - val_mean_absolute_error: 0.2465\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2510 - val_mean_absolute_error: 0.2465\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2510 - val_mean_absolute_error: 0.2465\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2401 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2444 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2442 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2510 - val_mean_absolute_error: 0.2466\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2439 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2442 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2444 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 1s 89ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2439 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2423 - mean_absolute_error: 0.2417 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2441 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2400 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2401 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2403 - val_loss: 0.2515 - val_mean_absolute_error: 0.2469\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2516 - val_mean_absolute_error: 0.2469\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2515 - val_mean_absolute_error: 0.2468\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 1s 80ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2515 - val_mean_absolute_error: 0.2469\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2444 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2447 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2445 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2401 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2423 - mean_absolute_error: 0.2434 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2406 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 1s 73ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2405 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 1s 69ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2407 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2435 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2423 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2396 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2404 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2393 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2428 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2404 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2389 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 1s 74ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2449 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2439 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 1s 71ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 1s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2421 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2416 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2442 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2432 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2418 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 55ms/step - loss: 0.2422 - mean_absolute_error: 0.2409 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2437 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2419 - val_loss: 0.2514 - val_mean_absolute_error: 0.2468\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 1s 70ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2440 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2448 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2423 - mean_absolute_error: 0.2431 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2411 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 1s 66ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2434 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2422 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 1s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2433 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2408 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2415 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 1s 75ms/step - loss: 0.2422 - mean_absolute_error: 0.2410 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 1s 68ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 1s 81ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2511 - val_mean_absolute_error: 0.2466\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 1s 82ms/step - loss: 0.2422 - mean_absolute_error: 0.2431 - val_loss: 0.2512 - val_mean_absolute_error: 0.2466\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 62ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 65ms/step - loss: 0.2422 - mean_absolute_error: 0.2426 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 1s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2436 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 1s 72ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 1s 67ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 64ms/step - loss: 0.2422 - mean_absolute_error: 0.2423 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 61ms/step - loss: 0.2422 - mean_absolute_error: 0.2425 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.2422 - mean_absolute_error: 0.2430 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2423 - mean_absolute_error: 0.2417 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2404 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2412 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2414 - val_loss: 0.2512 - val_mean_absolute_error: 0.2467\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 58ms/step - loss: 0.2422 - mean_absolute_error: 0.2420 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 60ms/step - loss: 0.2422 - mean_absolute_error: 0.2413 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 0.2422 - mean_absolute_error: 0.2424 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 59ms/step - loss: 0.2422 - mean_absolute_error: 0.2427 - val_loss: 0.2513 - val_mean_absolute_error: 0.2467\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 0.2422 - mean_absolute_error: 0.2429 - val_loss: 0.2513 - val_mean_absolute_error: 0.2468\n"
     ]
    }
   ],
   "source": [
    "history_ab_1d = model_ab_1d.fit(x=X_train_ab_1d_2, y=y_train_ab_1d, epochs=1000, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "y_pred_ab_1d = model_ab_1d.predict(X_test_ab_1d_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1fb8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24660706191078655\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_pred_ab_1d, y_test_ab_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ead31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, key):\n",
    "    plt.plot(history.history[key])\n",
    "    plt.plot(history.history['val_'+key])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(key)\n",
    "    plt.legend([key, 'val_'+key])\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8a27ff68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_ab_1d, 'mean_absolute_error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
