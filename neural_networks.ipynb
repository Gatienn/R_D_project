{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T11:47:02.573274Z",
     "start_time": "2022-09-23T11:47:00.891259Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from copy import deepcopy as dc\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from itertools import permutations\n",
    "import numpy as np\n",
    "from scipy.optimize import linprog\n",
    "import math\n",
    "import pickle\n",
    "#from graphviz import Digraph\n",
    "import time\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def get_signature(x):\n",
    "    return_string = ''\n",
    "    for ele in list_entite:\n",
    "        return_string = return_string + str(int(x[ele]))\n",
    "    return return_string\n",
    "\n",
    "\n",
    "def simulation(ini_d_s, ini_c_s, nb_ite):\n",
    "    \"\"\"\n",
    "    initial_discrete_state = '100'\n",
    "    initial_domain = [0.1,0.2,0.3]\n",
    "    \"\"\"\n",
    "    nb_dim = len(ini_c_s)\n",
    "    return_series = np.zeros((1, nb_dim))\n",
    "    times = np.zeros((1, 1))\n",
    "    count = 0\n",
    "    for dim_i in range(nb_dim):\n",
    "        return_series[0][dim_i] = int(ini_d_s[dim_i]) + ini_c_s[dim_i]\n",
    "    times[0][0] = 0\n",
    "    d_s = ini_d_s\n",
    "    c_s = ini_c_s.copy()\n",
    "    for num_ite in range(nb_ite):\n",
    "        # instant transition\n",
    "        instant_transition = True\n",
    "        current_d_s = dc(d_s)\n",
    "        c_count = 0\n",
    "        while instant_transition:\n",
    "            instant_transition = False\n",
    "            for dim_i in range(nb_dim):\n",
    "                if c_s[dim_i] == 1 and classify_boundary(d_s, dim_i, 1) == 'output':\n",
    "                    instant_transition = True\n",
    "                    c_s[dim_i] = 0\n",
    "                    d_s = d_s[0:dim_i] + str(int(d_s[dim_i]) + 1) + d_s[dim_i + 1:]\n",
    "                    break\n",
    "                elif c_s[dim_i] == 0 and classify_boundary(d_s, dim_i, -1) == 'output':\n",
    "                    instant_transition = True\n",
    "                    c_s[dim_i] = 1\n",
    "                    d_s = d_s[0:dim_i] + str(int(d_s[dim_i]) - 1) + d_s[dim_i + 1:]\n",
    "                    break\n",
    "            c_count = c_count + 1\n",
    "            #             print(d_s)\n",
    "            if c_count > 1 and current_d_s == d_s:\n",
    "                return (return_series, times)\n",
    "        delta_t = math.inf\n",
    "        first_touch_dim = nb_dim\n",
    "        first_touch_sign = 0\n",
    "        one_return_series = np.zeros((1, nb_dim))\n",
    "        one_times = np.zeros((1, 1))\n",
    "        set_att = []\n",
    "        for dim_i in range(nb_dim):\n",
    "            if c_s[dim_i] == 1 and classify_boundary(d_s, dim_i, 1) == 'attractif':\n",
    "                set_att = set_att + [dim_i]\n",
    "            elif c_s[dim_i] == 0 and classify_boundary(d_s, dim_i, -1) == 'attractif':\n",
    "                set_att = set_att + [dim_i]\n",
    "        if len(set_att) == nb_dim:\n",
    "            return (return_series, times)\n",
    "        for dim_i in range(nb_dim):\n",
    "            if dim_i not in set_att:\n",
    "                speed = get_celerity(d_s, dim_i)\n",
    "                if speed > 0:\n",
    "                    delta = (1 - c_s[dim_i]) / speed\n",
    "                    sign = 1\n",
    "                elif speed < 0:\n",
    "                    delta = (0 - c_s[dim_i]) / speed\n",
    "                    sign = 0\n",
    "                elif speed == 0:\n",
    "                    delta = math.inf\n",
    "                if delta < delta_t:\n",
    "                    delta_t = delta\n",
    "                    first_touch_dim = dim_i\n",
    "                    first_touch_sign = sign\n",
    "        # check if two boundary are reached at the same time\n",
    "        for dim_i in range(nb_dim):\n",
    "            if dim_i not in set_att:\n",
    "                speed = get_celerity(d_s, dim_i)\n",
    "                if speed > 0:\n",
    "                    delta = (1 - c_s[dim_i]) / speed\n",
    "                    sign = 1\n",
    "                elif speed < 0:\n",
    "                    delta = (0 - c_s[dim_i]) / speed\n",
    "                    sign = 0\n",
    "                elif speed == 0:\n",
    "                    delta = math.inf\n",
    "                if delta == delta_t and dim_i != first_touch_dim:\n",
    "                    print('reach two new boundaries at the same time!')\n",
    "\n",
    "        c_s[first_touch_dim] = first_touch_sign\n",
    "        count = count + delta_t\n",
    "        for dim_i in range(nb_dim):\n",
    "            if dim_i not in set_att and dim_i != first_touch_dim:\n",
    "                speed = get_celerity(d_s, dim_i)\n",
    "                c_s[dim_i] = c_s[dim_i] + delta_t * speed\n",
    "            one_return_series[0][dim_i] = int(d_s[dim_i]) + c_s[dim_i]\n",
    "        #         print('discrete state:',d_s)\n",
    "        #         print('continuous state:',c_s)\n",
    "        #         print('***********************')\n",
    "        one_times[0][0] = count\n",
    "        return_series = np.vstack([return_series, one_return_series])\n",
    "        times = np.vstack([times, one_times])\n",
    "    return (return_series, times)\n",
    "\n",
    "\n",
    "def classify_boundary(state, dim, domain):\n",
    "    \"\"\"\n",
    "    state: '010'\n",
    "    dim: 2\n",
    "    domain: 1/0/-1\n",
    "    \"\"\"\n",
    "    current_row = celerities.query('signature == @state')\n",
    "    speed = current_row['c_' + list_entite[dim]].values[0]\n",
    "    if domain == 0:\n",
    "        return 'interior'\n",
    "    elif domain == 1:\n",
    "        if speed > 0:\n",
    "            if int(state[dim]) == max_level[list_entite[dim]]:\n",
    "                return 'attractif'\n",
    "            else:\n",
    "                upper_discrete_state = state\n",
    "                upper_discrete_state = list(upper_discrete_state)\n",
    "                upper_discrete_state[dim] = str(int(upper_discrete_state[dim]) + 1)\n",
    "                upper_discrete_state = \"\".join(upper_discrete_state)\n",
    "                upper_speed = celerities.query('signature == @upper_discrete_state')['c_' + list_entite[dim]].values[0]\n",
    "                if upper_speed <= 0:\n",
    "                    return 'attractif'\n",
    "                elif upper_speed > 0:\n",
    "                    return 'output'\n",
    "        elif speed == 0:\n",
    "            return 'neutral'\n",
    "        elif speed < 0:\n",
    "            return 'input'\n",
    "    elif domain == -1:\n",
    "        if speed < 0:\n",
    "            if int(state[dim]) == 0:\n",
    "                return 'attractif'\n",
    "            else:\n",
    "                lower_discrete_state = state\n",
    "                lower_discrete_state = list(lower_discrete_state)\n",
    "                lower_discrete_state[dim] = str(int(lower_discrete_state[dim]) - 1)\n",
    "                lower_discrete_state = \"\".join(lower_discrete_state)\n",
    "                lower_speed = celerities.query('signature == @lower_discrete_state')['c_' + list_entite[dim]].values[0]\n",
    "                if lower_speed >= 0:\n",
    "                    return 'attractif'\n",
    "                elif lower_speed < 0:\n",
    "                    return 'output'\n",
    "        elif speed == 0:\n",
    "            return 'neutral'\n",
    "        elif speed > 0:\n",
    "            return 'input'\n",
    "\n",
    "\n",
    "def get_celerity(state, dim):\n",
    "    current_row = celerities.query('signature == @state')\n",
    "    speed = current_row['c_' + list_entite[dim]].values[0]\n",
    "    return speed\n",
    "\n",
    "\n",
    "def get_transition_matrix(state, first_domain, second_domain):\n",
    "    \"\"\"\n",
    "    state: '0101'\n",
    "    first_domain(second_domain): [0,-1,1,0]\n",
    "    \"\"\"\n",
    "    # get first reach dimension\n",
    "    first_reach_dim = len(second_domain) + 1\n",
    "    for num_dim in range(len(second_domain)):\n",
    "        if second_domain[num_dim] in [-1, 1] and first_domain[num_dim] != second_domain[num_dim]:\n",
    "            first_reach_dim = num_dim\n",
    "            break\n",
    "    # Calculate delta t\n",
    "    speed = get_celerity(state, first_reach_dim)\n",
    "    if first_domain[first_reach_dim] in [1, -1]:\n",
    "        if second_domain[first_reach_dim] == 1:\n",
    "            delta_cons = 1 / speed\n",
    "            delta_var = 0\n",
    "        elif second_domain[first_reach_dim] == -1:\n",
    "            delta_cons = (-1) / speed\n",
    "            delta_var = 0\n",
    "    else:\n",
    "        if second_domain[first_reach_dim] == 1:\n",
    "            delta_cons = 1 / speed\n",
    "            delta_var = (-1) / speed\n",
    "        elif second_domain[first_reach_dim] == -1:\n",
    "            delta_cons = 0\n",
    "            delta_var = (-1) / speed\n",
    "    # calculate transition matrix\n",
    "    nb_dim = len(second_domain)\n",
    "    # the supplementary dimension is 1\n",
    "    t_m = np.zeros((nb_dim + 1, nb_dim + 1))\n",
    "    t_m[nb_dim][nb_dim] = 1\n",
    "    delta1 = time.time()\n",
    "    for num_dim in range(nb_dim):\n",
    "        if num_dim == first_reach_dim:\n",
    "            # for first reached dimension\n",
    "            if second_domain[first_reach_dim] == 1:\n",
    "                t_m[first_reach_dim][nb_dim] = 1\n",
    "            elif second_domain[first_reach_dim] == -1:\n",
    "                t_m[first_reach_dim][nb_dim] = 0\n",
    "        else:\n",
    "            # slide\n",
    "            if second_domain[num_dim] in [-1, 1] and second_domain[num_dim] == first_domain[num_dim]:\n",
    "                t_m[num_dim][num_dim] = 1\n",
    "            else:\n",
    "                # normal tranform x_new = x + c * delta_t\n",
    "                current_speed = get_celerity(state, num_dim)\n",
    "                t_m[num_dim][num_dim] = 1\n",
    "                t_m[num_dim][first_reach_dim] = current_speed * delta_var\n",
    "                t_m[num_dim][nb_dim] = current_speed * delta_cons\n",
    "    return t_m\n",
    "\n",
    "\n",
    "def get_transition_cross_state(state1, state2):\n",
    "    \"\"\"\n",
    "    state1: '0101'\n",
    "    state2: '0100'\n",
    "    \"\"\"\n",
    "    nb_dim = len(state1)\n",
    "    # initialize transiton matrix\n",
    "    t_m = np.zeros((nb_dim + 1, nb_dim + 1))\n",
    "    t_m[nb_dim][nb_dim] = 1\n",
    "    for dim_i in range(nb_dim):\n",
    "        t_m[dim_i][dim_i] = 1\n",
    "        if state2[dim_i] > state1[dim_i]:\n",
    "            t_m[dim_i][nb_dim] = -1\n",
    "        elif state2[dim_i] < state1[dim_i]:\n",
    "            t_m[dim_i][nb_dim] = 1\n",
    "    return t_m\n",
    "\n",
    "\n",
    "def get_fixed_point(A):\n",
    "    nb_dim = A.shape[0]\n",
    "    iden = np.zeros((nb_dim, nb_dim))\n",
    "    for i_dim in range(nb_dim):\n",
    "        iden[i_dim][i_dim] = 1\n",
    "    X = np.subtract(A, iden)\n",
    "    b = np.zeros(nb_dim)\n",
    "    fixed_point = np.linalg.solve(X, b)\n",
    "    return fixed_point\n",
    "\n",
    "\n",
    "def get_constraint1(discrete_domain):\n",
    "    dim_free = []\n",
    "    for one_dim in range(len(discrete_domain)):\n",
    "        if discrete_domain[one_dim] not in [-1, 1]:\n",
    "            dim_free = dim_free + [one_dim]\n",
    "    last_constraint_a = np.zeros((2 * len(dim_free), len(discrete_domain)))\n",
    "    last_constraint_b = np.zeros((2 * len(dim_free), 1))\n",
    "    for one_dim in range(len(dim_free)):\n",
    "        last_constraint_a[one_dim * 2][dim_free[one_dim]] = 1\n",
    "        last_constraint_a[one_dim * 2 + 1][dim_free[one_dim]] = -1\n",
    "        last_constraint_b[one_dim * 2][0] = 1\n",
    "        last_constraint_b[one_dim * 2 + 1][0] = 0\n",
    "    return last_constraint_a, last_constraint_b\n",
    "\n",
    "\n",
    "def get_stable_zone(one_trajectory):\n",
    "    len_state = len(one_trajectory)\n",
    "    nb_dim = len(list_entite)\n",
    "    t_m = np.zeros((nb_dim + 1, nb_dim + 1))\n",
    "    cons_a = np.zeros((1, nb_dim))\n",
    "    cons_b = np.ones((1, 1))\n",
    "    for dim_i in range(nb_dim + 1):\n",
    "        t_m[dim_i][dim_i] = 1\n",
    "    for i_state in range(len_state):\n",
    "        current_discrete_state = list(one_trajectory[i_state].keys())[0]\n",
    "        if i_state < len_state - 1:\n",
    "            post_discrete_state = list(one_trajectory[i_state + 1].keys())[0]\n",
    "        current_discrete_trajectory = one_trajectory[i_state][current_discrete_state]\n",
    "        len_domain = len(current_discrete_trajectory)\n",
    "        for i_domain in range(len_domain):\n",
    "            # calculate current constraints\n",
    "            current_cons_a, current_cons_b = get_constraint1(current_discrete_trajectory[i_domain])\n",
    "            new_cons_a = np.matmul(current_cons_a, t_m[:-1, :-1])\n",
    "            temp_b = np.matmul(current_cons_a, t_m[:-1, -1])\n",
    "            new_cons_b = current_cons_b - temp_b.reshape(temp_b.shape[0], 1)\n",
    "            cons_a = np.vstack([cons_a, new_cons_a])\n",
    "            cons_b = np.vstack([cons_b, new_cons_b])\n",
    "            # calculate next transition matrix\n",
    "            if i_domain < len_domain - 1:\n",
    "                current_transition_matrix = get_transition_matrix(current_discrete_state,\n",
    "                                                                  current_discrete_trajectory[i_domain],\n",
    "                                                                  current_discrete_trajectory[i_domain + 1])\n",
    "                t_m = np.matmul(current_transition_matrix, t_m)\n",
    "            elif i_domain == len_domain - 1 and i_state < len_state - 1:\n",
    "                current_transition_matrix = get_transition_cross_state(current_discrete_state, post_discrete_state)\n",
    "                t_m = np.matmul(current_transition_matrix, t_m)\n",
    "    # regularise the constrains in the first discrete domain\n",
    "    first_discrete_state = list(one_trajectory[0].keys())[0]\n",
    "    first_domain = one_trajectory[0][first_discrete_state][0]\n",
    "    for num_dim in range(len(first_domain)):\n",
    "        if first_domain[num_dim] == -1:\n",
    "            cons_a[:, num_dim] = 0\n",
    "        elif first_domain[num_dim] == 1:\n",
    "            cons_b = cons_b - cons_a[:, num_dim].reshape(cons_a[:, num_dim].shape[0], 1)\n",
    "            cons_a[:, num_dim] = 0\n",
    "    c = np.zeros((cons_a.shape[1],))\n",
    "    res = linprog(c, cons_a, cons_b)\n",
    "    if res.success == False:\n",
    "        return False, [cons_a, cons_b]\n",
    "    else:\n",
    "        return True, [cons_a, cons_b]\n",
    "\n",
    "\n",
    "def dfs(graph, trace, start):\n",
    "    global cycles\n",
    "    global reached\n",
    "    trace = dc(trace)\n",
    "    if start in trace:\n",
    "        index = trace.index(start)\n",
    "        tmp = [i for i in trace[index:]]\n",
    "        temp_bool = False\n",
    "        for ele in cycles:\n",
    "            if same(ele, tmp) == True:\n",
    "                temp_bool = True\n",
    "        if temp_bool == False:\n",
    "            cycles = cycles + [tmp]\n",
    "        return\n",
    "    if start not in reached:\n",
    "        reached = reached + [start]\n",
    "    trace.append(start)\n",
    "    for i in graph[start]:\n",
    "        dfs(graph, trace, i)\n",
    "\n",
    "\n",
    "def same(list1, list2):\n",
    "    if len(list1) != len(list2):\n",
    "        return False\n",
    "    elif list1[0] not in list2:\n",
    "        return False\n",
    "    else:\n",
    "        length = len(list1)\n",
    "        first = list2.index(list1[0])\n",
    "        for i in range(length):\n",
    "            if list1[i] != list2[(first + i) % length]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "def get_next_state(cycle, state):\n",
    "    len_cycle = len(cycle)\n",
    "    i_c = cycle.index(state)\n",
    "    if i_c < len_cycle - 1:\n",
    "        return cycle[i_c + 1]\n",
    "    elif i_c == len_cycle - 1:\n",
    "        return cycle[0]\n",
    "\n",
    "\n",
    "def dfs_discrete_all(domain, s_domain, state, cycle, t_m, s_z):\n",
    "    \"\"\"\n",
    "    domain: [1,-1,1]\n",
    "    s_domain: current discrete trajectory without domain [{'01':[[-1,1],[0,-1]]},{}]\n",
    "    state: discrete state of domain\n",
    "    cycle: the cycle of discrete state\n",
    "    t_m: transition matrix without considering domain\n",
    "    s_z: stable zone without considering domain\n",
    "    \"\"\"\n",
    "    global list_discrete_trajectory\n",
    "    global list_transition_matrix\n",
    "    global list_stable_zone\n",
    "    global list_cycle\n",
    "    s_domain = dc(s_domain)\n",
    "    t_m = dc(t_m)\n",
    "    s_z = dc(s_z)\n",
    "    cycle = dc(cycle)\n",
    "    domain = dc(domain)\n",
    "    state = dc(state)\n",
    "    #     print('s_domain',s_domain)\n",
    "    #     print('domain',domain)\n",
    "    #     print('state',state)\n",
    "    #     print('cycle',cycle)\n",
    "    #     print('t_m',t_m)\n",
    "    #     print('s_z',s_z)\n",
    "\n",
    "    if len(cycle) > 1 and state == cycle[0]:\n",
    "        list_discrete_trajectory = list_discrete_trajectory + [s_domain]\n",
    "        list_transition_matrix = list_transition_matrix + [t_m]\n",
    "        list_stable_zone = list_stable_zone + [s_z]\n",
    "        list_cycle = list_cycle + [cycle]\n",
    "        return\n",
    "    elif len(cycle) > 1 and state in cycle[:-1] and state != cycle[0]:\n",
    "        return\n",
    "    # step1: add domain to s_domain\n",
    "    if len(s_domain) == 0:\n",
    "        new_dict = dict()\n",
    "        new_dict[state] = [dc(domain)]\n",
    "        s_domain = [new_dict]\n",
    "        s_z_a, s_z_b = get_constraint1(domain)\n",
    "        s_z = [s_z_a, s_z_b]\n",
    "        cycle = cycle + [dc(state)]\n",
    "\n",
    "        # instant transition\n",
    "        instant = False\n",
    "        for i_dim in range(len(domain)):\n",
    "            if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                next_domain = dc(domain)\n",
    "                next_domain[i_dim] = -1\n",
    "                next_state = dc(state)\n",
    "                next_state = list(next_state)\n",
    "                next_state[i_dim] = str(int(next_state[i_dim]) + 1)\n",
    "                next_state = \"\".join(next_state)\n",
    "                dfs_discrete_all(next_domain, s_domain, next_state, cycle, t_m, s_z)\n",
    "                instant = True\n",
    "                break\n",
    "            elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                next_domain = dc(domain)\n",
    "                next_domain[i_dim] = 1\n",
    "                next_state = dc(state)\n",
    "                next_state = list(next_state)\n",
    "                next_state[i_dim] = str(int(next_state[i_dim]) - 1)\n",
    "                next_state = \"\".join(next_state)\n",
    "                dfs_discrete_all(next_domain, s_domain, next_state, cycle, t_m, s_z)\n",
    "                instant = True\n",
    "                break\n",
    "\n",
    "        # non instant transition\n",
    "        if instant == False:\n",
    "            for i_dim in range(len(domain)):\n",
    "                if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'input':\n",
    "                    domain[i_dim] = 0\n",
    "                elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'input':\n",
    "                    domain[i_dim] = 0\n",
    "            for i_dim in range(len(domain)):\n",
    "                if domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = 1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "                elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = -1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "                elif domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'attractif':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = 1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "                elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'attractif':\n",
    "                    new_domain = dc(domain)\n",
    "                    new_domain[i_dim] = -1\n",
    "                    dfs_discrete_all(new_domain, s_domain, state, cycle, t_m, s_z)\n",
    "    else:\n",
    "        # calculate new transition matrix\n",
    "        current_state = list(s_domain[-1].keys())[0]\n",
    "        if current_state == state:\n",
    "            last_domain = s_domain[-1][current_state][-1]\n",
    "            temp_t_m = get_transition_matrix(state, last_domain, domain)\n",
    "        elif current_state != state:\n",
    "            temp_t_m = get_transition_cross_state(current_state, state)\n",
    "        #         print('temp_t_m',temp_t_m)\n",
    "        new_t_m = np.matmul(temp_t_m, t_m)\n",
    "        # calculate new constraint\n",
    "        c_a, c_b = get_constraint1(domain)\n",
    "        new_a = np.matmul(c_a, new_t_m[:-1, :-1])\n",
    "        temp_b = np.matmul(c_a, new_t_m[:-1, -1])\n",
    "        new_b = c_b - temp_b.reshape(temp_b.shape[0], 1)\n",
    "        # regulate the constraint considering the first domain\n",
    "        first_state = cycle[0]\n",
    "        first_domain = s_domain[0][first_state][0]\n",
    "        for num_dim in range(len(first_domain)):\n",
    "            if first_domain[num_dim] == -1:\n",
    "                new_a[:, num_dim] = 0\n",
    "            elif first_domain[num_dim] == 1:\n",
    "                new_b = new_b - new_a[:, num_dim].reshape(new_a[:, num_dim].shape[0], 1)\n",
    "                new_a[:, num_dim] = 0\n",
    "        #         print('new_a',new_a)\n",
    "        #         print('new_b',new_b)\n",
    "        #         print('************')\n",
    "        new_s_z_a = np.vstack([s_z[0], new_a])\n",
    "        new_s_z_b = np.vstack([s_z[1], new_b])\n",
    "        c = np.zeros((new_s_z_a.shape[1],))\n",
    "        try:\n",
    "            res = linprog(c, new_s_z_a, new_s_z_b)\n",
    "            add_bool = res.success\n",
    "        except:\n",
    "            add_bool = False\n",
    "        if add_bool == False:\n",
    "            # path end without returning a discrete trajectory\n",
    "            return\n",
    "        else:\n",
    "            # add domain to s_domain\n",
    "            if current_state == state:\n",
    "                s_domain[-1][state] = s_domain[-1][state] + [dc(domain)]\n",
    "            elif current_state != state:\n",
    "                new_dict = dict()\n",
    "                new_dict[state] = [dc(domain)]\n",
    "                s_domain = s_domain + [new_dict]\n",
    "                cycle = cycle + [dc(state)]\n",
    "            # choose all possible next domain\n",
    "\n",
    "            # instant transition\n",
    "            instant = False\n",
    "            for i_dim in range(len(domain)):\n",
    "                if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                    next_domain = dc(domain)\n",
    "                    next_domain[i_dim] = -1\n",
    "                    next_state = dc(state)\n",
    "                    next_state = list(next_state)\n",
    "                    next_state[i_dim] = str(int(next_state[i_dim]) + 1)\n",
    "                    next_state = \"\".join(next_state)\n",
    "                    dfs_discrete_all(next_domain, s_domain, next_state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    instant = True\n",
    "                    break\n",
    "                elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                    next_domain = dc(domain)\n",
    "                    next_domain[i_dim] = 1\n",
    "                    next_state = dc(state)\n",
    "                    next_state = list(next_state)\n",
    "                    next_state[i_dim] = str(int(next_state[i_dim]) - 1)\n",
    "                    next_state = \"\".join(next_state)\n",
    "                    dfs_discrete_all(next_domain, s_domain, next_state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    instant = True\n",
    "                    break\n",
    "\n",
    "            # non instant transition\n",
    "            if instant == False:\n",
    "                for i_dim in range(len(domain)):\n",
    "                    if domain[i_dim] == 1 and classify_boundary(state, i_dim, 1) == 'input':\n",
    "                        domain[i_dim] = 0\n",
    "                    elif domain[i_dim] == -1 and classify_boundary(state, i_dim, -1) == 'input':\n",
    "                        domain[i_dim] = 0\n",
    "                for i_dim in range(len(domain)):\n",
    "                    if domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'output':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = 1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'output':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = -1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    elif domain[i_dim] != 1 and classify_boundary(state, i_dim, 1) == 'attractif':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = 1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "                    elif domain[i_dim] != -1 and classify_boundary(state, i_dim, -1) == 'attractif':\n",
    "                        new_domain = dc(domain)\n",
    "                        new_domain[i_dim] = -1\n",
    "                        dfs_discrete_all(new_domain, s_domain, state, cycle, new_t_m, [new_s_z_a, new_s_z_b])\n",
    "    return\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-23T11:48:11.563856Z",
     "start_time": "2022-09-23T11:48:10.750718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_entite = ['a','b','c']\n",
    "max_level = dict()\n",
    "max_level['a'] = 1\n",
    "max_level['b'] = 1\n",
    "max_level['c'] = 1\n",
    "\n",
    "list_colums = []\n",
    "list_colums = list_colums + list_entite\n",
    "for one_ele in list_entite:\n",
    "    list_colums = list_colums + ['c_'+one_ele]\n",
    "celerities = pd.DataFrame(columns=list_colums)\n",
    "\n",
    "sca = 0.8\n",
    "scmax = 1.7\n",
    "sab = 1.4\n",
    "samax = 2.7\n",
    "sbc = 1.2\n",
    "sbmax = 3\n",
    "\n",
    "vac0a0=1\n",
    "vac0a1=1.9\n",
    "vac1a0=1.3\n",
    "vac1a1=0.4\n",
    "vba0b0=3.8\n",
    "vba0b1=2.5\n",
    "vba1b0=2.7\n",
    "vba1b1=3.3\n",
    "vcb0c0=1.5\n",
    "vcb0c1=0.8\n",
    "vcb1c0=1.9\n",
    "vcb1c1=1.5\n",
    "\n",
    "num = 20\n",
    "initial_state  = (0.5,0.7,0.8)\n",
    "nb = 10\n",
    "\n",
    "noise1 = 0.2\n",
    "noise2 = 0.2\n",
    "noise3 = 0.2\n",
    "\n",
    "cac0a0=vac0a0/(sab - 0)\n",
    "cac0a1=vac0a1/(samax - sab)\n",
    "cac1a0=vac1a0/(sab - 0)\n",
    "cac1a1=vac1a1/(samax - sab)\n",
    "cba0b0=vba0b0/(sbc - 0)\n",
    "cba0b1=vba0b1/(sbmax - sbc)\n",
    "cba1b0=vba1b0/(sbc - 0)\n",
    "cba1b1=vba1b1/(sbmax - sbc)\n",
    "ccb0c0=vcb0c0/(sca - 0)\n",
    "ccb0c1=vcb0c1/(scmax -sca)\n",
    "ccb1c0=vcb1c0/(sca - 0)\n",
    "ccb1c1=vcb1c1/(scmax -sca)\n",
    "\n",
    "df1 = pd.DataFrame([[0,0,0,cac0a0,cba0b0,ccb0c0]],columns=list_colums)\n",
    "df2 = pd.DataFrame([[0,0,1,-cac1a0,cba0b0,ccb0c1]],columns=list_colums)\n",
    "df3 = pd.DataFrame([[0,1,0,cac0a0,cba0b1,-ccb1c0]],columns=list_colums)\n",
    "df4 = pd.DataFrame([[0,1,1,-cac1a0,cba0b1,-ccb1c1]],columns=list_colums)\n",
    "df5 = pd.DataFrame([[1,0,0,cac0a1,-cba1b0,ccb0c0]],columns=list_colums)\n",
    "df6 = pd.DataFrame([[1,0,1,-cac1a1,-cba1b0,ccb0c1]],columns=list_colums)\n",
    "df7 = pd.DataFrame([[1,1,0,cac0a1,-cba1b1,-ccb1c0]],columns=list_colums)\n",
    "df8 = pd.DataFrame([[1,1,1,-cac1a1,-cba1b1,-ccb1c1]],columns=list_colums)\n",
    "\n",
    "celerities = celerities.append(df1)\n",
    "celerities = celerities.append(df2)\n",
    "celerities = celerities.append(df3)\n",
    "celerities = celerities.append(df4)\n",
    "celerities = celerities.append(df5)\n",
    "celerities = celerities.append(df6)\n",
    "celerities = celerities.append(df7)\n",
    "celerities = celerities.append(df8)\n",
    "celerities['signature'] = celerities.apply(get_signature,axis=1)\n",
    "\n",
    "ini_discrete = ''\n",
    "ini_fractional = []\n",
    "if initial_state[0]>=sab:\n",
    "    ini_discrete = ini_discrete+'1'\n",
    "    ini_fractional = ini_fractional + [(initial_state[0]-sab)/(samax - sab)]\n",
    "elif initial_state[0]<sab:\n",
    "    ini_discrete = ini_discrete+'0'\n",
    "    ini_fractional = ini_fractional + [initial_state[0]/sab]\n",
    "    \n",
    "if initial_state[1]>=sbc:\n",
    "    ini_discrete = ini_discrete+'1'\n",
    "    ini_fractional = ini_fractional + [(initial_state[1]-sbc)/(sbmax - sbc)]\n",
    "elif initial_state[1]<sbc:\n",
    "    ini_discrete = ini_discrete+'0'\n",
    "    ini_fractional = ini_fractional + [initial_state[1]/sbc]\n",
    "    \n",
    "if initial_state[2]>=sca:\n",
    "    ini_discrete = ini_discrete+'1'\n",
    "    ini_fractional = ini_fractional + [(initial_state[2]-sca)/(scmax - sca)]\n",
    "elif initial_state[2]<sca:\n",
    "    ini_discrete = ini_discrete+'0'\n",
    "    ini_fractional = ini_fractional + [initial_state[2]/sca]\n",
    "    \n",
    "data,t = simulation(ini_discrete,ini_fractional,num)\n",
    "real_data = dc(data)\n",
    "for i in range(data.shape[0]):\n",
    "    if data[i][0] < 1:\n",
    "        real_data[i][0] = data[i][0]*sab\n",
    "    elif data[i][0] >= 1:\n",
    "        real_data[i][0] = (data[i][0] - 1)*(samax - sab) + sab\n",
    "    if data[i][1] < 1:\n",
    "        real_data[i][1] = data[i][1]*sbc\n",
    "    elif data[i][1] >= 1:\n",
    "        real_data[i][1] = (data[i][1] - 1)*(sbmax - sbc) + sbc\n",
    "    if data[i][2] < 1:\n",
    "        real_data[i][2] = data[i][2]*sca\n",
    "    elif data[i][2] >= 1:\n",
    "        real_data[i][2] = (data[i][2] - 1)*(scmax - sca) + sca\n",
    "noise_data = np.zeros((nb+1,3))\n",
    "delta_t = t[-1][0]/nb\n",
    "new_t = np.zeros((nb+1,1))\n",
    "for i in range(nb+1):\n",
    "    new_t[i][0] = i*delta_t\n",
    "    for j in range(t.shape[0]-1):\n",
    "        if t[j][0] <= new_t[i][0] and t[j+1][0] >= new_t[i][0]:\n",
    "            noise_data[i][0] = random.gauss(0,noise1) + real_data[j][0] + (real_data[j+1][0] - real_data[j][0])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "            noise_data[i][1] = random.gauss(0,noise2) + real_data[j][1] + (real_data[j+1][1] - real_data[j][1])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "            noise_data[i][2] = random.gauss(0,noise3) + real_data[j][2] + (real_data[j+1][2] - real_data[j][2])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "            break\n",
    "plt.plot(new_t[0:nb],noise_data[0:nb,0],label='a')\n",
    "plt.plot(new_t[0:nb],noise_data[0:nb,1],label='b')\n",
    "plt.plot(new_t[0:nb],noise_data[0:nb,2],label='c')\n",
    "plt.legend()\n",
    "plt.savefig('simu1',dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cration du dataset avec n_sim simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "n_sim = 100\n",
    "nb = 100\n",
    "\n",
    "col2 = [\"sca\", \"sab\", \"sbc\", \"vac0a0\", \"vac0a1\", \n",
    "       \"vac1a0\", \"vac1a1\", \"vba0b0\", \"vba0b1\", \"vba1b0\", \"vba1b1\", \"vcb0c0\", \n",
    "       \"vcb0c1\", \"vcb1c0\", \"vcb1c1\"]\n",
    "dataset = np.zeros((n_sim, nb, 3))\n",
    "y = np.zeros((n_sim, len(col2)))\n",
    "\n",
    "for k in range(n_sim):\n",
    "    print(k)\n",
    "    list_entite = ['a','b','c']\n",
    "    max_level = dict()\n",
    "    max_level['a'] = 1\n",
    "    max_level['b'] = 1\n",
    "    max_level['c'] = 1\n",
    "\n",
    "    list_colums = []\n",
    "    list_colums = list_colums + list_entite\n",
    "    for one_ele in list_entite:\n",
    "        list_colums = list_colums + ['c_'+one_ele]\n",
    "    celerities = pd.DataFrame(columns=list_colums)\n",
    "\n",
    "    sca = random.uniform(0, 1)\n",
    "    scmax = 1\n",
    "    sab = random.uniform(0, 1)\n",
    "    samax = 1\n",
    "    sbc = random.uniform(0, 1)\n",
    "    sbmax = 1\n",
    "\n",
    "    vac0a0=random.uniform(0, 10)\n",
    "    vac0a1=random.uniform(0, 10)\n",
    "    vac1a0=random.uniform(0, 10)\n",
    "    vac1a1=random.uniform(0, 10)\n",
    "    vba0b0=random.uniform(0, 10)\n",
    "    vba0b1=random.uniform(0, 10)\n",
    "    vba1b0=random.uniform(0, 10)\n",
    "    vba1b1=random.uniform(0, 10)\n",
    "    vcb0c0=random.uniform(0, 10)\n",
    "    vcb0c1=random.uniform(0, 10)\n",
    "    vcb1c0=random.uniform(0, 10)\n",
    "    vcb1c1=random.uniform(0, 10)\n",
    "\n",
    "    num = 20\n",
    "    initial_state  = (0.5,0.7,0.8)\n",
    "\n",
    "    noise1 = 0\n",
    "    noise2 = 0\n",
    "    noise3 = 0\n",
    "\n",
    "    cac0a0=vac0a0/(sab - 0)\n",
    "    cac0a1=vac0a1/(samax - sab)\n",
    "    cac1a0=vac1a0/(sab - 0)\n",
    "    cac1a1=vac1a1/(samax - sab)\n",
    "    cba0b0=vba0b0/(sbc - 0)\n",
    "    cba0b1=vba0b1/(sbmax - sbc)\n",
    "    cba1b0=vba1b0/(sbc - 0)\n",
    "    cba1b1=vba1b1/(sbmax - sbc)\n",
    "    ccb0c0=vcb0c0/(sca - 0)\n",
    "    ccb0c1=vcb0c1/(scmax -sca)\n",
    "    ccb1c0=vcb1c0/(sca - 0)\n",
    "    ccb1c1=vcb1c1/(scmax -sca)\n",
    "\n",
    "    df1 = pd.DataFrame([[0,0,0,cac0a0,cba0b0,ccb0c0]],columns=list_colums)\n",
    "    df2 = pd.DataFrame([[0,0,1,-cac1a0,cba0b0,ccb0c1]],columns=list_colums)\n",
    "    df3 = pd.DataFrame([[0,1,0,cac0a0,cba0b1,-ccb1c0]],columns=list_colums)\n",
    "    df4 = pd.DataFrame([[0,1,1,-cac1a0,cba0b1,-ccb1c1]],columns=list_colums)\n",
    "    df5 = pd.DataFrame([[1,0,0,cac0a1,-cba1b0,ccb0c0]],columns=list_colums)\n",
    "    df6 = pd.DataFrame([[1,0,1,-cac1a1,-cba1b0,ccb0c1]],columns=list_colums)\n",
    "    df7 = pd.DataFrame([[1,1,0,cac0a1,-cba1b1,-ccb1c0]],columns=list_colums)\n",
    "    df8 = pd.DataFrame([[1,1,1,-cac1a1,-cba1b1,-ccb1c1]],columns=list_colums)\n",
    "\n",
    "    celerities = celerities.append(df1)\n",
    "    celerities = celerities.append(df2)\n",
    "    celerities = celerities.append(df3)\n",
    "    celerities = celerities.append(df4)\n",
    "    celerities = celerities.append(df5)\n",
    "    celerities = celerities.append(df6)\n",
    "    celerities = celerities.append(df7)\n",
    "    celerities = celerities.append(df8)\n",
    "    celerities['signature'] = celerities.apply(get_signature,axis=1)\n",
    "\n",
    "    ini_discrete = ''\n",
    "    ini_fractional = []\n",
    "    if initial_state[0]>=sab:\n",
    "        ini_discrete = ini_discrete+'1'\n",
    "        ini_fractional = ini_fractional + [(initial_state[0]-sab)/(samax - sab)]\n",
    "    elif initial_state[0]<sab:\n",
    "        ini_discrete = ini_discrete+'0'\n",
    "        ini_fractional = ini_fractional + [initial_state[0]/sab]\n",
    "\n",
    "    if initial_state[1]>=sbc:\n",
    "        ini_discrete = ini_discrete+'1'\n",
    "        ini_fractional = ini_fractional + [(initial_state[1]-sbc)/(sbmax - sbc)]\n",
    "    elif initial_state[1]<sbc:\n",
    "        ini_discrete = ini_discrete+'0'\n",
    "        ini_fractional = ini_fractional + [initial_state[1]/sbc]\n",
    "\n",
    "    if initial_state[2]>=sca:\n",
    "        ini_discrete = ini_discrete+'1'\n",
    "        ini_fractional = ini_fractional + [(initial_state[2]-sca)/(scmax - sca)]\n",
    "    elif initial_state[2]<sca:\n",
    "        ini_discrete = ini_discrete+'0'\n",
    "        ini_fractional = ini_fractional + [initial_state[2]/sca]\n",
    "\n",
    "    data,t = simulation(ini_discrete,ini_fractional,num)\n",
    "    real_data = dc(data)\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i][0] < 1:\n",
    "            real_data[i][0] = data[i][0]*sab\n",
    "        elif data[i][0] >= 1:\n",
    "            real_data[i][0] = (data[i][0] - 1)*(samax - sab) + sab\n",
    "        if data[i][1] < 1:\n",
    "            real_data[i][1] = data[i][1]*sbc\n",
    "        elif data[i][1] >= 1:\n",
    "            real_data[i][1] = (data[i][1] - 1)*(sbmax - sbc) + sbc\n",
    "        if data[i][2] < 1:\n",
    "            real_data[i][2] = data[i][2]*sca\n",
    "        elif data[i][2] >= 1:\n",
    "            real_data[i][2] = (data[i][2] - 1)*(scmax - sca) + sca\n",
    "    noise_data = np.zeros((nb+1,3))\n",
    "    delta_t = t[-1][0]/nb\n",
    "    new_t = np.zeros((nb+1,1))\n",
    "    for i in range(nb+1):\n",
    "        new_t[i][0] = i*delta_t\n",
    "        for j in range(t.shape[0]-1):\n",
    "            if t[j][0] <= new_t[i][0] and t[j+1][0] >= new_t[i][0]:\n",
    "                noise_data[i][0] = random.gauss(0,noise1) + real_data[j][0] + (real_data[j+1][0] - real_data[j][0])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                noise_data[i][1] = random.gauss(0,noise2) + real_data[j][1] + (real_data[j+1][1] - real_data[j][1])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                noise_data[i][2] = random.gauss(0,noise3) + real_data[j][2] + (real_data[j+1][2] - real_data[j][2])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                break\n",
    "    #plt.plot(new_t[0:nb],noise_data[0:nb,0],label='a')\n",
    "    #plt.plot(new_t[0:nb],noise_data[0:nb,1],label='b')\n",
    "    #plt.plot(new_t[0:nb],noise_data[0:nb,2],label='c')\n",
    "    #plt.legend()\n",
    "    #plt.savefig('simu1',dpi=1200)\n",
    "    \n",
    "    dataset[k, :, 0] = noise_data[0:nb,0]\n",
    "    dataset[k, :, 1] = noise_data[0:nb,1]\n",
    "    dataset[k, :, 2] = noise_data[0:nb,2]\n",
    "\n",
    "    y[k, :] = [sca, sab, sbc, vac0a0, vac0a1, vac1a0, vac1a1, \n",
    "            vba0b0, vba0b1, vba1b0, vba1b1, vcb0c0, vcb0c1, vcb1c0, vcb1c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, SimpleRNN, concatenate, LSTM, Conv1D, Activation\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, key):\n",
    "    plt.plot(history.history[key])\n",
    "    plt.plot(history.history['val_'+key])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(key)\n",
    "    plt.legend([key, 'val_'+key])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rseau de neurones pour prdire les 15 paramtres *model1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, y, train_size = 0.7, shuffle = False)\n",
    "X_train = np.asarray(X_train)\n",
    "#print(np.shape(X_train))\n",
    "y_train = np.asarray(y_train)\n",
    "#print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 10, 256)           1024      \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 10, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 10, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 15)                19215     \n",
      "=================================================================\n",
      "Total params: 86,159\n",
      "Trainable params: 86,159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 1000\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(Dense(units=256, activation='relu', input_shape=(dataset.shape[1], dataset.shape[2])))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "model1.add(Dense(units=128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(units=128, activation='relu'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Dense(units=128, activation='linear'))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(units=15))\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 60ms/step - loss: 3.7374 - mean_absolute_error: 3.7091 - val_loss: 2.8860 - val_mean_absolute_error: 2.8613\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.4542 - mean_absolute_error: 2.4515 - val_loss: 2.2266 - val_mean_absolute_error: 2.2256\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 2.1785 - mean_absolute_error: 2.1780 - val_loss: 2.2100 - val_mean_absolute_error: 2.1833\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1439 - mean_absolute_error: 2.1410 - val_loss: 2.0955 - val_mean_absolute_error: 2.0875\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.1107 - mean_absolute_error: 2.1106 - val_loss: 2.0945 - val_mean_absolute_error: 2.0858\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0826 - mean_absolute_error: 2.0831 - val_loss: 2.0897 - val_mean_absolute_error: 2.0796\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0737 - mean_absolute_error: 2.0755 - val_loss: 2.0875 - val_mean_absolute_error: 2.0778\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.0662 - mean_absolute_error: 2.0655 - val_loss: 2.0802 - val_mean_absolute_error: 2.0673\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0642 - mean_absolute_error: 2.0606 - val_loss: 2.0691 - val_mean_absolute_error: 2.0592\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0633 - mean_absolute_error: 2.0668 - val_loss: 2.0727 - val_mean_absolute_error: 2.0578\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0450 - mean_absolute_error: 2.0467 - val_loss: 2.0580 - val_mean_absolute_error: 2.0480\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 2.0378 - mean_absolute_error: 2.0364 - val_loss: 2.0793 - val_mean_absolute_error: 2.0596\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.0392 - mean_absolute_error: 2.0369 - val_loss: 2.0386 - val_mean_absolute_error: 2.0290\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0073 - mean_absolute_error: 2.0069 - val_loss: 2.0366 - val_mean_absolute_error: 2.0255\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 2.0037 - mean_absolute_error: 2.0028 - val_loss: 2.0324 - val_mean_absolute_error: 2.0175\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9866 - mean_absolute_error: 1.9880 - val_loss: 2.0260 - val_mean_absolute_error: 2.0152\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.9751 - mean_absolute_error: 1.9770 - val_loss: 2.0206 - val_mean_absolute_error: 2.0116\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9742 - mean_absolute_error: 1.9773 - val_loss: 2.0241 - val_mean_absolute_error: 2.0141\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9698 - mean_absolute_error: 1.9713 - val_loss: 2.0107 - val_mean_absolute_error: 2.0046\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9592 - mean_absolute_error: 1.9643 - val_loss: 2.0127 - val_mean_absolute_error: 2.0033\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.9515 - mean_absolute_error: 1.9498 - val_loss: 2.0030 - val_mean_absolute_error: 1.9977\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9525 - mean_absolute_error: 1.9526 - val_loss: 2.0161 - val_mean_absolute_error: 2.0036\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9389 - mean_absolute_error: 1.9369 - val_loss: 1.9992 - val_mean_absolute_error: 1.9880\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9356 - mean_absolute_error: 1.9347 - val_loss: 1.9976 - val_mean_absolute_error: 1.9877\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9227 - mean_absolute_error: 1.9266 - val_loss: 1.9944 - val_mean_absolute_error: 1.9851\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.9122 - mean_absolute_error: 1.9110 - val_loss: 1.9927 - val_mean_absolute_error: 1.9835\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.9093 - mean_absolute_error: 1.9097 - val_loss: 1.9889 - val_mean_absolute_error: 1.9807\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.9032 - mean_absolute_error: 1.9001 - val_loss: 1.9878 - val_mean_absolute_error: 1.9739\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8868 - mean_absolute_error: 1.8885 - val_loss: 1.9802 - val_mean_absolute_error: 1.9695\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8781 - mean_absolute_error: 1.8805 - val_loss: 1.9801 - val_mean_absolute_error: 1.9672\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.8725 - mean_absolute_error: 1.8732 - val_loss: 1.9652 - val_mean_absolute_error: 1.9587\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8564 - mean_absolute_error: 1.8540 - val_loss: 1.9648 - val_mean_absolute_error: 1.9562\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8493 - mean_absolute_error: 1.8468 - val_loss: 1.9674 - val_mean_absolute_error: 1.9597\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.8401 - mean_absolute_error: 1.8390 - val_loss: 1.9655 - val_mean_absolute_error: 1.9532\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.8458 - mean_absolute_error: 1.8417 - val_loss: 1.9930 - val_mean_absolute_error: 1.9770\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.8369 - mean_absolute_error: 1.8359 - val_loss: 2.0023 - val_mean_absolute_error: 1.9850\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.8387 - mean_absolute_error: 1.8401 - val_loss: 1.9739 - val_mean_absolute_error: 1.9618\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.8258 - mean_absolute_error: 1.8262 - val_loss: 1.9760 - val_mean_absolute_error: 1.9636\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.8092 - mean_absolute_error: 1.8084 - val_loss: 1.9856 - val_mean_absolute_error: 1.9690\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8108 - mean_absolute_error: 1.8102 - val_loss: 1.9789 - val_mean_absolute_error: 1.9618\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.8142 - mean_absolute_error: 1.8142 - val_loss: 1.9811 - val_mean_absolute_error: 1.9659\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.8095 - mean_absolute_error: 1.8060 - val_loss: 1.9850 - val_mean_absolute_error: 1.9704\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.8068 - mean_absolute_error: 1.8091 - val_loss: 1.9773 - val_mean_absolute_error: 1.9640\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.7982 - mean_absolute_error: 1.8016 - val_loss: 1.9756 - val_mean_absolute_error: 1.9611\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.8009 - mean_absolute_error: 1.8021 - val_loss: 1.9833 - val_mean_absolute_error: 1.9693\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7949 - mean_absolute_error: 1.7976 - val_loss: 1.9787 - val_mean_absolute_error: 1.9603\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7804 - mean_absolute_error: 1.7794 - val_loss: 1.9788 - val_mean_absolute_error: 1.9642\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.7806 - mean_absolute_error: 1.7777 - val_loss: 1.9838 - val_mean_absolute_error: 1.9655\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7854 - mean_absolute_error: 1.7832 - val_loss: 1.9878 - val_mean_absolute_error: 1.9766\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7670 - mean_absolute_error: 1.7680 - val_loss: 1.9766 - val_mean_absolute_error: 1.9612\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7710 - mean_absolute_error: 1.7724 - val_loss: 1.9788 - val_mean_absolute_error: 1.9638\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.7711 - mean_absolute_error: 1.7710 - val_loss: 1.9880 - val_mean_absolute_error: 1.9746\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.7658 - mean_absolute_error: 1.7651 - val_loss: 1.9895 - val_mean_absolute_error: 1.9765\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7543 - mean_absolute_error: 1.7512 - val_loss: 1.9932 - val_mean_absolute_error: 1.9829\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.7535 - mean_absolute_error: 1.7587 - val_loss: 1.9849 - val_mean_absolute_error: 1.9727\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.7462 - mean_absolute_error: 1.7457 - val_loss: 1.9909 - val_mean_absolute_error: 1.9795\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.7504 - mean_absolute_error: 1.7514 - val_loss: 1.9871 - val_mean_absolute_error: 1.9735\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.7470 - mean_absolute_error: 1.7464 - val_loss: 1.9831 - val_mean_absolute_error: 1.9688\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7373 - mean_absolute_error: 1.7419 - val_loss: 1.9874 - val_mean_absolute_error: 1.9729\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.7382 - mean_absolute_error: 1.7353 - val_loss: 1.9823 - val_mean_absolute_error: 1.9692\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7286 - mean_absolute_error: 1.7320 - val_loss: 1.9778 - val_mean_absolute_error: 1.9666\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.7285 - mean_absolute_error: 1.7334 - val_loss: 1.9835 - val_mean_absolute_error: 1.9714\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7321 - mean_absolute_error: 1.7305 - val_loss: 2.0001 - val_mean_absolute_error: 1.9863\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.7295 - mean_absolute_error: 1.7291 - val_loss: 2.0038 - val_mean_absolute_error: 1.9879\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7227 - mean_absolute_error: 1.7237 - val_loss: 1.9894 - val_mean_absolute_error: 1.9742\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.7026 - mean_absolute_error: 1.7027 - val_loss: 1.9905 - val_mean_absolute_error: 1.9803\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.7044 - mean_absolute_error: 1.7032 - val_loss: 2.0016 - val_mean_absolute_error: 1.9859\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.7251 - mean_absolute_error: 1.7270 - val_loss: 2.0112 - val_mean_absolute_error: 1.9905\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.7119 - mean_absolute_error: 1.7116 - val_loss: 1.9795 - val_mean_absolute_error: 1.9705\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7143 - mean_absolute_error: 1.7126 - val_loss: 1.9974 - val_mean_absolute_error: 1.9845\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6991 - mean_absolute_error: 1.6969 - val_loss: 2.0046 - val_mean_absolute_error: 1.9894\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.7022 - mean_absolute_error: 1.7073 - val_loss: 1.9828 - val_mean_absolute_error: 1.9713\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.7007 - mean_absolute_error: 1.6997 - val_loss: 1.9938 - val_mean_absolute_error: 1.9847\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.7074 - mean_absolute_error: 1.7084 - val_loss: 1.9828 - val_mean_absolute_error: 1.9721\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6994 - mean_absolute_error: 1.6970 - val_loss: 2.0004 - val_mean_absolute_error: 1.9837\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6881 - mean_absolute_error: 1.6870 - val_loss: 2.0094 - val_mean_absolute_error: 1.9890\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6930 - mean_absolute_error: 1.6916 - val_loss: 1.9966 - val_mean_absolute_error: 1.9852\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6881 - mean_absolute_error: 1.6896 - val_loss: 1.9957 - val_mean_absolute_error: 1.9848\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6939 - mean_absolute_error: 1.6974 - val_loss: 1.9984 - val_mean_absolute_error: 1.9884\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6808 - mean_absolute_error: 1.6798 - val_loss: 2.0058 - val_mean_absolute_error: 1.9904\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6783 - mean_absolute_error: 1.6757 - val_loss: 1.9983 - val_mean_absolute_error: 1.9852\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6791 - mean_absolute_error: 1.6795 - val_loss: 1.9994 - val_mean_absolute_error: 1.9835\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6682 - mean_absolute_error: 1.6699 - val_loss: 2.0114 - val_mean_absolute_error: 2.0013\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6929 - mean_absolute_error: 1.6941 - val_loss: 2.0103 - val_mean_absolute_error: 1.9926\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6822 - mean_absolute_error: 1.6853 - val_loss: 2.0195 - val_mean_absolute_error: 1.9983\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6831 - mean_absolute_error: 1.6830 - val_loss: 1.9957 - val_mean_absolute_error: 1.9837\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6664 - mean_absolute_error: 1.6670 - val_loss: 2.0126 - val_mean_absolute_error: 2.0024\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6596 - mean_absolute_error: 1.6619 - val_loss: 2.0093 - val_mean_absolute_error: 1.9987\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6713 - mean_absolute_error: 1.6708 - val_loss: 2.0153 - val_mean_absolute_error: 2.0006\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6678 - mean_absolute_error: 1.6714 - val_loss: 2.0129 - val_mean_absolute_error: 1.9991\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6558 - mean_absolute_error: 1.6531 - val_loss: 2.0066 - val_mean_absolute_error: 1.9951\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6650 - mean_absolute_error: 1.6637 - val_loss: 2.0076 - val_mean_absolute_error: 1.9942\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6408 - mean_absolute_error: 1.6401 - val_loss: 2.0101 - val_mean_absolute_error: 1.9995\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6522 - mean_absolute_error: 1.6519 - val_loss: 2.0162 - val_mean_absolute_error: 2.0053\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6558 - mean_absolute_error: 1.6555 - val_loss: 2.0202 - val_mean_absolute_error: 2.0104\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6631 - mean_absolute_error: 1.6614 - val_loss: 2.0100 - val_mean_absolute_error: 2.0031\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6527 - mean_absolute_error: 1.6540 - val_loss: 2.0167 - val_mean_absolute_error: 2.0015\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.6449 - mean_absolute_error: 1.6467 - val_loss: 2.0191 - val_mean_absolute_error: 2.0028\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6346 - mean_absolute_error: 1.6377 - val_loss: 2.0184 - val_mean_absolute_error: 2.0103\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6605 - mean_absolute_error: 1.6612 - val_loss: 2.0130 - val_mean_absolute_error: 2.0029\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6465 - mean_absolute_error: 1.6468 - val_loss: 2.0294 - val_mean_absolute_error: 2.0154\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.6297 - mean_absolute_error: 1.6312 - val_loss: 2.0220 - val_mean_absolute_error: 2.0051\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6355 - mean_absolute_error: 1.6390 - val_loss: 2.0196 - val_mean_absolute_error: 2.0064\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6352 - mean_absolute_error: 1.6361 - val_loss: 2.0223 - val_mean_absolute_error: 2.0091\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6327 - mean_absolute_error: 1.6318 - val_loss: 2.0171 - val_mean_absolute_error: 2.0053\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.6262 - mean_absolute_error: 1.6263 - val_loss: 2.0260 - val_mean_absolute_error: 2.0107\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6342 - mean_absolute_error: 1.6342 - val_loss: 2.0178 - val_mean_absolute_error: 2.0042\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6195 - mean_absolute_error: 1.6208 - val_loss: 2.0278 - val_mean_absolute_error: 2.0166\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.6373 - mean_absolute_error: 1.6384 - val_loss: 2.0282 - val_mean_absolute_error: 2.0104\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6189 - mean_absolute_error: 1.6174 - val_loss: 2.0293 - val_mean_absolute_error: 2.0165\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6246 - mean_absolute_error: 1.6284 - val_loss: 2.0275 - val_mean_absolute_error: 2.0130\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6191 - mean_absolute_error: 1.6186 - val_loss: 2.0291 - val_mean_absolute_error: 2.0124\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.6325 - mean_absolute_error: 1.6364 - val_loss: 2.0275 - val_mean_absolute_error: 2.0091\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6007 - mean_absolute_error: 1.6001 - val_loss: 2.0204 - val_mean_absolute_error: 2.0068\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6124 - mean_absolute_error: 1.6068 - val_loss: 2.0318 - val_mean_absolute_error: 2.0200\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6087 - mean_absolute_error: 1.6047 - val_loss: 2.0292 - val_mean_absolute_error: 2.0179\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6102 - mean_absolute_error: 1.6126 - val_loss: 2.0304 - val_mean_absolute_error: 2.0128\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5976 - mean_absolute_error: 1.5958 - val_loss: 2.0234 - val_mean_absolute_error: 2.0036\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.6139 - mean_absolute_error: 1.6144 - val_loss: 2.0372 - val_mean_absolute_error: 2.0211\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.6047 - mean_absolute_error: 1.6051 - val_loss: 2.0262 - val_mean_absolute_error: 2.0086\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.5992 - mean_absolute_error: 1.5999 - val_loss: 2.0292 - val_mean_absolute_error: 2.0112\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5925 - mean_absolute_error: 1.5922 - val_loss: 2.0308 - val_mean_absolute_error: 2.0137\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5934 - mean_absolute_error: 1.5921 - val_loss: 2.0321 - val_mean_absolute_error: 2.0162\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5881 - mean_absolute_error: 1.5876 - val_loss: 2.0399 - val_mean_absolute_error: 2.0233\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.5991 - mean_absolute_error: 1.5983 - val_loss: 2.0384 - val_mean_absolute_error: 2.0193\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5894 - mean_absolute_error: 1.5938 - val_loss: 2.0328 - val_mean_absolute_error: 2.0201\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5949 - mean_absolute_error: 1.5982 - val_loss: 2.0386 - val_mean_absolute_error: 2.0247\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5864 - mean_absolute_error: 1.5893 - val_loss: 2.0256 - val_mean_absolute_error: 2.0073\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5845 - mean_absolute_error: 1.5800 - val_loss: 2.0526 - val_mean_absolute_error: 2.0261\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5874 - mean_absolute_error: 1.5916 - val_loss: 2.0315 - val_mean_absolute_error: 2.0164\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5959 - mean_absolute_error: 1.5935 - val_loss: 2.0434 - val_mean_absolute_error: 2.0298\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5922 - mean_absolute_error: 1.5932 - val_loss: 2.0393 - val_mean_absolute_error: 2.0215\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.5798 - mean_absolute_error: 1.5767 - val_loss: 2.0352 - val_mean_absolute_error: 2.0181\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5798 - mean_absolute_error: 1.5807 - val_loss: 2.0413 - val_mean_absolute_error: 2.0257\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5816 - mean_absolute_error: 1.5808 - val_loss: 2.0369 - val_mean_absolute_error: 2.0165\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.5721 - mean_absolute_error: 1.5747 - val_loss: 2.0377 - val_mean_absolute_error: 2.0164\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.5634 - mean_absolute_error: 1.5640 - val_loss: 2.0371 - val_mean_absolute_error: 2.0228\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5790 - mean_absolute_error: 1.5787 - val_loss: 2.0386 - val_mean_absolute_error: 2.0174\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5779 - mean_absolute_error: 1.5774 - val_loss: 2.0431 - val_mean_absolute_error: 2.0234\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.5727 - mean_absolute_error: 1.5759 - val_loss: 2.0443 - val_mean_absolute_error: 2.0280\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5686 - mean_absolute_error: 1.5698 - val_loss: 2.0440 - val_mean_absolute_error: 2.0308\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5799 - mean_absolute_error: 1.5782 - val_loss: 2.0486 - val_mean_absolute_error: 2.0257\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5705 - mean_absolute_error: 1.5706 - val_loss: 2.0443 - val_mean_absolute_error: 2.0237\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5758 - mean_absolute_error: 1.5807 - val_loss: 2.0462 - val_mean_absolute_error: 2.0288\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5721 - mean_absolute_error: 1.5692 - val_loss: 2.0445 - val_mean_absolute_error: 2.0285\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5644 - mean_absolute_error: 1.5628 - val_loss: 2.0651 - val_mean_absolute_error: 2.0405\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5744 - mean_absolute_error: 1.5747 - val_loss: 2.0468 - val_mean_absolute_error: 2.0311\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5642 - mean_absolute_error: 1.5643 - val_loss: 2.0507 - val_mean_absolute_error: 2.0372\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5773 - mean_absolute_error: 1.5752 - val_loss: 2.0536 - val_mean_absolute_error: 2.0295\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5579 - mean_absolute_error: 1.5604 - val_loss: 2.0339 - val_mean_absolute_error: 2.0184\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5443 - mean_absolute_error: 1.5495 - val_loss: 2.0415 - val_mean_absolute_error: 2.0207\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5535 - mean_absolute_error: 1.5555 - val_loss: 2.0488 - val_mean_absolute_error: 2.0304\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5772 - mean_absolute_error: 1.5790 - val_loss: 2.0619 - val_mean_absolute_error: 2.0383\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5506 - mean_absolute_error: 1.5519 - val_loss: 2.0421 - val_mean_absolute_error: 2.0248\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5567 - mean_absolute_error: 1.5575 - val_loss: 2.0645 - val_mean_absolute_error: 2.0509\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5438 - mean_absolute_error: 1.5498 - val_loss: 2.0475 - val_mean_absolute_error: 2.0261\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5480 - mean_absolute_error: 1.5502 - val_loss: 2.0414 - val_mean_absolute_error: 2.0264\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5446 - mean_absolute_error: 1.5466 - val_loss: 2.0424 - val_mean_absolute_error: 2.0264\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.5378 - mean_absolute_error: 1.5371 - val_loss: 2.0537 - val_mean_absolute_error: 2.0371\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5396 - mean_absolute_error: 1.5416 - val_loss: 2.0501 - val_mean_absolute_error: 2.0332\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5337 - mean_absolute_error: 1.5366 - val_loss: 2.0577 - val_mean_absolute_error: 2.0419\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.5549 - mean_absolute_error: 1.5550 - val_loss: 2.0559 - val_mean_absolute_error: 2.0365\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5298 - mean_absolute_error: 1.5339 - val_loss: 2.0561 - val_mean_absolute_error: 2.0401\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5333 - mean_absolute_error: 1.5337 - val_loss: 2.0573 - val_mean_absolute_error: 2.0400\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.5169 - mean_absolute_error: 1.5177 - val_loss: 2.0566 - val_mean_absolute_error: 2.0451\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5476 - mean_absolute_error: 1.5473 - val_loss: 2.0508 - val_mean_absolute_error: 2.0297\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5233 - mean_absolute_error: 1.5221 - val_loss: 2.0536 - val_mean_absolute_error: 2.0378\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5311 - mean_absolute_error: 1.5315 - val_loss: 2.0511 - val_mean_absolute_error: 2.0324\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5200 - mean_absolute_error: 1.5202 - val_loss: 2.0571 - val_mean_absolute_error: 2.0356\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5209 - mean_absolute_error: 1.5230 - val_loss: 2.0604 - val_mean_absolute_error: 2.0374\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.5297 - mean_absolute_error: 1.5293 - val_loss: 2.0554 - val_mean_absolute_error: 2.0384\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5143 - mean_absolute_error: 1.5125 - val_loss: 2.0582 - val_mean_absolute_error: 2.0424\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5177 - mean_absolute_error: 1.5189 - val_loss: 2.0575 - val_mean_absolute_error: 2.0369\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5145 - mean_absolute_error: 1.5161 - val_loss: 2.0491 - val_mean_absolute_error: 2.0297\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5296 - mean_absolute_error: 1.5297 - val_loss: 2.0559 - val_mean_absolute_error: 2.0432\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5251 - mean_absolute_error: 1.5258 - val_loss: 2.0604 - val_mean_absolute_error: 2.0360\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.5104 - mean_absolute_error: 1.5128 - val_loss: 2.0646 - val_mean_absolute_error: 2.0383\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5237 - mean_absolute_error: 1.5231 - val_loss: 2.0592 - val_mean_absolute_error: 2.0445\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5166 - mean_absolute_error: 1.5186 - val_loss: 2.0557 - val_mean_absolute_error: 2.0317\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4998 - mean_absolute_error: 1.4976 - val_loss: 2.0596 - val_mean_absolute_error: 2.0364\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5122 - mean_absolute_error: 1.5128 - val_loss: 2.0595 - val_mean_absolute_error: 2.0398\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5003 - mean_absolute_error: 1.5053 - val_loss: 2.0593 - val_mean_absolute_error: 2.0407\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4997 - mean_absolute_error: 1.4979 - val_loss: 2.0684 - val_mean_absolute_error: 2.0445\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4980 - mean_absolute_error: 1.4977 - val_loss: 2.0618 - val_mean_absolute_error: 2.0371\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4997 - mean_absolute_error: 1.5008 - val_loss: 2.0603 - val_mean_absolute_error: 2.0396\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5049 - mean_absolute_error: 1.5055 - val_loss: 2.0627 - val_mean_absolute_error: 2.0433\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5027 - mean_absolute_error: 1.5039 - val_loss: 2.0623 - val_mean_absolute_error: 2.0496\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5088 - mean_absolute_error: 1.5100 - val_loss: 2.0762 - val_mean_absolute_error: 2.0595\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5080 - mean_absolute_error: 1.5117 - val_loss: 2.0677 - val_mean_absolute_error: 2.0435\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5071 - mean_absolute_error: 1.5100 - val_loss: 2.0663 - val_mean_absolute_error: 2.0474\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4930 - mean_absolute_error: 1.4962 - val_loss: 2.0545 - val_mean_absolute_error: 2.0344\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4863 - mean_absolute_error: 1.4884 - val_loss: 2.0681 - val_mean_absolute_error: 2.0495\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5013 - mean_absolute_error: 1.5032 - val_loss: 2.0604 - val_mean_absolute_error: 2.0371\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5005 - mean_absolute_error: 1.5021 - val_loss: 2.0696 - val_mean_absolute_error: 2.0526\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4842 - mean_absolute_error: 1.4852 - val_loss: 2.0674 - val_mean_absolute_error: 2.0466\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4929 - mean_absolute_error: 1.4901 - val_loss: 2.0729 - val_mean_absolute_error: 2.0501\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.5006 - mean_absolute_error: 1.5028 - val_loss: 2.0698 - val_mean_absolute_error: 2.0523\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4875 - mean_absolute_error: 1.4869 - val_loss: 2.0739 - val_mean_absolute_error: 2.0561\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4858 - mean_absolute_error: 1.4842 - val_loss: 2.0698 - val_mean_absolute_error: 2.0479\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4854 - mean_absolute_error: 1.4844 - val_loss: 2.0642 - val_mean_absolute_error: 2.0392\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4763 - mean_absolute_error: 1.4787 - val_loss: 2.0663 - val_mean_absolute_error: 2.0431\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4683 - mean_absolute_error: 1.4636 - val_loss: 2.0741 - val_mean_absolute_error: 2.0510\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4714 - mean_absolute_error: 1.4753 - val_loss: 2.0783 - val_mean_absolute_error: 2.0568\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4769 - mean_absolute_error: 1.4789 - val_loss: 2.0800 - val_mean_absolute_error: 2.0624\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4957 - mean_absolute_error: 1.4952 - val_loss: 2.0764 - val_mean_absolute_error: 2.0536\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4763 - mean_absolute_error: 1.4760 - val_loss: 2.0640 - val_mean_absolute_error: 2.0417\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4761 - mean_absolute_error: 1.4778 - val_loss: 2.0710 - val_mean_absolute_error: 2.0510\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4863 - mean_absolute_error: 1.4844 - val_loss: 2.0815 - val_mean_absolute_error: 2.0555\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4717 - mean_absolute_error: 1.4716 - val_loss: 2.0746 - val_mean_absolute_error: 2.0558\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4682 - mean_absolute_error: 1.4637 - val_loss: 2.0740 - val_mean_absolute_error: 2.0554\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4832 - mean_absolute_error: 1.4864 - val_loss: 2.0681 - val_mean_absolute_error: 2.0404\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4874 - mean_absolute_error: 1.4886 - val_loss: 2.0561 - val_mean_absolute_error: 2.0352\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4683 - mean_absolute_error: 1.4640 - val_loss: 2.0627 - val_mean_absolute_error: 2.0403\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4756 - mean_absolute_error: 1.4789 - val_loss: 2.0628 - val_mean_absolute_error: 2.0419\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4715 - mean_absolute_error: 1.4695 - val_loss: 2.0699 - val_mean_absolute_error: 2.0489\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4788 - mean_absolute_error: 1.4782 - val_loss: 2.0710 - val_mean_absolute_error: 2.0514\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4604 - mean_absolute_error: 1.4594 - val_loss: 2.0750 - val_mean_absolute_error: 2.0531\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4631 - mean_absolute_error: 1.4637 - val_loss: 2.0709 - val_mean_absolute_error: 2.0445\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4594 - mean_absolute_error: 1.4614 - val_loss: 2.0696 - val_mean_absolute_error: 2.0564\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4773 - mean_absolute_error: 1.4759 - val_loss: 2.0672 - val_mean_absolute_error: 2.0445\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4578 - mean_absolute_error: 1.4592 - val_loss: 2.0648 - val_mean_absolute_error: 2.0473\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4627 - mean_absolute_error: 1.4614 - val_loss: 2.0722 - val_mean_absolute_error: 2.0559\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4652 - mean_absolute_error: 1.4697 - val_loss: 2.0773 - val_mean_absolute_error: 2.0518\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4573 - mean_absolute_error: 1.4592 - val_loss: 2.0813 - val_mean_absolute_error: 2.0620\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4574 - mean_absolute_error: 1.4515 - val_loss: 2.0784 - val_mean_absolute_error: 2.0622\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4514 - mean_absolute_error: 1.4508 - val_loss: 2.0913 - val_mean_absolute_error: 2.0649\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4494 - mean_absolute_error: 1.4460 - val_loss: 2.0792 - val_mean_absolute_error: 2.0614\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4472 - mean_absolute_error: 1.4464 - val_loss: 2.0800 - val_mean_absolute_error: 2.0615\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4532 - mean_absolute_error: 1.4509 - val_loss: 2.0830 - val_mean_absolute_error: 2.0624\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4473 - mean_absolute_error: 1.4454 - val_loss: 2.0711 - val_mean_absolute_error: 2.0508\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4405 - mean_absolute_error: 1.4418 - val_loss: 2.0789 - val_mean_absolute_error: 2.0574\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.4506 - mean_absolute_error: 1.4481 - val_loss: 2.0854 - val_mean_absolute_error: 2.0592\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4496 - mean_absolute_error: 1.4505 - val_loss: 2.0781 - val_mean_absolute_error: 2.0606\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.4656 - mean_absolute_error: 1.4659 - val_loss: 2.0759 - val_mean_absolute_error: 2.0574\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4349 - mean_absolute_error: 1.4330 - val_loss: 2.0876 - val_mean_absolute_error: 2.0662\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4339 - mean_absolute_error: 1.4358 - val_loss: 2.0798 - val_mean_absolute_error: 2.0566\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4455 - mean_absolute_error: 1.4479 - val_loss: 2.0865 - val_mean_absolute_error: 2.0705\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4418 - mean_absolute_error: 1.4427 - val_loss: 2.0903 - val_mean_absolute_error: 2.0706\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4333 - mean_absolute_error: 1.4313 - val_loss: 2.0749 - val_mean_absolute_error: 2.0577\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4489 - mean_absolute_error: 1.4482 - val_loss: 2.0777 - val_mean_absolute_error: 2.0561\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4344 - mean_absolute_error: 1.4348 - val_loss: 2.0805 - val_mean_absolute_error: 2.0582\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4321 - mean_absolute_error: 1.4338 - val_loss: 2.0816 - val_mean_absolute_error: 2.0616\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4423 - mean_absolute_error: 1.4419 - val_loss: 2.0899 - val_mean_absolute_error: 2.0668\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4390 - mean_absolute_error: 1.4379 - val_loss: 2.0771 - val_mean_absolute_error: 2.0576\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4382 - mean_absolute_error: 1.4344 - val_loss: 2.0799 - val_mean_absolute_error: 2.0619\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4272 - mean_absolute_error: 1.4291 - val_loss: 2.0868 - val_mean_absolute_error: 2.0661\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4319 - mean_absolute_error: 1.4339 - val_loss: 2.0902 - val_mean_absolute_error: 2.0697\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.4333 - mean_absolute_error: 1.4314 - val_loss: 2.0847 - val_mean_absolute_error: 2.0600\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4300 - mean_absolute_error: 1.4315 - val_loss: 2.0862 - val_mean_absolute_error: 2.0657\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4324 - mean_absolute_error: 1.4289 - val_loss: 2.0871 - val_mean_absolute_error: 2.0696\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4213 - mean_absolute_error: 1.4241 - val_loss: 2.0851 - val_mean_absolute_error: 2.0656\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4173 - mean_absolute_error: 1.4153 - val_loss: 2.0908 - val_mean_absolute_error: 2.0718\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4388 - mean_absolute_error: 1.4415 - val_loss: 2.0929 - val_mean_absolute_error: 2.0710\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4372 - mean_absolute_error: 1.4375 - val_loss: 2.0873 - val_mean_absolute_error: 2.0642\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4296 - mean_absolute_error: 1.4313 - val_loss: 2.0978 - val_mean_absolute_error: 2.0788\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4243 - mean_absolute_error: 1.4275 - val_loss: 2.0869 - val_mean_absolute_error: 2.0664\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4156 - mean_absolute_error: 1.4161 - val_loss: 2.0916 - val_mean_absolute_error: 2.0706\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4139 - mean_absolute_error: 1.4108 - val_loss: 2.0864 - val_mean_absolute_error: 2.0639\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4119 - mean_absolute_error: 1.4098 - val_loss: 2.0880 - val_mean_absolute_error: 2.0688\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4221 - mean_absolute_error: 1.4232 - val_loss: 2.0884 - val_mean_absolute_error: 2.0660\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4101 - mean_absolute_error: 1.4112 - val_loss: 2.0803 - val_mean_absolute_error: 2.0583\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4207 - mean_absolute_error: 1.4183 - val_loss: 2.0845 - val_mean_absolute_error: 2.0680\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4153 - mean_absolute_error: 1.4181 - val_loss: 2.0874 - val_mean_absolute_error: 2.0713\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4249 - mean_absolute_error: 1.4257 - val_loss: 2.0878 - val_mean_absolute_error: 2.0717\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4052 - mean_absolute_error: 1.4007 - val_loss: 2.0827 - val_mean_absolute_error: 2.0608\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4220 - mean_absolute_error: 1.4218 - val_loss: 2.0840 - val_mean_absolute_error: 2.0700\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4207 - mean_absolute_error: 1.4208 - val_loss: 2.0878 - val_mean_absolute_error: 2.0708\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4061 - mean_absolute_error: 1.4022 - val_loss: 2.0870 - val_mean_absolute_error: 2.0670\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3941 - mean_absolute_error: 1.3951 - val_loss: 2.0884 - val_mean_absolute_error: 2.0683\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4131 - mean_absolute_error: 1.4152 - val_loss: 2.0891 - val_mean_absolute_error: 2.0706\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4066 - mean_absolute_error: 1.4076 - val_loss: 2.0834 - val_mean_absolute_error: 2.0672\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4111 - mean_absolute_error: 1.4119 - val_loss: 2.0780 - val_mean_absolute_error: 2.0582\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3949 - mean_absolute_error: 1.3967 - val_loss: 2.0806 - val_mean_absolute_error: 2.0601\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3909 - mean_absolute_error: 1.3892 - val_loss: 2.0839 - val_mean_absolute_error: 2.0682\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4030 - mean_absolute_error: 1.4018 - val_loss: 2.0886 - val_mean_absolute_error: 2.0707\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3958 - mean_absolute_error: 1.3944 - val_loss: 2.0728 - val_mean_absolute_error: 2.0505\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3910 - mean_absolute_error: 1.3903 - val_loss: 2.0857 - val_mean_absolute_error: 2.0627\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4044 - mean_absolute_error: 1.4045 - val_loss: 2.0926 - val_mean_absolute_error: 2.0759\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3878 - mean_absolute_error: 1.3897 - val_loss: 2.0878 - val_mean_absolute_error: 2.0690\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3863 - mean_absolute_error: 1.3888 - val_loss: 2.0839 - val_mean_absolute_error: 2.0631\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.4163 - mean_absolute_error: 1.4140 - val_loss: 2.0871 - val_mean_absolute_error: 2.0659\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3957 - mean_absolute_error: 1.3892 - val_loss: 2.0810 - val_mean_absolute_error: 2.0661\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.4063 - mean_absolute_error: 1.4075 - val_loss: 2.0841 - val_mean_absolute_error: 2.0536\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3989 - mean_absolute_error: 1.3986 - val_loss: 2.0892 - val_mean_absolute_error: 2.0718\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3893 - mean_absolute_error: 1.3917 - val_loss: 2.0868 - val_mean_absolute_error: 2.0627\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3971 - mean_absolute_error: 1.3976 - val_loss: 2.0914 - val_mean_absolute_error: 2.0653\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3943 - mean_absolute_error: 1.3953 - val_loss: 2.0964 - val_mean_absolute_error: 2.0781\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3929 - mean_absolute_error: 1.3925 - val_loss: 2.0893 - val_mean_absolute_error: 2.0709\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3815 - mean_absolute_error: 1.3785 - val_loss: 2.0941 - val_mean_absolute_error: 2.0733\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3838 - mean_absolute_error: 1.3892 - val_loss: 2.0973 - val_mean_absolute_error: 2.0776\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3842 - mean_absolute_error: 1.3844 - val_loss: 2.0961 - val_mean_absolute_error: 2.0756\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3708 - mean_absolute_error: 1.3694 - val_loss: 2.1000 - val_mean_absolute_error: 2.0792\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3700 - mean_absolute_error: 1.3701 - val_loss: 2.0950 - val_mean_absolute_error: 2.0695\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3720 - mean_absolute_error: 1.3717 - val_loss: 2.0940 - val_mean_absolute_error: 2.0722\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3917 - mean_absolute_error: 1.3939 - val_loss: 2.1015 - val_mean_absolute_error: 2.0841\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3890 - mean_absolute_error: 1.3908 - val_loss: 2.0862 - val_mean_absolute_error: 2.0606\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3843 - mean_absolute_error: 1.3821 - val_loss: 2.0958 - val_mean_absolute_error: 2.0734\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3704 - mean_absolute_error: 1.3694 - val_loss: 2.0987 - val_mean_absolute_error: 2.0738\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3591 - mean_absolute_error: 1.3604 - val_loss: 2.0942 - val_mean_absolute_error: 2.0694\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3669 - mean_absolute_error: 1.3660 - val_loss: 2.1001 - val_mean_absolute_error: 2.0794\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3705 - mean_absolute_error: 1.3698 - val_loss: 2.1024 - val_mean_absolute_error: 2.0811\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3710 - mean_absolute_error: 1.3736 - val_loss: 2.0941 - val_mean_absolute_error: 2.0739\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3744 - mean_absolute_error: 1.3741 - val_loss: 2.0981 - val_mean_absolute_error: 2.0775\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3715 - mean_absolute_error: 1.3728 - val_loss: 2.0991 - val_mean_absolute_error: 2.0816\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3580 - mean_absolute_error: 1.3632 - val_loss: 2.1024 - val_mean_absolute_error: 2.0821\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3650 - mean_absolute_error: 1.3660 - val_loss: 2.1028 - val_mean_absolute_error: 2.0846\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3677 - mean_absolute_error: 1.3691 - val_loss: 2.1024 - val_mean_absolute_error: 2.0789\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3599 - mean_absolute_error: 1.3651 - val_loss: 2.0953 - val_mean_absolute_error: 2.0789\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3657 - mean_absolute_error: 1.3689 - val_loss: 2.1059 - val_mean_absolute_error: 2.0835\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3705 - mean_absolute_error: 1.3721 - val_loss: 2.1025 - val_mean_absolute_error: 2.0814\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3710 - mean_absolute_error: 1.3727 - val_loss: 2.0968 - val_mean_absolute_error: 2.0818\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3699 - mean_absolute_error: 1.3711 - val_loss: 2.1036 - val_mean_absolute_error: 2.0824\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3679 - mean_absolute_error: 1.3640 - val_loss: 2.1076 - val_mean_absolute_error: 2.0901\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3492 - mean_absolute_error: 1.3489 - val_loss: 2.1032 - val_mean_absolute_error: 2.0884\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.3424 - mean_absolute_error: 1.3414 - val_loss: 2.1049 - val_mean_absolute_error: 2.0846\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3512 - mean_absolute_error: 1.3497 - val_loss: 2.1102 - val_mean_absolute_error: 2.0929\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3389 - mean_absolute_error: 1.3379 - val_loss: 2.1077 - val_mean_absolute_error: 2.0876\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3688 - mean_absolute_error: 1.3696 - val_loss: 2.1001 - val_mean_absolute_error: 2.0833\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3662 - mean_absolute_error: 1.3658 - val_loss: 2.1039 - val_mean_absolute_error: 2.0866\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3443 - mean_absolute_error: 1.3440 - val_loss: 2.1021 - val_mean_absolute_error: 2.0881\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3456 - mean_absolute_error: 1.3480 - val_loss: 2.1000 - val_mean_absolute_error: 2.0831\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3487 - mean_absolute_error: 1.3497 - val_loss: 2.1022 - val_mean_absolute_error: 2.0846\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3560 - mean_absolute_error: 1.3592 - val_loss: 2.0939 - val_mean_absolute_error: 2.0777\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3470 - mean_absolute_error: 1.3509 - val_loss: 2.0978 - val_mean_absolute_error: 2.0820\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3450 - mean_absolute_error: 1.3474 - val_loss: 2.0973 - val_mean_absolute_error: 2.0796\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3421 - mean_absolute_error: 1.3434 - val_loss: 2.1011 - val_mean_absolute_error: 2.0829\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3412 - mean_absolute_error: 1.3432 - val_loss: 2.0986 - val_mean_absolute_error: 2.0796\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3672 - mean_absolute_error: 1.3655 - val_loss: 2.0978 - val_mean_absolute_error: 2.0795\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3307 - mean_absolute_error: 1.3294 - val_loss: 2.1016 - val_mean_absolute_error: 2.0854\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3377 - mean_absolute_error: 1.3412 - val_loss: 2.1086 - val_mean_absolute_error: 2.0905\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3385 - mean_absolute_error: 1.3346 - val_loss: 2.0967 - val_mean_absolute_error: 2.0804\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3314 - mean_absolute_error: 1.3324 - val_loss: 2.0996 - val_mean_absolute_error: 2.0801\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3277 - mean_absolute_error: 1.3273 - val_loss: 2.1055 - val_mean_absolute_error: 2.0858\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3467 - mean_absolute_error: 1.3443 - val_loss: 2.1149 - val_mean_absolute_error: 2.0972\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3348 - mean_absolute_error: 1.3359 - val_loss: 2.1064 - val_mean_absolute_error: 2.0827\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3489 - mean_absolute_error: 1.3496 - val_loss: 2.1089 - val_mean_absolute_error: 2.0946\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3388 - mean_absolute_error: 1.3398 - val_loss: 2.1097 - val_mean_absolute_error: 2.0912\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3581 - mean_absolute_error: 1.3571 - val_loss: 2.1093 - val_mean_absolute_error: 2.0872\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3370 - mean_absolute_error: 1.3400 - val_loss: 2.1041 - val_mean_absolute_error: 2.0837\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3249 - mean_absolute_error: 1.3258 - val_loss: 2.1026 - val_mean_absolute_error: 2.0822\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3217 - mean_absolute_error: 1.3229 - val_loss: 2.0997 - val_mean_absolute_error: 2.0805\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3360 - mean_absolute_error: 1.3386 - val_loss: 2.0949 - val_mean_absolute_error: 2.0752\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3324 - mean_absolute_error: 1.3332 - val_loss: 2.1128 - val_mean_absolute_error: 2.0939\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3413 - mean_absolute_error: 1.3420 - val_loss: 2.1097 - val_mean_absolute_error: 2.0840\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3350 - mean_absolute_error: 1.3314 - val_loss: 2.1070 - val_mean_absolute_error: 2.0909\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3472 - mean_absolute_error: 1.3475 - val_loss: 2.1121 - val_mean_absolute_error: 2.0967\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3345 - mean_absolute_error: 1.3323 - val_loss: 2.0923 - val_mean_absolute_error: 2.0672\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3356 - mean_absolute_error: 1.3382 - val_loss: 2.0992 - val_mean_absolute_error: 2.0845\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3164 - mean_absolute_error: 1.3151 - val_loss: 2.1038 - val_mean_absolute_error: 2.0789\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3302 - mean_absolute_error: 1.3305 - val_loss: 2.0988 - val_mean_absolute_error: 2.0781\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3187 - mean_absolute_error: 1.3205 - val_loss: 2.1038 - val_mean_absolute_error: 2.0845\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3168 - mean_absolute_error: 1.3189 - val_loss: 2.1015 - val_mean_absolute_error: 2.0889\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3212 - mean_absolute_error: 1.3212 - val_loss: 2.1076 - val_mean_absolute_error: 2.0874\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3194 - mean_absolute_error: 1.3193 - val_loss: 2.1014 - val_mean_absolute_error: 2.0807\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.3191 - mean_absolute_error: 1.3177 - val_loss: 2.1068 - val_mean_absolute_error: 2.0914\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3184 - mean_absolute_error: 1.3155 - val_loss: 2.1105 - val_mean_absolute_error: 2.0885\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3169 - mean_absolute_error: 1.3190 - val_loss: 2.1024 - val_mean_absolute_error: 2.0813\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.3201 - mean_absolute_error: 1.3173 - val_loss: 2.1041 - val_mean_absolute_error: 2.0888\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2977 - mean_absolute_error: 1.2973 - val_loss: 2.1090 - val_mean_absolute_error: 2.0933\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3175 - mean_absolute_error: 1.3172 - val_loss: 2.1128 - val_mean_absolute_error: 2.0931\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3125 - mean_absolute_error: 1.3109 - val_loss: 2.1131 - val_mean_absolute_error: 2.0974\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3154 - mean_absolute_error: 1.3157 - val_loss: 2.1021 - val_mean_absolute_error: 2.0852\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.3162 - mean_absolute_error: 1.3207 - val_loss: 2.1074 - val_mean_absolute_error: 2.0881\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3047 - mean_absolute_error: 1.3039 - val_loss: 2.1052 - val_mean_absolute_error: 2.0914\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3237 - mean_absolute_error: 1.3234 - val_loss: 2.1047 - val_mean_absolute_error: 2.0837\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3213 - mean_absolute_error: 1.3190 - val_loss: 2.1108 - val_mean_absolute_error: 2.0953\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 33ms/step - loss: 1.3134 - mean_absolute_error: 1.3123 - val_loss: 2.1134 - val_mean_absolute_error: 2.0913\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.3007 - mean_absolute_error: 1.3020 - val_loss: 2.1163 - val_mean_absolute_error: 2.0987\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2990 - mean_absolute_error: 1.2995 - val_loss: 2.1106 - val_mean_absolute_error: 2.0925\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.3159 - mean_absolute_error: 1.3126 - val_loss: 2.1033 - val_mean_absolute_error: 2.0826\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3144 - mean_absolute_error: 1.3157 - val_loss: 2.1088 - val_mean_absolute_error: 2.0912\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3046 - mean_absolute_error: 1.3043 - val_loss: 2.1111 - val_mean_absolute_error: 2.0956\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3047 - mean_absolute_error: 1.3066 - val_loss: 2.1148 - val_mean_absolute_error: 2.0979\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3182 - mean_absolute_error: 1.3173 - val_loss: 2.1022 - val_mean_absolute_error: 2.0810\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2849 - mean_absolute_error: 1.2845 - val_loss: 2.1100 - val_mean_absolute_error: 2.0853\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3019 - mean_absolute_error: 1.3022 - val_loss: 2.1118 - val_mean_absolute_error: 2.0922\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3143 - mean_absolute_error: 1.3141 - val_loss: 2.1099 - val_mean_absolute_error: 2.0847\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2925 - mean_absolute_error: 1.2923 - val_loss: 2.1182 - val_mean_absolute_error: 2.0945\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.3039 - mean_absolute_error: 1.3033 - val_loss: 2.1250 - val_mean_absolute_error: 2.1056\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.3095 - mean_absolute_error: 1.3079 - val_loss: 2.1140 - val_mean_absolute_error: 2.0855\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.3110 - mean_absolute_error: 1.3111 - val_loss: 2.1030 - val_mean_absolute_error: 2.0820\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2969 - mean_absolute_error: 1.2945 - val_loss: 2.1050 - val_mean_absolute_error: 2.0836\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2986 - mean_absolute_error: 1.2987 - val_loss: 2.1153 - val_mean_absolute_error: 2.0961\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2826 - mean_absolute_error: 1.2819 - val_loss: 2.0992 - val_mean_absolute_error: 2.0759\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2946 - mean_absolute_error: 1.2934 - val_loss: 2.1116 - val_mean_absolute_error: 2.0978\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2945 - mean_absolute_error: 1.2932 - val_loss: 2.1243 - val_mean_absolute_error: 2.1005\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2994 - mean_absolute_error: 1.2998 - val_loss: 2.1250 - val_mean_absolute_error: 2.1048\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2888 - mean_absolute_error: 1.2879 - val_loss: 2.1254 - val_mean_absolute_error: 2.1082\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2707 - mean_absolute_error: 1.2723 - val_loss: 2.1144 - val_mean_absolute_error: 2.0942\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2871 - mean_absolute_error: 1.2907 - val_loss: 2.1067 - val_mean_absolute_error: 2.0859\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2964 - mean_absolute_error: 1.2971 - val_loss: 2.1104 - val_mean_absolute_error: 2.0869\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.3002 - mean_absolute_error: 1.2998 - val_loss: 2.1173 - val_mean_absolute_error: 2.0979\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2966 - mean_absolute_error: 1.2940 - val_loss: 2.1144 - val_mean_absolute_error: 2.0953\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2943 - mean_absolute_error: 1.2989 - val_loss: 2.1146 - val_mean_absolute_error: 2.0913\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2806 - mean_absolute_error: 1.2868 - val_loss: 2.1207 - val_mean_absolute_error: 2.1032\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2877 - mean_absolute_error: 1.2879 - val_loss: 2.1134 - val_mean_absolute_error: 2.0913\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2713 - mean_absolute_error: 1.2708 - val_loss: 2.1090 - val_mean_absolute_error: 2.0869\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.2833 - mean_absolute_error: 1.2823 - val_loss: 2.1221 - val_mean_absolute_error: 2.1095\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2957 - mean_absolute_error: 1.2974 - val_loss: 2.1055 - val_mean_absolute_error: 2.0825\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2869 - mean_absolute_error: 1.2878 - val_loss: 2.1130 - val_mean_absolute_error: 2.0949\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2795 - mean_absolute_error: 1.2821 - val_loss: 2.1270 - val_mean_absolute_error: 2.1050\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2649 - mean_absolute_error: 1.2654 - val_loss: 2.1177 - val_mean_absolute_error: 2.0974\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.2829 - mean_absolute_error: 1.2834 - val_loss: 2.1093 - val_mean_absolute_error: 2.0907\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2673 - mean_absolute_error: 1.2691 - val_loss: 2.1161 - val_mean_absolute_error: 2.0953\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2890 - mean_absolute_error: 1.2896 - val_loss: 2.1201 - val_mean_absolute_error: 2.0985\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2848 - mean_absolute_error: 1.2829 - val_loss: 2.1122 - val_mean_absolute_error: 2.0949\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2814 - mean_absolute_error: 1.2879 - val_loss: 2.1070 - val_mean_absolute_error: 2.0835\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2752 - mean_absolute_error: 1.2740 - val_loss: 2.1067 - val_mean_absolute_error: 2.0836\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2787 - mean_absolute_error: 1.2787 - val_loss: 2.1093 - val_mean_absolute_error: 2.0845\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2618 - mean_absolute_error: 1.2603 - val_loss: 2.1130 - val_mean_absolute_error: 2.0907\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2731 - mean_absolute_error: 1.2768 - val_loss: 2.1138 - val_mean_absolute_error: 2.0886\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2686 - mean_absolute_error: 1.2700 - val_loss: 2.1140 - val_mean_absolute_error: 2.0887\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2644 - mean_absolute_error: 1.2679 - val_loss: 2.1234 - val_mean_absolute_error: 2.1027\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2821 - mean_absolute_error: 1.2839 - val_loss: 2.1195 - val_mean_absolute_error: 2.1001\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2763 - mean_absolute_error: 1.2758 - val_loss: 2.1067 - val_mean_absolute_error: 2.0822\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2940 - mean_absolute_error: 1.2905 - val_loss: 2.1110 - val_mean_absolute_error: 2.0897\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2739 - mean_absolute_error: 1.2752 - val_loss: 2.1200 - val_mean_absolute_error: 2.0990\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2696 - mean_absolute_error: 1.2725 - val_loss: 2.1133 - val_mean_absolute_error: 2.0942\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2779 - mean_absolute_error: 1.2772 - val_loss: 2.1163 - val_mean_absolute_error: 2.0941\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2675 - mean_absolute_error: 1.2698 - val_loss: 2.1161 - val_mean_absolute_error: 2.0942\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2663 - mean_absolute_error: 1.2687 - val_loss: 2.1153 - val_mean_absolute_error: 2.0886\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2825 - mean_absolute_error: 1.2833 - val_loss: 2.1208 - val_mean_absolute_error: 2.1006\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2704 - mean_absolute_error: 1.2721 - val_loss: 2.1252 - val_mean_absolute_error: 2.1018\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2706 - mean_absolute_error: 1.2746 - val_loss: 2.1168 - val_mean_absolute_error: 2.0936\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2762 - mean_absolute_error: 1.2743 - val_loss: 2.1091 - val_mean_absolute_error: 2.0849\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2619 - mean_absolute_error: 1.2645 - val_loss: 2.1108 - val_mean_absolute_error: 2.0890\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2577 - mean_absolute_error: 1.2573 - val_loss: 2.1285 - val_mean_absolute_error: 2.1033\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2649 - mean_absolute_error: 1.2645 - val_loss: 2.1312 - val_mean_absolute_error: 2.1047\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.2719 - mean_absolute_error: 1.2725 - val_loss: 2.1319 - val_mean_absolute_error: 2.1086\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2856 - mean_absolute_error: 1.2858 - val_loss: 2.1185 - val_mean_absolute_error: 2.0954\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2792 - mean_absolute_error: 1.2773 - val_loss: 2.1084 - val_mean_absolute_error: 2.0863\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2585 - mean_absolute_error: 1.2582 - val_loss: 2.1133 - val_mean_absolute_error: 2.0872\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2682 - mean_absolute_error: 1.2647 - val_loss: 2.1214 - val_mean_absolute_error: 2.0998\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2714 - mean_absolute_error: 1.2712 - val_loss: 2.1145 - val_mean_absolute_error: 2.0870\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2693 - mean_absolute_error: 1.2700 - val_loss: 2.1138 - val_mean_absolute_error: 2.0909\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2629 - mean_absolute_error: 1.2625 - val_loss: 2.1240 - val_mean_absolute_error: 2.1059\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2432 - mean_absolute_error: 1.2434 - val_loss: 2.1237 - val_mean_absolute_error: 2.0978\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2587 - mean_absolute_error: 1.2570 - val_loss: 2.1192 - val_mean_absolute_error: 2.0987\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2506 - mean_absolute_error: 1.2495 - val_loss: 2.1215 - val_mean_absolute_error: 2.1014\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2657 - mean_absolute_error: 1.2656 - val_loss: 2.1220 - val_mean_absolute_error: 2.1025\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2603 - mean_absolute_error: 1.2610 - val_loss: 2.1124 - val_mean_absolute_error: 2.0859\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2576 - mean_absolute_error: 1.2620 - val_loss: 2.1139 - val_mean_absolute_error: 2.0938\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2746 - mean_absolute_error: 1.2784 - val_loss: 2.1158 - val_mean_absolute_error: 2.0945\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.2571 - mean_absolute_error: 1.2582 - val_loss: 2.1140 - val_mean_absolute_error: 2.0923\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2474 - mean_absolute_error: 1.2478 - val_loss: 2.1206 - val_mean_absolute_error: 2.0974\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2643 - mean_absolute_error: 1.2652 - val_loss: 2.1301 - val_mean_absolute_error: 2.1063\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2547 - mean_absolute_error: 1.2543 - val_loss: 2.1228 - val_mean_absolute_error: 2.1001\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2731 - mean_absolute_error: 1.2742 - val_loss: 2.1161 - val_mean_absolute_error: 2.0909\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2612 - mean_absolute_error: 1.2597 - val_loss: 2.1218 - val_mean_absolute_error: 2.0970\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2458 - mean_absolute_error: 1.2471 - val_loss: 2.1171 - val_mean_absolute_error: 2.0915\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2517 - mean_absolute_error: 1.2505 - val_loss: 2.1245 - val_mean_absolute_error: 2.1051\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2611 - mean_absolute_error: 1.2648 - val_loss: 2.1249 - val_mean_absolute_error: 2.1023\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2627 - mean_absolute_error: 1.2632 - val_loss: 2.1150 - val_mean_absolute_error: 2.0928\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2520 - mean_absolute_error: 1.2537 - val_loss: 2.1156 - val_mean_absolute_error: 2.0906\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2329 - mean_absolute_error: 1.2337 - val_loss: 2.1229 - val_mean_absolute_error: 2.0961\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2604 - mean_absolute_error: 1.2596 - val_loss: 2.1173 - val_mean_absolute_error: 2.0909\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2370 - mean_absolute_error: 1.2365 - val_loss: 2.1177 - val_mean_absolute_error: 2.0930\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2614 - mean_absolute_error: 1.2615 - val_loss: 2.1138 - val_mean_absolute_error: 2.0874\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2553 - mean_absolute_error: 1.2554 - val_loss: 2.1136 - val_mean_absolute_error: 2.0906\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2382 - mean_absolute_error: 1.2362 - val_loss: 2.1106 - val_mean_absolute_error: 2.0869\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2515 - mean_absolute_error: 1.2532 - val_loss: 2.1176 - val_mean_absolute_error: 2.0928\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2457 - mean_absolute_error: 1.2468 - val_loss: 2.1198 - val_mean_absolute_error: 2.0952\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2531 - mean_absolute_error: 1.2534 - val_loss: 2.1191 - val_mean_absolute_error: 2.0957\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2449 - mean_absolute_error: 1.2427 - val_loss: 2.1206 - val_mean_absolute_error: 2.1027\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2462 - mean_absolute_error: 1.2439 - val_loss: 2.1264 - val_mean_absolute_error: 2.1076\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2461 - mean_absolute_error: 1.2436 - val_loss: 2.1267 - val_mean_absolute_error: 2.1016\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2408 - mean_absolute_error: 1.2428 - val_loss: 2.1260 - val_mean_absolute_error: 2.1058\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2375 - mean_absolute_error: 1.2378 - val_loss: 2.1255 - val_mean_absolute_error: 2.1020\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2259 - mean_absolute_error: 1.2300 - val_loss: 2.1199 - val_mean_absolute_error: 2.0970\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.2390 - mean_absolute_error: 1.2413 - val_loss: 2.1167 - val_mean_absolute_error: 2.0948\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2371 - mean_absolute_error: 1.2396 - val_loss: 2.1158 - val_mean_absolute_error: 2.0963\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2378 - mean_absolute_error: 1.2356 - val_loss: 2.1170 - val_mean_absolute_error: 2.0928\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2444 - mean_absolute_error: 1.2444 - val_loss: 2.1209 - val_mean_absolute_error: 2.0972\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2271 - mean_absolute_error: 1.2241 - val_loss: 2.1267 - val_mean_absolute_error: 2.1007\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2315 - mean_absolute_error: 1.2300 - val_loss: 2.1320 - val_mean_absolute_error: 2.1123\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2441 - mean_absolute_error: 1.2440 - val_loss: 2.1349 - val_mean_absolute_error: 2.1067\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2460 - mean_absolute_error: 1.2456 - val_loss: 2.1313 - val_mean_absolute_error: 2.1094\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2231 - mean_absolute_error: 1.2235 - val_loss: 2.1298 - val_mean_absolute_error: 2.0992\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2547 - mean_absolute_error: 1.2595 - val_loss: 2.1324 - val_mean_absolute_error: 2.1120\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2311 - mean_absolute_error: 1.2326 - val_loss: 2.1297 - val_mean_absolute_error: 2.1044\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2260 - mean_absolute_error: 1.2240 - val_loss: 2.1295 - val_mean_absolute_error: 2.1073\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2280 - mean_absolute_error: 1.2283 - val_loss: 2.1231 - val_mean_absolute_error: 2.0973\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2202 - mean_absolute_error: 1.2200 - val_loss: 2.1301 - val_mean_absolute_error: 2.1032\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2315 - mean_absolute_error: 1.2316 - val_loss: 2.1306 - val_mean_absolute_error: 2.1088\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2206 - mean_absolute_error: 1.2233 - val_loss: 2.1260 - val_mean_absolute_error: 2.1002\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2310 - mean_absolute_error: 1.2336 - val_loss: 2.1307 - val_mean_absolute_error: 2.1073\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2328 - mean_absolute_error: 1.2293 - val_loss: 2.1287 - val_mean_absolute_error: 2.1018\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2388 - mean_absolute_error: 1.2410 - val_loss: 2.1281 - val_mean_absolute_error: 2.1064\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2306 - mean_absolute_error: 1.2312 - val_loss: 2.1271 - val_mean_absolute_error: 2.1042\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2272 - mean_absolute_error: 1.2272 - val_loss: 2.1160 - val_mean_absolute_error: 2.0909\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2227 - mean_absolute_error: 1.2190 - val_loss: 2.1190 - val_mean_absolute_error: 2.0946\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2268 - mean_absolute_error: 1.2277 - val_loss: 2.1272 - val_mean_absolute_error: 2.1070\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2252 - mean_absolute_error: 1.2268 - val_loss: 2.1352 - val_mean_absolute_error: 2.1158\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2354 - mean_absolute_error: 1.2348 - val_loss: 2.1269 - val_mean_absolute_error: 2.1028\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2362 - mean_absolute_error: 1.2356 - val_loss: 2.1263 - val_mean_absolute_error: 2.1068\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2291 - mean_absolute_error: 1.2274 - val_loss: 2.1258 - val_mean_absolute_error: 2.1018\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.2243 - mean_absolute_error: 1.2265 - val_loss: 2.1242 - val_mean_absolute_error: 2.0995\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2438 - mean_absolute_error: 1.2464 - val_loss: 2.1303 - val_mean_absolute_error: 2.1086\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2241 - mean_absolute_error: 1.2251 - val_loss: 2.1321 - val_mean_absolute_error: 2.1089\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2172 - mean_absolute_error: 1.2160 - val_loss: 2.1336 - val_mean_absolute_error: 2.1105\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2170 - mean_absolute_error: 1.2185 - val_loss: 2.1304 - val_mean_absolute_error: 2.1065\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2192 - mean_absolute_error: 1.2210 - val_loss: 2.1213 - val_mean_absolute_error: 2.0936\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2095 - mean_absolute_error: 1.2103 - val_loss: 2.1177 - val_mean_absolute_error: 2.0920\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2279 - mean_absolute_error: 1.2323 - val_loss: 2.1252 - val_mean_absolute_error: 2.0985\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2123 - mean_absolute_error: 1.2100 - val_loss: 2.1284 - val_mean_absolute_error: 2.1033\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2243 - mean_absolute_error: 1.2230 - val_loss: 2.1306 - val_mean_absolute_error: 2.1098\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2137 - mean_absolute_error: 1.2157 - val_loss: 2.1320 - val_mean_absolute_error: 2.1088\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2261 - mean_absolute_error: 1.2256 - val_loss: 2.1325 - val_mean_absolute_error: 2.1090\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2231 - mean_absolute_error: 1.2245 - val_loss: 2.1327 - val_mean_absolute_error: 2.1105\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2146 - mean_absolute_error: 1.2180 - val_loss: 2.1260 - val_mean_absolute_error: 2.1009\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2216 - mean_absolute_error: 1.2242 - val_loss: 2.1232 - val_mean_absolute_error: 2.1010\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2120 - mean_absolute_error: 1.2125 - val_loss: 2.1332 - val_mean_absolute_error: 2.1086\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2117 - mean_absolute_error: 1.2126 - val_loss: 2.1412 - val_mean_absolute_error: 2.1201\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2126 - mean_absolute_error: 1.2117 - val_loss: 2.1357 - val_mean_absolute_error: 2.1148\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2048 - mean_absolute_error: 1.2012 - val_loss: 2.1361 - val_mean_absolute_error: 2.1152\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2084 - mean_absolute_error: 1.2042 - val_loss: 2.1438 - val_mean_absolute_error: 2.1206\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2004 - mean_absolute_error: 1.2033 - val_loss: 2.1356 - val_mean_absolute_error: 2.1079\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2213 - mean_absolute_error: 1.2196 - val_loss: 2.1270 - val_mean_absolute_error: 2.1058\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2079 - mean_absolute_error: 1.2085 - val_loss: 2.1295 - val_mean_absolute_error: 2.1032\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2040 - mean_absolute_error: 1.2057 - val_loss: 2.1273 - val_mean_absolute_error: 2.1049\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2071 - mean_absolute_error: 1.2045 - val_loss: 2.1272 - val_mean_absolute_error: 2.1050\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2133 - mean_absolute_error: 1.2116 - val_loss: 2.1278 - val_mean_absolute_error: 2.1055\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1943 - mean_absolute_error: 1.1965 - val_loss: 2.1285 - val_mean_absolute_error: 2.1069\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2264 - mean_absolute_error: 1.2300 - val_loss: 2.1369 - val_mean_absolute_error: 2.1133\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1851 - mean_absolute_error: 1.1824 - val_loss: 2.1321 - val_mean_absolute_error: 2.1040\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1866 - mean_absolute_error: 1.1835 - val_loss: 2.1328 - val_mean_absolute_error: 2.1095\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2056 - mean_absolute_error: 1.2038 - val_loss: 2.1301 - val_mean_absolute_error: 2.1067\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1963 - mean_absolute_error: 1.1960 - val_loss: 2.1315 - val_mean_absolute_error: 2.1104\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2152 - mean_absolute_error: 1.2142 - val_loss: 2.1233 - val_mean_absolute_error: 2.0978\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2044 - mean_absolute_error: 1.2024 - val_loss: 2.1293 - val_mean_absolute_error: 2.1111\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2163 - mean_absolute_error: 1.2159 - val_loss: 2.1242 - val_mean_absolute_error: 2.1027\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2192 - mean_absolute_error: 1.2222 - val_loss: 2.1272 - val_mean_absolute_error: 2.1063\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2148 - mean_absolute_error: 1.2183 - val_loss: 2.1213 - val_mean_absolute_error: 2.0955\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2049 - mean_absolute_error: 1.2059 - val_loss: 2.1288 - val_mean_absolute_error: 2.1085\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.2130 - mean_absolute_error: 1.2135 - val_loss: 2.1325 - val_mean_absolute_error: 2.1039\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2186 - mean_absolute_error: 1.2171 - val_loss: 2.1286 - val_mean_absolute_error: 2.1116\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.2015 - mean_absolute_error: 1.2042 - val_loss: 2.1186 - val_mean_absolute_error: 2.0980\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.2012 - mean_absolute_error: 1.2012 - val_loss: 2.1313 - val_mean_absolute_error: 2.1136\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1999 - mean_absolute_error: 1.2005 - val_loss: 2.1256 - val_mean_absolute_error: 2.1040\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1818 - mean_absolute_error: 1.1811 - val_loss: 2.1283 - val_mean_absolute_error: 2.1087\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1894 - mean_absolute_error: 1.1921 - val_loss: 2.1377 - val_mean_absolute_error: 2.1139\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2193 - mean_absolute_error: 1.2152 - val_loss: 2.1245 - val_mean_absolute_error: 2.1018\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.1900 - mean_absolute_error: 1.1916 - val_loss: 2.1242 - val_mean_absolute_error: 2.1043\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1894 - mean_absolute_error: 1.1902 - val_loss: 2.1305 - val_mean_absolute_error: 2.1080\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1936 - mean_absolute_error: 1.1928 - val_loss: 2.1299 - val_mean_absolute_error: 2.1100\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2096 - mean_absolute_error: 1.2093 - val_loss: 2.1266 - val_mean_absolute_error: 2.1052\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2038 - mean_absolute_error: 1.2026 - val_loss: 2.1324 - val_mean_absolute_error: 2.1135\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2136 - mean_absolute_error: 1.2104 - val_loss: 2.1369 - val_mean_absolute_error: 2.1169\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1863 - mean_absolute_error: 1.1877 - val_loss: 2.1344 - val_mean_absolute_error: 2.1154\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2060 - mean_absolute_error: 1.2017 - val_loss: 2.1342 - val_mean_absolute_error: 2.1157\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1854 - mean_absolute_error: 1.1824 - val_loss: 2.1346 - val_mean_absolute_error: 2.1125\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1894 - mean_absolute_error: 1.1897 - val_loss: 2.1312 - val_mean_absolute_error: 2.1069\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1853 - mean_absolute_error: 1.1876 - val_loss: 2.1395 - val_mean_absolute_error: 2.1211\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2016 - mean_absolute_error: 1.2007 - val_loss: 2.1309 - val_mean_absolute_error: 2.1091\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.2019 - mean_absolute_error: 1.2036 - val_loss: 2.1394 - val_mean_absolute_error: 2.1165\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1974 - mean_absolute_error: 1.1984 - val_loss: 2.1409 - val_mean_absolute_error: 2.1140\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1996 - mean_absolute_error: 1.2018 - val_loss: 2.1471 - val_mean_absolute_error: 2.1234\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1865 - mean_absolute_error: 1.1881 - val_loss: 2.1446 - val_mean_absolute_error: 2.1218\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1906 - mean_absolute_error: 1.1910 - val_loss: 2.1452 - val_mean_absolute_error: 2.1265\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2039 - mean_absolute_error: 1.2051 - val_loss: 2.1298 - val_mean_absolute_error: 2.1090\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.2035 - mean_absolute_error: 1.2062 - val_loss: 2.1297 - val_mean_absolute_error: 2.1052\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1855 - mean_absolute_error: 1.1878 - val_loss: 2.1323 - val_mean_absolute_error: 2.1120\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1965 - mean_absolute_error: 1.1953 - val_loss: 2.1254 - val_mean_absolute_error: 2.1028\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1918 - mean_absolute_error: 1.1947 - val_loss: 2.1295 - val_mean_absolute_error: 2.1048\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1822 - mean_absolute_error: 1.1856 - val_loss: 2.1313 - val_mean_absolute_error: 2.1052\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1872 - mean_absolute_error: 1.1848 - val_loss: 2.1290 - val_mean_absolute_error: 2.1049\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1913 - mean_absolute_error: 1.1925 - val_loss: 2.1325 - val_mean_absolute_error: 2.1033\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.2029 - mean_absolute_error: 1.2043 - val_loss: 2.1357 - val_mean_absolute_error: 2.1130\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2048 - mean_absolute_error: 1.2043 - val_loss: 2.1303 - val_mean_absolute_error: 2.1018\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1743 - mean_absolute_error: 1.1755 - val_loss: 2.1374 - val_mean_absolute_error: 2.1149\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1917 - mean_absolute_error: 1.1948 - val_loss: 2.1443 - val_mean_absolute_error: 2.1173\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1961 - mean_absolute_error: 1.1955 - val_loss: 2.1460 - val_mean_absolute_error: 2.1236\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1815 - mean_absolute_error: 1.1830 - val_loss: 2.1447 - val_mean_absolute_error: 2.1195\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1965 - mean_absolute_error: 1.1966 - val_loss: 2.1392 - val_mean_absolute_error: 2.1190\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1801 - mean_absolute_error: 1.1789 - val_loss: 2.1315 - val_mean_absolute_error: 2.1080\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1730 - mean_absolute_error: 1.1733 - val_loss: 2.1371 - val_mean_absolute_error: 2.1114\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1934 - mean_absolute_error: 1.1929 - val_loss: 2.1356 - val_mean_absolute_error: 2.1065\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1884 - mean_absolute_error: 1.1845 - val_loss: 2.1416 - val_mean_absolute_error: 2.1145\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1705 - mean_absolute_error: 1.1686 - val_loss: 2.1370 - val_mean_absolute_error: 2.1068\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1732 - mean_absolute_error: 1.1716 - val_loss: 2.1401 - val_mean_absolute_error: 2.1149\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1809 - mean_absolute_error: 1.1815 - val_loss: 2.1396 - val_mean_absolute_error: 2.1139\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1909 - mean_absolute_error: 1.1883 - val_loss: 2.1439 - val_mean_absolute_error: 2.1204\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1762 - mean_absolute_error: 1.1749 - val_loss: 2.1417 - val_mean_absolute_error: 2.1221\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1796 - mean_absolute_error: 1.1790 - val_loss: 2.1301 - val_mean_absolute_error: 2.1069\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1765 - mean_absolute_error: 1.1766 - val_loss: 2.1364 - val_mean_absolute_error: 2.1110\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1734 - mean_absolute_error: 1.1757 - val_loss: 2.1331 - val_mean_absolute_error: 2.1103\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1777 - mean_absolute_error: 1.1755 - val_loss: 2.1286 - val_mean_absolute_error: 2.1034\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1739 - mean_absolute_error: 1.1779 - val_loss: 2.1377 - val_mean_absolute_error: 2.1123\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1778 - mean_absolute_error: 1.1775 - val_loss: 2.1468 - val_mean_absolute_error: 2.1199\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1781 - mean_absolute_error: 1.1794 - val_loss: 2.1447 - val_mean_absolute_error: 2.1215\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1700 - mean_absolute_error: 1.1705 - val_loss: 2.1365 - val_mean_absolute_error: 2.1115\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1714 - mean_absolute_error: 1.1727 - val_loss: 2.1349 - val_mean_absolute_error: 2.1141\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1664 - mean_absolute_error: 1.1682 - val_loss: 2.1384 - val_mean_absolute_error: 2.1185\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1676 - mean_absolute_error: 1.1674 - val_loss: 2.1375 - val_mean_absolute_error: 2.1147\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1832 - mean_absolute_error: 1.1832 - val_loss: 2.1398 - val_mean_absolute_error: 2.1165\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1802 - mean_absolute_error: 1.1793 - val_loss: 2.1409 - val_mean_absolute_error: 2.1169\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1761 - mean_absolute_error: 1.1756 - val_loss: 2.1380 - val_mean_absolute_error: 2.1130\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1677 - mean_absolute_error: 1.1696 - val_loss: 2.1305 - val_mean_absolute_error: 2.1080\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1602 - mean_absolute_error: 1.1613 - val_loss: 2.1355 - val_mean_absolute_error: 2.1116\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1618 - mean_absolute_error: 1.1610 - val_loss: 2.1460 - val_mean_absolute_error: 2.1265\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1714 - mean_absolute_error: 1.1687 - val_loss: 2.1478 - val_mean_absolute_error: 2.1222\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1613 - mean_absolute_error: 1.1605 - val_loss: 2.1476 - val_mean_absolute_error: 2.1226\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1626 - mean_absolute_error: 1.1643 - val_loss: 2.1495 - val_mean_absolute_error: 2.1259\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1552 - mean_absolute_error: 1.1548 - val_loss: 2.1464 - val_mean_absolute_error: 2.1217\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1581 - mean_absolute_error: 1.1586 - val_loss: 2.1296 - val_mean_absolute_error: 2.1018\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1708 - mean_absolute_error: 1.1694 - val_loss: 2.1246 - val_mean_absolute_error: 2.0973\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1745 - mean_absolute_error: 1.1765 - val_loss: 2.1357 - val_mean_absolute_error: 2.1124\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1518 - mean_absolute_error: 1.1520 - val_loss: 2.1424 - val_mean_absolute_error: 2.1150\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1567 - mean_absolute_error: 1.1593 - val_loss: 2.1351 - val_mean_absolute_error: 2.1096\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1796 - mean_absolute_error: 1.1782 - val_loss: 2.1410 - val_mean_absolute_error: 2.1150\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1714 - mean_absolute_error: 1.1740 - val_loss: 2.1479 - val_mean_absolute_error: 2.1245\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1636 - mean_absolute_error: 1.1641 - val_loss: 2.1412 - val_mean_absolute_error: 2.1146\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1716 - mean_absolute_error: 1.1750 - val_loss: 2.1396 - val_mean_absolute_error: 2.1125\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1670 - mean_absolute_error: 1.1701 - val_loss: 2.1349 - val_mean_absolute_error: 2.1058\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1645 - mean_absolute_error: 1.1667 - val_loss: 2.1411 - val_mean_absolute_error: 2.1174\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1643 - mean_absolute_error: 1.1630 - val_loss: 2.1450 - val_mean_absolute_error: 2.1172\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1671 - mean_absolute_error: 1.1663 - val_loss: 2.1515 - val_mean_absolute_error: 2.1277\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1613 - mean_absolute_error: 1.1623 - val_loss: 2.1527 - val_mean_absolute_error: 2.1279\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1513 - mean_absolute_error: 1.1528 - val_loss: 2.1480 - val_mean_absolute_error: 2.1269\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1847 - mean_absolute_error: 1.1851 - val_loss: 2.1474 - val_mean_absolute_error: 2.1221\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1570 - mean_absolute_error: 1.1562 - val_loss: 2.1409 - val_mean_absolute_error: 2.1158\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1512 - mean_absolute_error: 1.1491 - val_loss: 2.1518 - val_mean_absolute_error: 2.1276\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1620 - mean_absolute_error: 1.1628 - val_loss: 2.1608 - val_mean_absolute_error: 2.1364\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1657 - mean_absolute_error: 1.1681 - val_loss: 2.1544 - val_mean_absolute_error: 2.1267\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1537 - mean_absolute_error: 1.1565 - val_loss: 2.1649 - val_mean_absolute_error: 2.1414\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1679 - mean_absolute_error: 1.1692 - val_loss: 2.1534 - val_mean_absolute_error: 2.1286\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1835 - mean_absolute_error: 1.1825 - val_loss: 2.1394 - val_mean_absolute_error: 2.1177\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1644 - mean_absolute_error: 1.1667 - val_loss: 2.1422 - val_mean_absolute_error: 2.1182\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1606 - mean_absolute_error: 1.1583 - val_loss: 2.1429 - val_mean_absolute_error: 2.1210\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.1480 - mean_absolute_error: 1.1484 - val_loss: 2.1484 - val_mean_absolute_error: 2.1265\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1598 - mean_absolute_error: 1.1583 - val_loss: 2.1463 - val_mean_absolute_error: 2.1237\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1537 - mean_absolute_error: 1.1552 - val_loss: 2.1517 - val_mean_absolute_error: 2.1275\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1519 - mean_absolute_error: 1.1548 - val_loss: 2.1554 - val_mean_absolute_error: 2.1305\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1425 - mean_absolute_error: 1.1422 - val_loss: 2.1509 - val_mean_absolute_error: 2.1283\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1483 - mean_absolute_error: 1.1502 - val_loss: 2.1465 - val_mean_absolute_error: 2.1212\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1567 - mean_absolute_error: 1.1555 - val_loss: 2.1488 - val_mean_absolute_error: 2.1217\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1464 - mean_absolute_error: 1.1465 - val_loss: 2.1508 - val_mean_absolute_error: 2.1226\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1530 - mean_absolute_error: 1.1516 - val_loss: 2.1420 - val_mean_absolute_error: 2.1172\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1402 - mean_absolute_error: 1.1383 - val_loss: 2.1518 - val_mean_absolute_error: 2.1275\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1602 - mean_absolute_error: 1.1589 - val_loss: 2.1552 - val_mean_absolute_error: 2.1320\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1558 - mean_absolute_error: 1.1564 - val_loss: 2.1514 - val_mean_absolute_error: 2.1269\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1481 - mean_absolute_error: 1.1492 - val_loss: 2.1392 - val_mean_absolute_error: 2.1153\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1596 - mean_absolute_error: 1.1606 - val_loss: 2.1472 - val_mean_absolute_error: 2.1256\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1548 - mean_absolute_error: 1.1540 - val_loss: 2.1497 - val_mean_absolute_error: 2.1262\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1436 - mean_absolute_error: 1.1448 - val_loss: 2.1508 - val_mean_absolute_error: 2.1262\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1491 - mean_absolute_error: 1.1486 - val_loss: 2.1474 - val_mean_absolute_error: 2.1234\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1566 - mean_absolute_error: 1.1599 - val_loss: 2.1398 - val_mean_absolute_error: 2.1153\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1578 - mean_absolute_error: 1.1539 - val_loss: 2.1439 - val_mean_absolute_error: 2.1210\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1555 - mean_absolute_error: 1.1535 - val_loss: 2.1390 - val_mean_absolute_error: 2.1120\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1619 - mean_absolute_error: 1.1678 - val_loss: 2.1422 - val_mean_absolute_error: 2.1196\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1388 - mean_absolute_error: 1.1412 - val_loss: 2.1404 - val_mean_absolute_error: 2.1197\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1441 - mean_absolute_error: 1.1423 - val_loss: 2.1381 - val_mean_absolute_error: 2.1148\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1384 - mean_absolute_error: 1.1367 - val_loss: 2.1500 - val_mean_absolute_error: 2.1236\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1516 - mean_absolute_error: 1.1489 - val_loss: 2.1547 - val_mean_absolute_error: 2.1373\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1597 - mean_absolute_error: 1.1599 - val_loss: 2.1498 - val_mean_absolute_error: 2.1250\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1482 - mean_absolute_error: 1.1513 - val_loss: 2.1531 - val_mean_absolute_error: 2.1290\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1526 - mean_absolute_error: 1.1547 - val_loss: 2.1462 - val_mean_absolute_error: 2.1194\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1510 - mean_absolute_error: 1.1525 - val_loss: 2.1562 - val_mean_absolute_error: 2.1338\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1331 - mean_absolute_error: 1.1332 - val_loss: 2.1557 - val_mean_absolute_error: 2.1302\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1466 - mean_absolute_error: 1.1474 - val_loss: 2.1485 - val_mean_absolute_error: 2.1242\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1509 - mean_absolute_error: 1.1500 - val_loss: 2.1404 - val_mean_absolute_error: 2.1155\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1317 - mean_absolute_error: 1.1301 - val_loss: 2.1478 - val_mean_absolute_error: 2.1251\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1459 - mean_absolute_error: 1.1454 - val_loss: 2.1516 - val_mean_absolute_error: 2.1283\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1551 - mean_absolute_error: 1.1535 - val_loss: 2.1477 - val_mean_absolute_error: 2.1221\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1421 - mean_absolute_error: 1.1424 - val_loss: 2.1469 - val_mean_absolute_error: 2.1223\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1315 - mean_absolute_error: 1.1330 - val_loss: 2.1511 - val_mean_absolute_error: 2.1304\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1414 - mean_absolute_error: 1.1451 - val_loss: 2.1487 - val_mean_absolute_error: 2.1271\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1184 - mean_absolute_error: 1.1155 - val_loss: 2.1459 - val_mean_absolute_error: 2.1184\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1475 - mean_absolute_error: 1.1455 - val_loss: 2.1510 - val_mean_absolute_error: 2.1214\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1484 - mean_absolute_error: 1.1479 - val_loss: 2.1492 - val_mean_absolute_error: 2.1263\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1440 - mean_absolute_error: 1.1469 - val_loss: 2.1391 - val_mean_absolute_error: 2.1121\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1282 - mean_absolute_error: 1.1304 - val_loss: 2.1416 - val_mean_absolute_error: 2.1177\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1469 - mean_absolute_error: 1.1464 - val_loss: 2.1419 - val_mean_absolute_error: 2.1166\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1335 - mean_absolute_error: 1.1345 - val_loss: 2.1407 - val_mean_absolute_error: 2.1165\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.1427 - mean_absolute_error: 1.1412 - val_loss: 2.1369 - val_mean_absolute_error: 2.1099\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1315 - mean_absolute_error: 1.1303 - val_loss: 2.1408 - val_mean_absolute_error: 2.1171\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 1.1382 - mean_absolute_error: 1.1380 - val_loss: 2.1453 - val_mean_absolute_error: 2.1218\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1312 - mean_absolute_error: 1.1339 - val_loss: 2.1510 - val_mean_absolute_error: 2.1241\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1401 - mean_absolute_error: 1.1392 - val_loss: 2.1463 - val_mean_absolute_error: 2.1184\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1466 - mean_absolute_error: 1.1453 - val_loss: 2.1419 - val_mean_absolute_error: 2.1142\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1233 - mean_absolute_error: 1.1252 - val_loss: 2.1450 - val_mean_absolute_error: 2.1191\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1341 - mean_absolute_error: 1.1362 - val_loss: 2.1431 - val_mean_absolute_error: 2.1166\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1307 - mean_absolute_error: 1.1329 - val_loss: 2.1495 - val_mean_absolute_error: 2.1214\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1276 - mean_absolute_error: 1.1279 - val_loss: 2.1517 - val_mean_absolute_error: 2.1227\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1369 - mean_absolute_error: 1.1359 - val_loss: 2.1459 - val_mean_absolute_error: 2.1208\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1411 - mean_absolute_error: 1.1431 - val_loss: 2.1434 - val_mean_absolute_error: 2.1210\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1337 - mean_absolute_error: 1.1320 - val_loss: 2.1445 - val_mean_absolute_error: 2.1252\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1199 - mean_absolute_error: 1.1191 - val_loss: 2.1407 - val_mean_absolute_error: 2.1187\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1127 - mean_absolute_error: 1.1137 - val_loss: 2.1459 - val_mean_absolute_error: 2.1182\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1356 - mean_absolute_error: 1.1374 - val_loss: 2.1448 - val_mean_absolute_error: 2.1193\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1213 - mean_absolute_error: 1.1228 - val_loss: 2.1490 - val_mean_absolute_error: 2.1217\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1235 - mean_absolute_error: 1.1228 - val_loss: 2.1454 - val_mean_absolute_error: 2.1205\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1182 - mean_absolute_error: 1.1192 - val_loss: 2.1409 - val_mean_absolute_error: 2.1132\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1277 - mean_absolute_error: 1.1289 - val_loss: 2.1403 - val_mean_absolute_error: 2.1150\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1322 - mean_absolute_error: 1.1318 - val_loss: 2.1467 - val_mean_absolute_error: 2.1197\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1302 - mean_absolute_error: 1.1306 - val_loss: 2.1463 - val_mean_absolute_error: 2.1236\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1455 - mean_absolute_error: 1.1481 - val_loss: 2.1435 - val_mean_absolute_error: 2.1208\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1146 - mean_absolute_error: 1.1130 - val_loss: 2.1528 - val_mean_absolute_error: 2.1327\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1264 - mean_absolute_error: 1.1282 - val_loss: 2.1480 - val_mean_absolute_error: 2.1245\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1298 - mean_absolute_error: 1.1290 - val_loss: 2.1392 - val_mean_absolute_error: 2.1187\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1286 - mean_absolute_error: 1.1280 - val_loss: 2.1367 - val_mean_absolute_error: 2.1185\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1234 - mean_absolute_error: 1.1226 - val_loss: 2.1313 - val_mean_absolute_error: 2.1126\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1160 - mean_absolute_error: 1.1153 - val_loss: 2.1434 - val_mean_absolute_error: 2.1211\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1355 - mean_absolute_error: 1.1389 - val_loss: 2.1442 - val_mean_absolute_error: 2.1213\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1245 - mean_absolute_error: 1.1242 - val_loss: 2.1413 - val_mean_absolute_error: 2.1155\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1232 - mean_absolute_error: 1.1263 - val_loss: 2.1384 - val_mean_absolute_error: 2.1180\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1155 - mean_absolute_error: 1.1143 - val_loss: 2.1454 - val_mean_absolute_error: 2.1236\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1412 - mean_absolute_error: 1.1400 - val_loss: 2.1526 - val_mean_absolute_error: 2.1325\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1232 - mean_absolute_error: 1.1242 - val_loss: 2.1421 - val_mean_absolute_error: 2.1171\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1282 - mean_absolute_error: 1.1291 - val_loss: 2.1420 - val_mean_absolute_error: 2.1202\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1307 - mean_absolute_error: 1.1310 - val_loss: 2.1398 - val_mean_absolute_error: 2.1152\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.1322 - mean_absolute_error: 1.1290 - val_loss: 2.1409 - val_mean_absolute_error: 2.1220\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1247 - mean_absolute_error: 1.1262 - val_loss: 2.1436 - val_mean_absolute_error: 2.1179\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1252 - mean_absolute_error: 1.1263 - val_loss: 2.1397 - val_mean_absolute_error: 2.1136\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1120 - mean_absolute_error: 1.1109 - val_loss: 2.1368 - val_mean_absolute_error: 2.1148\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1269 - mean_absolute_error: 1.1254 - val_loss: 2.1376 - val_mean_absolute_error: 2.1148\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1066 - mean_absolute_error: 1.1106 - val_loss: 2.1336 - val_mean_absolute_error: 2.1132\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1317 - mean_absolute_error: 1.1314 - val_loss: 2.1340 - val_mean_absolute_error: 2.1100\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1208 - mean_absolute_error: 1.1181 - val_loss: 2.1447 - val_mean_absolute_error: 2.1208\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1092 - mean_absolute_error: 1.1106 - val_loss: 2.1495 - val_mean_absolute_error: 2.1231\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1230 - mean_absolute_error: 1.1263 - val_loss: 2.1486 - val_mean_absolute_error: 2.1209\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1291 - mean_absolute_error: 1.1270 - val_loss: 2.1524 - val_mean_absolute_error: 2.1263\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1049 - mean_absolute_error: 1.1053 - val_loss: 2.1496 - val_mean_absolute_error: 2.1199\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1258 - mean_absolute_error: 1.1247 - val_loss: 2.1446 - val_mean_absolute_error: 2.1187\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1292 - mean_absolute_error: 1.1282 - val_loss: 2.1501 - val_mean_absolute_error: 2.1237\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1269 - mean_absolute_error: 1.1251 - val_loss: 2.1463 - val_mean_absolute_error: 2.1211\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1056 - mean_absolute_error: 1.1062 - val_loss: 2.1476 - val_mean_absolute_error: 2.1197\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1071 - mean_absolute_error: 1.1082 - val_loss: 2.1418 - val_mean_absolute_error: 2.1181\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1058 - mean_absolute_error: 1.1063 - val_loss: 2.1336 - val_mean_absolute_error: 2.1089\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1192 - mean_absolute_error: 1.1190 - val_loss: 2.1432 - val_mean_absolute_error: 2.1180\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1174 - mean_absolute_error: 1.1202 - val_loss: 2.1475 - val_mean_absolute_error: 2.1222\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0953 - mean_absolute_error: 1.0977 - val_loss: 2.1440 - val_mean_absolute_error: 2.1177\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1185 - mean_absolute_error: 1.1196 - val_loss: 2.1420 - val_mean_absolute_error: 2.1169\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1280 - mean_absolute_error: 1.1285 - val_loss: 2.1428 - val_mean_absolute_error: 2.1160\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1232 - mean_absolute_error: 1.1269 - val_loss: 2.1322 - val_mean_absolute_error: 2.1073\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1130 - mean_absolute_error: 1.1120 - val_loss: 2.1267 - val_mean_absolute_error: 2.1026\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1268 - mean_absolute_error: 1.1283 - val_loss: 2.1314 - val_mean_absolute_error: 2.1070\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1116 - mean_absolute_error: 1.1122 - val_loss: 2.1338 - val_mean_absolute_error: 2.1047\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1164 - mean_absolute_error: 1.1157 - val_loss: 2.1338 - val_mean_absolute_error: 2.1074\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1032 - mean_absolute_error: 1.1021 - val_loss: 2.1366 - val_mean_absolute_error: 2.1088\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1242 - mean_absolute_error: 1.1241 - val_loss: 2.1404 - val_mean_absolute_error: 2.1152\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1150 - mean_absolute_error: 1.1176 - val_loss: 2.1407 - val_mean_absolute_error: 2.1131\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1058 - mean_absolute_error: 1.1083 - val_loss: 2.1405 - val_mean_absolute_error: 2.1164\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 1.1152 - mean_absolute_error: 1.1153 - val_loss: 2.1411 - val_mean_absolute_error: 2.1198\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1158 - mean_absolute_error: 1.1148 - val_loss: 2.1431 - val_mean_absolute_error: 2.1200\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1188 - mean_absolute_error: 1.1177 - val_loss: 2.1398 - val_mean_absolute_error: 2.1146\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1118 - mean_absolute_error: 1.1145 - val_loss: 2.1447 - val_mean_absolute_error: 2.1220\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1022 - mean_absolute_error: 1.1030 - val_loss: 2.1426 - val_mean_absolute_error: 2.1191\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1108 - mean_absolute_error: 1.1103 - val_loss: 2.1374 - val_mean_absolute_error: 2.1150\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1012 - mean_absolute_error: 1.0996 - val_loss: 2.1384 - val_mean_absolute_error: 2.1098\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1022 - mean_absolute_error: 1.1037 - val_loss: 2.1407 - val_mean_absolute_error: 2.1150\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1067 - mean_absolute_error: 1.1072 - val_loss: 2.1318 - val_mean_absolute_error: 2.1051\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.1153 - mean_absolute_error: 1.1166 - val_loss: 2.1385 - val_mean_absolute_error: 2.1149\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0970 - mean_absolute_error: 1.0993 - val_loss: 2.1434 - val_mean_absolute_error: 2.1157\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.1036 - mean_absolute_error: 1.1046 - val_loss: 2.1431 - val_mean_absolute_error: 2.1178\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1020 - mean_absolute_error: 1.1017 - val_loss: 2.1410 - val_mean_absolute_error: 2.1171\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1249 - mean_absolute_error: 1.1267 - val_loss: 2.1426 - val_mean_absolute_error: 2.1182\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1053 - mean_absolute_error: 1.1027 - val_loss: 2.1438 - val_mean_absolute_error: 2.1158\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0900 - mean_absolute_error: 1.0910 - val_loss: 2.1490 - val_mean_absolute_error: 2.1234\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1020 - mean_absolute_error: 1.1014 - val_loss: 2.1488 - val_mean_absolute_error: 2.1248\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0938 - mean_absolute_error: 1.0924 - val_loss: 2.1417 - val_mean_absolute_error: 2.1172\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1201 - mean_absolute_error: 1.1206 - val_loss: 2.1424 - val_mean_absolute_error: 2.1196\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1168 - mean_absolute_error: 1.1174 - val_loss: 2.1414 - val_mean_absolute_error: 2.1142\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.1108 - mean_absolute_error: 1.1099 - val_loss: 2.1356 - val_mean_absolute_error: 2.1108\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1071 - mean_absolute_error: 1.1052 - val_loss: 2.1340 - val_mean_absolute_error: 2.1073\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0977 - mean_absolute_error: 1.0986 - val_loss: 2.1285 - val_mean_absolute_error: 2.1054\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1125 - mean_absolute_error: 1.1132 - val_loss: 2.1297 - val_mean_absolute_error: 2.1022\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0914 - mean_absolute_error: 1.0919 - val_loss: 2.1314 - val_mean_absolute_error: 2.1040\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0901 - mean_absolute_error: 1.0915 - val_loss: 2.1378 - val_mean_absolute_error: 2.1074\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1126 - mean_absolute_error: 1.1118 - val_loss: 2.1360 - val_mean_absolute_error: 2.1064\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0852 - mean_absolute_error: 1.0876 - val_loss: 2.1346 - val_mean_absolute_error: 2.1071\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0970 - mean_absolute_error: 1.0973 - val_loss: 2.1414 - val_mean_absolute_error: 2.1144\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1047 - mean_absolute_error: 1.1044 - val_loss: 2.1453 - val_mean_absolute_error: 2.1164\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0990 - mean_absolute_error: 1.0996 - val_loss: 2.1383 - val_mean_absolute_error: 2.1082\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0965 - mean_absolute_error: 1.0948 - val_loss: 2.1376 - val_mean_absolute_error: 2.1118\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0824 - mean_absolute_error: 1.0812 - val_loss: 2.1374 - val_mean_absolute_error: 2.1121\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1064 - mean_absolute_error: 1.1048 - val_loss: 2.1322 - val_mean_absolute_error: 2.1076\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1046 - mean_absolute_error: 1.1051 - val_loss: 2.1344 - val_mean_absolute_error: 2.1085\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0860 - mean_absolute_error: 1.0869 - val_loss: 2.1426 - val_mean_absolute_error: 2.1144\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.1059 - mean_absolute_error: 1.1093 - val_loss: 2.1410 - val_mean_absolute_error: 2.1159\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1101 - mean_absolute_error: 1.1085 - val_loss: 2.1331 - val_mean_absolute_error: 2.1098\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0987 - mean_absolute_error: 1.0968 - val_loss: 2.1402 - val_mean_absolute_error: 2.1114\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0952 - mean_absolute_error: 1.0962 - val_loss: 2.1433 - val_mean_absolute_error: 2.1169\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1107 - mean_absolute_error: 1.1112 - val_loss: 2.1456 - val_mean_absolute_error: 2.1211\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0864 - mean_absolute_error: 1.0856 - val_loss: 2.1458 - val_mean_absolute_error: 2.1218\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1070 - mean_absolute_error: 1.1047 - val_loss: 2.1469 - val_mean_absolute_error: 2.1192\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0797 - mean_absolute_error: 1.0835 - val_loss: 2.1492 - val_mean_absolute_error: 2.1223\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0894 - mean_absolute_error: 1.0907 - val_loss: 2.1401 - val_mean_absolute_error: 2.1104\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0956 - mean_absolute_error: 1.0947 - val_loss: 2.1347 - val_mean_absolute_error: 2.1033\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0830 - mean_absolute_error: 1.0838 - val_loss: 2.1399 - val_mean_absolute_error: 2.1115\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.1073 - mean_absolute_error: 1.1061 - val_loss: 2.1419 - val_mean_absolute_error: 2.1148\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1031 - mean_absolute_error: 1.1048 - val_loss: 2.1508 - val_mean_absolute_error: 2.1209\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0706 - mean_absolute_error: 1.0691 - val_loss: 2.1434 - val_mean_absolute_error: 2.1152\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0737 - mean_absolute_error: 1.0753 - val_loss: 2.1467 - val_mean_absolute_error: 2.1166\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0909 - mean_absolute_error: 1.0891 - val_loss: 2.1417 - val_mean_absolute_error: 2.1126\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0899 - mean_absolute_error: 1.0896 - val_loss: 2.1405 - val_mean_absolute_error: 2.1110\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0932 - mean_absolute_error: 1.0887 - val_loss: 2.1365 - val_mean_absolute_error: 2.1058\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1152 - mean_absolute_error: 1.1169 - val_loss: 2.1356 - val_mean_absolute_error: 2.1051\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0977 - mean_absolute_error: 1.0941 - val_loss: 2.1344 - val_mean_absolute_error: 2.1084\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.1054 - mean_absolute_error: 1.1036 - val_loss: 2.1453 - val_mean_absolute_error: 2.1194\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0932 - mean_absolute_error: 1.0955 - val_loss: 2.1458 - val_mean_absolute_error: 2.1147\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0877 - mean_absolute_error: 1.0868 - val_loss: 2.1404 - val_mean_absolute_error: 2.1095\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1025 - mean_absolute_error: 1.1016 - val_loss: 2.1418 - val_mean_absolute_error: 2.1109\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1025 - mean_absolute_error: 1.1029 - val_loss: 2.1421 - val_mean_absolute_error: 2.1133\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0813 - mean_absolute_error: 1.0832 - val_loss: 2.1395 - val_mean_absolute_error: 2.1089\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0877 - mean_absolute_error: 1.0886 - val_loss: 2.1443 - val_mean_absolute_error: 2.1152\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0935 - mean_absolute_error: 1.0910 - val_loss: 2.1437 - val_mean_absolute_error: 2.1185\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0856 - mean_absolute_error: 1.0828 - val_loss: 2.1392 - val_mean_absolute_error: 2.1130\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0839 - mean_absolute_error: 1.0868 - val_loss: 2.1396 - val_mean_absolute_error: 2.1151\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.1011 - mean_absolute_error: 1.1022 - val_loss: 2.1371 - val_mean_absolute_error: 2.1106\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0932 - mean_absolute_error: 1.0963 - val_loss: 2.1300 - val_mean_absolute_error: 2.1046\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0729 - mean_absolute_error: 1.0749 - val_loss: 2.1402 - val_mean_absolute_error: 2.1152\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0928 - mean_absolute_error: 1.0929 - val_loss: 2.1433 - val_mean_absolute_error: 2.1171\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0928 - mean_absolute_error: 1.0925 - val_loss: 2.1399 - val_mean_absolute_error: 2.1162\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0950 - mean_absolute_error: 1.0952 - val_loss: 2.1381 - val_mean_absolute_error: 2.1135\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0966 - mean_absolute_error: 1.0972 - val_loss: 2.1386 - val_mean_absolute_error: 2.1165\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0965 - mean_absolute_error: 1.0975 - val_loss: 2.1398 - val_mean_absolute_error: 2.1138\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0723 - mean_absolute_error: 1.0713 - val_loss: 2.1382 - val_mean_absolute_error: 2.1139\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0781 - mean_absolute_error: 1.0767 - val_loss: 2.1343 - val_mean_absolute_error: 2.1098\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1046 - mean_absolute_error: 1.1038 - val_loss: 2.1352 - val_mean_absolute_error: 2.1127\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0944 - mean_absolute_error: 1.0961 - val_loss: 2.1378 - val_mean_absolute_error: 2.1102\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0815 - mean_absolute_error: 1.0822 - val_loss: 2.1408 - val_mean_absolute_error: 2.1153\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0899 - mean_absolute_error: 1.0889 - val_loss: 2.1341 - val_mean_absolute_error: 2.1067\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0800 - mean_absolute_error: 1.0812 - val_loss: 2.1363 - val_mean_absolute_error: 2.1064\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.1015 - mean_absolute_error: 1.1035 - val_loss: 2.1428 - val_mean_absolute_error: 2.1164\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0834 - mean_absolute_error: 1.0861 - val_loss: 2.1381 - val_mean_absolute_error: 2.1110\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0895 - mean_absolute_error: 1.0886 - val_loss: 2.1423 - val_mean_absolute_error: 2.1151\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0830 - mean_absolute_error: 1.0836 - val_loss: 2.1483 - val_mean_absolute_error: 2.1169\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0753 - mean_absolute_error: 1.0752 - val_loss: 2.1470 - val_mean_absolute_error: 2.1185\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0754 - mean_absolute_error: 1.0783 - val_loss: 2.1405 - val_mean_absolute_error: 2.1144\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0818 - mean_absolute_error: 1.0843 - val_loss: 2.1435 - val_mean_absolute_error: 2.1161\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0903 - mean_absolute_error: 1.0892 - val_loss: 2.1469 - val_mean_absolute_error: 2.1199\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0966 - mean_absolute_error: 1.0945 - val_loss: 2.1476 - val_mean_absolute_error: 2.1176\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0823 - mean_absolute_error: 1.0823 - val_loss: 2.1471 - val_mean_absolute_error: 2.1200\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0769 - mean_absolute_error: 1.0763 - val_loss: 2.1415 - val_mean_absolute_error: 2.1148\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0731 - mean_absolute_error: 1.0732 - val_loss: 2.1398 - val_mean_absolute_error: 2.1162\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0876 - mean_absolute_error: 1.0835 - val_loss: 2.1498 - val_mean_absolute_error: 2.1245\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0812 - mean_absolute_error: 1.0823 - val_loss: 2.1430 - val_mean_absolute_error: 2.1160\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0750 - mean_absolute_error: 1.0761 - val_loss: 2.1424 - val_mean_absolute_error: 2.1171\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0848 - mean_absolute_error: 1.0848 - val_loss: 2.1415 - val_mean_absolute_error: 2.1160\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0905 - mean_absolute_error: 1.0925 - val_loss: 2.1445 - val_mean_absolute_error: 2.1195\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0900 - mean_absolute_error: 1.0887 - val_loss: 2.1460 - val_mean_absolute_error: 2.1197\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0681 - mean_absolute_error: 1.0687 - val_loss: 2.1423 - val_mean_absolute_error: 2.1150\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0801 - mean_absolute_error: 1.0777 - val_loss: 2.1402 - val_mean_absolute_error: 2.1161\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0839 - mean_absolute_error: 1.0835 - val_loss: 2.1515 - val_mean_absolute_error: 2.1263\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0868 - mean_absolute_error: 1.0868 - val_loss: 2.1529 - val_mean_absolute_error: 2.1296\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0745 - mean_absolute_error: 1.0737 - val_loss: 2.1487 - val_mean_absolute_error: 2.1264\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0863 - mean_absolute_error: 1.0847 - val_loss: 2.1477 - val_mean_absolute_error: 2.1224\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0754 - mean_absolute_error: 1.0757 - val_loss: 2.1413 - val_mean_absolute_error: 2.1164\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0875 - mean_absolute_error: 1.0889 - val_loss: 2.1373 - val_mean_absolute_error: 2.1109\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0937 - mean_absolute_error: 1.0948 - val_loss: 2.1356 - val_mean_absolute_error: 2.1092\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0926 - mean_absolute_error: 1.0959 - val_loss: 2.1422 - val_mean_absolute_error: 2.1164\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0710 - mean_absolute_error: 1.0697 - val_loss: 2.1446 - val_mean_absolute_error: 2.1192\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0646 - mean_absolute_error: 1.0608 - val_loss: 2.1443 - val_mean_absolute_error: 2.1204\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0807 - mean_absolute_error: 1.0801 - val_loss: 2.1422 - val_mean_absolute_error: 2.1167\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0773 - mean_absolute_error: 1.0765 - val_loss: 2.1460 - val_mean_absolute_error: 2.1218\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0830 - mean_absolute_error: 1.0836 - val_loss: 2.1425 - val_mean_absolute_error: 2.1176\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0693 - mean_absolute_error: 1.0693 - val_loss: 2.1410 - val_mean_absolute_error: 2.1158\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0888 - mean_absolute_error: 1.0892 - val_loss: 2.1457 - val_mean_absolute_error: 2.1161\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0601 - mean_absolute_error: 1.0608 - val_loss: 2.1449 - val_mean_absolute_error: 2.1141\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0822 - mean_absolute_error: 1.0838 - val_loss: 2.1481 - val_mean_absolute_error: 2.1176\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0738 - mean_absolute_error: 1.0758 - val_loss: 2.1438 - val_mean_absolute_error: 2.1119\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0837 - mean_absolute_error: 1.0808 - val_loss: 2.1453 - val_mean_absolute_error: 2.1149\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0605 - mean_absolute_error: 1.0624 - val_loss: 2.1471 - val_mean_absolute_error: 2.1171\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0790 - mean_absolute_error: 1.0795 - val_loss: 2.1454 - val_mean_absolute_error: 2.1196\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0780 - mean_absolute_error: 1.0803 - val_loss: 2.1425 - val_mean_absolute_error: 2.1146\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0672 - mean_absolute_error: 1.0675 - val_loss: 2.1413 - val_mean_absolute_error: 2.1107\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0742 - mean_absolute_error: 1.0779 - val_loss: 2.1444 - val_mean_absolute_error: 2.1170\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0620 - mean_absolute_error: 1.0679 - val_loss: 2.1455 - val_mean_absolute_error: 2.1152\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0625 - mean_absolute_error: 1.0629 - val_loss: 2.1472 - val_mean_absolute_error: 2.1198\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0590 - mean_absolute_error: 1.0611 - val_loss: 2.1377 - val_mean_absolute_error: 2.1094\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0724 - mean_absolute_error: 1.0725 - val_loss: 2.1378 - val_mean_absolute_error: 2.1111\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0888 - mean_absolute_error: 1.0868 - val_loss: 2.1446 - val_mean_absolute_error: 2.1186\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0637 - mean_absolute_error: 1.0639 - val_loss: 2.1406 - val_mean_absolute_error: 2.1112\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0907 - mean_absolute_error: 1.0916 - val_loss: 2.1391 - val_mean_absolute_error: 2.1082\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0759 - mean_absolute_error: 1.0757 - val_loss: 2.1401 - val_mean_absolute_error: 2.1092\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0554 - mean_absolute_error: 1.0547 - val_loss: 2.1445 - val_mean_absolute_error: 2.1151\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0808 - mean_absolute_error: 1.0808 - val_loss: 2.1444 - val_mean_absolute_error: 2.1135\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0709 - mean_absolute_error: 1.0693 - val_loss: 2.1399 - val_mean_absolute_error: 2.1093\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0598 - mean_absolute_error: 1.0593 - val_loss: 2.1378 - val_mean_absolute_error: 2.1047\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0800 - mean_absolute_error: 1.0816 - val_loss: 2.1409 - val_mean_absolute_error: 2.1121\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0799 - mean_absolute_error: 1.0824 - val_loss: 2.1380 - val_mean_absolute_error: 2.1144\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0777 - mean_absolute_error: 1.0749 - val_loss: 2.1346 - val_mean_absolute_error: 2.1060\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0720 - mean_absolute_error: 1.0715 - val_loss: 2.1339 - val_mean_absolute_error: 2.1059\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0638 - mean_absolute_error: 1.0654 - val_loss: 2.1378 - val_mean_absolute_error: 2.1110\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0695 - mean_absolute_error: 1.0688 - val_loss: 2.1399 - val_mean_absolute_error: 2.1107\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0692 - mean_absolute_error: 1.0720 - val_loss: 2.1369 - val_mean_absolute_error: 2.1082\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0490 - mean_absolute_error: 1.0486 - val_loss: 2.1452 - val_mean_absolute_error: 2.1133\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0630 - mean_absolute_error: 1.0633 - val_loss: 2.1463 - val_mean_absolute_error: 2.1136\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0675 - mean_absolute_error: 1.0665 - val_loss: 2.1415 - val_mean_absolute_error: 2.1103\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0612 - mean_absolute_error: 1.0617 - val_loss: 2.1378 - val_mean_absolute_error: 2.1065\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0688 - mean_absolute_error: 1.0675 - val_loss: 2.1370 - val_mean_absolute_error: 2.1066\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0537 - mean_absolute_error: 1.0497 - val_loss: 2.1310 - val_mean_absolute_error: 2.1003\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0832 - mean_absolute_error: 1.0856 - val_loss: 2.1404 - val_mean_absolute_error: 2.1109\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0600 - mean_absolute_error: 1.0625 - val_loss: 2.1518 - val_mean_absolute_error: 2.1224\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0687 - mean_absolute_error: 1.0707 - val_loss: 2.1471 - val_mean_absolute_error: 2.1160\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0693 - mean_absolute_error: 1.0715 - val_loss: 2.1394 - val_mean_absolute_error: 2.1113\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0586 - mean_absolute_error: 1.0596 - val_loss: 2.1355 - val_mean_absolute_error: 2.1092\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0736 - mean_absolute_error: 1.0721 - val_loss: 2.1336 - val_mean_absolute_error: 2.1054\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0578 - mean_absolute_error: 1.0575 - val_loss: 2.1351 - val_mean_absolute_error: 2.1054\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0711 - mean_absolute_error: 1.0711 - val_loss: 2.1372 - val_mean_absolute_error: 2.1066\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0648 - mean_absolute_error: 1.0658 - val_loss: 2.1368 - val_mean_absolute_error: 2.1094\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0610 - mean_absolute_error: 1.0606 - val_loss: 2.1374 - val_mean_absolute_error: 2.1068\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0761 - mean_absolute_error: 1.0738 - val_loss: 2.1340 - val_mean_absolute_error: 2.1055\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0571 - mean_absolute_error: 1.0556 - val_loss: 2.1316 - val_mean_absolute_error: 2.1033\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0605 - mean_absolute_error: 1.0594 - val_loss: 2.1385 - val_mean_absolute_error: 2.1130\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0657 - mean_absolute_error: 1.0652 - val_loss: 2.1449 - val_mean_absolute_error: 2.1204\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0736 - mean_absolute_error: 1.0719 - val_loss: 2.1399 - val_mean_absolute_error: 2.1116\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0836 - mean_absolute_error: 1.0811 - val_loss: 2.1351 - val_mean_absolute_error: 2.1085\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0634 - mean_absolute_error: 1.0647 - val_loss: 2.1337 - val_mean_absolute_error: 2.1045\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0519 - mean_absolute_error: 1.0523 - val_loss: 2.1413 - val_mean_absolute_error: 2.1137\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0725 - mean_absolute_error: 1.0708 - val_loss: 2.1404 - val_mean_absolute_error: 2.1150\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0439 - mean_absolute_error: 1.0442 - val_loss: 2.1396 - val_mean_absolute_error: 2.1152\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0348 - mean_absolute_error: 1.0345 - val_loss: 2.1447 - val_mean_absolute_error: 2.1171\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0370 - mean_absolute_error: 1.0365 - val_loss: 2.1418 - val_mean_absolute_error: 2.1167\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0585 - mean_absolute_error: 1.0567 - val_loss: 2.1439 - val_mean_absolute_error: 2.1190\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0638 - mean_absolute_error: 1.0655 - val_loss: 2.1446 - val_mean_absolute_error: 2.1205\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0678 - mean_absolute_error: 1.0674 - val_loss: 2.1351 - val_mean_absolute_error: 2.1092\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0601 - mean_absolute_error: 1.0629 - val_loss: 2.1329 - val_mean_absolute_error: 2.1048\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0701 - mean_absolute_error: 1.0699 - val_loss: 2.1417 - val_mean_absolute_error: 2.1157\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0469 - mean_absolute_error: 1.0494 - val_loss: 2.1382 - val_mean_absolute_error: 2.1127\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0633 - mean_absolute_error: 1.0653 - val_loss: 2.1316 - val_mean_absolute_error: 2.1044\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0405 - mean_absolute_error: 1.0417 - val_loss: 2.1381 - val_mean_absolute_error: 2.1091\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0678 - mean_absolute_error: 1.0679 - val_loss: 2.1431 - val_mean_absolute_error: 2.1182\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0639 - mean_absolute_error: 1.0623 - val_loss: 2.1369 - val_mean_absolute_error: 2.1138\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0466 - mean_absolute_error: 1.0495 - val_loss: 2.1333 - val_mean_absolute_error: 2.1080\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0617 - mean_absolute_error: 1.0628 - val_loss: 2.1362 - val_mean_absolute_error: 2.1118\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0389 - mean_absolute_error: 1.0411 - val_loss: 2.1434 - val_mean_absolute_error: 2.1206\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0562 - mean_absolute_error: 1.0572 - val_loss: 2.1462 - val_mean_absolute_error: 2.1229\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0369 - mean_absolute_error: 1.0393 - val_loss: 2.1382 - val_mean_absolute_error: 2.1172\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0708 - mean_absolute_error: 1.0719 - val_loss: 2.1346 - val_mean_absolute_error: 2.1144\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0509 - mean_absolute_error: 1.0537 - val_loss: 2.1401 - val_mean_absolute_error: 2.1189\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0448 - mean_absolute_error: 1.0441 - val_loss: 2.1428 - val_mean_absolute_error: 2.1221\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0472 - mean_absolute_error: 1.0500 - val_loss: 2.1409 - val_mean_absolute_error: 2.1201\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0561 - mean_absolute_error: 1.0551 - val_loss: 2.1393 - val_mean_absolute_error: 2.1137\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0482 - mean_absolute_error: 1.0477 - val_loss: 2.1453 - val_mean_absolute_error: 2.1196\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0597 - mean_absolute_error: 1.0573 - val_loss: 2.1475 - val_mean_absolute_error: 2.1227\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0600 - mean_absolute_error: 1.0621 - val_loss: 2.1421 - val_mean_absolute_error: 2.1192\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0449 - mean_absolute_error: 1.0443 - val_loss: 2.1438 - val_mean_absolute_error: 2.1192\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0549 - mean_absolute_error: 1.0544 - val_loss: 2.1429 - val_mean_absolute_error: 2.1208\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0365 - mean_absolute_error: 1.0382 - val_loss: 2.1447 - val_mean_absolute_error: 2.1192\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0613 - mean_absolute_error: 1.0630 - val_loss: 2.1496 - val_mean_absolute_error: 2.1235\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0457 - mean_absolute_error: 1.0458 - val_loss: 2.1465 - val_mean_absolute_error: 2.1192\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0492 - mean_absolute_error: 1.0474 - val_loss: 2.1463 - val_mean_absolute_error: 2.1174\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0483 - mean_absolute_error: 1.0480 - val_loss: 2.1459 - val_mean_absolute_error: 2.1165\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0518 - mean_absolute_error: 1.0531 - val_loss: 2.1454 - val_mean_absolute_error: 2.1189\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0382 - mean_absolute_error: 1.0380 - val_loss: 2.1430 - val_mean_absolute_error: 2.1174\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0429 - mean_absolute_error: 1.0422 - val_loss: 2.1439 - val_mean_absolute_error: 2.1169\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0281 - mean_absolute_error: 1.0296 - val_loss: 2.1488 - val_mean_absolute_error: 2.1201\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.0429 - mean_absolute_error: 1.0411 - val_loss: 2.1395 - val_mean_absolute_error: 2.1124\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0512 - mean_absolute_error: 1.0526 - val_loss: 2.1430 - val_mean_absolute_error: 2.1165\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0511 - mean_absolute_error: 1.0514 - val_loss: 2.1477 - val_mean_absolute_error: 2.1245\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0515 - mean_absolute_error: 1.0533 - val_loss: 2.1385 - val_mean_absolute_error: 2.1153\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0440 - mean_absolute_error: 1.0434 - val_loss: 2.1294 - val_mean_absolute_error: 2.1066\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0420 - mean_absolute_error: 1.0406 - val_loss: 2.1367 - val_mean_absolute_error: 2.1152\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0513 - mean_absolute_error: 1.0514 - val_loss: 2.1405 - val_mean_absolute_error: 2.1142\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0250 - mean_absolute_error: 1.0263 - val_loss: 2.1295 - val_mean_absolute_error: 2.1071\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0584 - mean_absolute_error: 1.0582 - val_loss: 2.1281 - val_mean_absolute_error: 2.1046\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0443 - mean_absolute_error: 1.0475 - val_loss: 2.1309 - val_mean_absolute_error: 2.1088\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 1.0447 - mean_absolute_error: 1.0464 - val_loss: 2.1345 - val_mean_absolute_error: 2.1087\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0443 - mean_absolute_error: 1.0431 - val_loss: 2.1311 - val_mean_absolute_error: 2.1059\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0471 - mean_absolute_error: 1.0516 - val_loss: 2.1340 - val_mean_absolute_error: 2.1057\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0464 - mean_absolute_error: 1.0473 - val_loss: 2.1378 - val_mean_absolute_error: 2.1123\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0412 - mean_absolute_error: 1.0416 - val_loss: 2.1381 - val_mean_absolute_error: 2.1085\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0446 - mean_absolute_error: 1.0453 - val_loss: 2.1364 - val_mean_absolute_error: 2.1114\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0724 - mean_absolute_error: 1.0705 - val_loss: 2.1299 - val_mean_absolute_error: 2.1036\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0481 - mean_absolute_error: 1.0489 - val_loss: 2.1283 - val_mean_absolute_error: 2.1019\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0548 - mean_absolute_error: 1.0543 - val_loss: 2.1349 - val_mean_absolute_error: 2.1109\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0471 - mean_absolute_error: 1.0491 - val_loss: 2.1424 - val_mean_absolute_error: 2.1170\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0296 - mean_absolute_error: 1.0301 - val_loss: 2.1358 - val_mean_absolute_error: 2.1118\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0461 - mean_absolute_error: 1.0444 - val_loss: 2.1329 - val_mean_absolute_error: 2.1062\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0562 - mean_absolute_error: 1.0548 - val_loss: 2.1312 - val_mean_absolute_error: 2.1033\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0442 - mean_absolute_error: 1.0465 - val_loss: 2.1327 - val_mean_absolute_error: 2.1056\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0468 - mean_absolute_error: 1.0463 - val_loss: 2.1318 - val_mean_absolute_error: 2.1057\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0464 - mean_absolute_error: 1.0486 - val_loss: 2.1342 - val_mean_absolute_error: 2.1112\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0347 - mean_absolute_error: 1.0330 - val_loss: 2.1335 - val_mean_absolute_error: 2.1091\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0355 - mean_absolute_error: 1.0385 - val_loss: 2.1292 - val_mean_absolute_error: 2.1039\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0412 - mean_absolute_error: 1.0423 - val_loss: 2.1364 - val_mean_absolute_error: 2.1140\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0618 - mean_absolute_error: 1.0664 - val_loss: 2.1343 - val_mean_absolute_error: 2.1038\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0324 - mean_absolute_error: 1.0336 - val_loss: 2.1326 - val_mean_absolute_error: 2.1051\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0295 - mean_absolute_error: 1.0306 - val_loss: 2.1348 - val_mean_absolute_error: 2.1080\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0517 - mean_absolute_error: 1.0503 - val_loss: 2.1321 - val_mean_absolute_error: 2.1071\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0450 - mean_absolute_error: 1.0447 - val_loss: 2.1432 - val_mean_absolute_error: 2.1150\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0425 - mean_absolute_error: 1.0430 - val_loss: 2.1406 - val_mean_absolute_error: 2.1103\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0218 - mean_absolute_error: 1.0234 - val_loss: 2.1341 - val_mean_absolute_error: 2.1040\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0534 - mean_absolute_error: 1.0509 - val_loss: 2.1365 - val_mean_absolute_error: 2.1075\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0422 - mean_absolute_error: 1.0441 - val_loss: 2.1429 - val_mean_absolute_error: 2.1167\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0368 - mean_absolute_error: 1.0367 - val_loss: 2.1417 - val_mean_absolute_error: 2.1156\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0462 - mean_absolute_error: 1.0489 - val_loss: 2.1339 - val_mean_absolute_error: 2.1072\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 1.0347 - mean_absolute_error: 1.0340 - val_loss: 2.1294 - val_mean_absolute_error: 2.1033\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0434 - mean_absolute_error: 1.0453 - val_loss: 2.1257 - val_mean_absolute_error: 2.0973\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0376 - mean_absolute_error: 1.0369 - val_loss: 2.1346 - val_mean_absolute_error: 2.1072\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.0484 - mean_absolute_error: 1.0480 - val_loss: 2.1357 - val_mean_absolute_error: 2.1073\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 1.0324 - mean_absolute_error: 1.0321 - val_loss: 2.1301 - val_mean_absolute_error: 2.1030\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0381 - mean_absolute_error: 1.0364 - val_loss: 2.1313 - val_mean_absolute_error: 2.1042\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0310 - mean_absolute_error: 1.0320 - val_loss: 2.1331 - val_mean_absolute_error: 2.1053\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0394 - mean_absolute_error: 1.0398 - val_loss: 2.1411 - val_mean_absolute_error: 2.1143\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.0356 - mean_absolute_error: 1.0353 - val_loss: 2.1465 - val_mean_absolute_error: 2.1229\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0418 - mean_absolute_error: 1.0422 - val_loss: 2.1383 - val_mean_absolute_error: 2.1115\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 1.0255 - mean_absolute_error: 1.0265 - val_loss: 2.1356 - val_mean_absolute_error: 2.1104\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, epochs=MAX_EPOCHS, batch_size = 64, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history1, 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66414697 0.78665135 0.77614194 0.39363502 7.55496482 4.69259199\n",
      " 8.41778036 1.77775675 2.40187552 8.86480884 5.74699222 0.15203723\n",
      " 9.67635508 5.25870437 2.65330178]\n",
      "[0.11083026 0.6047768  0.5438263  3.45897    7.119399   6.6704893\n",
      " 6.5769887  4.121364   6.0357313  8.1196165  5.936111   1.4167961\n",
      " 5.832543   5.253071   9.4687805 ]\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 2.0896 - mean_absolute_error: 2.0951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.08957839012146, 2.0950520038604736]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error pour les seuils : 0.20180587000313646\n",
      "Mean absolute error pour les vitesses : 2.5615212662779845\n"
     ]
    }
   ],
   "source": [
    "#mse_s = mean_squared_error(y_test[:, 0:3], y_pred[:, 0:3])\n",
    "#print(\"Mean squared error pour les seuils : \" + str(mse_s))\n",
    "\n",
    "mae_s = mean_absolute_error(y_test[:, 0:3], y_pred[:, 0:3])\n",
    "print(\"Mean absolute error pour les seuils : \" + str(mae_s))\n",
    "\n",
    "#mse_v = mean_squared_error(y_test[:, 3:], y_pred[:, 3:])\n",
    "#print(\"Mean squared error pour les vitesses : \" + str(mse_v))\n",
    "\n",
    "mae_v = mean_absolute_error(y_test[:, 3:], y_pred[:, 3:])\n",
    "print(\"Mean absolute error pour les vitesses : \" + str(mae_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rseau de neurones pour les 3 seuils *model_s* <br/>\n",
    "Rseau de neurones pour les 12 vitesses *model_v*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 3)\n",
      "(5000, 12)\n"
     ]
    }
   ],
   "source": [
    "y_s = y[:, 0:3]\n",
    "y_v = y[:, 3:]\n",
    "print(y_s.shape)\n",
    "print(y_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(dataset, y_s, train_size = 0.7, shuffle = False)\n",
    "X_train_v, X_test_v, y_train_v, y_test_v = train_test_split(dataset, y_v, train_size = 0.7, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_765\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16184 (Dense)         (None, 100, 256)          1024      \n",
      "                                                                 \n",
      " dropout_17388 (Dropout)     (None, 100, 256)          0         \n",
      "                                                                 \n",
      " dense_16185 (Dense)         (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " dropout_17389 (Dropout)     (None, 100, 128)          0         \n",
      "                                                                 \n",
      " dense_16186 (Dense)         (None, 100, 128)          16512     \n",
      "                                                                 \n",
      " dropout_17390 (Dropout)     (None, 100, 128)          0         \n",
      "                                                                 \n",
      " dense_16187 (Dense)         (None, 100, 128)          16512     \n",
      "                                                                 \n",
      " dropout_17391 (Dropout)     (None, 100, 128)          0         \n",
      "                                                                 \n",
      " flatten_6216 (Flatten)      (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_16188 (Dense)         (None, 3)                 38403     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 105,347\n",
      "Trainable params: 105,347\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s = Sequential()\n",
    "\n",
    "model_s.add(Dense(units=256, activation='relu', input_shape=(dataset.shape[1], dataset.shape[2])))\n",
    "model_s.add(Dropout(0.2))\n",
    "\n",
    "model_s.add(Dense(units=128, activation='relu'))\n",
    "model_s.add(Dropout(0.2))\n",
    "model_s.add(Dense(units=128, activation='relu'))\n",
    "model_s.add(Dropout(0.2))\n",
    "model_s.add(Dense(units=128, activation='linear'))\n",
    "model_s.add(Dropout(0.2))\n",
    "model_s.add(Flatten())\n",
    "\n",
    "model_s.add(Dense(units=y_s.shape[1]))\n",
    "\n",
    "model_s.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "39/39 [==============================] - 4s 28ms/step - loss: 0.0158 - mean_absolute_error: 0.0162 - val_loss: 2.5432e-04 - val_mean_absolute_error: 2.5432e-04\n",
      "Epoch 2/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0115 - mean_absolute_error: 0.0113 - val_loss: 1.4159e-04 - val_mean_absolute_error: 1.4159e-04\n",
      "Epoch 3/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0103 - mean_absolute_error: 0.0104 - val_loss: 1.1368e-04 - val_mean_absolute_error: 1.1368e-04\n",
      "Epoch 4/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0097 - mean_absolute_error: 0.0096 - val_loss: 1.5330e-04 - val_mean_absolute_error: 1.5330e-04\n",
      "Epoch 5/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0093 - mean_absolute_error: 0.0091 - val_loss: 1.4300e-04 - val_mean_absolute_error: 1.4300e-04\n",
      "Epoch 6/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 1.0676e-04 - val_mean_absolute_error: 1.0676e-04\n",
      "Epoch 7/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0092 - mean_absolute_error: 0.0092 - val_loss: 9.8514e-05 - val_mean_absolute_error: 9.8514e-05\n",
      "Epoch 8/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0090 - mean_absolute_error: 0.0089 - val_loss: 2.0160e-04 - val_mean_absolute_error: 2.0160e-04\n",
      "Epoch 9/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0083 - mean_absolute_error: 0.0084 - val_loss: 3.6330e-04 - val_mean_absolute_error: 3.6330e-04\n",
      "Epoch 10/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0087 - mean_absolute_error: 0.0085 - val_loss: 2.4476e-04 - val_mean_absolute_error: 2.4476e-04\n",
      "Epoch 11/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0084 - mean_absolute_error: 0.0085 - val_loss: 3.7162e-05 - val_mean_absolute_error: 3.7162e-05\n",
      "Epoch 12/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0080 - mean_absolute_error: 0.0079 - val_loss: 4.1872e-05 - val_mean_absolute_error: 4.1872e-05\n",
      "Epoch 13/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0080 - mean_absolute_error: 0.0078 - val_loss: 2.4235e-04 - val_mean_absolute_error: 2.4235e-04\n",
      "Epoch 14/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0080 - mean_absolute_error: 0.0080 - val_loss: 7.2345e-05 - val_mean_absolute_error: 7.2345e-05\n",
      "Epoch 15/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0077 - mean_absolute_error: 0.0076 - val_loss: 1.1085e-04 - val_mean_absolute_error: 1.1085e-04\n",
      "Epoch 16/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0080 - mean_absolute_error: 0.0083 - val_loss: 1.7273e-04 - val_mean_absolute_error: 1.7273e-04\n",
      "Epoch 17/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0081 - mean_absolute_error: 0.0079 - val_loss: 1.4985e-04 - val_mean_absolute_error: 1.4985e-04\n",
      "Epoch 18/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0078 - mean_absolute_error: 0.0077 - val_loss: 9.6396e-05 - val_mean_absolute_error: 9.6396e-05\n",
      "Epoch 19/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0076 - mean_absolute_error: 0.0077 - val_loss: 3.9340e-05 - val_mean_absolute_error: 3.9340e-05\n",
      "Epoch 20/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0077 - mean_absolute_error: 0.0078 - val_loss: 2.1198e-04 - val_mean_absolute_error: 2.1198e-04\n",
      "Epoch 21/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0078 - mean_absolute_error: 0.0077 - val_loss: 2.5313e-04 - val_mean_absolute_error: 2.5313e-04\n",
      "Epoch 22/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0072 - mean_absolute_error: 0.0071 - val_loss: 1.4106e-04 - val_mean_absolute_error: 1.4106e-04\n",
      "Epoch 23/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0072 - mean_absolute_error: 0.0070 - val_loss: 1.3171e-04 - val_mean_absolute_error: 1.3171e-04\n",
      "Epoch 24/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0071 - mean_absolute_error: 0.0069 - val_loss: 1.2876e-04 - val_mean_absolute_error: 1.2876e-04\n",
      "Epoch 25/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0071 - mean_absolute_error: 0.0070 - val_loss: 9.7632e-05 - val_mean_absolute_error: 9.7632e-05\n",
      "Epoch 26/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0073 - mean_absolute_error: 0.0075 - val_loss: 6.5163e-05 - val_mean_absolute_error: 6.5163e-05\n",
      "Epoch 27/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0071 - mean_absolute_error: 0.0072 - val_loss: 9.9870e-05 - val_mean_absolute_error: 9.9870e-05\n",
      "Epoch 28/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0069 - mean_absolute_error: 0.0067 - val_loss: 8.2713e-05 - val_mean_absolute_error: 8.2713e-05\n",
      "Epoch 29/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0072 - mean_absolute_error: 0.0075 - val_loss: 2.4945e-04 - val_mean_absolute_error: 2.4945e-04\n",
      "Epoch 30/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0068 - mean_absolute_error: 0.0069 - val_loss: 8.6221e-05 - val_mean_absolute_error: 8.6221e-05\n",
      "Epoch 31/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0069 - mean_absolute_error: 0.0073 - val_loss: 8.3917e-05 - val_mean_absolute_error: 8.3917e-05\n",
      "Epoch 32/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0068 - mean_absolute_error: 0.0069 - val_loss: 1.0325e-04 - val_mean_absolute_error: 1.0325e-04\n",
      "Epoch 33/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0070 - mean_absolute_error: 0.0070 - val_loss: 5.0403e-05 - val_mean_absolute_error: 5.0403e-05\n",
      "Epoch 34/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0070 - mean_absolute_error: 0.0068 - val_loss: 1.1064e-04 - val_mean_absolute_error: 1.1064e-04\n",
      "Epoch 35/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0073 - mean_absolute_error: 0.0072 - val_loss: 1.3123e-04 - val_mean_absolute_error: 1.3123e-04\n",
      "Epoch 36/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0067 - mean_absolute_error: 0.0070 - val_loss: 9.5094e-05 - val_mean_absolute_error: 9.5094e-05\n",
      "Epoch 37/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0069 - mean_absolute_error: 0.0071 - val_loss: 7.1132e-05 - val_mean_absolute_error: 7.1132e-05\n",
      "Epoch 38/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0069 - mean_absolute_error: 0.0068 - val_loss: 1.5135e-04 - val_mean_absolute_error: 1.5135e-04\n",
      "Epoch 39/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0069 - mean_absolute_error: 0.0072 - val_loss: 3.3789e-05 - val_mean_absolute_error: 3.3789e-05\n",
      "Epoch 40/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0065 - mean_absolute_error: 0.0066 - val_loss: 4.0398e-05 - val_mean_absolute_error: 4.0398e-05\n",
      "Epoch 41/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0063 - mean_absolute_error: 0.0064 - val_loss: 1.4500e-04 - val_mean_absolute_error: 1.4500e-04\n",
      "Epoch 42/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.0062 - mean_absolute_error: 0.0061 - val_loss: 2.1420e-04 - val_mean_absolute_error: 2.1420e-04\n",
      "Epoch 43/1000\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_absolute_error: 0.0061 - val_loss: 1.3865e-04 - val_mean_absolute_error: 1.3865e-04\n",
      "Epoch 44/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 7.4198e-05 - val_mean_absolute_error: 7.4198e-05\n",
      "Epoch 45/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0067 - mean_absolute_error: 0.0067 - val_loss: 1.0328e-04 - val_mean_absolute_error: 1.0328e-04\n",
      "Epoch 46/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 4.8301e-05 - val_mean_absolute_error: 4.8301e-05\n",
      "Epoch 47/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0064 - mean_absolute_error: 0.0063 - val_loss: 1.8426e-04 - val_mean_absolute_error: 1.8426e-04\n",
      "Epoch 48/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0065 - mean_absolute_error: 0.0065 - val_loss: 2.4336e-04 - val_mean_absolute_error: 2.4336e-04\n",
      "Epoch 49/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 2.2123e-04 - val_mean_absolute_error: 2.2123e-04\n",
      "Epoch 50/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0064 - mean_absolute_error: 0.0065 - val_loss: 6.2711e-05 - val_mean_absolute_error: 6.2711e-05\n",
      "Epoch 51/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_absolute_error: 0.0062 - val_loss: 2.9695e-05 - val_mean_absolute_error: 2.9695e-05\n",
      "Epoch 52/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0065 - mean_absolute_error: 0.0066 - val_loss: 1.2346e-04 - val_mean_absolute_error: 1.2346e-04\n",
      "Epoch 53/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0063 - mean_absolute_error: 0.0063 - val_loss: 5.5445e-05 - val_mean_absolute_error: 5.5445e-05\n",
      "Epoch 54/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 2.4809e-05 - val_mean_absolute_error: 2.4809e-05\n",
      "Epoch 55/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0066 - mean_absolute_error: 0.0066 - val_loss: 1.2851e-04 - val_mean_absolute_error: 1.2851e-04\n",
      "Epoch 56/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0062 - mean_absolute_error: 0.0060 - val_loss: 1.5089e-04 - val_mean_absolute_error: 1.5089e-04\n",
      "Epoch 57/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0063 - mean_absolute_error: 0.0062 - val_loss: 2.8996e-05 - val_mean_absolute_error: 2.8996e-05\n",
      "Epoch 58/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0065 - mean_absolute_error: 0.0064 - val_loss: 7.9257e-05 - val_mean_absolute_error: 7.9257e-05\n",
      "Epoch 59/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_absolute_error: 0.0064 - val_loss: 1.2594e-04 - val_mean_absolute_error: 1.2594e-04\n",
      "Epoch 60/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0062 - mean_absolute_error: 0.0061 - val_loss: 9.0522e-05 - val_mean_absolute_error: 9.0522e-05\n",
      "Epoch 61/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0059 - mean_absolute_error: 0.0062 - val_loss: 7.3975e-05 - val_mean_absolute_error: 7.3975e-05\n",
      "Epoch 62/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0063 - mean_absolute_error: 0.0066 - val_loss: 1.5624e-04 - val_mean_absolute_error: 1.5624e-04\n",
      "Epoch 63/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 1.1456e-04 - val_mean_absolute_error: 1.1456e-04\n",
      "Epoch 64/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_absolute_error: 0.0061 - val_loss: 2.0485e-04 - val_mean_absolute_error: 2.0485e-04\n",
      "Epoch 65/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0064 - mean_absolute_error: 0.0063 - val_loss: 4.0764e-05 - val_mean_absolute_error: 4.0764e-05\n",
      "Epoch 66/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.0061 - mean_absolute_error: 0.0065 - val_loss: 1.0691e-04 - val_mean_absolute_error: 1.0691e-04\n",
      "Epoch 67/1000\n",
      "39/39 [==============================] - 0s 9ms/step - loss: 0.0062 - mean_absolute_error: 0.0062 - val_loss: 1.3796e-04 - val_mean_absolute_error: 1.3796e-04\n",
      "Epoch 68/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.0061 - mean_absolute_error: 0.0063 - val_loss: 6.7604e-05 - val_mean_absolute_error: 6.7604e-05\n",
      "Epoch 69/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0061 - mean_absolute_error: 0.0060 - val_loss: 1.6627e-04 - val_mean_absolute_error: 1.6627e-04\n",
      "Epoch 70/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 1.3452e-04 - val_mean_absolute_error: 1.3452e-04\n",
      "Epoch 71/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 9.3741e-05 - val_mean_absolute_error: 9.3741e-05\n",
      "Epoch 72/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_absolute_error: 0.0062 - val_loss: 1.5761e-04 - val_mean_absolute_error: 1.5761e-04\n",
      "Epoch 73/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 1.1493e-04 - val_mean_absolute_error: 1.1493e-04\n",
      "Epoch 74/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0058 - mean_absolute_error: 0.0060 - val_loss: 8.0017e-05 - val_mean_absolute_error: 8.0017e-05\n",
      "Epoch 75/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0061 - mean_absolute_error: 0.0060 - val_loss: 1.0419e-04 - val_mean_absolute_error: 1.0419e-04\n",
      "Epoch 76/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 3.8579e-05 - val_mean_absolute_error: 3.8579e-05\n",
      "Epoch 77/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.0059 - mean_absolute_error: 0.0059 - val_loss: 1.7482e-04 - val_mean_absolute_error: 1.7482e-04\n",
      "Epoch 78/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.0056 - mean_absolute_error: 0.0055 - val_loss: 1.6598e-04 - val_mean_absolute_error: 1.6598e-04\n",
      "Epoch 79/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 1.8183e-04 - val_mean_absolute_error: 1.8183e-04\n",
      "Epoch 80/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0057 - mean_absolute_error: 0.0057 - val_loss: 7.0114e-05 - val_mean_absolute_error: 7.0114e-05\n",
      "Epoch 81/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.0058 - mean_absolute_error: 0.0058 - val_loss: 3.3050e-05 - val_mean_absolute_error: 3.3050e-05\n",
      "Epoch 82/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.0057 - mean_absolute_error: 0.0058 - val_loss: 5.3109e-05 - val_mean_absolute_error: 5.3109e-05\n",
      "Epoch 83/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.0058 - mean_absolute_error: 0.0063 - val_loss: 8.0871e-05 - val_mean_absolute_error: 8.0871e-05\n",
      "Epoch 84/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.0060 - mean_absolute_error: 0.0060 - val_loss: 1.4220e-04 - val_mean_absolute_error: 1.4220e-04\n",
      "Epoch 85/1000\n",
      " 1/39 [..............................] - ETA: 0s - loss: 0.0071 - mean_absolute_error: 0.0071"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-447-71b78be0fb16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMeanAbsoluteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMeanAbsoluteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0my_pred_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_s = Input(shape = (dataset.shape[1], dataset.shape[2],))\n",
    "x = Dense(16, activation=\"relu\")(input_s)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(3, activation=\"linear\")(x)\n",
    "\n",
    "model = Model(inputs=input_s, outputs=x)\n",
    "adam = Adam(learning_rate = 0.001)\n",
    "\n",
    "model.compile(loss=MeanAbsoluteError(), optimizer=adam, metrics=[MeanAbsoluteError()])\n",
    "\n",
    "history_s = model.fit(X_train_s, y_train_s, epochs=1000, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "y_pred_s = model.predict(X_test_s)\n",
    "print(mean_absolute_error(y_test_s, y_pred_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_s, 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_108 (Dense)            (None, 10, 256)           1024      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 10, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 10, 128)           32896     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 10, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 10, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 12)                15372     \n",
      "=================================================================\n",
      "Total params: 82,316\n",
      "Trainable params: 82,316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MAX_EPOCHS = 1000\n",
    "\n",
    "model_v = Sequential()\n",
    "\n",
    "model_v.add(Dense(units=256, activation='relu', input_shape=(dataset.shape[1], dataset.shape[2])))\n",
    "model_v.add(Dropout(0.2))\n",
    "\n",
    "model_v.add(Dense(units=128, activation='relu'))\n",
    "model_v.add(Dropout(0.2))\n",
    "model_v.add(Dense(units=128, activation='relu'))\n",
    "model_v.add(Dropout(0.2))\n",
    "model_v.add(Dense(units=128, activation='linear'))\n",
    "model_v.add(Dropout(0.2))\n",
    "model_v.add(Flatten())\n",
    "\n",
    "model_v.add(Dense(units=y_v.shape[1]))\n",
    "\n",
    "model_v.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "39/39 [==============================] - 2s 19ms/step - loss: 0.2443 - mean_squared_error: 0.0954 - val_loss: 0.1724 - val_mean_squared_error: 0.0514\n",
      "Epoch 2/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1819 - mean_squared_error: 0.0531 - val_loss: 0.1582 - val_mean_squared_error: 0.0438\n",
      "Epoch 3/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1672 - mean_squared_error: 0.0464 - val_loss: 0.1542 - val_mean_squared_error: 0.0403\n",
      "Epoch 4/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1631 - mean_squared_error: 0.0443 - val_loss: 0.1644 - val_mean_squared_error: 0.0453\n",
      "Epoch 5/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1576 - mean_squared_error: 0.0416 - val_loss: 0.1561 - val_mean_squared_error: 0.0412\n",
      "Epoch 6/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1556 - mean_squared_error: 0.0414 - val_loss: 0.1519 - val_mean_squared_error: 0.0397\n",
      "Epoch 7/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1560 - mean_squared_error: 0.0415 - val_loss: 0.1682 - val_mean_squared_error: 0.0469\n",
      "Epoch 8/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1539 - mean_squared_error: 0.0405 - val_loss: 0.1470 - val_mean_squared_error: 0.0383\n",
      "Epoch 9/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1536 - mean_squared_error: 0.0403 - val_loss: 0.1500 - val_mean_squared_error: 0.0392\n",
      "Epoch 10/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1524 - mean_squared_error: 0.0398 - val_loss: 0.1460 - val_mean_squared_error: 0.0375\n",
      "Epoch 11/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1497 - mean_squared_error: 0.0386 - val_loss: 0.1514 - val_mean_squared_error: 0.0393\n",
      "Epoch 12/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1495 - mean_squared_error: 0.0387 - val_loss: 0.1487 - val_mean_squared_error: 0.0376\n",
      "Epoch 13/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1484 - mean_squared_error: 0.0381 - val_loss: 0.1454 - val_mean_squared_error: 0.0365\n",
      "Epoch 14/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1499 - mean_squared_error: 0.0383 - val_loss: 0.1437 - val_mean_squared_error: 0.0362\n",
      "Epoch 15/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1470 - mean_squared_error: 0.0374 - val_loss: 0.1443 - val_mean_squared_error: 0.0363\n",
      "Epoch 16/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1465 - mean_squared_error: 0.0374 - val_loss: 0.1457 - val_mean_squared_error: 0.0366\n",
      "Epoch 17/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1457 - mean_squared_error: 0.0368 - val_loss: 0.1442 - val_mean_squared_error: 0.0364\n",
      "Epoch 18/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1450 - mean_squared_error: 0.0365 - val_loss: 0.1434 - val_mean_squared_error: 0.0360\n",
      "Epoch 19/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1452 - mean_squared_error: 0.0366 - val_loss: 0.1420 - val_mean_squared_error: 0.0354\n",
      "Epoch 20/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1424 - mean_squared_error: 0.0353 - val_loss: 0.1378 - val_mean_squared_error: 0.0333\n",
      "Epoch 21/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1422 - mean_squared_error: 0.0354 - val_loss: 0.1472 - val_mean_squared_error: 0.0362\n",
      "Epoch 22/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1430 - mean_squared_error: 0.0356 - val_loss: 0.1364 - val_mean_squared_error: 0.0334\n",
      "Epoch 23/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1404 - mean_squared_error: 0.0347 - val_loss: 0.1359 - val_mean_squared_error: 0.0331\n",
      "Epoch 24/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1413 - mean_squared_error: 0.0348 - val_loss: 0.1370 - val_mean_squared_error: 0.0334\n",
      "Epoch 25/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1401 - mean_squared_error: 0.0344 - val_loss: 0.1358 - val_mean_squared_error: 0.0329\n",
      "Epoch 26/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1388 - mean_squared_error: 0.0341 - val_loss: 0.1362 - val_mean_squared_error: 0.0329\n",
      "Epoch 27/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1385 - mean_squared_error: 0.0337 - val_loss: 0.1352 - val_mean_squared_error: 0.0327\n",
      "Epoch 28/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1387 - mean_squared_error: 0.0339 - val_loss: 0.1391 - val_mean_squared_error: 0.0341\n",
      "Epoch 29/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1379 - mean_squared_error: 0.0333 - val_loss: 0.1369 - val_mean_squared_error: 0.0332\n",
      "Epoch 30/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1373 - mean_squared_error: 0.0336 - val_loss: 0.1331 - val_mean_squared_error: 0.0317\n",
      "Epoch 31/1000\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 0.1390 - mean_squared_error: 0.0338 - val_loss: 0.1370 - val_mean_squared_error: 0.0328\n",
      "Epoch 32/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1375 - mean_squared_error: 0.0333 - val_loss: 0.1410 - val_mean_squared_error: 0.0342\n",
      "Epoch 33/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1369 - mean_squared_error: 0.0327 - val_loss: 0.1327 - val_mean_squared_error: 0.0318\n",
      "Epoch 34/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1365 - mean_squared_error: 0.0328 - val_loss: 0.1369 - val_mean_squared_error: 0.0326\n",
      "Epoch 35/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1371 - mean_squared_error: 0.0328 - val_loss: 0.1352 - val_mean_squared_error: 0.0321\n",
      "Epoch 36/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1356 - mean_squared_error: 0.0326 - val_loss: 0.1346 - val_mean_squared_error: 0.0318\n",
      "Epoch 37/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1352 - mean_squared_error: 0.0321 - val_loss: 0.1321 - val_mean_squared_error: 0.0314\n",
      "Epoch 38/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1350 - mean_squared_error: 0.0320 - val_loss: 0.1335 - val_mean_squared_error: 0.0320\n",
      "Epoch 39/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1345 - mean_squared_error: 0.0318 - val_loss: 0.1374 - val_mean_squared_error: 0.0330\n",
      "Epoch 40/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1343 - mean_squared_error: 0.0320 - val_loss: 0.1311 - val_mean_squared_error: 0.0311\n",
      "Epoch 41/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1338 - mean_squared_error: 0.0316 - val_loss: 0.1305 - val_mean_squared_error: 0.0304\n",
      "Epoch 42/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1344 - mean_squared_error: 0.0318 - val_loss: 0.1312 - val_mean_squared_error: 0.0308\n",
      "Epoch 43/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1329 - mean_squared_error: 0.0313 - val_loss: 0.1316 - val_mean_squared_error: 0.0313\n",
      "Epoch 44/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1346 - mean_squared_error: 0.0322 - val_loss: 0.1300 - val_mean_squared_error: 0.0301\n",
      "Epoch 45/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1334 - mean_squared_error: 0.0314 - val_loss: 0.1330 - val_mean_squared_error: 0.0310\n",
      "Epoch 46/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1338 - mean_squared_error: 0.0317 - val_loss: 0.1325 - val_mean_squared_error: 0.0315\n",
      "Epoch 47/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1331 - mean_squared_error: 0.0311 - val_loss: 0.1382 - val_mean_squared_error: 0.0329\n",
      "Epoch 48/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1331 - mean_squared_error: 0.0310 - val_loss: 0.1314 - val_mean_squared_error: 0.0310\n",
      "Epoch 49/1000\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.1303 - mean_squared_error: 0.0303 - val_loss: 0.1303 - val_mean_squared_error: 0.0300\n",
      "Epoch 50/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1321 - mean_squared_error: 0.0305 - val_loss: 0.1289 - val_mean_squared_error: 0.0301\n",
      "Epoch 51/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1321 - mean_squared_error: 0.0308 - val_loss: 0.1310 - val_mean_squared_error: 0.0307\n",
      "Epoch 52/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1333 - mean_squared_error: 0.0311 - val_loss: 0.1290 - val_mean_squared_error: 0.0299\n",
      "Epoch 53/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1312 - mean_squared_error: 0.0304 - val_loss: 0.1290 - val_mean_squared_error: 0.0301\n",
      "Epoch 54/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1308 - mean_squared_error: 0.0304 - val_loss: 0.1293 - val_mean_squared_error: 0.0305\n",
      "Epoch 55/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1307 - mean_squared_error: 0.0304 - val_loss: 0.1319 - val_mean_squared_error: 0.0305\n",
      "Epoch 56/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1306 - mean_squared_error: 0.0305 - val_loss: 0.1294 - val_mean_squared_error: 0.0302\n",
      "Epoch 57/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1321 - mean_squared_error: 0.0308 - val_loss: 0.1311 - val_mean_squared_error: 0.0307\n",
      "Epoch 58/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1318 - mean_squared_error: 0.0307 - val_loss: 0.1298 - val_mean_squared_error: 0.0299\n",
      "Epoch 59/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1305 - mean_squared_error: 0.0303 - val_loss: 0.1292 - val_mean_squared_error: 0.0299\n",
      "Epoch 60/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1297 - mean_squared_error: 0.0298 - val_loss: 0.1285 - val_mean_squared_error: 0.0297\n",
      "Epoch 61/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1307 - mean_squared_error: 0.0301 - val_loss: 0.1283 - val_mean_squared_error: 0.0298\n",
      "Epoch 62/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1309 - mean_squared_error: 0.0302 - val_loss: 0.1313 - val_mean_squared_error: 0.0305\n",
      "Epoch 63/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1290 - mean_squared_error: 0.0298 - val_loss: 0.1287 - val_mean_squared_error: 0.0294\n",
      "Epoch 64/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1305 - mean_squared_error: 0.0302 - val_loss: 0.1310 - val_mean_squared_error: 0.0306\n",
      "Epoch 65/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1304 - mean_squared_error: 0.0300 - val_loss: 0.1273 - val_mean_squared_error: 0.0291\n",
      "Epoch 66/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1290 - mean_squared_error: 0.0295 - val_loss: 0.1279 - val_mean_squared_error: 0.0294\n",
      "Epoch 67/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1303 - mean_squared_error: 0.0301 - val_loss: 0.1289 - val_mean_squared_error: 0.0294\n",
      "Epoch 68/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1296 - mean_squared_error: 0.0295 - val_loss: 0.1297 - val_mean_squared_error: 0.0297\n",
      "Epoch 69/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1277 - mean_squared_error: 0.0293 - val_loss: 0.1301 - val_mean_squared_error: 0.0297\n",
      "Epoch 70/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1278 - mean_squared_error: 0.0292 - val_loss: 0.1281 - val_mean_squared_error: 0.0293\n",
      "Epoch 71/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1290 - mean_squared_error: 0.0293 - val_loss: 0.1291 - val_mean_squared_error: 0.0302\n",
      "Epoch 72/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1285 - mean_squared_error: 0.0295 - val_loss: 0.1278 - val_mean_squared_error: 0.0290\n",
      "Epoch 73/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1292 - mean_squared_error: 0.0295 - val_loss: 0.1315 - val_mean_squared_error: 0.0306\n",
      "Epoch 74/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1292 - mean_squared_error: 0.0294 - val_loss: 0.1316 - val_mean_squared_error: 0.0307\n",
      "Epoch 75/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1279 - mean_squared_error: 0.0292 - val_loss: 0.1305 - val_mean_squared_error: 0.0301\n",
      "Epoch 76/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1296 - mean_squared_error: 0.0298 - val_loss: 0.1285 - val_mean_squared_error: 0.0297\n",
      "Epoch 77/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1275 - mean_squared_error: 0.0289 - val_loss: 0.1272 - val_mean_squared_error: 0.0290\n",
      "Epoch 78/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1282 - mean_squared_error: 0.0292 - val_loss: 0.1267 - val_mean_squared_error: 0.0288\n",
      "Epoch 79/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1281 - mean_squared_error: 0.0292 - val_loss: 0.1283 - val_mean_squared_error: 0.0296\n",
      "Epoch 80/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1279 - mean_squared_error: 0.0292 - val_loss: 0.1283 - val_mean_squared_error: 0.0296\n",
      "Epoch 81/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1273 - mean_squared_error: 0.0292 - val_loss: 0.1271 - val_mean_squared_error: 0.0289\n",
      "Epoch 82/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1271 - mean_squared_error: 0.0286 - val_loss: 0.1271 - val_mean_squared_error: 0.0292\n",
      "Epoch 83/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1276 - mean_squared_error: 0.0288 - val_loss: 0.1271 - val_mean_squared_error: 0.0290\n",
      "Epoch 84/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1291 - mean_squared_error: 0.0294 - val_loss: 0.1274 - val_mean_squared_error: 0.0291\n",
      "Epoch 85/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1267 - mean_squared_error: 0.0285 - val_loss: 0.1276 - val_mean_squared_error: 0.0289\n",
      "Epoch 86/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1281 - mean_squared_error: 0.0292 - val_loss: 0.1307 - val_mean_squared_error: 0.0304\n",
      "Epoch 87/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1276 - mean_squared_error: 0.0289 - val_loss: 0.1284 - val_mean_squared_error: 0.0294\n",
      "Epoch 88/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1272 - mean_squared_error: 0.0288 - val_loss: 0.1269 - val_mean_squared_error: 0.0289\n",
      "Epoch 89/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1263 - mean_squared_error: 0.0282 - val_loss: 0.1317 - val_mean_squared_error: 0.0305\n",
      "Epoch 90/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1270 - mean_squared_error: 0.0285 - val_loss: 0.1273 - val_mean_squared_error: 0.0291\n",
      "Epoch 91/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1269 - mean_squared_error: 0.0287 - val_loss: 0.1281 - val_mean_squared_error: 0.0294\n",
      "Epoch 92/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1257 - mean_squared_error: 0.0281 - val_loss: 0.1270 - val_mean_squared_error: 0.0291\n",
      "Epoch 93/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1256 - mean_squared_error: 0.0279 - val_loss: 0.1285 - val_mean_squared_error: 0.0290\n",
      "Epoch 94/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1262 - mean_squared_error: 0.0283 - val_loss: 0.1311 - val_mean_squared_error: 0.0300\n",
      "Epoch 95/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1267 - mean_squared_error: 0.0284 - val_loss: 0.1296 - val_mean_squared_error: 0.0295\n",
      "Epoch 96/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1256 - mean_squared_error: 0.0283 - val_loss: 0.1280 - val_mean_squared_error: 0.0291\n",
      "Epoch 97/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1266 - mean_squared_error: 0.0284 - val_loss: 0.1268 - val_mean_squared_error: 0.0291\n",
      "Epoch 98/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1263 - mean_squared_error: 0.0283 - val_loss: 0.1277 - val_mean_squared_error: 0.0297\n",
      "Epoch 99/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1256 - mean_squared_error: 0.0286 - val_loss: 0.1294 - val_mean_squared_error: 0.0296\n",
      "Epoch 100/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1245 - mean_squared_error: 0.0277 - val_loss: 0.1266 - val_mean_squared_error: 0.0286\n",
      "Epoch 101/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1260 - mean_squared_error: 0.0282 - val_loss: 0.1280 - val_mean_squared_error: 0.0292\n",
      "Epoch 102/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1255 - mean_squared_error: 0.0280 - val_loss: 0.1297 - val_mean_squared_error: 0.0294\n",
      "Epoch 103/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1270 - mean_squared_error: 0.0287 - val_loss: 0.1303 - val_mean_squared_error: 0.0300\n",
      "Epoch 104/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1255 - mean_squared_error: 0.0281 - val_loss: 0.1276 - val_mean_squared_error: 0.0292\n",
      "Epoch 105/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1262 - mean_squared_error: 0.0285 - val_loss: 0.1270 - val_mean_squared_error: 0.0289\n",
      "Epoch 106/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1262 - mean_squared_error: 0.0286 - val_loss: 0.1269 - val_mean_squared_error: 0.0291\n",
      "Epoch 107/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1244 - mean_squared_error: 0.0277 - val_loss: 0.1298 - val_mean_squared_error: 0.0295\n",
      "Epoch 108/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1262 - mean_squared_error: 0.0283 - val_loss: 0.1268 - val_mean_squared_error: 0.0290\n",
      "Epoch 109/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1264 - mean_squared_error: 0.0284 - val_loss: 0.1305 - val_mean_squared_error: 0.0301\n",
      "Epoch 110/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1263 - mean_squared_error: 0.0283 - val_loss: 0.1262 - val_mean_squared_error: 0.0289\n",
      "Epoch 111/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1251 - mean_squared_error: 0.0279 - val_loss: 0.1275 - val_mean_squared_error: 0.0289\n",
      "Epoch 112/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1246 - mean_squared_error: 0.0276 - val_loss: 0.1285 - val_mean_squared_error: 0.0293\n",
      "Epoch 113/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1248 - mean_squared_error: 0.0279 - val_loss: 0.1261 - val_mean_squared_error: 0.0285\n",
      "Epoch 114/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1261 - mean_squared_error: 0.0282 - val_loss: 0.1288 - val_mean_squared_error: 0.0292\n",
      "Epoch 115/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1254 - mean_squared_error: 0.0277 - val_loss: 0.1271 - val_mean_squared_error: 0.0289\n",
      "Epoch 116/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1260 - mean_squared_error: 0.0280 - val_loss: 0.1283 - val_mean_squared_error: 0.0292\n",
      "Epoch 117/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1243 - mean_squared_error: 0.0277 - val_loss: 0.1311 - val_mean_squared_error: 0.0304\n",
      "Epoch 118/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1251 - mean_squared_error: 0.0279 - val_loss: 0.1282 - val_mean_squared_error: 0.0289\n",
      "Epoch 119/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1253 - mean_squared_error: 0.0279 - val_loss: 0.1270 - val_mean_squared_error: 0.0291\n",
      "Epoch 120/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1244 - mean_squared_error: 0.0278 - val_loss: 0.1314 - val_mean_squared_error: 0.0300\n",
      "Epoch 121/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1241 - mean_squared_error: 0.0277 - val_loss: 0.1292 - val_mean_squared_error: 0.0295\n",
      "Epoch 122/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1236 - mean_squared_error: 0.0274 - val_loss: 0.1268 - val_mean_squared_error: 0.0285\n",
      "Epoch 123/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1243 - mean_squared_error: 0.0278 - val_loss: 0.1258 - val_mean_squared_error: 0.0285\n",
      "Epoch 124/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1244 - mean_squared_error: 0.0277 - val_loss: 0.1253 - val_mean_squared_error: 0.0281\n",
      "Epoch 125/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1244 - mean_squared_error: 0.0277 - val_loss: 0.1259 - val_mean_squared_error: 0.0285\n",
      "Epoch 126/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1227 - mean_squared_error: 0.0270 - val_loss: 0.1259 - val_mean_squared_error: 0.0283\n",
      "Epoch 127/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1237 - mean_squared_error: 0.0272 - val_loss: 0.1254 - val_mean_squared_error: 0.0284\n",
      "Epoch 128/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1235 - mean_squared_error: 0.0275 - val_loss: 0.1280 - val_mean_squared_error: 0.0291\n",
      "Epoch 129/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1235 - mean_squared_error: 0.0273 - val_loss: 0.1269 - val_mean_squared_error: 0.0288\n",
      "Epoch 130/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1242 - mean_squared_error: 0.0277 - val_loss: 0.1267 - val_mean_squared_error: 0.0287\n",
      "Epoch 131/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1236 - mean_squared_error: 0.0275 - val_loss: 0.1253 - val_mean_squared_error: 0.0283\n",
      "Epoch 132/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1243 - mean_squared_error: 0.0273 - val_loss: 0.1291 - val_mean_squared_error: 0.0292\n",
      "Epoch 133/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1226 - mean_squared_error: 0.0272 - val_loss: 0.1265 - val_mean_squared_error: 0.0289\n",
      "Epoch 134/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1244 - mean_squared_error: 0.0277 - val_loss: 0.1291 - val_mean_squared_error: 0.0296\n",
      "Epoch 135/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1235 - mean_squared_error: 0.0271 - val_loss: 0.1272 - val_mean_squared_error: 0.0285\n",
      "Epoch 136/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1227 - mean_squared_error: 0.0271 - val_loss: 0.1270 - val_mean_squared_error: 0.0287\n",
      "Epoch 137/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1234 - mean_squared_error: 0.0273 - val_loss: 0.1265 - val_mean_squared_error: 0.0284\n",
      "Epoch 138/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1246 - mean_squared_error: 0.0278 - val_loss: 0.1273 - val_mean_squared_error: 0.0288\n",
      "Epoch 139/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1226 - mean_squared_error: 0.0269 - val_loss: 0.1274 - val_mean_squared_error: 0.0287\n",
      "Epoch 140/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1224 - mean_squared_error: 0.0269 - val_loss: 0.1259 - val_mean_squared_error: 0.0284\n",
      "Epoch 141/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1215 - mean_squared_error: 0.0265 - val_loss: 0.1344 - val_mean_squared_error: 0.0306\n",
      "Epoch 142/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1247 - mean_squared_error: 0.0276 - val_loss: 0.1264 - val_mean_squared_error: 0.0286\n",
      "Epoch 143/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1219 - mean_squared_error: 0.0269 - val_loss: 0.1265 - val_mean_squared_error: 0.0285\n",
      "Epoch 144/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1260 - mean_squared_error: 0.0281 - val_loss: 0.1313 - val_mean_squared_error: 0.0297\n",
      "Epoch 145/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1222 - mean_squared_error: 0.0271 - val_loss: 0.1265 - val_mean_squared_error: 0.0285\n",
      "Epoch 146/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1235 - mean_squared_error: 0.0274 - val_loss: 0.1269 - val_mean_squared_error: 0.0286\n",
      "Epoch 147/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1228 - mean_squared_error: 0.0268 - val_loss: 0.1271 - val_mean_squared_error: 0.0288\n",
      "Epoch 148/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1231 - mean_squared_error: 0.0271 - val_loss: 0.1255 - val_mean_squared_error: 0.0282\n",
      "Epoch 149/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1224 - mean_squared_error: 0.0265 - val_loss: 0.1266 - val_mean_squared_error: 0.0284\n",
      "Epoch 150/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1232 - mean_squared_error: 0.0270 - val_loss: 0.1261 - val_mean_squared_error: 0.0284\n",
      "Epoch 151/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1219 - mean_squared_error: 0.0266 - val_loss: 0.1260 - val_mean_squared_error: 0.0285\n",
      "Epoch 152/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1219 - mean_squared_error: 0.0267 - val_loss: 0.1255 - val_mean_squared_error: 0.0283\n",
      "Epoch 153/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1226 - mean_squared_error: 0.0270 - val_loss: 0.1258 - val_mean_squared_error: 0.0282\n",
      "Epoch 154/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1223 - mean_squared_error: 0.0266 - val_loss: 0.1267 - val_mean_squared_error: 0.0287\n",
      "Epoch 155/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1222 - mean_squared_error: 0.0268 - val_loss: 0.1261 - val_mean_squared_error: 0.0283\n",
      "Epoch 156/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1226 - mean_squared_error: 0.0268 - val_loss: 0.1277 - val_mean_squared_error: 0.0289\n",
      "Epoch 157/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1212 - mean_squared_error: 0.0265 - val_loss: 0.1274 - val_mean_squared_error: 0.0284\n",
      "Epoch 158/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1226 - mean_squared_error: 0.0269 - val_loss: 0.1254 - val_mean_squared_error: 0.0282\n",
      "Epoch 159/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1217 - mean_squared_error: 0.0266 - val_loss: 0.1295 - val_mean_squared_error: 0.0292\n",
      "Epoch 160/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1222 - mean_squared_error: 0.0270 - val_loss: 0.1252 - val_mean_squared_error: 0.0280\n",
      "Epoch 161/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1208 - mean_squared_error: 0.0262 - val_loss: 0.1282 - val_mean_squared_error: 0.0294\n",
      "Epoch 162/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1232 - mean_squared_error: 0.0272 - val_loss: 0.1298 - val_mean_squared_error: 0.0290\n",
      "Epoch 163/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1227 - mean_squared_error: 0.0266 - val_loss: 0.1259 - val_mean_squared_error: 0.0282\n",
      "Epoch 164/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1211 - mean_squared_error: 0.0261 - val_loss: 0.1273 - val_mean_squared_error: 0.0286\n",
      "Epoch 165/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1214 - mean_squared_error: 0.0267 - val_loss: 0.1264 - val_mean_squared_error: 0.0283\n",
      "Epoch 166/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1207 - mean_squared_error: 0.0263 - val_loss: 0.1262 - val_mean_squared_error: 0.0285\n",
      "Epoch 167/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1224 - mean_squared_error: 0.0267 - val_loss: 0.1284 - val_mean_squared_error: 0.0287\n",
      "Epoch 168/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1218 - mean_squared_error: 0.0268 - val_loss: 0.1262 - val_mean_squared_error: 0.0285\n",
      "Epoch 169/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1216 - mean_squared_error: 0.0267 - val_loss: 0.1266 - val_mean_squared_error: 0.0283\n",
      "Epoch 170/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1223 - mean_squared_error: 0.0267 - val_loss: 0.1278 - val_mean_squared_error: 0.0291\n",
      "Epoch 171/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1216 - mean_squared_error: 0.0268 - val_loss: 0.1258 - val_mean_squared_error: 0.0284\n",
      "Epoch 172/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1211 - mean_squared_error: 0.0263 - val_loss: 0.1263 - val_mean_squared_error: 0.0283\n",
      "Epoch 173/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1194 - mean_squared_error: 0.0259 - val_loss: 0.1276 - val_mean_squared_error: 0.0288\n",
      "Epoch 174/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1210 - mean_squared_error: 0.0265 - val_loss: 0.1269 - val_mean_squared_error: 0.0282\n",
      "Epoch 175/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1211 - mean_squared_error: 0.0262 - val_loss: 0.1348 - val_mean_squared_error: 0.0313\n",
      "Epoch 176/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1222 - mean_squared_error: 0.0267 - val_loss: 0.1264 - val_mean_squared_error: 0.0284\n",
      "Epoch 177/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1214 - mean_squared_error: 0.0264 - val_loss: 0.1281 - val_mean_squared_error: 0.0288\n",
      "Epoch 178/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1202 - mean_squared_error: 0.0260 - val_loss: 0.1247 - val_mean_squared_error: 0.0279\n",
      "Epoch 179/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1207 - mean_squared_error: 0.0264 - val_loss: 0.1267 - val_mean_squared_error: 0.0285\n",
      "Epoch 180/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1206 - mean_squared_error: 0.0266 - val_loss: 0.1264 - val_mean_squared_error: 0.0284\n",
      "Epoch 181/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1200 - mean_squared_error: 0.0261 - val_loss: 0.1309 - val_mean_squared_error: 0.0298\n",
      "Epoch 182/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1211 - mean_squared_error: 0.0262 - val_loss: 0.1259 - val_mean_squared_error: 0.0281\n",
      "Epoch 183/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1204 - mean_squared_error: 0.0262 - val_loss: 0.1261 - val_mean_squared_error: 0.0285\n",
      "Epoch 184/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1219 - mean_squared_error: 0.0266 - val_loss: 0.1272 - val_mean_squared_error: 0.0284\n",
      "Epoch 185/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1208 - mean_squared_error: 0.0263 - val_loss: 0.1251 - val_mean_squared_error: 0.0280\n",
      "Epoch 186/1000\n",
      "39/39 [==============================] - 1s 19ms/step - loss: 0.1209 - mean_squared_error: 0.0263 - val_loss: 0.1254 - val_mean_squared_error: 0.0280\n",
      "Epoch 187/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1199 - mean_squared_error: 0.0260 - val_loss: 0.1273 - val_mean_squared_error: 0.0289\n",
      "Epoch 188/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1206 - mean_squared_error: 0.0262 - val_loss: 0.1276 - val_mean_squared_error: 0.0282\n",
      "Epoch 189/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1218 - mean_squared_error: 0.0265 - val_loss: 0.1303 - val_mean_squared_error: 0.0296\n",
      "Epoch 190/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1215 - mean_squared_error: 0.0264 - val_loss: 0.1267 - val_mean_squared_error: 0.0282\n",
      "Epoch 191/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1201 - mean_squared_error: 0.0261 - val_loss: 0.1260 - val_mean_squared_error: 0.0283\n",
      "Epoch 192/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1197 - mean_squared_error: 0.0259 - val_loss: 0.1269 - val_mean_squared_error: 0.0287\n",
      "Epoch 193/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1194 - mean_squared_error: 0.0257 - val_loss: 0.1264 - val_mean_squared_error: 0.0288\n",
      "Epoch 194/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1210 - mean_squared_error: 0.0263 - val_loss: 0.1268 - val_mean_squared_error: 0.0285\n",
      "Epoch 195/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1215 - mean_squared_error: 0.0264 - val_loss: 0.1260 - val_mean_squared_error: 0.0283\n",
      "Epoch 196/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1196 - mean_squared_error: 0.0258 - val_loss: 0.1260 - val_mean_squared_error: 0.0283\n",
      "Epoch 197/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1197 - mean_squared_error: 0.0258 - val_loss: 0.1276 - val_mean_squared_error: 0.0288\n",
      "Epoch 198/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1198 - mean_squared_error: 0.0259 - val_loss: 0.1262 - val_mean_squared_error: 0.0285\n",
      "Epoch 199/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1211 - mean_squared_error: 0.0262 - val_loss: 0.1253 - val_mean_squared_error: 0.0280\n",
      "Epoch 200/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1201 - mean_squared_error: 0.0261 - val_loss: 0.1275 - val_mean_squared_error: 0.0286\n",
      "Epoch 201/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.1201 - mean_squared_error: 0.0258 - val_loss: 0.1256 - val_mean_squared_error: 0.0281\n",
      "Epoch 202/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1188 - mean_squared_error: 0.0256 - val_loss: 0.1258 - val_mean_squared_error: 0.0282\n",
      "Epoch 203/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1191 - mean_squared_error: 0.0256 - val_loss: 0.1254 - val_mean_squared_error: 0.0278\n",
      "Epoch 204/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1186 - mean_squared_error: 0.0256 - val_loss: 0.1246 - val_mean_squared_error: 0.0275\n",
      "Epoch 205/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1186 - mean_squared_error: 0.0255 - val_loss: 0.1260 - val_mean_squared_error: 0.0283\n",
      "Epoch 206/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1201 - mean_squared_error: 0.0259 - val_loss: 0.1272 - val_mean_squared_error: 0.0282\n",
      "Epoch 207/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1184 - mean_squared_error: 0.0253 - val_loss: 0.1258 - val_mean_squared_error: 0.0281\n",
      "Epoch 208/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1195 - mean_squared_error: 0.0257 - val_loss: 0.1266 - val_mean_squared_error: 0.0282\n",
      "Epoch 209/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1189 - mean_squared_error: 0.0257 - val_loss: 0.1294 - val_mean_squared_error: 0.0289\n",
      "Epoch 210/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1189 - mean_squared_error: 0.0259 - val_loss: 0.1253 - val_mean_squared_error: 0.0282\n",
      "Epoch 211/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1197 - mean_squared_error: 0.0257 - val_loss: 0.1302 - val_mean_squared_error: 0.0290\n",
      "Epoch 212/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1190 - mean_squared_error: 0.0254 - val_loss: 0.1263 - val_mean_squared_error: 0.0279\n",
      "Epoch 213/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1189 - mean_squared_error: 0.0255 - val_loss: 0.1259 - val_mean_squared_error: 0.0283\n",
      "Epoch 214/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1190 - mean_squared_error: 0.0255 - val_loss: 0.1286 - val_mean_squared_error: 0.0288\n",
      "Epoch 215/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1180 - mean_squared_error: 0.0253 - val_loss: 0.1269 - val_mean_squared_error: 0.0287\n",
      "Epoch 216/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1215 - mean_squared_error: 0.0265 - val_loss: 0.1276 - val_mean_squared_error: 0.0289\n",
      "Epoch 217/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1201 - mean_squared_error: 0.0259 - val_loss: 0.1260 - val_mean_squared_error: 0.0279\n",
      "Epoch 218/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1195 - mean_squared_error: 0.0257 - val_loss: 0.1264 - val_mean_squared_error: 0.0281\n",
      "Epoch 219/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1189 - mean_squared_error: 0.0256 - val_loss: 0.1257 - val_mean_squared_error: 0.0281\n",
      "Epoch 220/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1200 - mean_squared_error: 0.0258 - val_loss: 0.1271 - val_mean_squared_error: 0.0285\n",
      "Epoch 221/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1180 - mean_squared_error: 0.0253 - val_loss: 0.1269 - val_mean_squared_error: 0.0280\n",
      "Epoch 222/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1190 - mean_squared_error: 0.0256 - val_loss: 0.1288 - val_mean_squared_error: 0.0289\n",
      "Epoch 223/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1205 - mean_squared_error: 0.0261 - val_loss: 0.1252 - val_mean_squared_error: 0.0277\n",
      "Epoch 224/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1187 - mean_squared_error: 0.0255 - val_loss: 0.1250 - val_mean_squared_error: 0.0278\n",
      "Epoch 225/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1197 - mean_squared_error: 0.0261 - val_loss: 0.1285 - val_mean_squared_error: 0.0289\n",
      "Epoch 226/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1195 - mean_squared_error: 0.0258 - val_loss: 0.1292 - val_mean_squared_error: 0.0291\n",
      "Epoch 227/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1216 - mean_squared_error: 0.0263 - val_loss: 0.1280 - val_mean_squared_error: 0.0282\n",
      "Epoch 228/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1198 - mean_squared_error: 0.0257 - val_loss: 0.1287 - val_mean_squared_error: 0.0289\n",
      "Epoch 229/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1196 - mean_squared_error: 0.0258 - val_loss: 0.1257 - val_mean_squared_error: 0.0279\n",
      "Epoch 230/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1180 - mean_squared_error: 0.0251 - val_loss: 0.1275 - val_mean_squared_error: 0.0286\n",
      "Epoch 231/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1199 - mean_squared_error: 0.0257 - val_loss: 0.1280 - val_mean_squared_error: 0.0287\n",
      "Epoch 232/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1182 - mean_squared_error: 0.0252 - val_loss: 0.1262 - val_mean_squared_error: 0.0281\n",
      "Epoch 233/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1174 - mean_squared_error: 0.0250 - val_loss: 0.1263 - val_mean_squared_error: 0.0283\n",
      "Epoch 234/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1173 - mean_squared_error: 0.0251 - val_loss: 0.1259 - val_mean_squared_error: 0.0282\n",
      "Epoch 235/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1194 - mean_squared_error: 0.0259 - val_loss: 0.1264 - val_mean_squared_error: 0.0279\n",
      "Epoch 236/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1189 - mean_squared_error: 0.0251 - val_loss: 0.1289 - val_mean_squared_error: 0.0294\n",
      "Epoch 237/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1174 - mean_squared_error: 0.0252 - val_loss: 0.1263 - val_mean_squared_error: 0.0280\n",
      "Epoch 238/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1179 - mean_squared_error: 0.0252 - val_loss: 0.1268 - val_mean_squared_error: 0.0280\n",
      "Epoch 239/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1182 - mean_squared_error: 0.0254 - val_loss: 0.1279 - val_mean_squared_error: 0.0286\n",
      "Epoch 240/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1189 - mean_squared_error: 0.0253 - val_loss: 0.1263 - val_mean_squared_error: 0.0280\n",
      "Epoch 241/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1189 - mean_squared_error: 0.0254 - val_loss: 0.1269 - val_mean_squared_error: 0.0285\n",
      "Epoch 242/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1170 - mean_squared_error: 0.0247 - val_loss: 0.1238 - val_mean_squared_error: 0.0276\n",
      "Epoch 243/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1180 - mean_squared_error: 0.0251 - val_loss: 0.1273 - val_mean_squared_error: 0.0284\n",
      "Epoch 244/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1174 - mean_squared_error: 0.0253 - val_loss: 0.1261 - val_mean_squared_error: 0.0281\n",
      "Epoch 245/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1179 - mean_squared_error: 0.0253 - val_loss: 0.1269 - val_mean_squared_error: 0.0285\n",
      "Epoch 246/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1179 - mean_squared_error: 0.0251 - val_loss: 0.1278 - val_mean_squared_error: 0.0284\n",
      "Epoch 247/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1185 - mean_squared_error: 0.0252 - val_loss: 0.1273 - val_mean_squared_error: 0.0285\n",
      "Epoch 248/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1180 - mean_squared_error: 0.0253 - val_loss: 0.1276 - val_mean_squared_error: 0.0289\n",
      "Epoch 249/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1180 - mean_squared_error: 0.0254 - val_loss: 0.1283 - val_mean_squared_error: 0.0288\n",
      "Epoch 250/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1169 - mean_squared_error: 0.0250 - val_loss: 0.1256 - val_mean_squared_error: 0.0279\n",
      "Epoch 251/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1167 - mean_squared_error: 0.0248 - val_loss: 0.1262 - val_mean_squared_error: 0.0281\n",
      "Epoch 252/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1168 - mean_squared_error: 0.0249 - val_loss: 0.1269 - val_mean_squared_error: 0.0283\n",
      "Epoch 253/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1170 - mean_squared_error: 0.0248 - val_loss: 0.1242 - val_mean_squared_error: 0.0275\n",
      "Epoch 254/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1175 - mean_squared_error: 0.0249 - val_loss: 0.1255 - val_mean_squared_error: 0.0277\n",
      "Epoch 255/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1172 - mean_squared_error: 0.0248 - val_loss: 0.1252 - val_mean_squared_error: 0.0276\n",
      "Epoch 256/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1173 - mean_squared_error: 0.0249 - val_loss: 0.1270 - val_mean_squared_error: 0.0280\n",
      "Epoch 257/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1172 - mean_squared_error: 0.0251 - val_loss: 0.1284 - val_mean_squared_error: 0.0284\n",
      "Epoch 258/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1186 - mean_squared_error: 0.0252 - val_loss: 0.1264 - val_mean_squared_error: 0.0285\n",
      "Epoch 259/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1178 - mean_squared_error: 0.0249 - val_loss: 0.1287 - val_mean_squared_error: 0.0285\n",
      "Epoch 260/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1169 - mean_squared_error: 0.0245 - val_loss: 0.1259 - val_mean_squared_error: 0.0280\n",
      "Epoch 261/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1172 - mean_squared_error: 0.0250 - val_loss: 0.1264 - val_mean_squared_error: 0.0280\n",
      "Epoch 262/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1169 - mean_squared_error: 0.0250 - val_loss: 0.1283 - val_mean_squared_error: 0.0288\n",
      "Epoch 263/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1169 - mean_squared_error: 0.0247 - val_loss: 0.1257 - val_mean_squared_error: 0.0283\n",
      "Epoch 264/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1171 - mean_squared_error: 0.0248 - val_loss: 0.1265 - val_mean_squared_error: 0.0280\n",
      "Epoch 265/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1183 - mean_squared_error: 0.0251 - val_loss: 0.1263 - val_mean_squared_error: 0.0279\n",
      "Epoch 266/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1167 - mean_squared_error: 0.0248 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 267/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1180 - mean_squared_error: 0.0250 - val_loss: 0.1267 - val_mean_squared_error: 0.0282\n",
      "Epoch 268/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1168 - mean_squared_error: 0.0248 - val_loss: 0.1268 - val_mean_squared_error: 0.0282\n",
      "Epoch 269/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1177 - mean_squared_error: 0.0252 - val_loss: 0.1251 - val_mean_squared_error: 0.0278\n",
      "Epoch 270/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1171 - mean_squared_error: 0.0251 - val_loss: 0.1255 - val_mean_squared_error: 0.0281\n",
      "Epoch 271/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1161 - mean_squared_error: 0.0247 - val_loss: 0.1246 - val_mean_squared_error: 0.0278\n",
      "Epoch 272/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1166 - mean_squared_error: 0.0245 - val_loss: 0.1279 - val_mean_squared_error: 0.0284\n",
      "Epoch 273/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1173 - mean_squared_error: 0.0249 - val_loss: 0.1251 - val_mean_squared_error: 0.0278\n",
      "Epoch 274/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1161 - mean_squared_error: 0.0248 - val_loss: 0.1268 - val_mean_squared_error: 0.0284\n",
      "Epoch 275/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1167 - mean_squared_error: 0.0245 - val_loss: 0.1263 - val_mean_squared_error: 0.0278\n",
      "Epoch 276/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1175 - mean_squared_error: 0.0251 - val_loss: 0.1278 - val_mean_squared_error: 0.0285\n",
      "Epoch 277/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1165 - mean_squared_error: 0.0246 - val_loss: 0.1252 - val_mean_squared_error: 0.0279\n",
      "Epoch 278/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1170 - mean_squared_error: 0.0248 - val_loss: 0.1297 - val_mean_squared_error: 0.0289\n",
      "Epoch 279/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1177 - mean_squared_error: 0.0250 - val_loss: 0.1286 - val_mean_squared_error: 0.0287\n",
      "Epoch 280/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1157 - mean_squared_error: 0.0243 - val_loss: 0.1268 - val_mean_squared_error: 0.0283\n",
      "Epoch 281/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1173 - mean_squared_error: 0.0248 - val_loss: 0.1281 - val_mean_squared_error: 0.0288\n",
      "Epoch 282/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1163 - mean_squared_error: 0.0244 - val_loss: 0.1259 - val_mean_squared_error: 0.0279\n",
      "Epoch 283/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1164 - mean_squared_error: 0.0245 - val_loss: 0.1269 - val_mean_squared_error: 0.0282\n",
      "Epoch 284/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1175 - mean_squared_error: 0.0248 - val_loss: 0.1278 - val_mean_squared_error: 0.0282\n",
      "Epoch 285/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1162 - mean_squared_error: 0.0245 - val_loss: 0.1263 - val_mean_squared_error: 0.0280\n",
      "Epoch 286/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1181 - mean_squared_error: 0.0252 - val_loss: 0.1264 - val_mean_squared_error: 0.0279\n",
      "Epoch 287/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1173 - mean_squared_error: 0.0251 - val_loss: 0.1268 - val_mean_squared_error: 0.0281\n",
      "Epoch 288/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1167 - mean_squared_error: 0.0247 - val_loss: 0.1293 - val_mean_squared_error: 0.0288\n",
      "Epoch 289/1000\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.1171 - mean_squared_error: 0.0247 - val_loss: 0.1269 - val_mean_squared_error: 0.0282\n",
      "Epoch 290/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1168 - mean_squared_error: 0.0248 - val_loss: 0.1263 - val_mean_squared_error: 0.0280\n",
      "Epoch 291/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1168 - mean_squared_error: 0.0251 - val_loss: 0.1249 - val_mean_squared_error: 0.0277\n",
      "Epoch 292/1000\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 0.1162 - mean_squared_error: 0.0244 - val_loss: 0.1276 - val_mean_squared_error: 0.0285\n",
      "Epoch 293/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1161 - mean_squared_error: 0.0244 - val_loss: 0.1261 - val_mean_squared_error: 0.0279\n",
      "Epoch 294/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1155 - mean_squared_error: 0.0242 - val_loss: 0.1280 - val_mean_squared_error: 0.0283\n",
      "Epoch 295/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1173 - mean_squared_error: 0.0247 - val_loss: 0.1276 - val_mean_squared_error: 0.0285\n",
      "Epoch 296/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1167 - mean_squared_error: 0.0247 - val_loss: 0.1286 - val_mean_squared_error: 0.0292\n",
      "Epoch 297/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1180 - mean_squared_error: 0.0254 - val_loss: 0.1254 - val_mean_squared_error: 0.0278\n",
      "Epoch 298/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1171 - mean_squared_error: 0.0249 - val_loss: 0.1278 - val_mean_squared_error: 0.0285\n",
      "Epoch 299/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1173 - mean_squared_error: 0.0250 - val_loss: 0.1264 - val_mean_squared_error: 0.0281\n",
      "Epoch 300/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1166 - mean_squared_error: 0.0248 - val_loss: 0.1263 - val_mean_squared_error: 0.0282\n",
      "Epoch 301/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1162 - mean_squared_error: 0.0245 - val_loss: 0.1267 - val_mean_squared_error: 0.0281\n",
      "Epoch 302/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1166 - mean_squared_error: 0.0247 - val_loss: 0.1276 - val_mean_squared_error: 0.0284\n",
      "Epoch 303/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1154 - mean_squared_error: 0.0242 - val_loss: 0.1267 - val_mean_squared_error: 0.0285\n",
      "Epoch 304/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1166 - mean_squared_error: 0.0246 - val_loss: 0.1291 - val_mean_squared_error: 0.0288\n",
      "Epoch 305/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1171 - mean_squared_error: 0.0248 - val_loss: 0.1271 - val_mean_squared_error: 0.0281\n",
      "Epoch 306/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1153 - mean_squared_error: 0.0242 - val_loss: 0.1257 - val_mean_squared_error: 0.0278\n",
      "Epoch 307/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1158 - mean_squared_error: 0.0242 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 308/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1167 - mean_squared_error: 0.0249 - val_loss: 0.1287 - val_mean_squared_error: 0.0286\n",
      "Epoch 309/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1159 - mean_squared_error: 0.0244 - val_loss: 0.1268 - val_mean_squared_error: 0.0278\n",
      "Epoch 310/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1151 - mean_squared_error: 0.0242 - val_loss: 0.1271 - val_mean_squared_error: 0.0282\n",
      "Epoch 311/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1159 - mean_squared_error: 0.0243 - val_loss: 0.1267 - val_mean_squared_error: 0.0278\n",
      "Epoch 312/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1150 - mean_squared_error: 0.0242 - val_loss: 0.1281 - val_mean_squared_error: 0.0284\n",
      "Epoch 313/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1160 - mean_squared_error: 0.0244 - val_loss: 0.1257 - val_mean_squared_error: 0.0277\n",
      "Epoch 314/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1163 - mean_squared_error: 0.0248 - val_loss: 0.1271 - val_mean_squared_error: 0.0284\n",
      "Epoch 315/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1163 - mean_squared_error: 0.0248 - val_loss: 0.1307 - val_mean_squared_error: 0.0293\n",
      "Epoch 316/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1153 - mean_squared_error: 0.0243 - val_loss: 0.1265 - val_mean_squared_error: 0.0283\n",
      "Epoch 317/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1158 - mean_squared_error: 0.0245 - val_loss: 0.1274 - val_mean_squared_error: 0.0285\n",
      "Epoch 318/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1148 - mean_squared_error: 0.0239 - val_loss: 0.1264 - val_mean_squared_error: 0.0283\n",
      "Epoch 319/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1160 - mean_squared_error: 0.0243 - val_loss: 0.1265 - val_mean_squared_error: 0.0280\n",
      "Epoch 320/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1159 - mean_squared_error: 0.0242 - val_loss: 0.1281 - val_mean_squared_error: 0.0286\n",
      "Epoch 321/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1180 - mean_squared_error: 0.0250 - val_loss: 0.1282 - val_mean_squared_error: 0.0286\n",
      "Epoch 322/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1155 - mean_squared_error: 0.0244 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 323/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1148 - mean_squared_error: 0.0241 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 324/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1170 - mean_squared_error: 0.0248 - val_loss: 0.1272 - val_mean_squared_error: 0.0282\n",
      "Epoch 325/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1152 - mean_squared_error: 0.0242 - val_loss: 0.1269 - val_mean_squared_error: 0.0282\n",
      "Epoch 326/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1159 - mean_squared_error: 0.0245 - val_loss: 0.1261 - val_mean_squared_error: 0.0279\n",
      "Epoch 327/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1157 - mean_squared_error: 0.0244 - val_loss: 0.1269 - val_mean_squared_error: 0.0281\n",
      "Epoch 328/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1151 - mean_squared_error: 0.0244 - val_loss: 0.1263 - val_mean_squared_error: 0.0280\n",
      "Epoch 329/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1144 - mean_squared_error: 0.0236 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 330/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1149 - mean_squared_error: 0.0240 - val_loss: 0.1262 - val_mean_squared_error: 0.0279\n",
      "Epoch 331/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1153 - mean_squared_error: 0.0242 - val_loss: 0.1267 - val_mean_squared_error: 0.0282\n",
      "Epoch 332/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1157 - mean_squared_error: 0.0242 - val_loss: 0.1279 - val_mean_squared_error: 0.0286\n",
      "Epoch 333/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1160 - mean_squared_error: 0.0245 - val_loss: 0.1281 - val_mean_squared_error: 0.0287\n",
      "Epoch 334/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1153 - mean_squared_error: 0.0241 - val_loss: 0.1274 - val_mean_squared_error: 0.0284\n",
      "Epoch 335/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1159 - mean_squared_error: 0.0243 - val_loss: 0.1268 - val_mean_squared_error: 0.0285\n",
      "Epoch 336/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1143 - mean_squared_error: 0.0240 - val_loss: 0.1277 - val_mean_squared_error: 0.0284\n",
      "Epoch 337/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1152 - mean_squared_error: 0.0241 - val_loss: 0.1276 - val_mean_squared_error: 0.0285\n",
      "Epoch 338/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1158 - mean_squared_error: 0.0240 - val_loss: 0.1281 - val_mean_squared_error: 0.0287\n",
      "Epoch 339/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1147 - mean_squared_error: 0.0240 - val_loss: 0.1272 - val_mean_squared_error: 0.0285\n",
      "Epoch 340/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1146 - mean_squared_error: 0.0241 - val_loss: 0.1270 - val_mean_squared_error: 0.0280\n",
      "Epoch 341/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1144 - mean_squared_error: 0.0238 - val_loss: 0.1266 - val_mean_squared_error: 0.0282\n",
      "Epoch 342/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1160 - mean_squared_error: 0.0242 - val_loss: 0.1269 - val_mean_squared_error: 0.0281\n",
      "Epoch 343/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1151 - mean_squared_error: 0.0240 - val_loss: 0.1305 - val_mean_squared_error: 0.0291\n",
      "Epoch 344/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1156 - mean_squared_error: 0.0242 - val_loss: 0.1260 - val_mean_squared_error: 0.0279\n",
      "Epoch 345/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1142 - mean_squared_error: 0.0239 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 346/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1153 - mean_squared_error: 0.0242 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 347/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1144 - mean_squared_error: 0.0240 - val_loss: 0.1267 - val_mean_squared_error: 0.0281\n",
      "Epoch 348/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1157 - mean_squared_error: 0.0244 - val_loss: 0.1280 - val_mean_squared_error: 0.0286\n",
      "Epoch 349/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1151 - mean_squared_error: 0.0239 - val_loss: 0.1269 - val_mean_squared_error: 0.0280\n",
      "Epoch 350/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1166 - mean_squared_error: 0.0244 - val_loss: 0.1274 - val_mean_squared_error: 0.0283\n",
      "Epoch 351/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1148 - mean_squared_error: 0.0238 - val_loss: 0.1274 - val_mean_squared_error: 0.0285\n",
      "Epoch 352/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1155 - mean_squared_error: 0.0242 - val_loss: 0.1271 - val_mean_squared_error: 0.0280\n",
      "Epoch 353/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1136 - mean_squared_error: 0.0237 - val_loss: 0.1263 - val_mean_squared_error: 0.0280\n",
      "Epoch 354/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1160 - mean_squared_error: 0.0242 - val_loss: 0.1282 - val_mean_squared_error: 0.0285\n",
      "Epoch 355/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1160 - mean_squared_error: 0.0243 - val_loss: 0.1262 - val_mean_squared_error: 0.0280\n",
      "Epoch 356/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1147 - mean_squared_error: 0.0239 - val_loss: 0.1276 - val_mean_squared_error: 0.0283\n",
      "Epoch 357/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1147 - mean_squared_error: 0.0240 - val_loss: 0.1274 - val_mean_squared_error: 0.0284\n",
      "Epoch 358/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1151 - mean_squared_error: 0.0241 - val_loss: 0.1275 - val_mean_squared_error: 0.0288\n",
      "Epoch 359/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1138 - mean_squared_error: 0.0238 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 360/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1141 - mean_squared_error: 0.0237 - val_loss: 0.1263 - val_mean_squared_error: 0.0281\n",
      "Epoch 361/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1149 - mean_squared_error: 0.0240 - val_loss: 0.1267 - val_mean_squared_error: 0.0283\n",
      "Epoch 362/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1156 - mean_squared_error: 0.0245 - val_loss: 0.1299 - val_mean_squared_error: 0.0290\n",
      "Epoch 363/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1158 - mean_squared_error: 0.0243 - val_loss: 0.1267 - val_mean_squared_error: 0.0283\n",
      "Epoch 364/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1135 - mean_squared_error: 0.0234 - val_loss: 0.1278 - val_mean_squared_error: 0.0282\n",
      "Epoch 365/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1138 - mean_squared_error: 0.0235 - val_loss: 0.1315 - val_mean_squared_error: 0.0293\n",
      "Epoch 366/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1154 - mean_squared_error: 0.0240 - val_loss: 0.1265 - val_mean_squared_error: 0.0279\n",
      "Epoch 367/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1138 - mean_squared_error: 0.0237 - val_loss: 0.1290 - val_mean_squared_error: 0.0286\n",
      "Epoch 368/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1147 - mean_squared_error: 0.0237 - val_loss: 0.1279 - val_mean_squared_error: 0.0285\n",
      "Epoch 369/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1138 - mean_squared_error: 0.0236 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 370/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1142 - mean_squared_error: 0.0237 - val_loss: 0.1270 - val_mean_squared_error: 0.0283\n",
      "Epoch 371/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1135 - mean_squared_error: 0.0237 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 372/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1154 - mean_squared_error: 0.0242 - val_loss: 0.1263 - val_mean_squared_error: 0.0282\n",
      "Epoch 373/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1145 - mean_squared_error: 0.0240 - val_loss: 0.1281 - val_mean_squared_error: 0.0282\n",
      "Epoch 374/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1146 - mean_squared_error: 0.0238 - val_loss: 0.1272 - val_mean_squared_error: 0.0281\n",
      "Epoch 375/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1139 - mean_squared_error: 0.0236 - val_loss: 0.1279 - val_mean_squared_error: 0.0287\n",
      "Epoch 376/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1151 - mean_squared_error: 0.0239 - val_loss: 0.1297 - val_mean_squared_error: 0.0288\n",
      "Epoch 377/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1129 - mean_squared_error: 0.0234 - val_loss: 0.1272 - val_mean_squared_error: 0.0281\n",
      "Epoch 378/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1134 - mean_squared_error: 0.0237 - val_loss: 0.1267 - val_mean_squared_error: 0.0281\n",
      "Epoch 379/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1139 - mean_squared_error: 0.0236 - val_loss: 0.1261 - val_mean_squared_error: 0.0281\n",
      "Epoch 380/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1135 - mean_squared_error: 0.0235 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 381/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1143 - mean_squared_error: 0.0239 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 382/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1153 - mean_squared_error: 0.0239 - val_loss: 0.1266 - val_mean_squared_error: 0.0279\n",
      "Epoch 383/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1138 - mean_squared_error: 0.0238 - val_loss: 0.1285 - val_mean_squared_error: 0.0285\n",
      "Epoch 384/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1143 - mean_squared_error: 0.0239 - val_loss: 0.1282 - val_mean_squared_error: 0.0284\n",
      "Epoch 385/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1144 - mean_squared_error: 0.0237 - val_loss: 0.1283 - val_mean_squared_error: 0.0286\n",
      "Epoch 386/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1132 - mean_squared_error: 0.0234 - val_loss: 0.1257 - val_mean_squared_error: 0.0278\n",
      "Epoch 387/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1142 - mean_squared_error: 0.0240 - val_loss: 0.1264 - val_mean_squared_error: 0.0284\n",
      "Epoch 388/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1140 - mean_squared_error: 0.0236 - val_loss: 0.1270 - val_mean_squared_error: 0.0279\n",
      "Epoch 389/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1138 - mean_squared_error: 0.0236 - val_loss: 0.1268 - val_mean_squared_error: 0.0281\n",
      "Epoch 390/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1146 - mean_squared_error: 0.0236 - val_loss: 0.1258 - val_mean_squared_error: 0.0279\n",
      "Epoch 391/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1144 - mean_squared_error: 0.0238 - val_loss: 0.1270 - val_mean_squared_error: 0.0281\n",
      "Epoch 392/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1137 - mean_squared_error: 0.0236 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 393/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1141 - mean_squared_error: 0.0235 - val_loss: 0.1270 - val_mean_squared_error: 0.0284\n",
      "Epoch 394/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1134 - mean_squared_error: 0.0234 - val_loss: 0.1287 - val_mean_squared_error: 0.0286\n",
      "Epoch 395/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1139 - mean_squared_error: 0.0236 - val_loss: 0.1287 - val_mean_squared_error: 0.0285\n",
      "Epoch 396/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1137 - mean_squared_error: 0.0236 - val_loss: 0.1278 - val_mean_squared_error: 0.0282\n",
      "Epoch 397/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1139 - mean_squared_error: 0.0235 - val_loss: 0.1278 - val_mean_squared_error: 0.0284\n",
      "Epoch 398/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1141 - mean_squared_error: 0.0235 - val_loss: 0.1285 - val_mean_squared_error: 0.0283\n",
      "Epoch 399/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1136 - mean_squared_error: 0.0235 - val_loss: 0.1267 - val_mean_squared_error: 0.0280\n",
      "Epoch 400/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1134 - mean_squared_error: 0.0233 - val_loss: 0.1265 - val_mean_squared_error: 0.0280\n",
      "Epoch 401/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1137 - mean_squared_error: 0.0235 - val_loss: 0.1288 - val_mean_squared_error: 0.0283\n",
      "Epoch 402/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1127 - mean_squared_error: 0.0232 - val_loss: 0.1263 - val_mean_squared_error: 0.0279\n",
      "Epoch 403/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1142 - mean_squared_error: 0.0235 - val_loss: 0.1274 - val_mean_squared_error: 0.0280\n",
      "Epoch 404/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1136 - mean_squared_error: 0.0235 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 405/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1143 - mean_squared_error: 0.0237 - val_loss: 0.1272 - val_mean_squared_error: 0.0281\n",
      "Epoch 406/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1121 - mean_squared_error: 0.0232 - val_loss: 0.1265 - val_mean_squared_error: 0.0280\n",
      "Epoch 407/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1147 - mean_squared_error: 0.0238 - val_loss: 0.1285 - val_mean_squared_error: 0.0284\n",
      "Epoch 408/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1128 - mean_squared_error: 0.0234 - val_loss: 0.1286 - val_mean_squared_error: 0.0285\n",
      "Epoch 409/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1126 - mean_squared_error: 0.0232 - val_loss: 0.1279 - val_mean_squared_error: 0.0284\n",
      "Epoch 410/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1140 - mean_squared_error: 0.0239 - val_loss: 0.1273 - val_mean_squared_error: 0.0282\n",
      "Epoch 411/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1129 - mean_squared_error: 0.0235 - val_loss: 0.1280 - val_mean_squared_error: 0.0283\n",
      "Epoch 412/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1126 - mean_squared_error: 0.0231 - val_loss: 0.1271 - val_mean_squared_error: 0.0280\n",
      "Epoch 413/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1134 - mean_squared_error: 0.0235 - val_loss: 0.1290 - val_mean_squared_error: 0.0284\n",
      "Epoch 414/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1135 - mean_squared_error: 0.0235 - val_loss: 0.1274 - val_mean_squared_error: 0.0281\n",
      "Epoch 415/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1125 - mean_squared_error: 0.0233 - val_loss: 0.1288 - val_mean_squared_error: 0.0289\n",
      "Epoch 416/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1153 - mean_squared_error: 0.0241 - val_loss: 0.1276 - val_mean_squared_error: 0.0282\n",
      "Epoch 417/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1133 - mean_squared_error: 0.0233 - val_loss: 0.1287 - val_mean_squared_error: 0.0283\n",
      "Epoch 418/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1136 - mean_squared_error: 0.0234 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 419/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1138 - mean_squared_error: 0.0234 - val_loss: 0.1282 - val_mean_squared_error: 0.0282\n",
      "Epoch 420/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1127 - mean_squared_error: 0.0230 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 421/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1127 - mean_squared_error: 0.0232 - val_loss: 0.1289 - val_mean_squared_error: 0.0286\n",
      "Epoch 422/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1140 - mean_squared_error: 0.0237 - val_loss: 0.1264 - val_mean_squared_error: 0.0279\n",
      "Epoch 423/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1126 - mean_squared_error: 0.0233 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 424/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1113 - mean_squared_error: 0.0228 - val_loss: 0.1272 - val_mean_squared_error: 0.0281\n",
      "Epoch 425/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1128 - mean_squared_error: 0.0231 - val_loss: 0.1299 - val_mean_squared_error: 0.0289\n",
      "Epoch 426/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1136 - mean_squared_error: 0.0236 - val_loss: 0.1283 - val_mean_squared_error: 0.0287\n",
      "Epoch 427/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1135 - mean_squared_error: 0.0233 - val_loss: 0.1270 - val_mean_squared_error: 0.0283\n",
      "Epoch 428/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1130 - mean_squared_error: 0.0234 - val_loss: 0.1278 - val_mean_squared_error: 0.0282\n",
      "Epoch 429/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1131 - mean_squared_error: 0.0236 - val_loss: 0.1308 - val_mean_squared_error: 0.0291\n",
      "Epoch 430/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1135 - mean_squared_error: 0.0236 - val_loss: 0.1285 - val_mean_squared_error: 0.0284\n",
      "Epoch 431/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1132 - mean_squared_error: 0.0235 - val_loss: 0.1277 - val_mean_squared_error: 0.0281\n",
      "Epoch 432/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1124 - mean_squared_error: 0.0233 - val_loss: 0.1276 - val_mean_squared_error: 0.0279\n",
      "Epoch 433/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1137 - mean_squared_error: 0.0234 - val_loss: 0.1293 - val_mean_squared_error: 0.0285\n",
      "Epoch 434/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1131 - mean_squared_error: 0.0233 - val_loss: 0.1288 - val_mean_squared_error: 0.0289\n",
      "Epoch 435/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1130 - mean_squared_error: 0.0233 - val_loss: 0.1284 - val_mean_squared_error: 0.0284\n",
      "Epoch 436/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1121 - mean_squared_error: 0.0231 - val_loss: 0.1280 - val_mean_squared_error: 0.0286\n",
      "Epoch 437/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1131 - mean_squared_error: 0.0237 - val_loss: 0.1279 - val_mean_squared_error: 0.0283\n",
      "Epoch 438/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1124 - mean_squared_error: 0.0232 - val_loss: 0.1283 - val_mean_squared_error: 0.0286\n",
      "Epoch 439/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1145 - mean_squared_error: 0.0238 - val_loss: 0.1270 - val_mean_squared_error: 0.0282\n",
      "Epoch 440/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1131 - mean_squared_error: 0.0235 - val_loss: 0.1279 - val_mean_squared_error: 0.0287\n",
      "Epoch 441/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1132 - mean_squared_error: 0.0233 - val_loss: 0.1288 - val_mean_squared_error: 0.0289\n",
      "Epoch 442/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1136 - mean_squared_error: 0.0238 - val_loss: 0.1268 - val_mean_squared_error: 0.0280\n",
      "Epoch 443/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1125 - mean_squared_error: 0.0232 - val_loss: 0.1308 - val_mean_squared_error: 0.0292\n",
      "Epoch 444/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1141 - mean_squared_error: 0.0237 - val_loss: 0.1286 - val_mean_squared_error: 0.0285\n",
      "Epoch 445/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1121 - mean_squared_error: 0.0233 - val_loss: 0.1272 - val_mean_squared_error: 0.0282\n",
      "Epoch 446/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1133 - mean_squared_error: 0.0233 - val_loss: 0.1275 - val_mean_squared_error: 0.0281\n",
      "Epoch 447/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1137 - mean_squared_error: 0.0233 - val_loss: 0.1277 - val_mean_squared_error: 0.0284\n",
      "Epoch 448/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1123 - mean_squared_error: 0.0233 - val_loss: 0.1305 - val_mean_squared_error: 0.0291\n",
      "Epoch 449/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1124 - mean_squared_error: 0.0231 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 450/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1128 - mean_squared_error: 0.0233 - val_loss: 0.1280 - val_mean_squared_error: 0.0287\n",
      "Epoch 451/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1118 - mean_squared_error: 0.0230 - val_loss: 0.1275 - val_mean_squared_error: 0.0284\n",
      "Epoch 452/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1132 - mean_squared_error: 0.0231 - val_loss: 0.1277 - val_mean_squared_error: 0.0282\n",
      "Epoch 453/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1122 - mean_squared_error: 0.0232 - val_loss: 0.1271 - val_mean_squared_error: 0.0280\n",
      "Epoch 454/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1131 - mean_squared_error: 0.0231 - val_loss: 0.1276 - val_mean_squared_error: 0.0283\n",
      "Epoch 455/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1140 - mean_squared_error: 0.0236 - val_loss: 0.1295 - val_mean_squared_error: 0.0287\n",
      "Epoch 456/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1119 - mean_squared_error: 0.0232 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 457/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1122 - mean_squared_error: 0.0232 - val_loss: 0.1281 - val_mean_squared_error: 0.0281\n",
      "Epoch 458/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1128 - mean_squared_error: 0.0232 - val_loss: 0.1291 - val_mean_squared_error: 0.0287\n",
      "Epoch 459/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1120 - mean_squared_error: 0.0230 - val_loss: 0.1279 - val_mean_squared_error: 0.0285\n",
      "Epoch 460/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1134 - mean_squared_error: 0.0233 - val_loss: 0.1278 - val_mean_squared_error: 0.0282\n",
      "Epoch 461/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1145 - mean_squared_error: 0.0240 - val_loss: 0.1276 - val_mean_squared_error: 0.0287\n",
      "Epoch 462/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1124 - mean_squared_error: 0.0230 - val_loss: 0.1264 - val_mean_squared_error: 0.0281\n",
      "Epoch 463/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1108 - mean_squared_error: 0.0226 - val_loss: 0.1287 - val_mean_squared_error: 0.0285\n",
      "Epoch 464/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1126 - mean_squared_error: 0.0233 - val_loss: 0.1275 - val_mean_squared_error: 0.0280\n",
      "Epoch 465/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0226 - val_loss: 0.1274 - val_mean_squared_error: 0.0283\n",
      "Epoch 466/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1125 - mean_squared_error: 0.0229 - val_loss: 0.1262 - val_mean_squared_error: 0.0279\n",
      "Epoch 467/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1129 - mean_squared_error: 0.0231 - val_loss: 0.1259 - val_mean_squared_error: 0.0278\n",
      "Epoch 468/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1124 - mean_squared_error: 0.0231 - val_loss: 0.1289 - val_mean_squared_error: 0.0288\n",
      "Epoch 469/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1130 - mean_squared_error: 0.0233 - val_loss: 0.1279 - val_mean_squared_error: 0.0281\n",
      "Epoch 470/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1128 - mean_squared_error: 0.0233 - val_loss: 0.1279 - val_mean_squared_error: 0.0283\n",
      "Epoch 471/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1120 - mean_squared_error: 0.0229 - val_loss: 0.1275 - val_mean_squared_error: 0.0282\n",
      "Epoch 472/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1126 - mean_squared_error: 0.0231 - val_loss: 0.1288 - val_mean_squared_error: 0.0283\n",
      "Epoch 473/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1119 - mean_squared_error: 0.0231 - val_loss: 0.1284 - val_mean_squared_error: 0.0283\n",
      "Epoch 474/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1110 - mean_squared_error: 0.0227 - val_loss: 0.1310 - val_mean_squared_error: 0.0297\n",
      "Epoch 475/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1132 - mean_squared_error: 0.0232 - val_loss: 0.1285 - val_mean_squared_error: 0.0288\n",
      "Epoch 476/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1113 - mean_squared_error: 0.0228 - val_loss: 0.1280 - val_mean_squared_error: 0.0283\n",
      "Epoch 477/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1127 - mean_squared_error: 0.0234 - val_loss: 0.1261 - val_mean_squared_error: 0.0281\n",
      "Epoch 478/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1113 - mean_squared_error: 0.0230 - val_loss: 0.1294 - val_mean_squared_error: 0.0288\n",
      "Epoch 479/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1129 - mean_squared_error: 0.0232 - val_loss: 0.1269 - val_mean_squared_error: 0.0281\n",
      "Epoch 480/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1122 - mean_squared_error: 0.0229 - val_loss: 0.1272 - val_mean_squared_error: 0.0281\n",
      "Epoch 481/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1112 - mean_squared_error: 0.0227 - val_loss: 0.1273 - val_mean_squared_error: 0.0284\n",
      "Epoch 482/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1124 - mean_squared_error: 0.0230 - val_loss: 0.1265 - val_mean_squared_error: 0.0278\n",
      "Epoch 483/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1118 - mean_squared_error: 0.0228 - val_loss: 0.1285 - val_mean_squared_error: 0.0284\n",
      "Epoch 484/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1119 - mean_squared_error: 0.0231 - val_loss: 0.1284 - val_mean_squared_error: 0.0283\n",
      "Epoch 485/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1116 - mean_squared_error: 0.0229 - val_loss: 0.1280 - val_mean_squared_error: 0.0288\n",
      "Epoch 486/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1116 - mean_squared_error: 0.0230 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 487/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1131 - mean_squared_error: 0.0235 - val_loss: 0.1280 - val_mean_squared_error: 0.0286\n",
      "Epoch 488/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1114 - mean_squared_error: 0.0227 - val_loss: 0.1290 - val_mean_squared_error: 0.0286\n",
      "Epoch 489/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1118 - mean_squared_error: 0.0228 - val_loss: 0.1290 - val_mean_squared_error: 0.0288\n",
      "Epoch 490/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1129 - mean_squared_error: 0.0234 - val_loss: 0.1282 - val_mean_squared_error: 0.0288\n",
      "Epoch 491/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1116 - mean_squared_error: 0.0230 - val_loss: 0.1276 - val_mean_squared_error: 0.0284\n",
      "Epoch 492/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1102 - mean_squared_error: 0.0225 - val_loss: 0.1281 - val_mean_squared_error: 0.0283\n",
      "Epoch 493/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1125 - mean_squared_error: 0.0228 - val_loss: 0.1284 - val_mean_squared_error: 0.0284\n",
      "Epoch 494/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1114 - mean_squared_error: 0.0228 - val_loss: 0.1278 - val_mean_squared_error: 0.0286\n",
      "Epoch 495/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1115 - mean_squared_error: 0.0229 - val_loss: 0.1272 - val_mean_squared_error: 0.0282\n",
      "Epoch 496/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1126 - mean_squared_error: 0.0231 - val_loss: 0.1278 - val_mean_squared_error: 0.0284\n",
      "Epoch 497/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1117 - mean_squared_error: 0.0229 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 498/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1119 - mean_squared_error: 0.0230 - val_loss: 0.1289 - val_mean_squared_error: 0.0285\n",
      "Epoch 499/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1118 - mean_squared_error: 0.0229 - val_loss: 0.1286 - val_mean_squared_error: 0.0288\n",
      "Epoch 500/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1115 - mean_squared_error: 0.0226 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 501/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1113 - mean_squared_error: 0.0228 - val_loss: 0.1271 - val_mean_squared_error: 0.0284\n",
      "Epoch 502/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1129 - mean_squared_error: 0.0231 - val_loss: 0.1286 - val_mean_squared_error: 0.0284\n",
      "Epoch 503/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1119 - mean_squared_error: 0.0230 - val_loss: 0.1296 - val_mean_squared_error: 0.0287\n",
      "Epoch 504/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1109 - mean_squared_error: 0.0225 - val_loss: 0.1276 - val_mean_squared_error: 0.0283\n",
      "Epoch 505/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1118 - mean_squared_error: 0.0229 - val_loss: 0.1295 - val_mean_squared_error: 0.0290\n",
      "Epoch 506/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1118 - mean_squared_error: 0.0229 - val_loss: 0.1267 - val_mean_squared_error: 0.0282\n",
      "Epoch 507/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1110 - mean_squared_error: 0.0227 - val_loss: 0.1276 - val_mean_squared_error: 0.0280\n",
      "Epoch 508/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1111 - mean_squared_error: 0.0228 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 509/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1116 - mean_squared_error: 0.0229 - val_loss: 0.1293 - val_mean_squared_error: 0.0287\n",
      "Epoch 510/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1125 - mean_squared_error: 0.0231 - val_loss: 0.1296 - val_mean_squared_error: 0.0285\n",
      "Epoch 511/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1105 - mean_squared_error: 0.0226 - val_loss: 0.1276 - val_mean_squared_error: 0.0281\n",
      "Epoch 512/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1117 - mean_squared_error: 0.0231 - val_loss: 0.1284 - val_mean_squared_error: 0.0284\n",
      "Epoch 513/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1103 - mean_squared_error: 0.0224 - val_loss: 0.1266 - val_mean_squared_error: 0.0280\n",
      "Epoch 514/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1117 - mean_squared_error: 0.0230 - val_loss: 0.1278 - val_mean_squared_error: 0.0280\n",
      "Epoch 515/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1125 - mean_squared_error: 0.0231 - val_loss: 0.1277 - val_mean_squared_error: 0.0282\n",
      "Epoch 516/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0226 - val_loss: 0.1315 - val_mean_squared_error: 0.0293\n",
      "Epoch 517/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1105 - mean_squared_error: 0.0227 - val_loss: 0.1276 - val_mean_squared_error: 0.0284\n",
      "Epoch 518/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1109 - mean_squared_error: 0.0227 - val_loss: 0.1277 - val_mean_squared_error: 0.0283\n",
      "Epoch 519/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1117 - mean_squared_error: 0.0228 - val_loss: 0.1291 - val_mean_squared_error: 0.0286\n",
      "Epoch 520/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1112 - mean_squared_error: 0.0226 - val_loss: 0.1273 - val_mean_squared_error: 0.0282\n",
      "Epoch 521/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1097 - mean_squared_error: 0.0224 - val_loss: 0.1267 - val_mean_squared_error: 0.0280\n",
      "Epoch 522/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1123 - mean_squared_error: 0.0230 - val_loss: 0.1274 - val_mean_squared_error: 0.0282\n",
      "Epoch 523/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1121 - mean_squared_error: 0.0232 - val_loss: 0.1264 - val_mean_squared_error: 0.0279\n",
      "Epoch 524/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1115 - mean_squared_error: 0.0228 - val_loss: 0.1277 - val_mean_squared_error: 0.0284\n",
      "Epoch 525/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1106 - mean_squared_error: 0.0227 - val_loss: 0.1296 - val_mean_squared_error: 0.0290\n",
      "Epoch 526/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1124 - mean_squared_error: 0.0232 - val_loss: 0.1292 - val_mean_squared_error: 0.0286\n",
      "Epoch 527/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1119 - mean_squared_error: 0.0230 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 528/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1103 - mean_squared_error: 0.0223 - val_loss: 0.1276 - val_mean_squared_error: 0.0283\n",
      "Epoch 529/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0227 - val_loss: 0.1288 - val_mean_squared_error: 0.0286\n",
      "Epoch 530/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1136 - mean_squared_error: 0.0236 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 531/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1126 - mean_squared_error: 0.0229 - val_loss: 0.1288 - val_mean_squared_error: 0.0284\n",
      "Epoch 532/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1121 - mean_squared_error: 0.0228 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 533/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1118 - mean_squared_error: 0.0227 - val_loss: 0.1297 - val_mean_squared_error: 0.0288\n",
      "Epoch 534/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1108 - mean_squared_error: 0.0226 - val_loss: 0.1285 - val_mean_squared_error: 0.0285\n",
      "Epoch 535/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1102 - mean_squared_error: 0.0221 - val_loss: 0.1272 - val_mean_squared_error: 0.0283\n",
      "Epoch 536/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1118 - mean_squared_error: 0.0229 - val_loss: 0.1275 - val_mean_squared_error: 0.0285\n",
      "Epoch 537/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1113 - mean_squared_error: 0.0227 - val_loss: 0.1293 - val_mean_squared_error: 0.0288\n",
      "Epoch 538/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1121 - mean_squared_error: 0.0230 - val_loss: 0.1283 - val_mean_squared_error: 0.0286\n",
      "Epoch 539/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1111 - mean_squared_error: 0.0228 - val_loss: 0.1286 - val_mean_squared_error: 0.0288\n",
      "Epoch 540/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1110 - mean_squared_error: 0.0230 - val_loss: 0.1281 - val_mean_squared_error: 0.0286\n",
      "Epoch 541/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1113 - mean_squared_error: 0.0227 - val_loss: 0.1280 - val_mean_squared_error: 0.0287\n",
      "Epoch 542/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1109 - mean_squared_error: 0.0225 - val_loss: 0.1289 - val_mean_squared_error: 0.0287\n",
      "Epoch 543/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1104 - mean_squared_error: 0.0225 - val_loss: 0.1280 - val_mean_squared_error: 0.0286\n",
      "Epoch 544/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1123 - mean_squared_error: 0.0231 - val_loss: 0.1289 - val_mean_squared_error: 0.0286\n",
      "Epoch 545/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1113 - mean_squared_error: 0.0228 - val_loss: 0.1276 - val_mean_squared_error: 0.0284\n",
      "Epoch 546/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1118 - mean_squared_error: 0.0231 - val_loss: 0.1276 - val_mean_squared_error: 0.0286\n",
      "Epoch 547/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1113 - mean_squared_error: 0.0229 - val_loss: 0.1284 - val_mean_squared_error: 0.0285\n",
      "Epoch 548/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.1108 - mean_squared_error: 0.0225 - val_loss: 0.1296 - val_mean_squared_error: 0.0288\n",
      "Epoch 549/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1102 - mean_squared_error: 0.0225 - val_loss: 0.1283 - val_mean_squared_error: 0.0288\n",
      "Epoch 550/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1118 - mean_squared_error: 0.0230 - val_loss: 0.1273 - val_mean_squared_error: 0.0282\n",
      "Epoch 551/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1108 - mean_squared_error: 0.0225 - val_loss: 0.1291 - val_mean_squared_error: 0.0286\n",
      "Epoch 552/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1121 - mean_squared_error: 0.0227 - val_loss: 0.1274 - val_mean_squared_error: 0.0281\n",
      "Epoch 553/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1119 - mean_squared_error: 0.0229 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 554/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1112 - mean_squared_error: 0.0227 - val_loss: 0.1296 - val_mean_squared_error: 0.0291\n",
      "Epoch 555/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1087 - mean_squared_error: 0.0221 - val_loss: 0.1272 - val_mean_squared_error: 0.0282\n",
      "Epoch 556/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1114 - mean_squared_error: 0.0227 - val_loss: 0.1285 - val_mean_squared_error: 0.0284\n",
      "Epoch 557/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1102 - mean_squared_error: 0.0226 - val_loss: 0.1278 - val_mean_squared_error: 0.0283\n",
      "Epoch 558/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1103 - mean_squared_error: 0.0224 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 559/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1102 - mean_squared_error: 0.0225 - val_loss: 0.1281 - val_mean_squared_error: 0.0284\n",
      "Epoch 560/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1103 - mean_squared_error: 0.0224 - val_loss: 0.1276 - val_mean_squared_error: 0.0282\n",
      "Epoch 561/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0224 - val_loss: 0.1285 - val_mean_squared_error: 0.0287\n",
      "Epoch 562/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0223 - val_loss: 0.1273 - val_mean_squared_error: 0.0282\n",
      "Epoch 563/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1119 - mean_squared_error: 0.0226 - val_loss: 0.1304 - val_mean_squared_error: 0.0291\n",
      "Epoch 564/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1112 - mean_squared_error: 0.0227 - val_loss: 0.1276 - val_mean_squared_error: 0.0286\n",
      "Epoch 565/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1100 - mean_squared_error: 0.0224 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 566/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1113 - mean_squared_error: 0.0229 - val_loss: 0.1284 - val_mean_squared_error: 0.0286\n",
      "Epoch 567/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1114 - mean_squared_error: 0.0226 - val_loss: 0.1290 - val_mean_squared_error: 0.0288\n",
      "Epoch 568/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1105 - mean_squared_error: 0.0223 - val_loss: 0.1278 - val_mean_squared_error: 0.0284\n",
      "Epoch 569/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1102 - mean_squared_error: 0.0224 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 570/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1104 - mean_squared_error: 0.0226 - val_loss: 0.1289 - val_mean_squared_error: 0.0285\n",
      "Epoch 571/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1100 - mean_squared_error: 0.0225 - val_loss: 0.1277 - val_mean_squared_error: 0.0283\n",
      "Epoch 572/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1104 - mean_squared_error: 0.0224 - val_loss: 0.1284 - val_mean_squared_error: 0.0285\n",
      "Epoch 573/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0223 - val_loss: 0.1294 - val_mean_squared_error: 0.0286\n",
      "Epoch 574/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1106 - mean_squared_error: 0.0223 - val_loss: 0.1282 - val_mean_squared_error: 0.0286\n",
      "Epoch 575/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1105 - mean_squared_error: 0.0226 - val_loss: 0.1290 - val_mean_squared_error: 0.0286\n",
      "Epoch 576/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1102 - mean_squared_error: 0.0223 - val_loss: 0.1294 - val_mean_squared_error: 0.0286\n",
      "Epoch 577/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1098 - mean_squared_error: 0.0223 - val_loss: 0.1288 - val_mean_squared_error: 0.0286\n",
      "Epoch 578/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1108 - mean_squared_error: 0.0225 - val_loss: 0.1277 - val_mean_squared_error: 0.0283\n",
      "Epoch 579/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1105 - mean_squared_error: 0.0224 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 580/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1109 - mean_squared_error: 0.0226 - val_loss: 0.1278 - val_mean_squared_error: 0.0288\n",
      "Epoch 581/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1101 - mean_squared_error: 0.0225 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 582/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1089 - mean_squared_error: 0.0220 - val_loss: 0.1300 - val_mean_squared_error: 0.0292\n",
      "Epoch 583/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1110 - mean_squared_error: 0.0226 - val_loss: 0.1299 - val_mean_squared_error: 0.0291\n",
      "Epoch 584/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1108 - mean_squared_error: 0.0225 - val_loss: 0.1277 - val_mean_squared_error: 0.0288\n",
      "Epoch 585/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1128 - mean_squared_error: 0.0231 - val_loss: 0.1303 - val_mean_squared_error: 0.0289\n",
      "Epoch 586/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1101 - mean_squared_error: 0.0223 - val_loss: 0.1288 - val_mean_squared_error: 0.0286\n",
      "Epoch 587/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1091 - mean_squared_error: 0.0221 - val_loss: 0.1287 - val_mean_squared_error: 0.0282\n",
      "Epoch 588/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1105 - mean_squared_error: 0.0227 - val_loss: 0.1295 - val_mean_squared_error: 0.0290\n",
      "Epoch 589/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1101 - mean_squared_error: 0.0225 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 590/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1107 - mean_squared_error: 0.0224 - val_loss: 0.1287 - val_mean_squared_error: 0.0285\n",
      "Epoch 591/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1107 - mean_squared_error: 0.0225 - val_loss: 0.1298 - val_mean_squared_error: 0.0288\n",
      "Epoch 592/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1106 - mean_squared_error: 0.0223 - val_loss: 0.1297 - val_mean_squared_error: 0.0287\n",
      "Epoch 593/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1101 - mean_squared_error: 0.0222 - val_loss: 0.1277 - val_mean_squared_error: 0.0283\n",
      "Epoch 594/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1100 - mean_squared_error: 0.0223 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 595/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1105 - mean_squared_error: 0.0227 - val_loss: 0.1273 - val_mean_squared_error: 0.0283\n",
      "Epoch 596/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1104 - mean_squared_error: 0.0224 - val_loss: 0.1295 - val_mean_squared_error: 0.0289\n",
      "Epoch 597/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1105 - mean_squared_error: 0.0225 - val_loss: 0.1294 - val_mean_squared_error: 0.0289\n",
      "Epoch 598/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1106 - mean_squared_error: 0.0223 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 599/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1109 - mean_squared_error: 0.0225 - val_loss: 0.1286 - val_mean_squared_error: 0.0285\n",
      "Epoch 600/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1085 - mean_squared_error: 0.0218 - val_loss: 0.1269 - val_mean_squared_error: 0.0280\n",
      "Epoch 601/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1101 - mean_squared_error: 0.0225 - val_loss: 0.1276 - val_mean_squared_error: 0.0283\n",
      "Epoch 602/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1094 - mean_squared_error: 0.0219 - val_loss: 0.1281 - val_mean_squared_error: 0.0286\n",
      "Epoch 603/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1095 - mean_squared_error: 0.0221 - val_loss: 0.1271 - val_mean_squared_error: 0.0284\n",
      "Epoch 604/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1104 - mean_squared_error: 0.0225 - val_loss: 0.1291 - val_mean_squared_error: 0.0284\n",
      "Epoch 605/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1107 - mean_squared_error: 0.0225 - val_loss: 0.1284 - val_mean_squared_error: 0.0286\n",
      "Epoch 606/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1104 - mean_squared_error: 0.0223 - val_loss: 0.1282 - val_mean_squared_error: 0.0286\n",
      "Epoch 607/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1100 - mean_squared_error: 0.0222 - val_loss: 0.1266 - val_mean_squared_error: 0.0280\n",
      "Epoch 608/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1104 - mean_squared_error: 0.0223 - val_loss: 0.1292 - val_mean_squared_error: 0.0286\n",
      "Epoch 609/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1108 - mean_squared_error: 0.0225 - val_loss: 0.1288 - val_mean_squared_error: 0.0284\n",
      "Epoch 610/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1095 - mean_squared_error: 0.0221 - val_loss: 0.1294 - val_mean_squared_error: 0.0284\n",
      "Epoch 611/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1107 - mean_squared_error: 0.0224 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 612/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1110 - mean_squared_error: 0.0225 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 613/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0222 - val_loss: 0.1288 - val_mean_squared_error: 0.0285\n",
      "Epoch 614/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1094 - mean_squared_error: 0.0218 - val_loss: 0.1292 - val_mean_squared_error: 0.0287\n",
      "Epoch 615/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1103 - mean_squared_error: 0.0225 - val_loss: 0.1298 - val_mean_squared_error: 0.0286\n",
      "Epoch 616/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1095 - mean_squared_error: 0.0221 - val_loss: 0.1287 - val_mean_squared_error: 0.0284\n",
      "Epoch 617/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1099 - mean_squared_error: 0.0221 - val_loss: 0.1278 - val_mean_squared_error: 0.0283\n",
      "Epoch 618/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1097 - mean_squared_error: 0.0223 - val_loss: 0.1283 - val_mean_squared_error: 0.0286\n",
      "Epoch 619/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1099 - mean_squared_error: 0.0223 - val_loss: 0.1278 - val_mean_squared_error: 0.0285\n",
      "Epoch 620/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1094 - mean_squared_error: 0.0221 - val_loss: 0.1296 - val_mean_squared_error: 0.0290\n",
      "Epoch 621/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1087 - mean_squared_error: 0.0218 - val_loss: 0.1293 - val_mean_squared_error: 0.0293\n",
      "Epoch 622/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1104 - mean_squared_error: 0.0224 - val_loss: 0.1292 - val_mean_squared_error: 0.0290\n",
      "Epoch 623/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1113 - mean_squared_error: 0.0227 - val_loss: 0.1283 - val_mean_squared_error: 0.0289\n",
      "Epoch 624/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1110 - mean_squared_error: 0.0225 - val_loss: 0.1292 - val_mean_squared_error: 0.0287\n",
      "Epoch 625/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1100 - mean_squared_error: 0.0223 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 626/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1093 - mean_squared_error: 0.0221 - val_loss: 0.1287 - val_mean_squared_error: 0.0286\n",
      "Epoch 627/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1091 - mean_squared_error: 0.0221 - val_loss: 0.1296 - val_mean_squared_error: 0.0289\n",
      "Epoch 628/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1094 - mean_squared_error: 0.0219 - val_loss: 0.1293 - val_mean_squared_error: 0.0286\n",
      "Epoch 629/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1102 - mean_squared_error: 0.0223 - val_loss: 0.1281 - val_mean_squared_error: 0.0286\n",
      "Epoch 630/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1098 - mean_squared_error: 0.0222 - val_loss: 0.1300 - val_mean_squared_error: 0.0288\n",
      "Epoch 631/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1103 - mean_squared_error: 0.0223 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 632/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1097 - mean_squared_error: 0.0225 - val_loss: 0.1280 - val_mean_squared_error: 0.0286\n",
      "Epoch 633/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1100 - mean_squared_error: 0.0223 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 634/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1098 - mean_squared_error: 0.0222 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 635/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1088 - mean_squared_error: 0.0219 - val_loss: 0.1292 - val_mean_squared_error: 0.0290\n",
      "Epoch 636/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1105 - mean_squared_error: 0.0226 - val_loss: 0.1288 - val_mean_squared_error: 0.0287\n",
      "Epoch 637/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1093 - mean_squared_error: 0.0221 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 638/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1102 - mean_squared_error: 0.0223 - val_loss: 0.1281 - val_mean_squared_error: 0.0283\n",
      "Epoch 639/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1096 - mean_squared_error: 0.0223 - val_loss: 0.1286 - val_mean_squared_error: 0.0284\n",
      "Epoch 640/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1092 - mean_squared_error: 0.0220 - val_loss: 0.1279 - val_mean_squared_error: 0.0281\n",
      "Epoch 641/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1090 - mean_squared_error: 0.0219 - val_loss: 0.1286 - val_mean_squared_error: 0.0289\n",
      "Epoch 642/1000\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 0.1116 - mean_squared_error: 0.0229 - val_loss: 0.1284 - val_mean_squared_error: 0.0285\n",
      "Epoch 643/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1086 - mean_squared_error: 0.0218 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 644/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1106 - mean_squared_error: 0.0225 - val_loss: 0.1303 - val_mean_squared_error: 0.0289\n",
      "Epoch 645/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1104 - mean_squared_error: 0.0224 - val_loss: 0.1286 - val_mean_squared_error: 0.0284\n",
      "Epoch 646/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1082 - mean_squared_error: 0.0214 - val_loss: 0.1289 - val_mean_squared_error: 0.0284\n",
      "Epoch 647/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1084 - mean_squared_error: 0.0221 - val_loss: 0.1284 - val_mean_squared_error: 0.0285\n",
      "Epoch 648/1000\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.1107 - mean_squared_error: 0.0225 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 649/1000\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.1098 - mean_squared_error: 0.0222 - val_loss: 0.1306 - val_mean_squared_error: 0.0294\n",
      "Epoch 650/1000\n",
      "39/39 [==============================] - 1s 26ms/step - loss: 0.1093 - mean_squared_error: 0.0219 - val_loss: 0.1272 - val_mean_squared_error: 0.0283\n",
      "Epoch 651/1000\n",
      "39/39 [==============================] - 1s 19ms/step - loss: 0.1092 - mean_squared_error: 0.0221 - val_loss: 0.1289 - val_mean_squared_error: 0.0287\n",
      "Epoch 652/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1101 - mean_squared_error: 0.0221 - val_loss: 0.1273 - val_mean_squared_error: 0.0283\n",
      "Epoch 653/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1105 - mean_squared_error: 0.0225 - val_loss: 0.1279 - val_mean_squared_error: 0.0284\n",
      "Epoch 654/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1104 - mean_squared_error: 0.0224 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 655/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1107 - mean_squared_error: 0.0223 - val_loss: 0.1280 - val_mean_squared_error: 0.0283\n",
      "Epoch 656/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1106 - mean_squared_error: 0.0225 - val_loss: 0.1293 - val_mean_squared_error: 0.0288\n",
      "Epoch 657/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1093 - mean_squared_error: 0.0220 - val_loss: 0.1313 - val_mean_squared_error: 0.0294\n",
      "Epoch 658/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1098 - mean_squared_error: 0.0222 - val_loss: 0.1280 - val_mean_squared_error: 0.0285\n",
      "Epoch 659/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1101 - mean_squared_error: 0.0225 - val_loss: 0.1296 - val_mean_squared_error: 0.0287\n",
      "Epoch 660/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1090 - mean_squared_error: 0.0218 - val_loss: 0.1291 - val_mean_squared_error: 0.0290\n",
      "Epoch 661/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1104 - mean_squared_error: 0.0224 - val_loss: 0.1304 - val_mean_squared_error: 0.0290\n",
      "Epoch 662/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1095 - mean_squared_error: 0.0220 - val_loss: 0.1297 - val_mean_squared_error: 0.0288\n",
      "Epoch 663/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1097 - mean_squared_error: 0.0223 - val_loss: 0.1295 - val_mean_squared_error: 0.0291\n",
      "Epoch 664/1000\n",
      "39/39 [==============================] - 0s 10ms/step - loss: 0.1089 - mean_squared_error: 0.0218 - val_loss: 0.1281 - val_mean_squared_error: 0.0282\n",
      "Epoch 665/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1088 - mean_squared_error: 0.0218 - val_loss: 0.1273 - val_mean_squared_error: 0.0283\n",
      "Epoch 666/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1091 - mean_squared_error: 0.0219 - val_loss: 0.1291 - val_mean_squared_error: 0.0285\n",
      "Epoch 667/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1097 - mean_squared_error: 0.0219 - val_loss: 0.1284 - val_mean_squared_error: 0.0283\n",
      "Epoch 668/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1074 - mean_squared_error: 0.0213 - val_loss: 0.1286 - val_mean_squared_error: 0.0285\n",
      "Epoch 669/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1099 - mean_squared_error: 0.0223 - val_loss: 0.1286 - val_mean_squared_error: 0.0287\n",
      "Epoch 670/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 0.1089 - mean_squared_error: 0.0221 - val_loss: 0.1292 - val_mean_squared_error: 0.0287\n",
      "Epoch 671/1000\n",
      "39/39 [==============================] - 1s 23ms/step - loss: 0.1092 - mean_squared_error: 0.0221 - val_loss: 0.1275 - val_mean_squared_error: 0.0281\n",
      "Epoch 672/1000\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 0.1103 - mean_squared_error: 0.0225 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 673/1000\n",
      "39/39 [==============================] - 1s 22ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1289 - val_mean_squared_error: 0.0289\n",
      "Epoch 674/1000\n",
      "39/39 [==============================] - 1s 24ms/step - loss: 0.1101 - mean_squared_error: 0.0223 - val_loss: 0.1294 - val_mean_squared_error: 0.0289\n",
      "Epoch 675/1000\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 0.1087 - mean_squared_error: 0.0220 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 676/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1087 - mean_squared_error: 0.0219 - val_loss: 0.1288 - val_mean_squared_error: 0.0285\n",
      "Epoch 677/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1104 - mean_squared_error: 0.0222 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 678/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1092 - mean_squared_error: 0.0219 - val_loss: 0.1286 - val_mean_squared_error: 0.0284\n",
      "Epoch 679/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 0.1092 - mean_squared_error: 0.0218 - val_loss: 0.1278 - val_mean_squared_error: 0.0287\n",
      "Epoch 680/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1095 - mean_squared_error: 0.0222 - val_loss: 0.1282 - val_mean_squared_error: 0.0286\n",
      "Epoch 681/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1098 - mean_squared_error: 0.0222 - val_loss: 0.1277 - val_mean_squared_error: 0.0286\n",
      "Epoch 682/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1093 - mean_squared_error: 0.0222 - val_loss: 0.1284 - val_mean_squared_error: 0.0286\n",
      "Epoch 683/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1096 - mean_squared_error: 0.0220 - val_loss: 0.1288 - val_mean_squared_error: 0.0287\n",
      "Epoch 684/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1094 - mean_squared_error: 0.0219 - val_loss: 0.1291 - val_mean_squared_error: 0.0288\n",
      "Epoch 685/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1114 - mean_squared_error: 0.0228 - val_loss: 0.1298 - val_mean_squared_error: 0.0287\n",
      "Epoch 686/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1098 - mean_squared_error: 0.0221 - val_loss: 0.1282 - val_mean_squared_error: 0.0287\n",
      "Epoch 687/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1099 - mean_squared_error: 0.0221 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 688/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1088 - mean_squared_error: 0.0217 - val_loss: 0.1281 - val_mean_squared_error: 0.0284\n",
      "Epoch 689/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1109 - mean_squared_error: 0.0225 - val_loss: 0.1279 - val_mean_squared_error: 0.0283\n",
      "Epoch 690/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1086 - mean_squared_error: 0.0220 - val_loss: 0.1294 - val_mean_squared_error: 0.0287\n",
      "Epoch 691/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1091 - mean_squared_error: 0.0219 - val_loss: 0.1313 - val_mean_squared_error: 0.0295\n",
      "Epoch 692/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1090 - mean_squared_error: 0.0220 - val_loss: 0.1306 - val_mean_squared_error: 0.0289\n",
      "Epoch 693/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1095 - mean_squared_error: 0.0223 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 694/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1084 - mean_squared_error: 0.0218 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 695/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1093 - mean_squared_error: 0.0219 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 696/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1086 - mean_squared_error: 0.0219 - val_loss: 0.1292 - val_mean_squared_error: 0.0287\n",
      "Epoch 697/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1083 - mean_squared_error: 0.0218 - val_loss: 0.1274 - val_mean_squared_error: 0.0283\n",
      "Epoch 698/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1093 - mean_squared_error: 0.0222 - val_loss: 0.1279 - val_mean_squared_error: 0.0286\n",
      "Epoch 699/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1101 - mean_squared_error: 0.0221 - val_loss: 0.1281 - val_mean_squared_error: 0.0288\n",
      "Epoch 700/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1095 - mean_squared_error: 0.0222 - val_loss: 0.1293 - val_mean_squared_error: 0.0290\n",
      "Epoch 701/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1095 - mean_squared_error: 0.0221 - val_loss: 0.1284 - val_mean_squared_error: 0.0286\n",
      "Epoch 702/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1093 - mean_squared_error: 0.0223 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 703/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1080 - mean_squared_error: 0.0214 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 704/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1094 - mean_squared_error: 0.0221 - val_loss: 0.1285 - val_mean_squared_error: 0.0289\n",
      "Epoch 705/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1087 - mean_squared_error: 0.0217 - val_loss: 0.1288 - val_mean_squared_error: 0.0290\n",
      "Epoch 706/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1100 - mean_squared_error: 0.0222 - val_loss: 0.1313 - val_mean_squared_error: 0.0293\n",
      "Epoch 707/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1092 - mean_squared_error: 0.0221 - val_loss: 0.1279 - val_mean_squared_error: 0.0284\n",
      "Epoch 708/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1090 - mean_squared_error: 0.0219 - val_loss: 0.1303 - val_mean_squared_error: 0.0288\n",
      "Epoch 709/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1095 - mean_squared_error: 0.0220 - val_loss: 0.1285 - val_mean_squared_error: 0.0287\n",
      "Epoch 710/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1079 - mean_squared_error: 0.0216 - val_loss: 0.1291 - val_mean_squared_error: 0.0291\n",
      "Epoch 711/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1091 - mean_squared_error: 0.0218 - val_loss: 0.1317 - val_mean_squared_error: 0.0296\n",
      "Epoch 712/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1093 - mean_squared_error: 0.0220 - val_loss: 0.1294 - val_mean_squared_error: 0.0290\n",
      "Epoch 713/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1089 - mean_squared_error: 0.0218 - val_loss: 0.1286 - val_mean_squared_error: 0.0289\n",
      "Epoch 714/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1088 - mean_squared_error: 0.0220 - val_loss: 0.1299 - val_mean_squared_error: 0.0289\n",
      "Epoch 715/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1082 - mean_squared_error: 0.0216 - val_loss: 0.1285 - val_mean_squared_error: 0.0285\n",
      "Epoch 716/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1096 - mean_squared_error: 0.0219 - val_loss: 0.1294 - val_mean_squared_error: 0.0292\n",
      "Epoch 717/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1094 - mean_squared_error: 0.0217 - val_loss: 0.1308 - val_mean_squared_error: 0.0293\n",
      "Epoch 718/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1095 - mean_squared_error: 0.0220 - val_loss: 0.1282 - val_mean_squared_error: 0.0285\n",
      "Epoch 719/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1082 - mean_squared_error: 0.0218 - val_loss: 0.1306 - val_mean_squared_error: 0.0293\n",
      "Epoch 720/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1297 - val_mean_squared_error: 0.0289\n",
      "Epoch 721/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0218 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 722/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1088 - mean_squared_error: 0.0218 - val_loss: 0.1294 - val_mean_squared_error: 0.0288\n",
      "Epoch 723/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1089 - mean_squared_error: 0.0219 - val_loss: 0.1294 - val_mean_squared_error: 0.0288\n",
      "Epoch 724/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1093 - mean_squared_error: 0.0219 - val_loss: 0.1279 - val_mean_squared_error: 0.0286\n",
      "Epoch 725/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1078 - mean_squared_error: 0.0218 - val_loss: 0.1300 - val_mean_squared_error: 0.0289\n",
      "Epoch 726/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1105 - mean_squared_error: 0.0225 - val_loss: 0.1284 - val_mean_squared_error: 0.0288\n",
      "Epoch 727/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1091 - mean_squared_error: 0.0218 - val_loss: 0.1308 - val_mean_squared_error: 0.0293\n",
      "Epoch 728/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1087 - mean_squared_error: 0.0220 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 729/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1087 - mean_squared_error: 0.0216 - val_loss: 0.1284 - val_mean_squared_error: 0.0285\n",
      "Epoch 730/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1093 - mean_squared_error: 0.0219 - val_loss: 0.1289 - val_mean_squared_error: 0.0289\n",
      "Epoch 731/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1096 - mean_squared_error: 0.0220 - val_loss: 0.1314 - val_mean_squared_error: 0.0294\n",
      "Epoch 732/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1090 - mean_squared_error: 0.0218 - val_loss: 0.1300 - val_mean_squared_error: 0.0289\n",
      "Epoch 733/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1083 - mean_squared_error: 0.0217 - val_loss: 0.1290 - val_mean_squared_error: 0.0289\n",
      "Epoch 734/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1088 - mean_squared_error: 0.0219 - val_loss: 0.1289 - val_mean_squared_error: 0.0287\n",
      "Epoch 735/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1072 - mean_squared_error: 0.0214 - val_loss: 0.1284 - val_mean_squared_error: 0.0283\n",
      "Epoch 736/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1090 - mean_squared_error: 0.0219 - val_loss: 0.1288 - val_mean_squared_error: 0.0286\n",
      "Epoch 737/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1097 - mean_squared_error: 0.0220 - val_loss: 0.1299 - val_mean_squared_error: 0.0289\n",
      "Epoch 738/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1074 - mean_squared_error: 0.0213 - val_loss: 0.1309 - val_mean_squared_error: 0.0294\n",
      "Epoch 739/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1103 - mean_squared_error: 0.0223 - val_loss: 0.1303 - val_mean_squared_error: 0.0293\n",
      "Epoch 740/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1097 - mean_squared_error: 0.0221 - val_loss: 0.1298 - val_mean_squared_error: 0.0291\n",
      "Epoch 741/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0215 - val_loss: 0.1284 - val_mean_squared_error: 0.0287\n",
      "Epoch 742/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1099 - mean_squared_error: 0.0223 - val_loss: 0.1290 - val_mean_squared_error: 0.0287\n",
      "Epoch 743/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1078 - mean_squared_error: 0.0213 - val_loss: 0.1293 - val_mean_squared_error: 0.0287\n",
      "Epoch 744/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1078 - mean_squared_error: 0.0216 - val_loss: 0.1293 - val_mean_squared_error: 0.0290\n",
      "Epoch 745/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1086 - mean_squared_error: 0.0221 - val_loss: 0.1287 - val_mean_squared_error: 0.0289\n",
      "Epoch 746/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1281 - val_mean_squared_error: 0.0286\n",
      "Epoch 747/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1098 - mean_squared_error: 0.0220 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 748/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1073 - mean_squared_error: 0.0212 - val_loss: 0.1306 - val_mean_squared_error: 0.0291\n",
      "Epoch 749/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0214 - val_loss: 0.1276 - val_mean_squared_error: 0.0283\n",
      "Epoch 750/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 0.1092 - mean_squared_error: 0.0220 - val_loss: 0.1275 - val_mean_squared_error: 0.0283\n",
      "Epoch 751/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1082 - mean_squared_error: 0.0217 - val_loss: 0.1290 - val_mean_squared_error: 0.0287\n",
      "Epoch 752/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0215 - val_loss: 0.1279 - val_mean_squared_error: 0.0285\n",
      "Epoch 753/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1086 - mean_squared_error: 0.0216 - val_loss: 0.1304 - val_mean_squared_error: 0.0291\n",
      "Epoch 754/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1079 - mean_squared_error: 0.0216 - val_loss: 0.1280 - val_mean_squared_error: 0.0286\n",
      "Epoch 755/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1095 - mean_squared_error: 0.0218 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 756/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1100 - mean_squared_error: 0.0222 - val_loss: 0.1310 - val_mean_squared_error: 0.0292\n",
      "Epoch 757/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1093 - mean_squared_error: 0.0219 - val_loss: 0.1280 - val_mean_squared_error: 0.0283\n",
      "Epoch 758/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1079 - mean_squared_error: 0.0214 - val_loss: 0.1278 - val_mean_squared_error: 0.0281\n",
      "Epoch 759/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1095 - mean_squared_error: 0.0219 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 760/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1087 - mean_squared_error: 0.0219 - val_loss: 0.1274 - val_mean_squared_error: 0.0281\n",
      "Epoch 761/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1095 - mean_squared_error: 0.0220 - val_loss: 0.1281 - val_mean_squared_error: 0.0281\n",
      "Epoch 762/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0215 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 763/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1089 - mean_squared_error: 0.0219 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 764/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0215 - val_loss: 0.1277 - val_mean_squared_error: 0.0285\n",
      "Epoch 765/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1084 - mean_squared_error: 0.0217 - val_loss: 0.1300 - val_mean_squared_error: 0.0289\n",
      "Epoch 766/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1080 - mean_squared_error: 0.0217 - val_loss: 0.1288 - val_mean_squared_error: 0.0289\n",
      "Epoch 767/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1100 - mean_squared_error: 0.0223 - val_loss: 0.1292 - val_mean_squared_error: 0.0292\n",
      "Epoch 768/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1083 - mean_squared_error: 0.0219 - val_loss: 0.1277 - val_mean_squared_error: 0.0283\n",
      "Epoch 769/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1080 - mean_squared_error: 0.0216 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 770/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1087 - mean_squared_error: 0.0217 - val_loss: 0.1308 - val_mean_squared_error: 0.0291\n",
      "Epoch 771/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1076 - mean_squared_error: 0.0215 - val_loss: 0.1301 - val_mean_squared_error: 0.0288\n",
      "Epoch 772/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1097 - mean_squared_error: 0.0220 - val_loss: 0.1291 - val_mean_squared_error: 0.0287\n",
      "Epoch 773/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1279 - val_mean_squared_error: 0.0285\n",
      "Epoch 774/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1092 - mean_squared_error: 0.0218 - val_loss: 0.1299 - val_mean_squared_error: 0.0290\n",
      "Epoch 775/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1090 - mean_squared_error: 0.0219 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 776/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 0.1080 - mean_squared_error: 0.0217 - val_loss: 0.1308 - val_mean_squared_error: 0.0291\n",
      "Epoch 777/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1087 - mean_squared_error: 0.0218 - val_loss: 0.1290 - val_mean_squared_error: 0.0289\n",
      "Epoch 778/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1099 - mean_squared_error: 0.0223 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 779/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1089 - mean_squared_error: 0.0218 - val_loss: 0.1278 - val_mean_squared_error: 0.0286\n",
      "Epoch 780/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1281 - val_mean_squared_error: 0.0287\n",
      "Epoch 781/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1089 - mean_squared_error: 0.0217 - val_loss: 0.1287 - val_mean_squared_error: 0.0286\n",
      "Epoch 782/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1076 - mean_squared_error: 0.0214 - val_loss: 0.1279 - val_mean_squared_error: 0.0285\n",
      "Epoch 783/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1101 - mean_squared_error: 0.0223 - val_loss: 0.1296 - val_mean_squared_error: 0.0287\n",
      "Epoch 784/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1090 - mean_squared_error: 0.0219 - val_loss: 0.1291 - val_mean_squared_error: 0.0289\n",
      "Epoch 785/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1266 - val_mean_squared_error: 0.0283\n",
      "Epoch 786/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1085 - mean_squared_error: 0.0217 - val_loss: 0.1285 - val_mean_squared_error: 0.0288\n",
      "Epoch 787/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1091 - mean_squared_error: 0.0218 - val_loss: 0.1279 - val_mean_squared_error: 0.0284\n",
      "Epoch 788/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1282 - val_mean_squared_error: 0.0286\n",
      "Epoch 789/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1089 - mean_squared_error: 0.0219 - val_loss: 0.1290 - val_mean_squared_error: 0.0287\n",
      "Epoch 790/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1097 - mean_squared_error: 0.0221 - val_loss: 0.1295 - val_mean_squared_error: 0.0289\n",
      "Epoch 791/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 0.1088 - mean_squared_error: 0.0220 - val_loss: 0.1289 - val_mean_squared_error: 0.0286\n",
      "Epoch 792/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1098 - mean_squared_error: 0.0222 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 793/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1086 - mean_squared_error: 0.0216 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 794/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1093 - mean_squared_error: 0.0218 - val_loss: 0.1295 - val_mean_squared_error: 0.0286\n",
      "Epoch 795/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1086 - mean_squared_error: 0.0217 - val_loss: 0.1295 - val_mean_squared_error: 0.0289\n",
      "Epoch 796/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1091 - mean_squared_error: 0.0218 - val_loss: 0.1280 - val_mean_squared_error: 0.0286\n",
      "Epoch 797/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1069 - mean_squared_error: 0.0212 - val_loss: 0.1287 - val_mean_squared_error: 0.0286\n",
      "Epoch 798/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1077 - mean_squared_error: 0.0215 - val_loss: 0.1273 - val_mean_squared_error: 0.0283\n",
      "Epoch 799/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1077 - mean_squared_error: 0.0215 - val_loss: 0.1293 - val_mean_squared_error: 0.0291\n",
      "Epoch 800/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1088 - mean_squared_error: 0.0220 - val_loss: 0.1287 - val_mean_squared_error: 0.0289\n",
      "Epoch 801/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0217 - val_loss: 0.1273 - val_mean_squared_error: 0.0283\n",
      "Epoch 802/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0212 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 803/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0217 - val_loss: 0.1293 - val_mean_squared_error: 0.0291\n",
      "Epoch 804/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1091 - mean_squared_error: 0.0219 - val_loss: 0.1279 - val_mean_squared_error: 0.0284\n",
      "Epoch 805/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0215 - val_loss: 0.1285 - val_mean_squared_error: 0.0285\n",
      "Epoch 806/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0215 - val_loss: 0.1280 - val_mean_squared_error: 0.0284\n",
      "Epoch 807/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0214 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 808/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1277 - val_mean_squared_error: 0.0286\n",
      "Epoch 809/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0211 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 810/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0212 - val_loss: 0.1292 - val_mean_squared_error: 0.0287\n",
      "Epoch 811/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0213 - val_loss: 0.1279 - val_mean_squared_error: 0.0284\n",
      "Epoch 812/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1086 - mean_squared_error: 0.0216 - val_loss: 0.1274 - val_mean_squared_error: 0.0284\n",
      "Epoch 813/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1073 - mean_squared_error: 0.0211 - val_loss: 0.1270 - val_mean_squared_error: 0.0284\n",
      "Epoch 814/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1087 - mean_squared_error: 0.0219 - val_loss: 0.1284 - val_mean_squared_error: 0.0283\n",
      "Epoch 815/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1065 - mean_squared_error: 0.0213 - val_loss: 0.1283 - val_mean_squared_error: 0.0288\n",
      "Epoch 816/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1079 - mean_squared_error: 0.0215 - val_loss: 0.1270 - val_mean_squared_error: 0.0282\n",
      "Epoch 817/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1085 - mean_squared_error: 0.0217 - val_loss: 0.1284 - val_mean_squared_error: 0.0285\n",
      "Epoch 818/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0214 - val_loss: 0.1284 - val_mean_squared_error: 0.0289\n",
      "Epoch 819/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0212 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 820/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1095 - mean_squared_error: 0.0220 - val_loss: 0.1295 - val_mean_squared_error: 0.0290\n",
      "Epoch 821/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0214 - val_loss: 0.1291 - val_mean_squared_error: 0.0290\n",
      "Epoch 822/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1083 - mean_squared_error: 0.0215 - val_loss: 0.1284 - val_mean_squared_error: 0.0287\n",
      "Epoch 823/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1090 - mean_squared_error: 0.0219 - val_loss: 0.1277 - val_mean_squared_error: 0.0284\n",
      "Epoch 824/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1082 - mean_squared_error: 0.0216 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 825/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0211 - val_loss: 0.1290 - val_mean_squared_error: 0.0286\n",
      "Epoch 826/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1087 - mean_squared_error: 0.0215 - val_loss: 0.1281 - val_mean_squared_error: 0.0284\n",
      "Epoch 827/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1078 - mean_squared_error: 0.0213 - val_loss: 0.1283 - val_mean_squared_error: 0.0285\n",
      "Epoch 828/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0214 - val_loss: 0.1298 - val_mean_squared_error: 0.0290\n",
      "Epoch 829/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1276 - val_mean_squared_error: 0.0286\n",
      "Epoch 830/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0214 - val_loss: 0.1278 - val_mean_squared_error: 0.0285\n",
      "Epoch 831/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1078 - mean_squared_error: 0.0217 - val_loss: 0.1296 - val_mean_squared_error: 0.0288\n",
      "Epoch 832/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1293 - val_mean_squared_error: 0.0289\n",
      "Epoch 833/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0214 - val_loss: 0.1294 - val_mean_squared_error: 0.0291\n",
      "Epoch 834/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1094 - mean_squared_error: 0.0218 - val_loss: 0.1281 - val_mean_squared_error: 0.0284\n",
      "Epoch 835/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1089 - mean_squared_error: 0.0217 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 836/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0213 - val_loss: 0.1293 - val_mean_squared_error: 0.0289\n",
      "Epoch 837/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1089 - mean_squared_error: 0.0215 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 838/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1082 - mean_squared_error: 0.0216 - val_loss: 0.1291 - val_mean_squared_error: 0.0288\n",
      "Epoch 839/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1085 - mean_squared_error: 0.0216 - val_loss: 0.1306 - val_mean_squared_error: 0.0292\n",
      "Epoch 840/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1090 - mean_squared_error: 0.0216 - val_loss: 0.1298 - val_mean_squared_error: 0.0291\n",
      "Epoch 841/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1064 - mean_squared_error: 0.0212 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 842/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1082 - mean_squared_error: 0.0217 - val_loss: 0.1291 - val_mean_squared_error: 0.0288\n",
      "Epoch 843/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1079 - mean_squared_error: 0.0214 - val_loss: 0.1305 - val_mean_squared_error: 0.0290\n",
      "Epoch 844/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1069 - mean_squared_error: 0.0211 - val_loss: 0.1294 - val_mean_squared_error: 0.0288\n",
      "Epoch 845/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1083 - mean_squared_error: 0.0218 - val_loss: 0.1286 - val_mean_squared_error: 0.0289\n",
      "Epoch 846/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0216 - val_loss: 0.1296 - val_mean_squared_error: 0.0288\n",
      "Epoch 847/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1295 - val_mean_squared_error: 0.0293\n",
      "Epoch 848/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1087 - mean_squared_error: 0.0216 - val_loss: 0.1290 - val_mean_squared_error: 0.0289\n",
      "Epoch 849/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0214 - val_loss: 0.1289 - val_mean_squared_error: 0.0289\n",
      "Epoch 850/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0212 - val_loss: 0.1300 - val_mean_squared_error: 0.0291\n",
      "Epoch 851/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1073 - mean_squared_error: 0.0214 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 852/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0215 - val_loss: 0.1283 - val_mean_squared_error: 0.0287\n",
      "Epoch 853/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1070 - mean_squared_error: 0.0213 - val_loss: 0.1288 - val_mean_squared_error: 0.0288\n",
      "Epoch 854/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1067 - mean_squared_error: 0.0211 - val_loss: 0.1280 - val_mean_squared_error: 0.0287\n",
      "Epoch 855/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0215 - val_loss: 0.1294 - val_mean_squared_error: 0.0288\n",
      "Epoch 856/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1082 - mean_squared_error: 0.0216 - val_loss: 0.1289 - val_mean_squared_error: 0.0289\n",
      "Epoch 857/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1090 - mean_squared_error: 0.0221 - val_loss: 0.1304 - val_mean_squared_error: 0.0291\n",
      "Epoch 858/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1092 - mean_squared_error: 0.0219 - val_loss: 0.1293 - val_mean_squared_error: 0.0287\n",
      "Epoch 859/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 860/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0216 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 861/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0214 - val_loss: 0.1283 - val_mean_squared_error: 0.0289\n",
      "Epoch 862/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0216 - val_loss: 0.1291 - val_mean_squared_error: 0.0289\n",
      "Epoch 863/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0216 - val_loss: 0.1300 - val_mean_squared_error: 0.0293\n",
      "Epoch 864/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0212 - val_loss: 0.1299 - val_mean_squared_error: 0.0291\n",
      "Epoch 865/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1073 - mean_squared_error: 0.0213 - val_loss: 0.1294 - val_mean_squared_error: 0.0290\n",
      "Epoch 866/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0213 - val_loss: 0.1285 - val_mean_squared_error: 0.0289\n",
      "Epoch 867/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0214 - val_loss: 0.1289 - val_mean_squared_error: 0.0290\n",
      "Epoch 868/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1078 - mean_squared_error: 0.0216 - val_loss: 0.1294 - val_mean_squared_error: 0.0290\n",
      "Epoch 869/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1085 - mean_squared_error: 0.0219 - val_loss: 0.1309 - val_mean_squared_error: 0.0291\n",
      "Epoch 870/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0214 - val_loss: 0.1291 - val_mean_squared_error: 0.0289\n",
      "Epoch 871/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1073 - mean_squared_error: 0.0213 - val_loss: 0.1290 - val_mean_squared_error: 0.0285\n",
      "Epoch 872/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1081 - mean_squared_error: 0.0216 - val_loss: 0.1293 - val_mean_squared_error: 0.0290\n",
      "Epoch 873/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1086 - mean_squared_error: 0.0217 - val_loss: 0.1297 - val_mean_squared_error: 0.0289\n",
      "Epoch 874/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0215 - val_loss: 0.1297 - val_mean_squared_error: 0.0288\n",
      "Epoch 875/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1062 - mean_squared_error: 0.0210 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 876/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1079 - mean_squared_error: 0.0214 - val_loss: 0.1293 - val_mean_squared_error: 0.0288\n",
      "Epoch 877/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0215 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 878/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1092 - mean_squared_error: 0.0220 - val_loss: 0.1295 - val_mean_squared_error: 0.0292\n",
      "Epoch 879/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0210 - val_loss: 0.1316 - val_mean_squared_error: 0.0300\n",
      "Epoch 880/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1088 - mean_squared_error: 0.0218 - val_loss: 0.1286 - val_mean_squared_error: 0.0285\n",
      "Epoch 881/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1078 - mean_squared_error: 0.0213 - val_loss: 0.1308 - val_mean_squared_error: 0.0293\n",
      "Epoch 882/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0214 - val_loss: 0.1296 - val_mean_squared_error: 0.0289\n",
      "Epoch 883/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1078 - mean_squared_error: 0.0216 - val_loss: 0.1293 - val_mean_squared_error: 0.0289\n",
      "Epoch 884/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1089 - mean_squared_error: 0.0218 - val_loss: 0.1308 - val_mean_squared_error: 0.0292\n",
      "Epoch 885/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1078 - mean_squared_error: 0.0214 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 886/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0214 - val_loss: 0.1281 - val_mean_squared_error: 0.0289\n",
      "Epoch 887/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1087 - mean_squared_error: 0.0217 - val_loss: 0.1289 - val_mean_squared_error: 0.0287\n",
      "Epoch 888/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1063 - mean_squared_error: 0.0213 - val_loss: 0.1299 - val_mean_squared_error: 0.0293\n",
      "Epoch 889/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1077 - mean_squared_error: 0.0217 - val_loss: 0.1290 - val_mean_squared_error: 0.0288\n",
      "Epoch 890/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.1082 - mean_squared_error: 0.0216 - val_loss: 0.1286 - val_mean_squared_error: 0.0290\n",
      "Epoch 891/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1079 - mean_squared_error: 0.0215 - val_loss: 0.1295 - val_mean_squared_error: 0.0292\n",
      "Epoch 892/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1082 - mean_squared_error: 0.0218 - val_loss: 0.1289 - val_mean_squared_error: 0.0290\n",
      "Epoch 893/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1058 - mean_squared_error: 0.0209 - val_loss: 0.1290 - val_mean_squared_error: 0.0289\n",
      "Epoch 894/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0215 - val_loss: 0.1283 - val_mean_squared_error: 0.0286\n",
      "Epoch 895/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1070 - mean_squared_error: 0.0211 - val_loss: 0.1305 - val_mean_squared_error: 0.0290\n",
      "Epoch 896/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0212 - val_loss: 0.1294 - val_mean_squared_error: 0.0288\n",
      "Epoch 897/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1090 - mean_squared_error: 0.0218 - val_loss: 0.1312 - val_mean_squared_error: 0.0293\n",
      "Epoch 898/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 899/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0215 - val_loss: 0.1296 - val_mean_squared_error: 0.0288\n",
      "Epoch 900/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1098 - mean_squared_error: 0.0219 - val_loss: 0.1298 - val_mean_squared_error: 0.0291\n",
      "Epoch 901/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1087 - mean_squared_error: 0.0217 - val_loss: 0.1287 - val_mean_squared_error: 0.0287\n",
      "Epoch 902/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0217 - val_loss: 0.1292 - val_mean_squared_error: 0.0291\n",
      "Epoch 903/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0212 - val_loss: 0.1302 - val_mean_squared_error: 0.0290\n",
      "Epoch 904/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0217 - val_loss: 0.1309 - val_mean_squared_error: 0.0294\n",
      "Epoch 905/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 906/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0211 - val_loss: 0.1293 - val_mean_squared_error: 0.0289\n",
      "Epoch 907/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0212 - val_loss: 0.1295 - val_mean_squared_error: 0.0287\n",
      "Epoch 908/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1061 - mean_squared_error: 0.0210 - val_loss: 0.1303 - val_mean_squared_error: 0.0293\n",
      "Epoch 909/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0214 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 910/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1079 - mean_squared_error: 0.0215 - val_loss: 0.1295 - val_mean_squared_error: 0.0287\n",
      "Epoch 911/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0215 - val_loss: 0.1298 - val_mean_squared_error: 0.0288\n",
      "Epoch 912/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0210 - val_loss: 0.1291 - val_mean_squared_error: 0.0286\n",
      "Epoch 913/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0214 - val_loss: 0.1307 - val_mean_squared_error: 0.0295\n",
      "Epoch 914/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0215 - val_loss: 0.1303 - val_mean_squared_error: 0.0291\n",
      "Epoch 915/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1289 - val_mean_squared_error: 0.0285\n",
      "Epoch 916/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0213 - val_loss: 0.1293 - val_mean_squared_error: 0.0286\n",
      "Epoch 917/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0214 - val_loss: 0.1294 - val_mean_squared_error: 0.0287\n",
      "Epoch 918/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1062 - mean_squared_error: 0.0207 - val_loss: 0.1284 - val_mean_squared_error: 0.0285\n",
      "Epoch 919/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0211 - val_loss: 0.1286 - val_mean_squared_error: 0.0288\n",
      "Epoch 920/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1066 - mean_squared_error: 0.0209 - val_loss: 0.1294 - val_mean_squared_error: 0.0284\n",
      "Epoch 921/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1069 - mean_squared_error: 0.0211 - val_loss: 0.1288 - val_mean_squared_error: 0.0287\n",
      "Epoch 922/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0213 - val_loss: 0.1299 - val_mean_squared_error: 0.0289\n",
      "Epoch 923/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1066 - mean_squared_error: 0.0211 - val_loss: 0.1286 - val_mean_squared_error: 0.0286\n",
      "Epoch 924/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1079 - mean_squared_error: 0.0214 - val_loss: 0.1284 - val_mean_squared_error: 0.0288\n",
      "Epoch 925/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1073 - mean_squared_error: 0.0214 - val_loss: 0.1283 - val_mean_squared_error: 0.0284\n",
      "Epoch 926/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1086 - mean_squared_error: 0.0216 - val_loss: 0.1309 - val_mean_squared_error: 0.0292\n",
      "Epoch 927/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0214 - val_loss: 0.1287 - val_mean_squared_error: 0.0287\n",
      "Epoch 928/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0215 - val_loss: 0.1309 - val_mean_squared_error: 0.0293\n",
      "Epoch 929/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1079 - mean_squared_error: 0.0217 - val_loss: 0.1306 - val_mean_squared_error: 0.0290\n",
      "Epoch 930/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0212 - val_loss: 0.1290 - val_mean_squared_error: 0.0287\n",
      "Epoch 931/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1079 - mean_squared_error: 0.0213 - val_loss: 0.1280 - val_mean_squared_error: 0.0285\n",
      "Epoch 932/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0209 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 933/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0213 - val_loss: 0.1309 - val_mean_squared_error: 0.0293\n",
      "Epoch 934/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0210 - val_loss: 0.1299 - val_mean_squared_error: 0.0290\n",
      "Epoch 935/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1080 - mean_squared_error: 0.0217 - val_loss: 0.1292 - val_mean_squared_error: 0.0287\n",
      "Epoch 936/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0210 - val_loss: 0.1291 - val_mean_squared_error: 0.0288\n",
      "Epoch 937/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1082 - mean_squared_error: 0.0218 - val_loss: 0.1304 - val_mean_squared_error: 0.0291\n",
      "Epoch 938/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0215 - val_loss: 0.1296 - val_mean_squared_error: 0.0289\n",
      "Epoch 939/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0211 - val_loss: 0.1297 - val_mean_squared_error: 0.0288\n",
      "Epoch 940/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1069 - mean_squared_error: 0.0211 - val_loss: 0.1291 - val_mean_squared_error: 0.0288\n",
      "Epoch 941/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1066 - mean_squared_error: 0.0211 - val_loss: 0.1290 - val_mean_squared_error: 0.0285\n",
      "Epoch 942/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1074 - mean_squared_error: 0.0210 - val_loss: 0.1291 - val_mean_squared_error: 0.0290\n",
      "Epoch 943/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1080 - mean_squared_error: 0.0215 - val_loss: 0.1302 - val_mean_squared_error: 0.0291\n",
      "Epoch 944/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1073 - mean_squared_error: 0.0213 - val_loss: 0.1306 - val_mean_squared_error: 0.0291\n",
      "Epoch 945/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1064 - mean_squared_error: 0.0208 - val_loss: 0.1298 - val_mean_squared_error: 0.0289\n",
      "Epoch 946/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1080 - mean_squared_error: 0.0216 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 947/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1055 - mean_squared_error: 0.0206 - val_loss: 0.1302 - val_mean_squared_error: 0.0293\n",
      "Epoch 948/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0216 - val_loss: 0.1281 - val_mean_squared_error: 0.0284\n",
      "Epoch 949/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1066 - mean_squared_error: 0.0210 - val_loss: 0.1300 - val_mean_squared_error: 0.0289\n",
      "Epoch 950/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0211 - val_loss: 0.1292 - val_mean_squared_error: 0.0287\n",
      "Epoch 951/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1061 - mean_squared_error: 0.0211 - val_loss: 0.1285 - val_mean_squared_error: 0.0286\n",
      "Epoch 952/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 953/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1086 - mean_squared_error: 0.0216 - val_loss: 0.1293 - val_mean_squared_error: 0.0289\n",
      "Epoch 954/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1085 - mean_squared_error: 0.0214 - val_loss: 0.1282 - val_mean_squared_error: 0.0285\n",
      "Epoch 955/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0212 - val_loss: 0.1303 - val_mean_squared_error: 0.0290\n",
      "Epoch 956/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1060 - mean_squared_error: 0.0210 - val_loss: 0.1290 - val_mean_squared_error: 0.0286\n",
      "Epoch 957/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0211 - val_loss: 0.1291 - val_mean_squared_error: 0.0290\n",
      "Epoch 958/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0216 - val_loss: 0.1296 - val_mean_squared_error: 0.0291\n",
      "Epoch 959/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1077 - mean_squared_error: 0.0215 - val_loss: 0.1290 - val_mean_squared_error: 0.0287\n",
      "Epoch 960/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1084 - mean_squared_error: 0.0214 - val_loss: 0.1291 - val_mean_squared_error: 0.0288\n",
      "Epoch 961/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1065 - mean_squared_error: 0.0210 - val_loss: 0.1297 - val_mean_squared_error: 0.0290\n",
      "Epoch 962/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1062 - mean_squared_error: 0.0209 - val_loss: 0.1304 - val_mean_squared_error: 0.0291\n",
      "Epoch 963/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0209 - val_loss: 0.1287 - val_mean_squared_error: 0.0286\n",
      "Epoch 964/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1083 - mean_squared_error: 0.0216 - val_loss: 0.1299 - val_mean_squared_error: 0.0289\n",
      "Epoch 965/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0211 - val_loss: 0.1300 - val_mean_squared_error: 0.0290\n",
      "Epoch 966/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0212 - val_loss: 0.1290 - val_mean_squared_error: 0.0291\n",
      "Epoch 967/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0215 - val_loss: 0.1286 - val_mean_squared_error: 0.0289\n",
      "Epoch 968/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 0.1070 - mean_squared_error: 0.0210 - val_loss: 0.1295 - val_mean_squared_error: 0.0289\n",
      "Epoch 969/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1073 - mean_squared_error: 0.0211 - val_loss: 0.1303 - val_mean_squared_error: 0.0292\n",
      "Epoch 970/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0213 - val_loss: 0.1301 - val_mean_squared_error: 0.0292\n",
      "Epoch 971/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1063 - mean_squared_error: 0.0210 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 972/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1058 - mean_squared_error: 0.0206 - val_loss: 0.1292 - val_mean_squared_error: 0.0288\n",
      "Epoch 973/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1064 - mean_squared_error: 0.0211 - val_loss: 0.1296 - val_mean_squared_error: 0.0287\n",
      "Epoch 974/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1081 - mean_squared_error: 0.0214 - val_loss: 0.1282 - val_mean_squared_error: 0.0284\n",
      "Epoch 975/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1069 - mean_squared_error: 0.0211 - val_loss: 0.1292 - val_mean_squared_error: 0.0289\n",
      "Epoch 976/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0213 - val_loss: 0.1291 - val_mean_squared_error: 0.0290\n",
      "Epoch 977/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1063 - mean_squared_error: 0.0210 - val_loss: 0.1287 - val_mean_squared_error: 0.0290\n",
      "Epoch 978/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1065 - mean_squared_error: 0.0211 - val_loss: 0.1295 - val_mean_squared_error: 0.0288\n",
      "Epoch 979/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1075 - mean_squared_error: 0.0213 - val_loss: 0.1289 - val_mean_squared_error: 0.0286\n",
      "Epoch 980/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1063 - mean_squared_error: 0.0211 - val_loss: 0.1297 - val_mean_squared_error: 0.0288\n",
      "Epoch 981/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0214 - val_loss: 0.1289 - val_mean_squared_error: 0.0286\n",
      "Epoch 982/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1074 - mean_squared_error: 0.0213 - val_loss: 0.1288 - val_mean_squared_error: 0.0289\n",
      "Epoch 983/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0211 - val_loss: 0.1318 - val_mean_squared_error: 0.0296\n",
      "Epoch 984/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1061 - mean_squared_error: 0.0205 - val_loss: 0.1293 - val_mean_squared_error: 0.0288\n",
      "Epoch 985/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1071 - mean_squared_error: 0.0211 - val_loss: 0.1294 - val_mean_squared_error: 0.0292\n",
      "Epoch 986/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1070 - mean_squared_error: 0.0213 - val_loss: 0.1295 - val_mean_squared_error: 0.0292\n",
      "Epoch 987/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1057 - mean_squared_error: 0.0208 - val_loss: 0.1299 - val_mean_squared_error: 0.0292\n",
      "Epoch 988/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1060 - mean_squared_error: 0.0210 - val_loss: 0.1292 - val_mean_squared_error: 0.0290\n",
      "Epoch 989/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1078 - mean_squared_error: 0.0215 - val_loss: 0.1297 - val_mean_squared_error: 0.0289\n",
      "Epoch 990/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0208 - val_loss: 0.1306 - val_mean_squared_error: 0.0292\n",
      "Epoch 991/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1070 - mean_squared_error: 0.0211 - val_loss: 0.1282 - val_mean_squared_error: 0.0285\n",
      "Epoch 992/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0213 - val_loss: 0.1290 - val_mean_squared_error: 0.0290\n",
      "Epoch 993/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1070 - mean_squared_error: 0.0213 - val_loss: 0.1292 - val_mean_squared_error: 0.0290\n",
      "Epoch 994/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1076 - mean_squared_error: 0.0215 - val_loss: 0.1300 - val_mean_squared_error: 0.0290\n",
      "Epoch 995/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1067 - mean_squared_error: 0.0210 - val_loss: 0.1283 - val_mean_squared_error: 0.0286\n",
      "Epoch 996/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1070 - mean_squared_error: 0.0212 - val_loss: 0.1285 - val_mean_squared_error: 0.0285\n",
      "Epoch 997/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1068 - mean_squared_error: 0.0212 - val_loss: 0.1279 - val_mean_squared_error: 0.0286\n",
      "Epoch 998/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1062 - mean_squared_error: 0.0209 - val_loss: 0.1282 - val_mean_squared_error: 0.0285\n",
      "Epoch 999/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1064 - mean_squared_error: 0.0209 - val_loss: 0.1281 - val_mean_squared_error: 0.0285\n",
      "Epoch 1000/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 0.1072 - mean_squared_error: 0.0214 - val_loss: 0.1302 - val_mean_squared_error: 0.0289\n",
      "Epoch 1/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 3.1194 - mean_squared_error: 14.5568 - val_loss: 2.5387 - val_mean_squared_error: 8.6383\n",
      "Epoch 2/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.5472 - mean_squared_error: 8.7561 - val_loss: 2.5275 - val_mean_squared_error: 8.5644\n",
      "Epoch 3/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.5157 - mean_squared_error: 8.5375 - val_loss: 2.4945 - val_mean_squared_error: 8.3304\n",
      "Epoch 4/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.4745 - mean_squared_error: 8.3498 - val_loss: 2.4455 - val_mean_squared_error: 8.2019\n",
      "Epoch 5/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.4471 - mean_squared_error: 8.3079 - val_loss: 2.4341 - val_mean_squared_error: 8.1540\n",
      "Epoch 6/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.4332 - mean_squared_error: 8.2092 - val_loss: 2.4169 - val_mean_squared_error: 8.0209\n",
      "Epoch 7/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.4018 - mean_squared_error: 8.0674 - val_loss: 2.3841 - val_mean_squared_error: 7.9478\n",
      "Epoch 8/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.3728 - mean_squared_error: 7.9519 - val_loss: 2.3398 - val_mean_squared_error: 7.7435\n",
      "Epoch 9/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.3470 - mean_squared_error: 7.8632 - val_loss: 2.3129 - val_mean_squared_error: 7.5891\n",
      "Epoch 10/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.3266 - mean_squared_error: 7.7184 - val_loss: 2.3046 - val_mean_squared_error: 7.5669\n",
      "Epoch 11/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.3175 - mean_squared_error: 7.7057 - val_loss: 2.3026 - val_mean_squared_error: 7.5634\n",
      "Epoch 12/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2953 - mean_squared_error: 7.5214 - val_loss: 2.2711 - val_mean_squared_error: 7.3536\n",
      "Epoch 13/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2845 - mean_squared_error: 7.4992 - val_loss: 2.2666 - val_mean_squared_error: 7.3264\n",
      "Epoch 14/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2743 - mean_squared_error: 7.4328 - val_loss: 2.2650 - val_mean_squared_error: 7.3534\n",
      "Epoch 15/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2645 - mean_squared_error: 7.3806 - val_loss: 2.2621 - val_mean_squared_error: 7.3037\n",
      "Epoch 16/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2592 - mean_squared_error: 7.3558 - val_loss: 2.2807 - val_mean_squared_error: 7.4650\n",
      "Epoch 17/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2607 - mean_squared_error: 7.3612 - val_loss: 2.2707 - val_mean_squared_error: 7.4086\n",
      "Epoch 18/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.2568 - mean_squared_error: 7.3234 - val_loss: 2.2631 - val_mean_squared_error: 7.3416\n",
      "Epoch 19/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2421 - mean_squared_error: 7.2577 - val_loss: 2.2568 - val_mean_squared_error: 7.3507\n",
      "Epoch 20/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2411 - mean_squared_error: 7.3032 - val_loss: 2.2543 - val_mean_squared_error: 7.2877\n",
      "Epoch 21/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2430 - mean_squared_error: 7.2535 - val_loss: 2.2446 - val_mean_squared_error: 7.2044\n",
      "Epoch 22/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2340 - mean_squared_error: 7.2247 - val_loss: 2.2497 - val_mean_squared_error: 7.2788\n",
      "Epoch 23/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2323 - mean_squared_error: 7.2158 - val_loss: 2.2410 - val_mean_squared_error: 7.2102\n",
      "Epoch 24/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2255 - mean_squared_error: 7.1748 - val_loss: 2.2639 - val_mean_squared_error: 7.3747\n",
      "Epoch 25/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2247 - mean_squared_error: 7.1923 - val_loss: 2.2323 - val_mean_squared_error: 7.1809\n",
      "Epoch 26/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2268 - mean_squared_error: 7.1892 - val_loss: 2.2337 - val_mean_squared_error: 7.1741\n",
      "Epoch 27/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2259 - mean_squared_error: 7.1772 - val_loss: 2.2273 - val_mean_squared_error: 7.1358\n",
      "Epoch 28/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2108 - mean_squared_error: 7.1173 - val_loss: 2.2453 - val_mean_squared_error: 7.2771\n",
      "Epoch 29/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2100 - mean_squared_error: 7.0992 - val_loss: 2.2190 - val_mean_squared_error: 7.0894\n",
      "Epoch 30/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.2030 - mean_squared_error: 7.0739 - val_loss: 2.2146 - val_mean_squared_error: 7.0590\n",
      "Epoch 31/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1928 - mean_squared_error: 7.0108 - val_loss: 2.2157 - val_mean_squared_error: 7.0935\n",
      "Epoch 32/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1906 - mean_squared_error: 7.0127 - val_loss: 2.2055 - val_mean_squared_error: 7.0507\n",
      "Epoch 33/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1918 - mean_squared_error: 7.0202 - val_loss: 2.1993 - val_mean_squared_error: 6.9997\n",
      "Epoch 34/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1886 - mean_squared_error: 7.0282 - val_loss: 2.2024 - val_mean_squared_error: 7.0101\n",
      "Epoch 35/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1903 - mean_squared_error: 7.0149 - val_loss: 2.2036 - val_mean_squared_error: 6.9908\n",
      "Epoch 36/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1802 - mean_squared_error: 6.9744 - val_loss: 2.2078 - val_mean_squared_error: 7.0688\n",
      "Epoch 37/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.1761 - mean_squared_error: 6.9618 - val_loss: 2.1979 - val_mean_squared_error: 6.9651\n",
      "Epoch 38/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1680 - mean_squared_error: 6.9201 - val_loss: 2.2007 - val_mean_squared_error: 7.0225\n",
      "Epoch 39/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.1747 - mean_squared_error: 6.9656 - val_loss: 2.1911 - val_mean_squared_error: 6.9815\n",
      "Epoch 40/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1773 - mean_squared_error: 6.9834 - val_loss: 2.1901 - val_mean_squared_error: 6.9615\n",
      "Epoch 41/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1631 - mean_squared_error: 6.8873 - val_loss: 2.1994 - val_mean_squared_error: 6.9941\n",
      "Epoch 42/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1664 - mean_squared_error: 6.9066 - val_loss: 2.1901 - val_mean_squared_error: 6.9321\n",
      "Epoch 43/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1589 - mean_squared_error: 6.8783 - val_loss: 2.1927 - val_mean_squared_error: 6.9682\n",
      "Epoch 44/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1602 - mean_squared_error: 6.8805 - val_loss: 2.1859 - val_mean_squared_error: 6.9440\n",
      "Epoch 45/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1521 - mean_squared_error: 6.8250 - val_loss: 2.1875 - val_mean_squared_error: 6.9450\n",
      "Epoch 46/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1542 - mean_squared_error: 6.8745 - val_loss: 2.1807 - val_mean_squared_error: 6.9286\n",
      "Epoch 47/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1614 - mean_squared_error: 6.8903 - val_loss: 2.1968 - val_mean_squared_error: 7.0127\n",
      "Epoch 48/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1510 - mean_squared_error: 6.8446 - val_loss: 2.1813 - val_mean_squared_error: 6.9012\n",
      "Epoch 49/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1457 - mean_squared_error: 6.8122 - val_loss: 2.1865 - val_mean_squared_error: 6.9551\n",
      "Epoch 50/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1358 - mean_squared_error: 6.7806 - val_loss: 2.1752 - val_mean_squared_error: 6.8494\n",
      "Epoch 51/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1417 - mean_squared_error: 6.7956 - val_loss: 2.1741 - val_mean_squared_error: 6.8589\n",
      "Epoch 52/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1308 - mean_squared_error: 6.7481 - val_loss: 2.1803 - val_mean_squared_error: 6.9360\n",
      "Epoch 53/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1340 - mean_squared_error: 6.7701 - val_loss: 2.1677 - val_mean_squared_error: 6.8255\n",
      "Epoch 54/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1310 - mean_squared_error: 6.7632 - val_loss: 2.1985 - val_mean_squared_error: 7.0439\n",
      "Epoch 55/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1313 - mean_squared_error: 6.7637 - val_loss: 2.1821 - val_mean_squared_error: 6.9523\n",
      "Epoch 56/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1264 - mean_squared_error: 6.7466 - val_loss: 2.1742 - val_mean_squared_error: 6.8807\n",
      "Epoch 57/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1236 - mean_squared_error: 6.7418 - val_loss: 2.1648 - val_mean_squared_error: 6.8329\n",
      "Epoch 58/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1241 - mean_squared_error: 6.7389 - val_loss: 2.1664 - val_mean_squared_error: 6.8503\n",
      "Epoch 59/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1249 - mean_squared_error: 6.7519 - val_loss: 2.1682 - val_mean_squared_error: 6.8179\n",
      "Epoch 60/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1223 - mean_squared_error: 6.7185 - val_loss: 2.1659 - val_mean_squared_error: 6.8310\n",
      "Epoch 61/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1181 - mean_squared_error: 6.7123 - val_loss: 2.1621 - val_mean_squared_error: 6.8093\n",
      "Epoch 62/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.1110 - mean_squared_error: 6.6864 - val_loss: 2.1632 - val_mean_squared_error: 6.8276\n",
      "Epoch 63/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1131 - mean_squared_error: 6.6838 - val_loss: 2.1621 - val_mean_squared_error: 6.8101\n",
      "Epoch 64/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1100 - mean_squared_error: 6.6641 - val_loss: 2.1577 - val_mean_squared_error: 6.7946\n",
      "Epoch 65/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.1050 - mean_squared_error: 6.6422 - val_loss: 2.1549 - val_mean_squared_error: 6.7752\n",
      "Epoch 66/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1016 - mean_squared_error: 6.6388 - val_loss: 2.1546 - val_mean_squared_error: 6.7845\n",
      "Epoch 67/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.1011 - mean_squared_error: 6.6105 - val_loss: 2.1535 - val_mean_squared_error: 6.7677\n",
      "Epoch 68/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0962 - mean_squared_error: 6.5803 - val_loss: 2.1566 - val_mean_squared_error: 6.7939\n",
      "Epoch 69/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.1004 - mean_squared_error: 6.6211 - val_loss: 2.1622 - val_mean_squared_error: 6.8258\n",
      "Epoch 70/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0979 - mean_squared_error: 6.6205 - val_loss: 2.1544 - val_mean_squared_error: 6.7903\n",
      "Epoch 71/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0922 - mean_squared_error: 6.5925 - val_loss: 2.1460 - val_mean_squared_error: 6.7138\n",
      "Epoch 72/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0912 - mean_squared_error: 6.5670 - val_loss: 2.1543 - val_mean_squared_error: 6.7900\n",
      "Epoch 73/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0820 - mean_squared_error: 6.5238 - val_loss: 2.1554 - val_mean_squared_error: 6.8124\n",
      "Epoch 74/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0953 - mean_squared_error: 6.6024 - val_loss: 2.1489 - val_mean_squared_error: 6.7694\n",
      "Epoch 75/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0867 - mean_squared_error: 6.5857 - val_loss: 2.1486 - val_mean_squared_error: 6.7330\n",
      "Epoch 76/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0857 - mean_squared_error: 6.5434 - val_loss: 2.1486 - val_mean_squared_error: 6.7489\n",
      "Epoch 77/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0895 - mean_squared_error: 6.5870 - val_loss: 2.1468 - val_mean_squared_error: 6.6950\n",
      "Epoch 78/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0856 - mean_squared_error: 6.5678 - val_loss: 2.1563 - val_mean_squared_error: 6.7833\n",
      "Epoch 79/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0801 - mean_squared_error: 6.5498 - val_loss: 2.1504 - val_mean_squared_error: 6.7494\n",
      "Epoch 80/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0826 - mean_squared_error: 6.5463 - val_loss: 2.1453 - val_mean_squared_error: 6.7000\n",
      "Epoch 81/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0731 - mean_squared_error: 6.4796 - val_loss: 2.1431 - val_mean_squared_error: 6.7350\n",
      "Epoch 82/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0764 - mean_squared_error: 6.5183 - val_loss: 2.1386 - val_mean_squared_error: 6.6777\n",
      "Epoch 83/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0763 - mean_squared_error: 6.5001 - val_loss: 2.1425 - val_mean_squared_error: 6.7083\n",
      "Epoch 84/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0738 - mean_squared_error: 6.5026 - val_loss: 2.1427 - val_mean_squared_error: 6.7324\n",
      "Epoch 85/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0698 - mean_squared_error: 6.5001 - val_loss: 2.1429 - val_mean_squared_error: 6.7035\n",
      "Epoch 86/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0668 - mean_squared_error: 6.4740 - val_loss: 2.1410 - val_mean_squared_error: 6.6937\n",
      "Epoch 87/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0639 - mean_squared_error: 6.4375 - val_loss: 2.1450 - val_mean_squared_error: 6.7355\n",
      "Epoch 88/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0665 - mean_squared_error: 6.4850 - val_loss: 2.1427 - val_mean_squared_error: 6.6701\n",
      "Epoch 89/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0655 - mean_squared_error: 6.4657 - val_loss: 2.1422 - val_mean_squared_error: 6.7025\n",
      "Epoch 90/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0644 - mean_squared_error: 6.4581 - val_loss: 2.1461 - val_mean_squared_error: 6.7181\n",
      "Epoch 91/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0676 - mean_squared_error: 6.4741 - val_loss: 2.1426 - val_mean_squared_error: 6.7323\n",
      "Epoch 92/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0629 - mean_squared_error: 6.4660 - val_loss: 2.1359 - val_mean_squared_error: 6.6700\n",
      "Epoch 93/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0611 - mean_squared_error: 6.4433 - val_loss: 2.1450 - val_mean_squared_error: 6.7387\n",
      "Epoch 94/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0583 - mean_squared_error: 6.4265 - val_loss: 2.1398 - val_mean_squared_error: 6.6919\n",
      "Epoch 95/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0604 - mean_squared_error: 6.4393 - val_loss: 2.1392 - val_mean_squared_error: 6.6829\n",
      "Epoch 96/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0559 - mean_squared_error: 6.3928 - val_loss: 2.1372 - val_mean_squared_error: 6.6649\n",
      "Epoch 97/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0533 - mean_squared_error: 6.4242 - val_loss: 2.1494 - val_mean_squared_error: 6.7730\n",
      "Epoch 98/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0588 - mean_squared_error: 6.4015 - val_loss: 2.1359 - val_mean_squared_error: 6.6689\n",
      "Epoch 99/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0606 - mean_squared_error: 6.4364 - val_loss: 2.1454 - val_mean_squared_error: 6.7319\n",
      "Epoch 100/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0522 - mean_squared_error: 6.3990 - val_loss: 2.1368 - val_mean_squared_error: 6.6534\n",
      "Epoch 101/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0468 - mean_squared_error: 6.3904 - val_loss: 2.1318 - val_mean_squared_error: 6.6511\n",
      "Epoch 102/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0487 - mean_squared_error: 6.3896 - val_loss: 2.1348 - val_mean_squared_error: 6.6671\n",
      "Epoch 103/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0502 - mean_squared_error: 6.3913 - val_loss: 2.1329 - val_mean_squared_error: 6.6736\n",
      "Epoch 104/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0532 - mean_squared_error: 6.4051 - val_loss: 2.1368 - val_mean_squared_error: 6.6759\n",
      "Epoch 105/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0494 - mean_squared_error: 6.4004 - val_loss: 2.1309 - val_mean_squared_error: 6.6423\n",
      "Epoch 106/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0437 - mean_squared_error: 6.3588 - val_loss: 2.1358 - val_mean_squared_error: 6.6848\n",
      "Epoch 107/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0415 - mean_squared_error: 6.3619 - val_loss: 2.1340 - val_mean_squared_error: 6.6457\n",
      "Epoch 108/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0407 - mean_squared_error: 6.3420 - val_loss: 2.1342 - val_mean_squared_error: 6.6518\n",
      "Epoch 109/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0423 - mean_squared_error: 6.3441 - val_loss: 2.1378 - val_mean_squared_error: 6.7077\n",
      "Epoch 110/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0414 - mean_squared_error: 6.3394 - val_loss: 2.1313 - val_mean_squared_error: 6.6638\n",
      "Epoch 111/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0341 - mean_squared_error: 6.3140 - val_loss: 2.1322 - val_mean_squared_error: 6.6748\n",
      "Epoch 112/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0437 - mean_squared_error: 6.3871 - val_loss: 2.1369 - val_mean_squared_error: 6.6795\n",
      "Epoch 113/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0411 - mean_squared_error: 6.3590 - val_loss: 2.1310 - val_mean_squared_error: 6.6752\n",
      "Epoch 114/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0360 - mean_squared_error: 6.3279 - val_loss: 2.1290 - val_mean_squared_error: 6.6534\n",
      "Epoch 115/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0353 - mean_squared_error: 6.3240 - val_loss: 2.1366 - val_mean_squared_error: 6.6655\n",
      "Epoch 116/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0386 - mean_squared_error: 6.3290 - val_loss: 2.1364 - val_mean_squared_error: 6.6568\n",
      "Epoch 117/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0313 - mean_squared_error: 6.3003 - val_loss: 2.1388 - val_mean_squared_error: 6.7132\n",
      "Epoch 118/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0349 - mean_squared_error: 6.3015 - val_loss: 2.1377 - val_mean_squared_error: 6.6924\n",
      "Epoch 119/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 2.0349 - mean_squared_error: 6.3279 - val_loss: 2.1268 - val_mean_squared_error: 6.6386\n",
      "Epoch 120/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0299 - mean_squared_error: 6.2797 - val_loss: 2.1297 - val_mean_squared_error: 6.6557\n",
      "Epoch 121/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0345 - mean_squared_error: 6.3337 - val_loss: 2.1330 - val_mean_squared_error: 6.6871\n",
      "Epoch 122/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0283 - mean_squared_error: 6.2880 - val_loss: 2.1343 - val_mean_squared_error: 6.7064\n",
      "Epoch 123/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0266 - mean_squared_error: 6.2936 - val_loss: 2.1386 - val_mean_squared_error: 6.7105\n",
      "Epoch 124/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0272 - mean_squared_error: 6.2896 - val_loss: 2.1349 - val_mean_squared_error: 6.7196\n",
      "Epoch 125/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0263 - mean_squared_error: 6.2807 - val_loss: 2.1349 - val_mean_squared_error: 6.6845\n",
      "Epoch 126/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0253 - mean_squared_error: 6.2827 - val_loss: 2.1366 - val_mean_squared_error: 6.6952\n",
      "Epoch 127/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0301 - mean_squared_error: 6.2925 - val_loss: 2.1387 - val_mean_squared_error: 6.6829\n",
      "Epoch 128/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0272 - mean_squared_error: 6.2857 - val_loss: 2.1356 - val_mean_squared_error: 6.7122\n",
      "Epoch 129/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0169 - mean_squared_error: 6.2287 - val_loss: 2.1299 - val_mean_squared_error: 6.6702\n",
      "Epoch 130/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0218 - mean_squared_error: 6.2583 - val_loss: 2.1325 - val_mean_squared_error: 6.6792\n",
      "Epoch 131/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0196 - mean_squared_error: 6.2414 - val_loss: 2.1354 - val_mean_squared_error: 6.7186\n",
      "Epoch 132/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0221 - mean_squared_error: 6.2474 - val_loss: 2.1321 - val_mean_squared_error: 6.6813\n",
      "Epoch 133/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0164 - mean_squared_error: 6.2382 - val_loss: 2.1376 - val_mean_squared_error: 6.6979\n",
      "Epoch 134/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0182 - mean_squared_error: 6.2522 - val_loss: 2.1240 - val_mean_squared_error: 6.6397\n",
      "Epoch 135/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0227 - mean_squared_error: 6.2655 - val_loss: 2.1316 - val_mean_squared_error: 6.6739\n",
      "Epoch 136/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0160 - mean_squared_error: 6.2081 - val_loss: 2.1278 - val_mean_squared_error: 6.6509\n",
      "Epoch 137/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0152 - mean_squared_error: 6.2184 - val_loss: 2.1295 - val_mean_squared_error: 6.6834\n",
      "Epoch 138/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0108 - mean_squared_error: 6.2194 - val_loss: 2.1254 - val_mean_squared_error: 6.6498\n",
      "Epoch 139/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0159 - mean_squared_error: 6.2395 - val_loss: 2.1334 - val_mean_squared_error: 6.6695\n",
      "Epoch 140/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0184 - mean_squared_error: 6.2432 - val_loss: 2.1288 - val_mean_squared_error: 6.6367\n",
      "Epoch 141/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0148 - mean_squared_error: 6.2172 - val_loss: 2.1305 - val_mean_squared_error: 6.6651\n",
      "Epoch 142/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0047 - mean_squared_error: 6.1834 - val_loss: 2.1387 - val_mean_squared_error: 6.7326\n",
      "Epoch 143/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0149 - mean_squared_error: 6.2377 - val_loss: 2.1301 - val_mean_squared_error: 6.6502\n",
      "Epoch 144/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0075 - mean_squared_error: 6.2115 - val_loss: 2.1280 - val_mean_squared_error: 6.6595\n",
      "Epoch 145/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0132 - mean_squared_error: 6.2199 - val_loss: 2.1259 - val_mean_squared_error: 6.6120\n",
      "Epoch 146/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0054 - mean_squared_error: 6.1737 - val_loss: 2.1246 - val_mean_squared_error: 6.6579\n",
      "Epoch 147/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0055 - mean_squared_error: 6.2030 - val_loss: 2.1298 - val_mean_squared_error: 6.6905\n",
      "Epoch 148/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0127 - mean_squared_error: 6.2070 - val_loss: 2.1254 - val_mean_squared_error: 6.6172\n",
      "Epoch 149/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0112 - mean_squared_error: 6.2416 - val_loss: 2.1279 - val_mean_squared_error: 6.6596\n",
      "Epoch 150/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0034 - mean_squared_error: 6.1730 - val_loss: 2.1340 - val_mean_squared_error: 6.7064\n",
      "Epoch 151/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0084 - mean_squared_error: 6.1988 - val_loss: 2.1310 - val_mean_squared_error: 6.7040\n",
      "Epoch 152/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0009 - mean_squared_error: 6.1735 - val_loss: 2.1192 - val_mean_squared_error: 6.6072\n",
      "Epoch 153/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0115 - mean_squared_error: 6.2186 - val_loss: 2.1226 - val_mean_squared_error: 6.6293\n",
      "Epoch 154/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0019 - mean_squared_error: 6.1659 - val_loss: 2.1263 - val_mean_squared_error: 6.6244\n",
      "Epoch 155/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9978 - mean_squared_error: 6.1370 - val_loss: 2.1283 - val_mean_squared_error: 6.6759\n",
      "Epoch 156/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9992 - mean_squared_error: 6.1508 - val_loss: 2.1255 - val_mean_squared_error: 6.6621\n",
      "Epoch 157/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9990 - mean_squared_error: 6.1590 - val_loss: 2.1290 - val_mean_squared_error: 6.6832\n",
      "Epoch 158/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9942 - mean_squared_error: 6.1265 - val_loss: 2.1292 - val_mean_squared_error: 6.6421\n",
      "Epoch 159/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 2.0055 - mean_squared_error: 6.1820 - val_loss: 2.1196 - val_mean_squared_error: 6.6172\n",
      "Epoch 160/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9943 - mean_squared_error: 6.1258 - val_loss: 2.1220 - val_mean_squared_error: 6.6532\n",
      "Epoch 161/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9940 - mean_squared_error: 6.1143 - val_loss: 2.1234 - val_mean_squared_error: 6.6353\n",
      "Epoch 162/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 2.0061 - mean_squared_error: 6.1939 - val_loss: 2.1321 - val_mean_squared_error: 6.6867\n",
      "Epoch 163/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9965 - mean_squared_error: 6.1516 - val_loss: 2.1270 - val_mean_squared_error: 6.6892\n",
      "Epoch 164/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9957 - mean_squared_error: 6.1522 - val_loss: 2.1286 - val_mean_squared_error: 6.6590\n",
      "Epoch 165/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9948 - mean_squared_error: 6.1368 - val_loss: 2.1270 - val_mean_squared_error: 6.6530\n",
      "Epoch 166/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9820 - mean_squared_error: 6.0680 - val_loss: 2.1220 - val_mean_squared_error: 6.6407\n",
      "Epoch 167/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9940 - mean_squared_error: 6.1254 - val_loss: 2.1237 - val_mean_squared_error: 6.6595\n",
      "Epoch 168/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9993 - mean_squared_error: 6.1578 - val_loss: 2.1292 - val_mean_squared_error: 6.6621\n",
      "Epoch 169/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9892 - mean_squared_error: 6.1222 - val_loss: 2.1250 - val_mean_squared_error: 6.6688\n",
      "Epoch 170/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9822 - mean_squared_error: 6.0799 - val_loss: 2.1309 - val_mean_squared_error: 6.6982\n",
      "Epoch 171/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9901 - mean_squared_error: 6.1326 - val_loss: 2.1306 - val_mean_squared_error: 6.7010\n",
      "Epoch 172/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9892 - mean_squared_error: 6.1188 - val_loss: 2.1280 - val_mean_squared_error: 6.6762\n",
      "Epoch 173/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9838 - mean_squared_error: 6.1005 - val_loss: 2.1318 - val_mean_squared_error: 6.7120\n",
      "Epoch 174/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9846 - mean_squared_error: 6.0918 - val_loss: 2.1302 - val_mean_squared_error: 6.7118\n",
      "Epoch 175/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9893 - mean_squared_error: 6.1120 - val_loss: 2.1245 - val_mean_squared_error: 6.6405\n",
      "Epoch 176/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9830 - mean_squared_error: 6.0799 - val_loss: 2.1237 - val_mean_squared_error: 6.6592\n",
      "Epoch 177/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9813 - mean_squared_error: 6.0980 - val_loss: 2.1300 - val_mean_squared_error: 6.7038\n",
      "Epoch 178/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9815 - mean_squared_error: 6.0900 - val_loss: 2.1360 - val_mean_squared_error: 6.7415\n",
      "Epoch 179/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9820 - mean_squared_error: 6.0759 - val_loss: 2.1313 - val_mean_squared_error: 6.7013\n",
      "Epoch 180/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9895 - mean_squared_error: 6.1077 - val_loss: 2.1392 - val_mean_squared_error: 6.7520\n",
      "Epoch 181/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9875 - mean_squared_error: 6.0928 - val_loss: 2.1287 - val_mean_squared_error: 6.6675\n",
      "Epoch 182/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9860 - mean_squared_error: 6.1177 - val_loss: 2.1269 - val_mean_squared_error: 6.6777\n",
      "Epoch 183/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9844 - mean_squared_error: 6.1050 - val_loss: 2.1283 - val_mean_squared_error: 6.6851\n",
      "Epoch 184/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9856 - mean_squared_error: 6.1201 - val_loss: 2.1262 - val_mean_squared_error: 6.6581\n",
      "Epoch 185/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9759 - mean_squared_error: 6.0446 - val_loss: 2.1200 - val_mean_squared_error: 6.6156\n",
      "Epoch 186/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9836 - mean_squared_error: 6.0678 - val_loss: 2.1209 - val_mean_squared_error: 6.6286\n",
      "Epoch 187/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9816 - mean_squared_error: 6.0797 - val_loss: 2.1283 - val_mean_squared_error: 6.6894\n",
      "Epoch 188/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9788 - mean_squared_error: 6.0816 - val_loss: 2.1249 - val_mean_squared_error: 6.6715\n",
      "Epoch 189/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9754 - mean_squared_error: 6.0456 - val_loss: 2.1270 - val_mean_squared_error: 6.6595\n",
      "Epoch 190/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9773 - mean_squared_error: 6.0701 - val_loss: 2.1309 - val_mean_squared_error: 6.6996\n",
      "Epoch 191/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9789 - mean_squared_error: 6.0559 - val_loss: 2.1228 - val_mean_squared_error: 6.6356\n",
      "Epoch 192/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9703 - mean_squared_error: 6.0396 - val_loss: 2.1264 - val_mean_squared_error: 6.6929\n",
      "Epoch 193/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9803 - mean_squared_error: 6.0902 - val_loss: 2.1361 - val_mean_squared_error: 6.7700\n",
      "Epoch 194/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9831 - mean_squared_error: 6.0932 - val_loss: 2.1277 - val_mean_squared_error: 6.6909\n",
      "Epoch 195/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9726 - mean_squared_error: 6.0673 - val_loss: 2.1321 - val_mean_squared_error: 6.7138\n",
      "Epoch 196/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9749 - mean_squared_error: 6.0653 - val_loss: 2.1322 - val_mean_squared_error: 6.6768\n",
      "Epoch 197/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9766 - mean_squared_error: 6.0518 - val_loss: 2.1246 - val_mean_squared_error: 6.6581\n",
      "Epoch 198/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9659 - mean_squared_error: 6.0072 - val_loss: 2.1341 - val_mean_squared_error: 6.7132\n",
      "Epoch 199/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9751 - mean_squared_error: 6.0208 - val_loss: 2.1349 - val_mean_squared_error: 6.7165\n",
      "Epoch 200/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9732 - mean_squared_error: 6.0382 - val_loss: 2.1250 - val_mean_squared_error: 6.6758\n",
      "Epoch 201/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9736 - mean_squared_error: 6.0371 - val_loss: 2.1298 - val_mean_squared_error: 6.6958\n",
      "Epoch 202/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9765 - mean_squared_error: 6.0652 - val_loss: 2.1284 - val_mean_squared_error: 6.6967\n",
      "Epoch 203/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9723 - mean_squared_error: 6.0279 - val_loss: 2.1280 - val_mean_squared_error: 6.6829\n",
      "Epoch 204/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9697 - mean_squared_error: 6.0154 - val_loss: 2.1268 - val_mean_squared_error: 6.6870\n",
      "Epoch 205/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9631 - mean_squared_error: 5.9852 - val_loss: 2.1291 - val_mean_squared_error: 6.6623\n",
      "Epoch 206/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9749 - mean_squared_error: 6.0529 - val_loss: 2.1259 - val_mean_squared_error: 6.6699\n",
      "Epoch 207/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9730 - mean_squared_error: 6.0257 - val_loss: 2.1251 - val_mean_squared_error: 6.6732\n",
      "Epoch 208/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9708 - mean_squared_error: 6.0367 - val_loss: 2.1288 - val_mean_squared_error: 6.7194\n",
      "Epoch 209/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9688 - mean_squared_error: 6.0449 - val_loss: 2.1294 - val_mean_squared_error: 6.6879\n",
      "Epoch 210/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9657 - mean_squared_error: 5.9934 - val_loss: 2.1310 - val_mean_squared_error: 6.6847\n",
      "Epoch 211/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9659 - mean_squared_error: 6.0088 - val_loss: 2.1268 - val_mean_squared_error: 6.6890\n",
      "Epoch 212/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9693 - mean_squared_error: 6.0314 - val_loss: 2.1308 - val_mean_squared_error: 6.6814\n",
      "Epoch 213/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9627 - mean_squared_error: 5.9983 - val_loss: 2.1295 - val_mean_squared_error: 6.6822\n",
      "Epoch 214/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9649 - mean_squared_error: 6.0190 - val_loss: 2.1275 - val_mean_squared_error: 6.6928\n",
      "Epoch 215/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9710 - mean_squared_error: 6.0202 - val_loss: 2.1233 - val_mean_squared_error: 6.6433\n",
      "Epoch 216/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9617 - mean_squared_error: 5.9926 - val_loss: 2.1312 - val_mean_squared_error: 6.6909\n",
      "Epoch 217/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9664 - mean_squared_error: 6.0173 - val_loss: 2.1306 - val_mean_squared_error: 6.7035\n",
      "Epoch 218/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9656 - mean_squared_error: 6.0126 - val_loss: 2.1250 - val_mean_squared_error: 6.6533\n",
      "Epoch 219/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9650 - mean_squared_error: 5.9869 - val_loss: 2.1266 - val_mean_squared_error: 6.6946\n",
      "Epoch 220/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9569 - mean_squared_error: 5.9696 - val_loss: 2.1318 - val_mean_squared_error: 6.7228\n",
      "Epoch 221/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9564 - mean_squared_error: 5.9654 - val_loss: 2.1326 - val_mean_squared_error: 6.7254\n",
      "Epoch 222/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9580 - mean_squared_error: 5.9753 - val_loss: 2.1295 - val_mean_squared_error: 6.6997\n",
      "Epoch 223/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9617 - mean_squared_error: 5.9818 - val_loss: 2.1306 - val_mean_squared_error: 6.7218\n",
      "Epoch 224/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9600 - mean_squared_error: 6.0046 - val_loss: 2.1294 - val_mean_squared_error: 6.6768\n",
      "Epoch 225/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9685 - mean_squared_error: 5.9861 - val_loss: 2.1248 - val_mean_squared_error: 6.6550\n",
      "Epoch 226/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9570 - mean_squared_error: 5.9536 - val_loss: 2.1239 - val_mean_squared_error: 6.6687\n",
      "Epoch 227/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9483 - mean_squared_error: 5.9395 - val_loss: 2.1295 - val_mean_squared_error: 6.7126\n",
      "Epoch 228/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9532 - mean_squared_error: 5.9616 - val_loss: 2.1341 - val_mean_squared_error: 6.7288\n",
      "Epoch 229/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9563 - mean_squared_error: 6.0047 - val_loss: 2.1328 - val_mean_squared_error: 6.7061\n",
      "Epoch 230/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9524 - mean_squared_error: 5.9320 - val_loss: 2.1406 - val_mean_squared_error: 6.7699\n",
      "Epoch 231/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9543 - mean_squared_error: 5.9537 - val_loss: 2.1270 - val_mean_squared_error: 6.7128\n",
      "Epoch 232/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9531 - mean_squared_error: 5.9614 - val_loss: 2.1304 - val_mean_squared_error: 6.7027\n",
      "Epoch 233/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9538 - mean_squared_error: 5.9533 - val_loss: 2.1272 - val_mean_squared_error: 6.6813\n",
      "Epoch 234/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9441 - mean_squared_error: 5.8916 - val_loss: 2.1321 - val_mean_squared_error: 6.7159\n",
      "Epoch 235/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9516 - mean_squared_error: 5.9356 - val_loss: 2.1275 - val_mean_squared_error: 6.7073\n",
      "Epoch 236/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9524 - mean_squared_error: 5.9473 - val_loss: 2.1246 - val_mean_squared_error: 6.6637\n",
      "Epoch 237/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9523 - mean_squared_error: 5.9502 - val_loss: 2.1283 - val_mean_squared_error: 6.6901\n",
      "Epoch 238/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9496 - mean_squared_error: 5.9231 - val_loss: 2.1302 - val_mean_squared_error: 6.7193\n",
      "Epoch 239/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9474 - mean_squared_error: 5.9556 - val_loss: 2.1326 - val_mean_squared_error: 6.7084\n",
      "Epoch 240/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9473 - mean_squared_error: 5.9195 - val_loss: 2.1232 - val_mean_squared_error: 6.6867\n",
      "Epoch 241/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9507 - mean_squared_error: 5.9476 - val_loss: 2.1234 - val_mean_squared_error: 6.6865\n",
      "Epoch 242/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9469 - mean_squared_error: 5.9174 - val_loss: 2.1273 - val_mean_squared_error: 6.6950\n",
      "Epoch 243/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9502 - mean_squared_error: 5.9546 - val_loss: 2.1272 - val_mean_squared_error: 6.7049\n",
      "Epoch 244/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9495 - mean_squared_error: 5.9096 - val_loss: 2.1342 - val_mean_squared_error: 6.7285\n",
      "Epoch 245/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9433 - mean_squared_error: 5.8948 - val_loss: 2.1349 - val_mean_squared_error: 6.7709\n",
      "Epoch 246/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9515 - mean_squared_error: 5.9441 - val_loss: 2.1329 - val_mean_squared_error: 6.7490\n",
      "Epoch 247/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9449 - mean_squared_error: 5.8934 - val_loss: 2.1265 - val_mean_squared_error: 6.7217\n",
      "Epoch 248/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9498 - mean_squared_error: 5.9354 - val_loss: 2.1406 - val_mean_squared_error: 6.7582\n",
      "Epoch 249/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9466 - mean_squared_error: 5.9112 - val_loss: 2.1267 - val_mean_squared_error: 6.6917\n",
      "Epoch 250/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9442 - mean_squared_error: 5.9104 - val_loss: 2.1349 - val_mean_squared_error: 6.7297\n",
      "Epoch 251/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9396 - mean_squared_error: 5.8959 - val_loss: 2.1341 - val_mean_squared_error: 6.7545\n",
      "Epoch 252/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9490 - mean_squared_error: 5.9346 - val_loss: 2.1381 - val_mean_squared_error: 6.7667\n",
      "Epoch 253/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9395 - mean_squared_error: 5.8916 - val_loss: 2.1318 - val_mean_squared_error: 6.7470\n",
      "Epoch 254/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9445 - mean_squared_error: 5.9065 - val_loss: 2.1303 - val_mean_squared_error: 6.7261\n",
      "Epoch 255/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9457 - mean_squared_error: 5.8825 - val_loss: 2.1305 - val_mean_squared_error: 6.7237\n",
      "Epoch 256/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9363 - mean_squared_error: 5.8757 - val_loss: 2.1314 - val_mean_squared_error: 6.7357\n",
      "Epoch 257/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9387 - mean_squared_error: 5.8710 - val_loss: 2.1349 - val_mean_squared_error: 6.7563\n",
      "Epoch 258/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9444 - mean_squared_error: 5.9109 - val_loss: 2.1238 - val_mean_squared_error: 6.6869\n",
      "Epoch 259/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9451 - mean_squared_error: 5.8993 - val_loss: 2.1341 - val_mean_squared_error: 6.7378\n",
      "Epoch 260/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9381 - mean_squared_error: 5.8829 - val_loss: 2.1324 - val_mean_squared_error: 6.7409\n",
      "Epoch 261/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9378 - mean_squared_error: 5.8805 - val_loss: 2.1289 - val_mean_squared_error: 6.7152\n",
      "Epoch 262/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9334 - mean_squared_error: 5.8562 - val_loss: 2.1337 - val_mean_squared_error: 6.7690\n",
      "Epoch 263/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9407 - mean_squared_error: 5.8893 - val_loss: 2.1360 - val_mean_squared_error: 6.7466\n",
      "Epoch 264/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9420 - mean_squared_error: 5.8976 - val_loss: 2.1342 - val_mean_squared_error: 6.7420\n",
      "Epoch 265/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9365 - mean_squared_error: 5.8964 - val_loss: 2.1246 - val_mean_squared_error: 6.6889\n",
      "Epoch 266/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9351 - mean_squared_error: 5.8604 - val_loss: 2.1337 - val_mean_squared_error: 6.7452\n",
      "Epoch 267/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9287 - mean_squared_error: 5.8276 - val_loss: 2.1319 - val_mean_squared_error: 6.7450\n",
      "Epoch 268/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9375 - mean_squared_error: 5.8688 - val_loss: 2.1301 - val_mean_squared_error: 6.7238\n",
      "Epoch 269/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9334 - mean_squared_error: 5.8694 - val_loss: 2.1318 - val_mean_squared_error: 6.7470\n",
      "Epoch 270/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9300 - mean_squared_error: 5.8285 - val_loss: 2.1373 - val_mean_squared_error: 6.7785\n",
      "Epoch 271/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9309 - mean_squared_error: 5.8445 - val_loss: 2.1283 - val_mean_squared_error: 6.7195\n",
      "Epoch 272/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9413 - mean_squared_error: 5.8987 - val_loss: 2.1355 - val_mean_squared_error: 6.7545\n",
      "Epoch 273/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9302 - mean_squared_error: 5.8376 - val_loss: 2.1341 - val_mean_squared_error: 6.7323\n",
      "Epoch 274/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9286 - mean_squared_error: 5.8616 - val_loss: 2.1333 - val_mean_squared_error: 6.7642\n",
      "Epoch 275/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9283 - mean_squared_error: 5.8248 - val_loss: 2.1280 - val_mean_squared_error: 6.7162\n",
      "Epoch 276/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9269 - mean_squared_error: 5.8368 - val_loss: 2.1344 - val_mean_squared_error: 6.7533\n",
      "Epoch 277/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9359 - mean_squared_error: 5.8436 - val_loss: 2.1337 - val_mean_squared_error: 6.7460\n",
      "Epoch 278/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9311 - mean_squared_error: 5.8491 - val_loss: 2.1386 - val_mean_squared_error: 6.7478\n",
      "Epoch 279/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9248 - mean_squared_error: 5.8200 - val_loss: 2.1382 - val_mean_squared_error: 6.7536\n",
      "Epoch 280/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9282 - mean_squared_error: 5.8385 - val_loss: 2.1373 - val_mean_squared_error: 6.7464\n",
      "Epoch 281/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9284 - mean_squared_error: 5.8379 - val_loss: 2.1313 - val_mean_squared_error: 6.7379\n",
      "Epoch 282/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9320 - mean_squared_error: 5.8496 - val_loss: 2.1373 - val_mean_squared_error: 6.7772\n",
      "Epoch 283/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9259 - mean_squared_error: 5.8231 - val_loss: 2.1356 - val_mean_squared_error: 6.7605\n",
      "Epoch 284/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9252 - mean_squared_error: 5.8210 - val_loss: 2.1343 - val_mean_squared_error: 6.7387\n",
      "Epoch 285/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9173 - mean_squared_error: 5.7826 - val_loss: 2.1411 - val_mean_squared_error: 6.7718\n",
      "Epoch 286/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9252 - mean_squared_error: 5.7942 - val_loss: 2.1385 - val_mean_squared_error: 6.7564\n",
      "Epoch 287/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9237 - mean_squared_error: 5.8201 - val_loss: 2.1262 - val_mean_squared_error: 6.6854\n",
      "Epoch 288/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9217 - mean_squared_error: 5.7891 - val_loss: 2.1314 - val_mean_squared_error: 6.7701\n",
      "Epoch 289/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9216 - mean_squared_error: 5.8093 - val_loss: 2.1377 - val_mean_squared_error: 6.7855\n",
      "Epoch 290/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9212 - mean_squared_error: 5.8102 - val_loss: 2.1306 - val_mean_squared_error: 6.7316\n",
      "Epoch 291/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9233 - mean_squared_error: 5.8225 - val_loss: 2.1305 - val_mean_squared_error: 6.7483\n",
      "Epoch 292/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9273 - mean_squared_error: 5.8377 - val_loss: 2.1324 - val_mean_squared_error: 6.7641\n",
      "Epoch 293/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9254 - mean_squared_error: 5.8231 - val_loss: 2.1334 - val_mean_squared_error: 6.7422\n",
      "Epoch 294/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9243 - mean_squared_error: 5.8014 - val_loss: 2.1299 - val_mean_squared_error: 6.7217\n",
      "Epoch 295/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9234 - mean_squared_error: 5.8159 - val_loss: 2.1326 - val_mean_squared_error: 6.7395\n",
      "Epoch 296/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9256 - mean_squared_error: 5.8144 - val_loss: 2.1347 - val_mean_squared_error: 6.7587\n",
      "Epoch 297/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9286 - mean_squared_error: 5.8467 - val_loss: 2.1352 - val_mean_squared_error: 6.7676\n",
      "Epoch 298/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9213 - mean_squared_error: 5.7866 - val_loss: 2.1375 - val_mean_squared_error: 6.7626\n",
      "Epoch 299/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9160 - mean_squared_error: 5.7876 - val_loss: 2.1287 - val_mean_squared_error: 6.7258\n",
      "Epoch 300/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9186 - mean_squared_error: 5.7900 - val_loss: 2.1325 - val_mean_squared_error: 6.7659\n",
      "Epoch 301/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9234 - mean_squared_error: 5.8024 - val_loss: 2.1355 - val_mean_squared_error: 6.7574\n",
      "Epoch 302/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9166 - mean_squared_error: 5.7801 - val_loss: 2.1326 - val_mean_squared_error: 6.7407\n",
      "Epoch 303/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9214 - mean_squared_error: 5.8068 - val_loss: 2.1316 - val_mean_squared_error: 6.7309\n",
      "Epoch 304/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9215 - mean_squared_error: 5.7814 - val_loss: 2.1292 - val_mean_squared_error: 6.7434\n",
      "Epoch 305/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9163 - mean_squared_error: 5.7801 - val_loss: 2.1321 - val_mean_squared_error: 6.7369\n",
      "Epoch 306/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9232 - mean_squared_error: 5.8115 - val_loss: 2.1343 - val_mean_squared_error: 6.7433\n",
      "Epoch 307/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9168 - mean_squared_error: 5.8011 - val_loss: 2.1323 - val_mean_squared_error: 6.7586\n",
      "Epoch 308/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9130 - mean_squared_error: 5.7576 - val_loss: 2.1371 - val_mean_squared_error: 6.7904\n",
      "Epoch 309/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9133 - mean_squared_error: 5.7774 - val_loss: 2.1330 - val_mean_squared_error: 6.7567\n",
      "Epoch 310/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9178 - mean_squared_error: 5.7859 - val_loss: 2.1365 - val_mean_squared_error: 6.7663\n",
      "Epoch 311/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9175 - mean_squared_error: 5.7605 - val_loss: 2.1374 - val_mean_squared_error: 6.7814\n",
      "Epoch 312/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9139 - mean_squared_error: 5.7688 - val_loss: 2.1341 - val_mean_squared_error: 6.7638\n",
      "Epoch 313/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9145 - mean_squared_error: 5.7711 - val_loss: 2.1345 - val_mean_squared_error: 6.7501\n",
      "Epoch 314/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9141 - mean_squared_error: 5.7554 - val_loss: 2.1374 - val_mean_squared_error: 6.7691\n",
      "Epoch 315/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9151 - mean_squared_error: 5.7998 - val_loss: 2.1328 - val_mean_squared_error: 6.7667\n",
      "Epoch 316/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9055 - mean_squared_error: 5.7500 - val_loss: 2.1375 - val_mean_squared_error: 6.7959\n",
      "Epoch 317/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9132 - mean_squared_error: 5.7667 - val_loss: 2.1339 - val_mean_squared_error: 6.7644\n",
      "Epoch 318/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9088 - mean_squared_error: 5.7432 - val_loss: 2.1395 - val_mean_squared_error: 6.8000\n",
      "Epoch 319/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9167 - mean_squared_error: 5.7816 - val_loss: 2.1359 - val_mean_squared_error: 6.7579\n",
      "Epoch 320/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9153 - mean_squared_error: 5.7491 - val_loss: 2.1335 - val_mean_squared_error: 6.7498\n",
      "Epoch 321/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9070 - mean_squared_error: 5.7502 - val_loss: 2.1301 - val_mean_squared_error: 6.7566\n",
      "Epoch 322/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9141 - mean_squared_error: 5.7578 - val_loss: 2.1342 - val_mean_squared_error: 6.7588\n",
      "Epoch 323/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9138 - mean_squared_error: 5.7819 - val_loss: 2.1310 - val_mean_squared_error: 6.7793\n",
      "Epoch 324/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9065 - mean_squared_error: 5.7537 - val_loss: 2.1365 - val_mean_squared_error: 6.7827\n",
      "Epoch 325/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9079 - mean_squared_error: 5.7529 - val_loss: 2.1362 - val_mean_squared_error: 6.7753\n",
      "Epoch 326/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9103 - mean_squared_error: 5.7609 - val_loss: 2.1384 - val_mean_squared_error: 6.8140\n",
      "Epoch 327/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9102 - mean_squared_error: 5.7455 - val_loss: 2.1350 - val_mean_squared_error: 6.7676\n",
      "Epoch 328/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9095 - mean_squared_error: 5.7549 - val_loss: 2.1351 - val_mean_squared_error: 6.7749\n",
      "Epoch 329/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9089 - mean_squared_error: 5.7471 - val_loss: 2.1382 - val_mean_squared_error: 6.7566\n",
      "Epoch 330/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9053 - mean_squared_error: 5.7452 - val_loss: 2.1504 - val_mean_squared_error: 6.8823\n",
      "Epoch 331/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.9077 - mean_squared_error: 5.7281 - val_loss: 2.1409 - val_mean_squared_error: 6.7967\n",
      "Epoch 332/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.9090 - mean_squared_error: 5.7461 - val_loss: 2.1395 - val_mean_squared_error: 6.7650\n",
      "Epoch 333/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9133 - mean_squared_error: 5.7525 - val_loss: 2.1287 - val_mean_squared_error: 6.7543\n",
      "Epoch 334/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9063 - mean_squared_error: 5.7327 - val_loss: 2.1397 - val_mean_squared_error: 6.7860\n",
      "Epoch 335/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.9036 - mean_squared_error: 5.7350 - val_loss: 2.1326 - val_mean_squared_error: 6.7675\n",
      "Epoch 336/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.9065 - mean_squared_error: 5.7268 - val_loss: 2.1356 - val_mean_squared_error: 6.7670\n",
      "Epoch 337/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9034 - mean_squared_error: 5.7343 - val_loss: 2.1314 - val_mean_squared_error: 6.7617\n",
      "Epoch 338/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9018 - mean_squared_error: 5.7145 - val_loss: 2.1383 - val_mean_squared_error: 6.7748\n",
      "Epoch 339/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9001 - mean_squared_error: 5.7088 - val_loss: 2.1341 - val_mean_squared_error: 6.7640\n",
      "Epoch 340/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9019 - mean_squared_error: 5.7136 - val_loss: 2.1397 - val_mean_squared_error: 6.7972\n",
      "Epoch 341/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8956 - mean_squared_error: 5.7016 - val_loss: 2.1298 - val_mean_squared_error: 6.7478\n",
      "Epoch 342/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9003 - mean_squared_error: 5.6919 - val_loss: 2.1378 - val_mean_squared_error: 6.8057\n",
      "Epoch 343/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9059 - mean_squared_error: 5.7612 - val_loss: 2.1390 - val_mean_squared_error: 6.7866\n",
      "Epoch 344/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9032 - mean_squared_error: 5.7100 - val_loss: 2.1401 - val_mean_squared_error: 6.7937\n",
      "Epoch 345/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9063 - mean_squared_error: 5.7477 - val_loss: 2.1439 - val_mean_squared_error: 6.8482\n",
      "Epoch 346/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9060 - mean_squared_error: 5.7117 - val_loss: 2.1428 - val_mean_squared_error: 6.8141\n",
      "Epoch 347/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9029 - mean_squared_error: 5.7130 - val_loss: 2.1370 - val_mean_squared_error: 6.7947\n",
      "Epoch 348/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8939 - mean_squared_error: 5.6865 - val_loss: 2.1356 - val_mean_squared_error: 6.7797\n",
      "Epoch 349/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8998 - mean_squared_error: 5.7128 - val_loss: 2.1384 - val_mean_squared_error: 6.8046\n",
      "Epoch 350/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8967 - mean_squared_error: 5.6866 - val_loss: 2.1351 - val_mean_squared_error: 6.7743\n",
      "Epoch 351/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9073 - mean_squared_error: 5.7364 - val_loss: 2.1371 - val_mean_squared_error: 6.8028\n",
      "Epoch 352/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8911 - mean_squared_error: 5.6850 - val_loss: 2.1340 - val_mean_squared_error: 6.7696\n",
      "Epoch 353/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9029 - mean_squared_error: 5.7215 - val_loss: 2.1330 - val_mean_squared_error: 6.7499\n",
      "Epoch 354/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8938 - mean_squared_error: 5.6945 - val_loss: 2.1388 - val_mean_squared_error: 6.7922\n",
      "Epoch 355/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9009 - mean_squared_error: 5.7079 - val_loss: 2.1482 - val_mean_squared_error: 6.8302\n",
      "Epoch 356/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8986 - mean_squared_error: 5.6738 - val_loss: 2.1297 - val_mean_squared_error: 6.7514\n",
      "Epoch 357/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8962 - mean_squared_error: 5.6991 - val_loss: 2.1350 - val_mean_squared_error: 6.7952\n",
      "Epoch 358/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8999 - mean_squared_error: 5.6894 - val_loss: 2.1389 - val_mean_squared_error: 6.8243\n",
      "Epoch 359/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8930 - mean_squared_error: 5.6896 - val_loss: 2.1324 - val_mean_squared_error: 6.7692\n",
      "Epoch 360/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9002 - mean_squared_error: 5.7004 - val_loss: 2.1403 - val_mean_squared_error: 6.8205\n",
      "Epoch 361/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8988 - mean_squared_error: 5.6944 - val_loss: 2.1393 - val_mean_squared_error: 6.8056\n",
      "Epoch 362/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9013 - mean_squared_error: 5.7134 - val_loss: 2.1432 - val_mean_squared_error: 6.8012\n",
      "Epoch 363/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8990 - mean_squared_error: 5.7094 - val_loss: 2.1403 - val_mean_squared_error: 6.8151\n",
      "Epoch 364/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9036 - mean_squared_error: 5.7184 - val_loss: 2.1396 - val_mean_squared_error: 6.7950\n",
      "Epoch 365/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9009 - mean_squared_error: 5.7086 - val_loss: 2.1329 - val_mean_squared_error: 6.7670\n",
      "Epoch 366/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.9010 - mean_squared_error: 5.7035 - val_loss: 2.1398 - val_mean_squared_error: 6.8094\n",
      "Epoch 367/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8936 - mean_squared_error: 5.6685 - val_loss: 2.1361 - val_mean_squared_error: 6.7902\n",
      "Epoch 368/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8909 - mean_squared_error: 5.6623 - val_loss: 2.1377 - val_mean_squared_error: 6.7962\n",
      "Epoch 369/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8963 - mean_squared_error: 5.6913 - val_loss: 2.1442 - val_mean_squared_error: 6.8120\n",
      "Epoch 370/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8973 - mean_squared_error: 5.6859 - val_loss: 2.1365 - val_mean_squared_error: 6.7780\n",
      "Epoch 371/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8888 - mean_squared_error: 5.6454 - val_loss: 2.1392 - val_mean_squared_error: 6.7914\n",
      "Epoch 372/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8881 - mean_squared_error: 5.6436 - val_loss: 2.1402 - val_mean_squared_error: 6.8223\n",
      "Epoch 373/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8895 - mean_squared_error: 5.6558 - val_loss: 2.1324 - val_mean_squared_error: 6.8008\n",
      "Epoch 374/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8895 - mean_squared_error: 5.6485 - val_loss: 2.1356 - val_mean_squared_error: 6.7599\n",
      "Epoch 375/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8949 - mean_squared_error: 5.6851 - val_loss: 2.1346 - val_mean_squared_error: 6.7909\n",
      "Epoch 376/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8856 - mean_squared_error: 5.6458 - val_loss: 2.1448 - val_mean_squared_error: 6.8262\n",
      "Epoch 377/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8942 - mean_squared_error: 5.7050 - val_loss: 2.1390 - val_mean_squared_error: 6.7975\n",
      "Epoch 378/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8871 - mean_squared_error: 5.6341 - val_loss: 2.1370 - val_mean_squared_error: 6.8052\n",
      "Epoch 379/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8925 - mean_squared_error: 5.6724 - val_loss: 2.1386 - val_mean_squared_error: 6.8111\n",
      "Epoch 380/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8782 - mean_squared_error: 5.6016 - val_loss: 2.1415 - val_mean_squared_error: 6.8370\n",
      "Epoch 381/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8910 - mean_squared_error: 5.6698 - val_loss: 2.1377 - val_mean_squared_error: 6.7921\n",
      "Epoch 382/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8960 - mean_squared_error: 5.6779 - val_loss: 2.1348 - val_mean_squared_error: 6.7934\n",
      "Epoch 383/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8907 - mean_squared_error: 5.6487 - val_loss: 2.1428 - val_mean_squared_error: 6.8529\n",
      "Epoch 384/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8816 - mean_squared_error: 5.6094 - val_loss: 2.1440 - val_mean_squared_error: 6.8352\n",
      "Epoch 385/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8862 - mean_squared_error: 5.6484 - val_loss: 2.1389 - val_mean_squared_error: 6.8257\n",
      "Epoch 386/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8872 - mean_squared_error: 5.6269 - val_loss: 2.1426 - val_mean_squared_error: 6.8134\n",
      "Epoch 387/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8868 - mean_squared_error: 5.6598 - val_loss: 2.1414 - val_mean_squared_error: 6.8313\n",
      "Epoch 388/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8819 - mean_squared_error: 5.6320 - val_loss: 2.1426 - val_mean_squared_error: 6.8174\n",
      "Epoch 389/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8839 - mean_squared_error: 5.6377 - val_loss: 2.1399 - val_mean_squared_error: 6.8030\n",
      "Epoch 390/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8899 - mean_squared_error: 5.6477 - val_loss: 2.1375 - val_mean_squared_error: 6.7969\n",
      "Epoch 391/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8907 - mean_squared_error: 5.6675 - val_loss: 2.1450 - val_mean_squared_error: 6.8382\n",
      "Epoch 392/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8855 - mean_squared_error: 5.6499 - val_loss: 2.1407 - val_mean_squared_error: 6.7979\n",
      "Epoch 393/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8904 - mean_squared_error: 5.6304 - val_loss: 2.1438 - val_mean_squared_error: 6.8551\n",
      "Epoch 394/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8832 - mean_squared_error: 5.6417 - val_loss: 2.1427 - val_mean_squared_error: 6.8217\n",
      "Epoch 395/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8773 - mean_squared_error: 5.5919 - val_loss: 2.1417 - val_mean_squared_error: 6.8089\n",
      "Epoch 396/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8835 - mean_squared_error: 5.6429 - val_loss: 2.1376 - val_mean_squared_error: 6.7902\n",
      "Epoch 397/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8862 - mean_squared_error: 5.6381 - val_loss: 2.1460 - val_mean_squared_error: 6.8459\n",
      "Epoch 398/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8894 - mean_squared_error: 5.6532 - val_loss: 2.1411 - val_mean_squared_error: 6.7941\n",
      "Epoch 399/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8747 - mean_squared_error: 5.5861 - val_loss: 2.1392 - val_mean_squared_error: 6.8074\n",
      "Epoch 400/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8841 - mean_squared_error: 5.6236 - val_loss: 2.1487 - val_mean_squared_error: 6.8584\n",
      "Epoch 401/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8825 - mean_squared_error: 5.6083 - val_loss: 2.1459 - val_mean_squared_error: 6.8519\n",
      "Epoch 402/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8855 - mean_squared_error: 5.6240 - val_loss: 2.1475 - val_mean_squared_error: 6.8766\n",
      "Epoch 403/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8863 - mean_squared_error: 5.6360 - val_loss: 2.1466 - val_mean_squared_error: 6.8506\n",
      "Epoch 404/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8887 - mean_squared_error: 5.6399 - val_loss: 2.1374 - val_mean_squared_error: 6.8181\n",
      "Epoch 405/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8865 - mean_squared_error: 5.6526 - val_loss: 2.1392 - val_mean_squared_error: 6.7958\n",
      "Epoch 406/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8815 - mean_squared_error: 5.6106 - val_loss: 2.1483 - val_mean_squared_error: 6.8391\n",
      "Epoch 407/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8823 - mean_squared_error: 5.6247 - val_loss: 2.1434 - val_mean_squared_error: 6.8300\n",
      "Epoch 408/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8791 - mean_squared_error: 5.5979 - val_loss: 2.1478 - val_mean_squared_error: 6.8502\n",
      "Epoch 409/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8791 - mean_squared_error: 5.5902 - val_loss: 2.1406 - val_mean_squared_error: 6.8260\n",
      "Epoch 410/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8777 - mean_squared_error: 5.5990 - val_loss: 2.1469 - val_mean_squared_error: 6.8446\n",
      "Epoch 411/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8756 - mean_squared_error: 5.6008 - val_loss: 2.1446 - val_mean_squared_error: 6.8370\n",
      "Epoch 412/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8709 - mean_squared_error: 5.5601 - val_loss: 2.1446 - val_mean_squared_error: 6.8282\n",
      "Epoch 413/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8761 - mean_squared_error: 5.5831 - val_loss: 2.1439 - val_mean_squared_error: 6.8266\n",
      "Epoch 414/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8809 - mean_squared_error: 5.6250 - val_loss: 2.1439 - val_mean_squared_error: 6.8586\n",
      "Epoch 415/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8801 - mean_squared_error: 5.6004 - val_loss: 2.1443 - val_mean_squared_error: 6.8353\n",
      "Epoch 416/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8839 - mean_squared_error: 5.6114 - val_loss: 2.1427 - val_mean_squared_error: 6.8013\n",
      "Epoch 417/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8856 - mean_squared_error: 5.6458 - val_loss: 2.1390 - val_mean_squared_error: 6.8077\n",
      "Epoch 418/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8847 - mean_squared_error: 5.6157 - val_loss: 2.1454 - val_mean_squared_error: 6.8436\n",
      "Epoch 419/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8741 - mean_squared_error: 5.5877 - val_loss: 2.1378 - val_mean_squared_error: 6.7756\n",
      "Epoch 420/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8759 - mean_squared_error: 5.5980 - val_loss: 2.1404 - val_mean_squared_error: 6.8032\n",
      "Epoch 421/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8751 - mean_squared_error: 5.5779 - val_loss: 2.1455 - val_mean_squared_error: 6.8620\n",
      "Epoch 422/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8815 - mean_squared_error: 5.5976 - val_loss: 2.1452 - val_mean_squared_error: 6.8121\n",
      "Epoch 423/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8705 - mean_squared_error: 5.5729 - val_loss: 2.1496 - val_mean_squared_error: 6.8739\n",
      "Epoch 424/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8781 - mean_squared_error: 5.5991 - val_loss: 2.1492 - val_mean_squared_error: 6.8305\n",
      "Epoch 425/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8851 - mean_squared_error: 5.6229 - val_loss: 2.1430 - val_mean_squared_error: 6.8210\n",
      "Epoch 426/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8767 - mean_squared_error: 5.5680 - val_loss: 2.1407 - val_mean_squared_error: 6.8267\n",
      "Epoch 427/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8734 - mean_squared_error: 5.5784 - val_loss: 2.1443 - val_mean_squared_error: 6.8369\n",
      "Epoch 428/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8720 - mean_squared_error: 5.5872 - val_loss: 2.1395 - val_mean_squared_error: 6.8118\n",
      "Epoch 429/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8790 - mean_squared_error: 5.5755 - val_loss: 2.1388 - val_mean_squared_error: 6.8240\n",
      "Epoch 430/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8764 - mean_squared_error: 5.5976 - val_loss: 2.1401 - val_mean_squared_error: 6.8005\n",
      "Epoch 431/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8679 - mean_squared_error: 5.5564 - val_loss: 2.1407 - val_mean_squared_error: 6.8373\n",
      "Epoch 432/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8764 - mean_squared_error: 5.5781 - val_loss: 2.1416 - val_mean_squared_error: 6.8501\n",
      "Epoch 433/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8733 - mean_squared_error: 5.5849 - val_loss: 2.1359 - val_mean_squared_error: 6.7960\n",
      "Epoch 434/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8672 - mean_squared_error: 5.5517 - val_loss: 2.1513 - val_mean_squared_error: 6.9042\n",
      "Epoch 435/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8811 - mean_squared_error: 5.6039 - val_loss: 2.1445 - val_mean_squared_error: 6.8273\n",
      "Epoch 436/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8762 - mean_squared_error: 5.5857 - val_loss: 2.1408 - val_mean_squared_error: 6.8384\n",
      "Epoch 437/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8732 - mean_squared_error: 5.5703 - val_loss: 2.1405 - val_mean_squared_error: 6.8106\n",
      "Epoch 438/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8691 - mean_squared_error: 5.5474 - val_loss: 2.1448 - val_mean_squared_error: 6.8883\n",
      "Epoch 439/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8677 - mean_squared_error: 5.5593 - val_loss: 2.1435 - val_mean_squared_error: 6.8476\n",
      "Epoch 440/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8714 - mean_squared_error: 5.5550 - val_loss: 2.1450 - val_mean_squared_error: 6.8566\n",
      "Epoch 441/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8800 - mean_squared_error: 5.6118 - val_loss: 2.1458 - val_mean_squared_error: 6.8278\n",
      "Epoch 442/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8767 - mean_squared_error: 5.5845 - val_loss: 2.1468 - val_mean_squared_error: 6.8449\n",
      "Epoch 443/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8675 - mean_squared_error: 5.5368 - val_loss: 2.1431 - val_mean_squared_error: 6.8371\n",
      "Epoch 444/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8698 - mean_squared_error: 5.5588 - val_loss: 2.1466 - val_mean_squared_error: 6.8461\n",
      "Epoch 445/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8701 - mean_squared_error: 5.5701 - val_loss: 2.1424 - val_mean_squared_error: 6.8338\n",
      "Epoch 446/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8731 - mean_squared_error: 5.5660 - val_loss: 2.1477 - val_mean_squared_error: 6.8580\n",
      "Epoch 447/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8648 - mean_squared_error: 5.5222 - val_loss: 2.1435 - val_mean_squared_error: 6.8529\n",
      "Epoch 448/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8711 - mean_squared_error: 5.5632 - val_loss: 2.1451 - val_mean_squared_error: 6.8395\n",
      "Epoch 449/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.8745 - mean_squared_error: 5.5736 - val_loss: 2.1525 - val_mean_squared_error: 6.8872\n",
      "Epoch 450/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8622 - mean_squared_error: 5.5170 - val_loss: 2.1499 - val_mean_squared_error: 6.8697\n",
      "Epoch 451/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8634 - mean_squared_error: 5.5238 - val_loss: 2.1432 - val_mean_squared_error: 6.8380\n",
      "Epoch 452/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8671 - mean_squared_error: 5.5572 - val_loss: 2.1463 - val_mean_squared_error: 6.8613\n",
      "Epoch 453/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8741 - mean_squared_error: 5.5728 - val_loss: 2.1403 - val_mean_squared_error: 6.8313\n",
      "Epoch 454/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8680 - mean_squared_error: 5.5477 - val_loss: 2.1427 - val_mean_squared_error: 6.8464\n",
      "Epoch 455/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8665 - mean_squared_error: 5.5480 - val_loss: 2.1466 - val_mean_squared_error: 6.8697\n",
      "Epoch 456/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8631 - mean_squared_error: 5.5351 - val_loss: 2.1511 - val_mean_squared_error: 6.8808\n",
      "Epoch 457/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8698 - mean_squared_error: 5.5391 - val_loss: 2.1449 - val_mean_squared_error: 6.8607\n",
      "Epoch 458/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8744 - mean_squared_error: 5.5599 - val_loss: 2.1413 - val_mean_squared_error: 6.8309\n",
      "Epoch 459/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8610 - mean_squared_error: 5.5032 - val_loss: 2.1473 - val_mean_squared_error: 6.8786\n",
      "Epoch 460/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8577 - mean_squared_error: 5.4926 - val_loss: 2.1426 - val_mean_squared_error: 6.8545\n",
      "Epoch 461/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8688 - mean_squared_error: 5.5546 - val_loss: 2.1509 - val_mean_squared_error: 6.8792\n",
      "Epoch 462/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8656 - mean_squared_error: 5.5352 - val_loss: 2.1455 - val_mean_squared_error: 6.8723\n",
      "Epoch 463/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8707 - mean_squared_error: 5.5702 - val_loss: 2.1480 - val_mean_squared_error: 6.8837\n",
      "Epoch 464/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8682 - mean_squared_error: 5.5595 - val_loss: 2.1458 - val_mean_squared_error: 6.8635\n",
      "Epoch 465/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8664 - mean_squared_error: 5.5345 - val_loss: 2.1432 - val_mean_squared_error: 6.8908\n",
      "Epoch 466/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8682 - mean_squared_error: 5.5621 - val_loss: 2.1446 - val_mean_squared_error: 6.8533\n",
      "Epoch 467/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8635 - mean_squared_error: 5.5214 - val_loss: 2.1422 - val_mean_squared_error: 6.8310\n",
      "Epoch 468/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8643 - mean_squared_error: 5.5435 - val_loss: 2.1389 - val_mean_squared_error: 6.8209\n",
      "Epoch 469/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8703 - mean_squared_error: 5.5427 - val_loss: 2.1452 - val_mean_squared_error: 6.8377\n",
      "Epoch 470/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8612 - mean_squared_error: 5.4966 - val_loss: 2.1461 - val_mean_squared_error: 6.8863\n",
      "Epoch 471/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8619 - mean_squared_error: 5.5187 - val_loss: 2.1418 - val_mean_squared_error: 6.8274\n",
      "Epoch 472/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8619 - mean_squared_error: 5.5270 - val_loss: 2.1440 - val_mean_squared_error: 6.8578\n",
      "Epoch 473/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8649 - mean_squared_error: 5.5450 - val_loss: 2.1489 - val_mean_squared_error: 6.8923\n",
      "Epoch 474/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8572 - mean_squared_error: 5.5018 - val_loss: 2.1422 - val_mean_squared_error: 6.8677\n",
      "Epoch 475/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8579 - mean_squared_error: 5.5227 - val_loss: 2.1406 - val_mean_squared_error: 6.8399\n",
      "Epoch 476/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8643 - mean_squared_error: 5.5530 - val_loss: 2.1475 - val_mean_squared_error: 6.8824\n",
      "Epoch 477/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8598 - mean_squared_error: 5.5205 - val_loss: 2.1435 - val_mean_squared_error: 6.8618\n",
      "Epoch 478/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8550 - mean_squared_error: 5.4778 - val_loss: 2.1397 - val_mean_squared_error: 6.8435\n",
      "Epoch 479/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8702 - mean_squared_error: 5.5792 - val_loss: 2.1458 - val_mean_squared_error: 6.8418\n",
      "Epoch 480/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8623 - mean_squared_error: 5.5033 - val_loss: 2.1461 - val_mean_squared_error: 6.8561\n",
      "Epoch 481/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8544 - mean_squared_error: 5.5072 - val_loss: 2.1480 - val_mean_squared_error: 6.8817\n",
      "Epoch 482/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8621 - mean_squared_error: 5.5277 - val_loss: 2.1370 - val_mean_squared_error: 6.8045\n",
      "Epoch 483/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8681 - mean_squared_error: 5.5466 - val_loss: 2.1452 - val_mean_squared_error: 6.8541\n",
      "Epoch 484/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8526 - mean_squared_error: 5.4815 - val_loss: 2.1469 - val_mean_squared_error: 6.8628\n",
      "Epoch 485/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8627 - mean_squared_error: 5.5121 - val_loss: 2.1434 - val_mean_squared_error: 6.8373\n",
      "Epoch 486/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8647 - mean_squared_error: 5.5173 - val_loss: 2.1456 - val_mean_squared_error: 6.8618\n",
      "Epoch 487/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8638 - mean_squared_error: 5.5269 - val_loss: 2.1476 - val_mean_squared_error: 6.8956\n",
      "Epoch 488/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8588 - mean_squared_error: 5.5129 - val_loss: 2.1448 - val_mean_squared_error: 6.8654\n",
      "Epoch 489/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8594 - mean_squared_error: 5.5033 - val_loss: 2.1439 - val_mean_squared_error: 6.8381\n",
      "Epoch 490/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8543 - mean_squared_error: 5.4624 - val_loss: 2.1531 - val_mean_squared_error: 6.9025\n",
      "Epoch 491/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8573 - mean_squared_error: 5.5025 - val_loss: 2.1441 - val_mean_squared_error: 6.8885\n",
      "Epoch 492/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8559 - mean_squared_error: 5.4852 - val_loss: 2.1481 - val_mean_squared_error: 6.8651\n",
      "Epoch 493/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8566 - mean_squared_error: 5.5038 - val_loss: 2.1545 - val_mean_squared_error: 6.9035\n",
      "Epoch 494/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8584 - mean_squared_error: 5.4830 - val_loss: 2.1528 - val_mean_squared_error: 6.9288\n",
      "Epoch 495/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8595 - mean_squared_error: 5.5152 - val_loss: 2.1426 - val_mean_squared_error: 6.8505\n",
      "Epoch 496/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8588 - mean_squared_error: 5.5186 - val_loss: 2.1461 - val_mean_squared_error: 6.8689\n",
      "Epoch 497/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8510 - mean_squared_error: 5.4875 - val_loss: 2.1488 - val_mean_squared_error: 6.9023\n",
      "Epoch 498/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8617 - mean_squared_error: 5.5065 - val_loss: 2.1449 - val_mean_squared_error: 6.8521\n",
      "Epoch 499/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8541 - mean_squared_error: 5.4826 - val_loss: 2.1431 - val_mean_squared_error: 6.8411\n",
      "Epoch 500/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8633 - mean_squared_error: 5.5268 - val_loss: 2.1450 - val_mean_squared_error: 6.8668\n",
      "Epoch 501/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8519 - mean_squared_error: 5.4725 - val_loss: 2.1464 - val_mean_squared_error: 6.8640\n",
      "Epoch 502/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8528 - mean_squared_error: 5.4929 - val_loss: 2.1505 - val_mean_squared_error: 6.9222\n",
      "Epoch 503/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8562 - mean_squared_error: 5.4808 - val_loss: 2.1435 - val_mean_squared_error: 6.8516\n",
      "Epoch 504/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8496 - mean_squared_error: 5.4621 - val_loss: 2.1464 - val_mean_squared_error: 6.8718\n",
      "Epoch 505/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8556 - mean_squared_error: 5.4898 - val_loss: 2.1467 - val_mean_squared_error: 6.8696\n",
      "Epoch 506/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8546 - mean_squared_error: 5.4979 - val_loss: 2.1438 - val_mean_squared_error: 6.8532\n",
      "Epoch 507/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8511 - mean_squared_error: 5.4714 - val_loss: 2.1464 - val_mean_squared_error: 6.8620\n",
      "Epoch 508/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8533 - mean_squared_error: 5.4739 - val_loss: 2.1482 - val_mean_squared_error: 6.8728\n",
      "Epoch 509/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8504 - mean_squared_error: 5.4581 - val_loss: 2.1486 - val_mean_squared_error: 6.8747\n",
      "Epoch 510/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8526 - mean_squared_error: 5.4711 - val_loss: 2.1495 - val_mean_squared_error: 6.8902\n",
      "Epoch 511/1000\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 1.8589 - mean_squared_error: 5.5132 - val_loss: 2.1417 - val_mean_squared_error: 6.8583\n",
      "Epoch 512/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8467 - mean_squared_error: 5.4719 - val_loss: 2.1468 - val_mean_squared_error: 6.8737\n",
      "Epoch 513/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8491 - mean_squared_error: 5.4489 - val_loss: 2.1477 - val_mean_squared_error: 6.8653\n",
      "Epoch 514/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8572 - mean_squared_error: 5.5024 - val_loss: 2.1422 - val_mean_squared_error: 6.8604\n",
      "Epoch 515/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8456 - mean_squared_error: 5.4691 - val_loss: 2.1477 - val_mean_squared_error: 6.8670\n",
      "Epoch 516/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8512 - mean_squared_error: 5.4747 - val_loss: 2.1422 - val_mean_squared_error: 6.8648\n",
      "Epoch 517/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8462 - mean_squared_error: 5.4490 - val_loss: 2.1460 - val_mean_squared_error: 6.8704\n",
      "Epoch 518/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8614 - mean_squared_error: 5.5220 - val_loss: 2.1474 - val_mean_squared_error: 6.8437\n",
      "Epoch 519/1000\n",
      "39/39 [==============================] - 1s 20ms/step - loss: 1.8504 - mean_squared_error: 5.4658 - val_loss: 2.1458 - val_mean_squared_error: 6.8408\n",
      "Epoch 520/1000\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 1.8471 - mean_squared_error: 5.4179 - val_loss: 2.1473 - val_mean_squared_error: 6.8930\n",
      "Epoch 521/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8456 - mean_squared_error: 5.4471 - val_loss: 2.1410 - val_mean_squared_error: 6.8280\n",
      "Epoch 522/1000\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 1.8542 - mean_squared_error: 5.4868 - val_loss: 2.1453 - val_mean_squared_error: 6.8640\n",
      "Epoch 523/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8474 - mean_squared_error: 5.4550 - val_loss: 2.1512 - val_mean_squared_error: 6.8705\n",
      "Epoch 524/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8535 - mean_squared_error: 5.4649 - val_loss: 2.1451 - val_mean_squared_error: 6.8673\n",
      "Epoch 525/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8593 - mean_squared_error: 5.5079 - val_loss: 2.1518 - val_mean_squared_error: 6.8831\n",
      "Epoch 526/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8578 - mean_squared_error: 5.4948 - val_loss: 2.1496 - val_mean_squared_error: 6.8870\n",
      "Epoch 527/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8489 - mean_squared_error: 5.4745 - val_loss: 2.1484 - val_mean_squared_error: 6.8664\n",
      "Epoch 528/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8510 - mean_squared_error: 5.4655 - val_loss: 2.1541 - val_mean_squared_error: 6.9020\n",
      "Epoch 529/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8516 - mean_squared_error: 5.4546 - val_loss: 2.1442 - val_mean_squared_error: 6.8529\n",
      "Epoch 530/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8464 - mean_squared_error: 5.4339 - val_loss: 2.1456 - val_mean_squared_error: 6.8567\n",
      "Epoch 531/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8485 - mean_squared_error: 5.4519 - val_loss: 2.1449 - val_mean_squared_error: 6.8718\n",
      "Epoch 532/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8427 - mean_squared_error: 5.4280 - val_loss: 2.1493 - val_mean_squared_error: 6.8961\n",
      "Epoch 533/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8487 - mean_squared_error: 5.4584 - val_loss: 2.1459 - val_mean_squared_error: 6.8739\n",
      "Epoch 534/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8454 - mean_squared_error: 5.4254 - val_loss: 2.1434 - val_mean_squared_error: 6.8443\n",
      "Epoch 535/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8424 - mean_squared_error: 5.4375 - val_loss: 2.1492 - val_mean_squared_error: 6.8572\n",
      "Epoch 536/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8478 - mean_squared_error: 5.4409 - val_loss: 2.1500 - val_mean_squared_error: 6.9044\n",
      "Epoch 537/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8458 - mean_squared_error: 5.4443 - val_loss: 2.1479 - val_mean_squared_error: 6.8686\n",
      "Epoch 538/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8513 - mean_squared_error: 5.4617 - val_loss: 2.1499 - val_mean_squared_error: 6.8885\n",
      "Epoch 539/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8526 - mean_squared_error: 5.4753 - val_loss: 2.1437 - val_mean_squared_error: 6.8614\n",
      "Epoch 540/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8428 - mean_squared_error: 5.4151 - val_loss: 2.1520 - val_mean_squared_error: 6.9191\n",
      "Epoch 541/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8458 - mean_squared_error: 5.4143 - val_loss: 2.1428 - val_mean_squared_error: 6.8597\n",
      "Epoch 542/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.8349 - mean_squared_error: 5.3924 - val_loss: 2.1519 - val_mean_squared_error: 6.8820\n",
      "Epoch 543/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8413 - mean_squared_error: 5.4155 - val_loss: 2.1508 - val_mean_squared_error: 6.9102\n",
      "Epoch 544/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8432 - mean_squared_error: 5.4386 - val_loss: 2.1486 - val_mean_squared_error: 6.8936\n",
      "Epoch 545/1000\n",
      "39/39 [==============================] - 1s 18ms/step - loss: 1.8450 - mean_squared_error: 5.4253 - val_loss: 2.1448 - val_mean_squared_error: 6.8578\n",
      "Epoch 546/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8479 - mean_squared_error: 5.4535 - val_loss: 2.1483 - val_mean_squared_error: 6.8916\n",
      "Epoch 547/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8508 - mean_squared_error: 5.4496 - val_loss: 2.1510 - val_mean_squared_error: 6.9191\n",
      "Epoch 548/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8502 - mean_squared_error: 5.4460 - val_loss: 2.1461 - val_mean_squared_error: 6.8776\n",
      "Epoch 549/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8437 - mean_squared_error: 5.4146 - val_loss: 2.1502 - val_mean_squared_error: 6.8907\n",
      "Epoch 550/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8401 - mean_squared_error: 5.4158 - val_loss: 2.1510 - val_mean_squared_error: 6.9027\n",
      "Epoch 551/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8496 - mean_squared_error: 5.4571 - val_loss: 2.1508 - val_mean_squared_error: 6.8839\n",
      "Epoch 552/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8527 - mean_squared_error: 5.4405 - val_loss: 2.1532 - val_mean_squared_error: 6.9032\n",
      "Epoch 553/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8539 - mean_squared_error: 5.4653 - val_loss: 2.1511 - val_mean_squared_error: 6.8910\n",
      "Epoch 554/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8412 - mean_squared_error: 5.4304 - val_loss: 2.1421 - val_mean_squared_error: 6.8472\n",
      "Epoch 555/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8548 - mean_squared_error: 5.4905 - val_loss: 2.1503 - val_mean_squared_error: 6.8832\n",
      "Epoch 556/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8448 - mean_squared_error: 5.4397 - val_loss: 2.1459 - val_mean_squared_error: 6.8560\n",
      "Epoch 557/1000\n",
      "39/39 [==============================] - 1s 21ms/step - loss: 1.8485 - mean_squared_error: 5.4341 - val_loss: 2.1500 - val_mean_squared_error: 6.8888\n",
      "Epoch 558/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8491 - mean_squared_error: 5.4532 - val_loss: 2.1484 - val_mean_squared_error: 6.9023\n",
      "Epoch 559/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8434 - mean_squared_error: 5.4469 - val_loss: 2.1489 - val_mean_squared_error: 6.8930\n",
      "Epoch 560/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8429 - mean_squared_error: 5.4361 - val_loss: 2.1432 - val_mean_squared_error: 6.8544\n",
      "Epoch 561/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8348 - mean_squared_error: 5.4059 - val_loss: 2.1520 - val_mean_squared_error: 6.9136\n",
      "Epoch 562/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8380 - mean_squared_error: 5.4220 - val_loss: 2.1546 - val_mean_squared_error: 6.9212\n",
      "Epoch 563/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8433 - mean_squared_error: 5.4381 - val_loss: 2.1471 - val_mean_squared_error: 6.8861\n",
      "Epoch 564/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8495 - mean_squared_error: 5.4506 - val_loss: 2.1456 - val_mean_squared_error: 6.8600\n",
      "Epoch 565/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8389 - mean_squared_error: 5.4117 - val_loss: 2.1474 - val_mean_squared_error: 6.8896\n",
      "Epoch 566/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8355 - mean_squared_error: 5.3947 - val_loss: 2.1454 - val_mean_squared_error: 6.8597\n",
      "Epoch 567/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8435 - mean_squared_error: 5.4491 - val_loss: 2.1515 - val_mean_squared_error: 6.8918\n",
      "Epoch 568/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8387 - mean_squared_error: 5.4082 - val_loss: 2.1482 - val_mean_squared_error: 6.8506\n",
      "Epoch 569/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8445 - mean_squared_error: 5.4288 - val_loss: 2.1558 - val_mean_squared_error: 6.8967\n",
      "Epoch 570/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8413 - mean_squared_error: 5.4349 - val_loss: 2.1554 - val_mean_squared_error: 6.9224\n",
      "Epoch 571/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8433 - mean_squared_error: 5.4378 - val_loss: 2.1485 - val_mean_squared_error: 6.8944\n",
      "Epoch 572/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8441 - mean_squared_error: 5.4255 - val_loss: 2.1503 - val_mean_squared_error: 6.8863\n",
      "Epoch 573/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8322 - mean_squared_error: 5.3872 - val_loss: 2.1496 - val_mean_squared_error: 6.8866\n",
      "Epoch 574/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8440 - mean_squared_error: 5.4225 - val_loss: 2.1470 - val_mean_squared_error: 6.8685\n",
      "Epoch 575/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8399 - mean_squared_error: 5.3906 - val_loss: 2.1447 - val_mean_squared_error: 6.8576\n",
      "Epoch 576/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8404 - mean_squared_error: 5.3934 - val_loss: 2.1504 - val_mean_squared_error: 6.9076\n",
      "Epoch 577/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.8466 - mean_squared_error: 5.4398 - val_loss: 2.1462 - val_mean_squared_error: 6.8846\n",
      "Epoch 578/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8411 - mean_squared_error: 5.3989 - val_loss: 2.1527 - val_mean_squared_error: 6.8961\n",
      "Epoch 579/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8344 - mean_squared_error: 5.3915 - val_loss: 2.1499 - val_mean_squared_error: 6.9009\n",
      "Epoch 580/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8497 - mean_squared_error: 5.4537 - val_loss: 2.1485 - val_mean_squared_error: 6.9110\n",
      "Epoch 581/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8426 - mean_squared_error: 5.4435 - val_loss: 2.1495 - val_mean_squared_error: 6.8857\n",
      "Epoch 582/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8347 - mean_squared_error: 5.3761 - val_loss: 2.1517 - val_mean_squared_error: 6.9067\n",
      "Epoch 583/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8354 - mean_squared_error: 5.3976 - val_loss: 2.1507 - val_mean_squared_error: 6.9145\n",
      "Epoch 584/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8483 - mean_squared_error: 5.4483 - val_loss: 2.1536 - val_mean_squared_error: 6.9150\n",
      "Epoch 585/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8340 - mean_squared_error: 5.3977 - val_loss: 2.1507 - val_mean_squared_error: 6.9022\n",
      "Epoch 586/1000\n",
      "39/39 [==============================] - 1s 17ms/step - loss: 1.8373 - mean_squared_error: 5.3863 - val_loss: 2.1545 - val_mean_squared_error: 6.9462\n",
      "Epoch 587/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8328 - mean_squared_error: 5.3697 - val_loss: 2.1469 - val_mean_squared_error: 6.8813\n",
      "Epoch 588/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8382 - mean_squared_error: 5.4042 - val_loss: 2.1540 - val_mean_squared_error: 6.9271\n",
      "Epoch 589/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8383 - mean_squared_error: 5.4009 - val_loss: 2.1465 - val_mean_squared_error: 6.8762\n",
      "Epoch 590/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8405 - mean_squared_error: 5.4062 - val_loss: 2.1492 - val_mean_squared_error: 6.8887\n",
      "Epoch 591/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8386 - mean_squared_error: 5.3918 - val_loss: 2.1559 - val_mean_squared_error: 6.9228\n",
      "Epoch 592/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8343 - mean_squared_error: 5.4007 - val_loss: 2.1524 - val_mean_squared_error: 6.8963\n",
      "Epoch 593/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8356 - mean_squared_error: 5.3974 - val_loss: 2.1551 - val_mean_squared_error: 6.9073\n",
      "Epoch 594/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8319 - mean_squared_error: 5.3755 - val_loss: 2.1548 - val_mean_squared_error: 6.9039\n",
      "Epoch 595/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8378 - mean_squared_error: 5.4100 - val_loss: 2.1503 - val_mean_squared_error: 6.8891\n",
      "Epoch 596/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8340 - mean_squared_error: 5.3940 - val_loss: 2.1574 - val_mean_squared_error: 6.9602\n",
      "Epoch 597/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8314 - mean_squared_error: 5.3792 - val_loss: 2.1501 - val_mean_squared_error: 6.9069\n",
      "Epoch 598/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8276 - mean_squared_error: 5.3540 - val_loss: 2.1542 - val_mean_squared_error: 6.9219\n",
      "Epoch 599/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8340 - mean_squared_error: 5.3878 - val_loss: 2.1495 - val_mean_squared_error: 6.8884\n",
      "Epoch 600/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8266 - mean_squared_error: 5.3508 - val_loss: 2.1560 - val_mean_squared_error: 6.9413\n",
      "Epoch 601/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8415 - mean_squared_error: 5.3966 - val_loss: 2.1539 - val_mean_squared_error: 6.9252\n",
      "Epoch 602/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8438 - mean_squared_error: 5.4293 - val_loss: 2.1504 - val_mean_squared_error: 6.8768\n",
      "Epoch 603/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8297 - mean_squared_error: 5.3635 - val_loss: 2.1482 - val_mean_squared_error: 6.8902\n",
      "Epoch 604/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8361 - mean_squared_error: 5.3884 - val_loss: 2.1516 - val_mean_squared_error: 6.8990\n",
      "Epoch 605/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8360 - mean_squared_error: 5.3999 - val_loss: 2.1521 - val_mean_squared_error: 6.9095\n",
      "Epoch 606/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8322 - mean_squared_error: 5.3625 - val_loss: 2.1488 - val_mean_squared_error: 6.8977\n",
      "Epoch 607/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8322 - mean_squared_error: 5.3500 - val_loss: 2.1527 - val_mean_squared_error: 6.8930\n",
      "Epoch 608/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8350 - mean_squared_error: 5.3981 - val_loss: 2.1477 - val_mean_squared_error: 6.8832\n",
      "Epoch 609/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8347 - mean_squared_error: 5.3849 - val_loss: 2.1508 - val_mean_squared_error: 6.9038\n",
      "Epoch 610/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8311 - mean_squared_error: 5.3737 - val_loss: 2.1505 - val_mean_squared_error: 6.8945\n",
      "Epoch 611/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8354 - mean_squared_error: 5.3749 - val_loss: 2.1513 - val_mean_squared_error: 6.9090\n",
      "Epoch 612/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8397 - mean_squared_error: 5.4084 - val_loss: 2.1566 - val_mean_squared_error: 6.9220\n",
      "Epoch 613/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8317 - mean_squared_error: 5.3662 - val_loss: 2.1542 - val_mean_squared_error: 6.9259\n",
      "Epoch 614/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8318 - mean_squared_error: 5.3775 - val_loss: 2.1512 - val_mean_squared_error: 6.8852\n",
      "Epoch 615/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8358 - mean_squared_error: 5.3845 - val_loss: 2.1576 - val_mean_squared_error: 6.9361\n",
      "Epoch 616/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8268 - mean_squared_error: 5.3667 - val_loss: 2.1475 - val_mean_squared_error: 6.8844\n",
      "Epoch 617/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8347 - mean_squared_error: 5.3873 - val_loss: 2.1512 - val_mean_squared_error: 6.8905\n",
      "Epoch 618/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8348 - mean_squared_error: 5.3801 - val_loss: 2.1477 - val_mean_squared_error: 6.8875\n",
      "Epoch 619/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8284 - mean_squared_error: 5.3543 - val_loss: 2.1542 - val_mean_squared_error: 6.8951\n",
      "Epoch 620/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8295 - mean_squared_error: 5.3607 - val_loss: 2.1495 - val_mean_squared_error: 6.8930\n",
      "Epoch 621/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8286 - mean_squared_error: 5.3529 - val_loss: 2.1528 - val_mean_squared_error: 6.9169\n",
      "Epoch 622/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8306 - mean_squared_error: 5.3696 - val_loss: 2.1565 - val_mean_squared_error: 6.9330\n",
      "Epoch 623/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8312 - mean_squared_error: 5.3653 - val_loss: 2.1569 - val_mean_squared_error: 6.9242\n",
      "Epoch 624/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8239 - mean_squared_error: 5.2976 - val_loss: 2.1500 - val_mean_squared_error: 6.9195\n",
      "Epoch 625/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8311 - mean_squared_error: 5.3607 - val_loss: 2.1531 - val_mean_squared_error: 6.9214\n",
      "Epoch 626/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8333 - mean_squared_error: 5.3530 - val_loss: 2.1580 - val_mean_squared_error: 6.9384\n",
      "Epoch 627/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8287 - mean_squared_error: 5.3634 - val_loss: 2.1568 - val_mean_squared_error: 6.9313\n",
      "Epoch 628/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8321 - mean_squared_error: 5.3657 - val_loss: 2.1569 - val_mean_squared_error: 6.9607\n",
      "Epoch 629/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8318 - mean_squared_error: 5.3921 - val_loss: 2.1560 - val_mean_squared_error: 6.9338\n",
      "Epoch 630/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8398 - mean_squared_error: 5.4023 - val_loss: 2.1573 - val_mean_squared_error: 6.9502\n",
      "Epoch 631/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8221 - mean_squared_error: 5.3210 - val_loss: 2.1553 - val_mean_squared_error: 6.9195\n",
      "Epoch 632/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8324 - mean_squared_error: 5.3689 - val_loss: 2.1523 - val_mean_squared_error: 6.9044\n",
      "Epoch 633/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8212 - mean_squared_error: 5.3081 - val_loss: 2.1568 - val_mean_squared_error: 6.9590\n",
      "Epoch 634/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8249 - mean_squared_error: 5.3193 - val_loss: 2.1546 - val_mean_squared_error: 6.9296\n",
      "Epoch 635/1000\n",
      "39/39 [==============================] - 1s 16ms/step - loss: 1.8400 - mean_squared_error: 5.4165 - val_loss: 2.1542 - val_mean_squared_error: 6.9310\n",
      "Epoch 636/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8245 - mean_squared_error: 5.3265 - val_loss: 2.1540 - val_mean_squared_error: 6.9155\n",
      "Epoch 637/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8258 - mean_squared_error: 5.3397 - val_loss: 2.1533 - val_mean_squared_error: 6.8953\n",
      "Epoch 638/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8309 - mean_squared_error: 5.3548 - val_loss: 2.1544 - val_mean_squared_error: 6.9223\n",
      "Epoch 639/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8230 - mean_squared_error: 5.3077 - val_loss: 2.1549 - val_mean_squared_error: 6.9418\n",
      "Epoch 640/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8338 - mean_squared_error: 5.3706 - val_loss: 2.1547 - val_mean_squared_error: 6.9428\n",
      "Epoch 641/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8253 - mean_squared_error: 5.3437 - val_loss: 2.1574 - val_mean_squared_error: 6.9331\n",
      "Epoch 642/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8320 - mean_squared_error: 5.3602 - val_loss: 2.1545 - val_mean_squared_error: 6.9281\n",
      "Epoch 643/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8227 - mean_squared_error: 5.3312 - val_loss: 2.1582 - val_mean_squared_error: 6.9574\n",
      "Epoch 644/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8301 - mean_squared_error: 5.3661 - val_loss: 2.1506 - val_mean_squared_error: 6.8955\n",
      "Epoch 645/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8176 - mean_squared_error: 5.3201 - val_loss: 2.1582 - val_mean_squared_error: 6.9551\n",
      "Epoch 646/1000\n",
      "39/39 [==============================] - 1s 15ms/step - loss: 1.8256 - mean_squared_error: 5.3238 - val_loss: 2.1599 - val_mean_squared_error: 6.9496\n",
      "Epoch 647/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8286 - mean_squared_error: 5.3748 - val_loss: 2.1546 - val_mean_squared_error: 6.9184\n",
      "Epoch 648/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8251 - mean_squared_error: 5.3458 - val_loss: 2.1568 - val_mean_squared_error: 6.9127\n",
      "Epoch 649/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8247 - mean_squared_error: 5.3374 - val_loss: 2.1535 - val_mean_squared_error: 6.8933\n",
      "Epoch 650/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8311 - mean_squared_error: 5.3697 - val_loss: 2.1516 - val_mean_squared_error: 6.9436\n",
      "Epoch 651/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8216 - mean_squared_error: 5.3189 - val_loss: 2.1488 - val_mean_squared_error: 6.9262\n",
      "Epoch 652/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8361 - mean_squared_error: 5.3832 - val_loss: 2.1561 - val_mean_squared_error: 6.9661\n",
      "Epoch 653/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8217 - mean_squared_error: 5.3103 - val_loss: 2.1607 - val_mean_squared_error: 6.9847\n",
      "Epoch 654/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8293 - mean_squared_error: 5.3404 - val_loss: 2.1578 - val_mean_squared_error: 6.9599\n",
      "Epoch 655/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8227 - mean_squared_error: 5.3199 - val_loss: 2.1543 - val_mean_squared_error: 6.9485\n",
      "Epoch 656/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8316 - mean_squared_error: 5.3527 - val_loss: 2.1515 - val_mean_squared_error: 6.9078\n",
      "Epoch 657/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8194 - mean_squared_error: 5.3190 - val_loss: 2.1538 - val_mean_squared_error: 6.9322\n",
      "Epoch 658/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8311 - mean_squared_error: 5.3837 - val_loss: 2.1556 - val_mean_squared_error: 6.9419\n",
      "Epoch 659/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8214 - mean_squared_error: 5.3013 - val_loss: 2.1545 - val_mean_squared_error: 6.9279\n",
      "Epoch 660/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8186 - mean_squared_error: 5.3065 - val_loss: 2.1558 - val_mean_squared_error: 6.9521\n",
      "Epoch 661/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8277 - mean_squared_error: 5.3571 - val_loss: 2.1529 - val_mean_squared_error: 6.9257\n",
      "Epoch 662/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8288 - mean_squared_error: 5.3457 - val_loss: 2.1578 - val_mean_squared_error: 6.9396\n",
      "Epoch 663/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8229 - mean_squared_error: 5.3279 - val_loss: 2.1532 - val_mean_squared_error: 6.8962\n",
      "Epoch 664/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8242 - mean_squared_error: 5.3400 - val_loss: 2.1591 - val_mean_squared_error: 6.9550\n",
      "Epoch 665/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8310 - mean_squared_error: 5.3588 - val_loss: 2.1493 - val_mean_squared_error: 6.9238\n",
      "Epoch 666/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8235 - mean_squared_error: 5.3121 - val_loss: 2.1565 - val_mean_squared_error: 6.9413\n",
      "Epoch 667/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8186 - mean_squared_error: 5.2943 - val_loss: 2.1584 - val_mean_squared_error: 6.9485\n",
      "Epoch 668/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8211 - mean_squared_error: 5.3128 - val_loss: 2.1593 - val_mean_squared_error: 6.9487\n",
      "Epoch 669/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8167 - mean_squared_error: 5.3110 - val_loss: 2.1580 - val_mean_squared_error: 6.9423\n",
      "Epoch 670/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8106 - mean_squared_error: 5.2646 - val_loss: 2.1551 - val_mean_squared_error: 6.9214\n",
      "Epoch 671/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8227 - mean_squared_error: 5.3010 - val_loss: 2.1610 - val_mean_squared_error: 6.9602\n",
      "Epoch 672/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8240 - mean_squared_error: 5.3249 - val_loss: 2.1619 - val_mean_squared_error: 6.9601\n",
      "Epoch 673/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8202 - mean_squared_error: 5.3081 - val_loss: 2.1596 - val_mean_squared_error: 6.9063\n",
      "Epoch 674/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8263 - mean_squared_error: 5.3327 - val_loss: 2.1607 - val_mean_squared_error: 6.9277\n",
      "Epoch 675/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8274 - mean_squared_error: 5.3313 - val_loss: 2.1553 - val_mean_squared_error: 6.9051\n",
      "Epoch 676/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8237 - mean_squared_error: 5.3242 - val_loss: 2.1576 - val_mean_squared_error: 6.9411\n",
      "Epoch 677/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8244 - mean_squared_error: 5.3153 - val_loss: 2.1575 - val_mean_squared_error: 6.9325\n",
      "Epoch 678/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8215 - mean_squared_error: 5.3106 - val_loss: 2.1563 - val_mean_squared_error: 6.9408\n",
      "Epoch 679/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8235 - mean_squared_error: 5.3231 - val_loss: 2.1548 - val_mean_squared_error: 6.9068\n",
      "Epoch 680/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8190 - mean_squared_error: 5.3032 - val_loss: 2.1552 - val_mean_squared_error: 6.9291\n",
      "Epoch 681/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8219 - mean_squared_error: 5.3161 - val_loss: 2.1624 - val_mean_squared_error: 6.9498\n",
      "Epoch 682/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8151 - mean_squared_error: 5.2711 - val_loss: 2.1549 - val_mean_squared_error: 6.9336\n",
      "Epoch 683/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8223 - mean_squared_error: 5.3132 - val_loss: 2.1581 - val_mean_squared_error: 6.9510\n",
      "Epoch 684/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8239 - mean_squared_error: 5.3297 - val_loss: 2.1593 - val_mean_squared_error: 6.9735\n",
      "Epoch 685/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8189 - mean_squared_error: 5.3172 - val_loss: 2.1558 - val_mean_squared_error: 6.9189\n",
      "Epoch 686/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8218 - mean_squared_error: 5.3302 - val_loss: 2.1585 - val_mean_squared_error: 6.9598\n",
      "Epoch 687/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8194 - mean_squared_error: 5.3009 - val_loss: 2.1612 - val_mean_squared_error: 6.9645\n",
      "Epoch 688/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8201 - mean_squared_error: 5.3104 - val_loss: 2.1610 - val_mean_squared_error: 6.9819\n",
      "Epoch 689/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8320 - mean_squared_error: 5.3532 - val_loss: 2.1553 - val_mean_squared_error: 6.9103\n",
      "Epoch 690/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8165 - mean_squared_error: 5.2977 - val_loss: 2.1573 - val_mean_squared_error: 6.9341\n",
      "Epoch 691/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8144 - mean_squared_error: 5.2749 - val_loss: 2.1558 - val_mean_squared_error: 6.9366\n",
      "Epoch 692/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8158 - mean_squared_error: 5.2971 - val_loss: 2.1516 - val_mean_squared_error: 6.9263\n",
      "Epoch 693/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8171 - mean_squared_error: 5.2927 - val_loss: 2.1572 - val_mean_squared_error: 6.9218\n",
      "Epoch 694/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8207 - mean_squared_error: 5.3274 - val_loss: 2.1590 - val_mean_squared_error: 6.9617\n",
      "Epoch 695/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8176 - mean_squared_error: 5.3074 - val_loss: 2.1590 - val_mean_squared_error: 6.9586\n",
      "Epoch 696/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8186 - mean_squared_error: 5.3293 - val_loss: 2.1634 - val_mean_squared_error: 6.9721\n",
      "Epoch 697/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8177 - mean_squared_error: 5.2976 - val_loss: 2.1548 - val_mean_squared_error: 6.9244\n",
      "Epoch 698/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8208 - mean_squared_error: 5.2998 - val_loss: 2.1591 - val_mean_squared_error: 6.9440\n",
      "Epoch 699/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8160 - mean_squared_error: 5.2783 - val_loss: 2.1622 - val_mean_squared_error: 6.9751\n",
      "Epoch 700/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8253 - mean_squared_error: 5.3049 - val_loss: 2.1658 - val_mean_squared_error: 6.9877\n",
      "Epoch 701/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8159 - mean_squared_error: 5.2743 - val_loss: 2.1595 - val_mean_squared_error: 6.9498\n",
      "Epoch 702/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8183 - mean_squared_error: 5.2920 - val_loss: 2.1574 - val_mean_squared_error: 6.9449\n",
      "Epoch 703/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8240 - mean_squared_error: 5.3355 - val_loss: 2.1588 - val_mean_squared_error: 6.9478\n",
      "Epoch 704/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8207 - mean_squared_error: 5.2886 - val_loss: 2.1647 - val_mean_squared_error: 6.9959\n",
      "Epoch 705/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8235 - mean_squared_error: 5.3306 - val_loss: 2.1631 - val_mean_squared_error: 6.9702\n",
      "Epoch 706/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8138 - mean_squared_error: 5.2897 - val_loss: 2.1619 - val_mean_squared_error: 6.9775\n",
      "Epoch 707/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8212 - mean_squared_error: 5.3278 - val_loss: 2.1623 - val_mean_squared_error: 6.9596\n",
      "Epoch 708/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8156 - mean_squared_error: 5.3015 - val_loss: 2.1580 - val_mean_squared_error: 6.9483\n",
      "Epoch 709/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8182 - mean_squared_error: 5.3119 - val_loss: 2.1612 - val_mean_squared_error: 6.9762\n",
      "Epoch 710/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8265 - mean_squared_error: 5.3373 - val_loss: 2.1593 - val_mean_squared_error: 6.9545\n",
      "Epoch 711/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8192 - mean_squared_error: 5.2974 - val_loss: 2.1585 - val_mean_squared_error: 6.9414\n",
      "Epoch 712/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8218 - mean_squared_error: 5.3089 - val_loss: 2.1626 - val_mean_squared_error: 6.9589\n",
      "Epoch 713/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8188 - mean_squared_error: 5.2972 - val_loss: 2.1602 - val_mean_squared_error: 6.9557\n",
      "Epoch 714/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8165 - mean_squared_error: 5.3187 - val_loss: 2.1583 - val_mean_squared_error: 6.9492\n",
      "Epoch 715/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8185 - mean_squared_error: 5.2835 - val_loss: 2.1626 - val_mean_squared_error: 6.9572\n",
      "Epoch 716/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8176 - mean_squared_error: 5.2957 - val_loss: 2.1657 - val_mean_squared_error: 6.9762\n",
      "Epoch 717/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8158 - mean_squared_error: 5.2741 - val_loss: 2.1592 - val_mean_squared_error: 6.9753\n",
      "Epoch 718/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8146 - mean_squared_error: 5.2734 - val_loss: 2.1602 - val_mean_squared_error: 6.9546\n",
      "Epoch 719/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8085 - mean_squared_error: 5.2643 - val_loss: 2.1569 - val_mean_squared_error: 6.9725\n",
      "Epoch 720/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8121 - mean_squared_error: 5.2804 - val_loss: 2.1652 - val_mean_squared_error: 6.9786\n",
      "Epoch 721/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8287 - mean_squared_error: 5.3298 - val_loss: 2.1585 - val_mean_squared_error: 6.9579\n",
      "Epoch 722/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8203 - mean_squared_error: 5.2870 - val_loss: 2.1592 - val_mean_squared_error: 6.9493\n",
      "Epoch 723/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8153 - mean_squared_error: 5.2769 - val_loss: 2.1633 - val_mean_squared_error: 6.9716\n",
      "Epoch 724/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8231 - mean_squared_error: 5.3273 - val_loss: 2.1618 - val_mean_squared_error: 6.9512\n",
      "Epoch 725/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8165 - mean_squared_error: 5.2745 - val_loss: 2.1606 - val_mean_squared_error: 6.9853\n",
      "Epoch 726/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8183 - mean_squared_error: 5.2950 - val_loss: 2.1641 - val_mean_squared_error: 6.9903\n",
      "Epoch 727/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8168 - mean_squared_error: 5.2872 - val_loss: 2.1668 - val_mean_squared_error: 6.9849\n",
      "Epoch 728/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8138 - mean_squared_error: 5.2597 - val_loss: 2.1613 - val_mean_squared_error: 6.9726\n",
      "Epoch 729/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8178 - mean_squared_error: 5.2931 - val_loss: 2.1592 - val_mean_squared_error: 6.9514\n",
      "Epoch 730/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8212 - mean_squared_error: 5.3072 - val_loss: 2.1610 - val_mean_squared_error: 6.9722\n",
      "Epoch 731/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8236 - mean_squared_error: 5.2885 - val_loss: 2.1638 - val_mean_squared_error: 6.9929\n",
      "Epoch 732/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8119 - mean_squared_error: 5.2712 - val_loss: 2.1647 - val_mean_squared_error: 7.0015\n",
      "Epoch 733/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8155 - mean_squared_error: 5.2764 - val_loss: 2.1614 - val_mean_squared_error: 6.9512\n",
      "Epoch 734/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8064 - mean_squared_error: 5.2316 - val_loss: 2.1586 - val_mean_squared_error: 6.9447\n",
      "Epoch 735/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8165 - mean_squared_error: 5.2681 - val_loss: 2.1637 - val_mean_squared_error: 6.9793\n",
      "Epoch 736/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8037 - mean_squared_error: 5.2377 - val_loss: 2.1608 - val_mean_squared_error: 6.9689\n",
      "Epoch 737/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8098 - mean_squared_error: 5.2609 - val_loss: 2.1645 - val_mean_squared_error: 6.9921\n",
      "Epoch 738/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8111 - mean_squared_error: 5.2564 - val_loss: 2.1672 - val_mean_squared_error: 6.9984\n",
      "Epoch 739/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8162 - mean_squared_error: 5.2941 - val_loss: 2.1666 - val_mean_squared_error: 6.9982\n",
      "Epoch 740/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8152 - mean_squared_error: 5.2892 - val_loss: 2.1647 - val_mean_squared_error: 6.9535\n",
      "Epoch 741/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8048 - mean_squared_error: 5.2562 - val_loss: 2.1634 - val_mean_squared_error: 6.9609\n",
      "Epoch 742/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8053 - mean_squared_error: 5.2259 - val_loss: 2.1604 - val_mean_squared_error: 6.9614\n",
      "Epoch 743/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8121 - mean_squared_error: 5.2737 - val_loss: 2.1635 - val_mean_squared_error: 6.9641\n",
      "Epoch 744/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8124 - mean_squared_error: 5.2785 - val_loss: 2.1593 - val_mean_squared_error: 6.9605\n",
      "Epoch 745/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8162 - mean_squared_error: 5.2741 - val_loss: 2.1607 - val_mean_squared_error: 6.9598\n",
      "Epoch 746/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8105 - mean_squared_error: 5.2590 - val_loss: 2.1577 - val_mean_squared_error: 6.9556\n",
      "Epoch 747/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8029 - mean_squared_error: 5.2174 - val_loss: 2.1648 - val_mean_squared_error: 6.9992\n",
      "Epoch 748/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8191 - mean_squared_error: 5.3016 - val_loss: 2.1605 - val_mean_squared_error: 6.9606\n",
      "Epoch 749/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8053 - mean_squared_error: 5.2487 - val_loss: 2.1573 - val_mean_squared_error: 6.9534\n",
      "Epoch 750/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8101 - mean_squared_error: 5.2547 - val_loss: 2.1587 - val_mean_squared_error: 6.9464\n",
      "Epoch 751/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8060 - mean_squared_error: 5.2625 - val_loss: 2.1650 - val_mean_squared_error: 6.9903\n",
      "Epoch 752/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8091 - mean_squared_error: 5.2624 - val_loss: 2.1622 - val_mean_squared_error: 6.9666\n",
      "Epoch 753/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8093 - mean_squared_error: 5.2929 - val_loss: 2.1638 - val_mean_squared_error: 6.9870\n",
      "Epoch 754/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8065 - mean_squared_error: 5.2560 - val_loss: 2.1601 - val_mean_squared_error: 6.9606\n",
      "Epoch 755/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8121 - mean_squared_error: 5.2580 - val_loss: 2.1656 - val_mean_squared_error: 6.9630\n",
      "Epoch 756/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8156 - mean_squared_error: 5.2677 - val_loss: 2.1670 - val_mean_squared_error: 7.0183\n",
      "Epoch 757/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8106 - mean_squared_error: 5.2640 - val_loss: 2.1665 - val_mean_squared_error: 6.9803\n",
      "Epoch 758/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8118 - mean_squared_error: 5.2710 - val_loss: 2.1653 - val_mean_squared_error: 6.9907\n",
      "Epoch 759/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8125 - mean_squared_error: 5.2726 - val_loss: 2.1741 - val_mean_squared_error: 7.0243\n",
      "Epoch 760/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8101 - mean_squared_error: 5.2889 - val_loss: 2.1653 - val_mean_squared_error: 7.0073\n",
      "Epoch 761/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8034 - mean_squared_error: 5.2408 - val_loss: 2.1667 - val_mean_squared_error: 7.0029\n",
      "Epoch 762/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8126 - mean_squared_error: 5.2777 - val_loss: 2.1636 - val_mean_squared_error: 6.9752\n",
      "Epoch 763/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8103 - mean_squared_error: 5.2522 - val_loss: 2.1625 - val_mean_squared_error: 6.9565\n",
      "Epoch 764/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8085 - mean_squared_error: 5.2470 - val_loss: 2.1640 - val_mean_squared_error: 6.9803\n",
      "Epoch 765/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8111 - mean_squared_error: 5.2807 - val_loss: 2.1649 - val_mean_squared_error: 7.0002\n",
      "Epoch 766/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8074 - mean_squared_error: 5.2433 - val_loss: 2.1678 - val_mean_squared_error: 6.9854\n",
      "Epoch 767/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8038 - mean_squared_error: 5.1984 - val_loss: 2.1637 - val_mean_squared_error: 6.9683\n",
      "Epoch 768/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8129 - mean_squared_error: 5.2809 - val_loss: 2.1599 - val_mean_squared_error: 6.9759\n",
      "Epoch 769/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8087 - mean_squared_error: 5.2456 - val_loss: 2.1640 - val_mean_squared_error: 7.0152\n",
      "Epoch 770/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8039 - mean_squared_error: 5.2369 - val_loss: 2.1627 - val_mean_squared_error: 6.9877\n",
      "Epoch 771/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8089 - mean_squared_error: 5.2768 - val_loss: 2.1637 - val_mean_squared_error: 6.9850\n",
      "Epoch 772/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8055 - mean_squared_error: 5.2352 - val_loss: 2.1626 - val_mean_squared_error: 6.9787\n",
      "Epoch 773/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8131 - mean_squared_error: 5.2767 - val_loss: 2.1654 - val_mean_squared_error: 6.9905\n",
      "Epoch 774/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8115 - mean_squared_error: 5.2770 - val_loss: 2.1631 - val_mean_squared_error: 6.9811\n",
      "Epoch 775/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8083 - mean_squared_error: 5.2549 - val_loss: 2.1690 - val_mean_squared_error: 7.0167\n",
      "Epoch 776/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8031 - mean_squared_error: 5.2171 - val_loss: 2.1691 - val_mean_squared_error: 7.0108\n",
      "Epoch 777/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8058 - mean_squared_error: 5.2422 - val_loss: 2.1658 - val_mean_squared_error: 7.0133\n",
      "Epoch 778/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.8025 - mean_squared_error: 5.2453 - val_loss: 2.1684 - val_mean_squared_error: 7.0081\n",
      "Epoch 779/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8073 - mean_squared_error: 5.2365 - val_loss: 2.1674 - val_mean_squared_error: 6.9977\n",
      "Epoch 780/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8019 - mean_squared_error: 5.2095 - val_loss: 2.1710 - val_mean_squared_error: 7.0183\n",
      "Epoch 781/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8105 - mean_squared_error: 5.2614 - val_loss: 2.1691 - val_mean_squared_error: 7.0185\n",
      "Epoch 782/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8097 - mean_squared_error: 5.2402 - val_loss: 2.1716 - val_mean_squared_error: 7.0274\n",
      "Epoch 783/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8078 - mean_squared_error: 5.2640 - val_loss: 2.1691 - val_mean_squared_error: 7.0031\n",
      "Epoch 784/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8052 - mean_squared_error: 5.2474 - val_loss: 2.1671 - val_mean_squared_error: 7.0005\n",
      "Epoch 785/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8085 - mean_squared_error: 5.2389 - val_loss: 2.1703 - val_mean_squared_error: 7.0427\n",
      "Epoch 786/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8148 - mean_squared_error: 5.2901 - val_loss: 2.1664 - val_mean_squared_error: 6.9929\n",
      "Epoch 787/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8125 - mean_squared_error: 5.2672 - val_loss: 2.1651 - val_mean_squared_error: 7.0027\n",
      "Epoch 788/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8115 - mean_squared_error: 5.2568 - val_loss: 2.1683 - val_mean_squared_error: 7.0143\n",
      "Epoch 789/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8073 - mean_squared_error: 5.2292 - val_loss: 2.1693 - val_mean_squared_error: 7.0161\n",
      "Epoch 790/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7982 - mean_squared_error: 5.1994 - val_loss: 2.1688 - val_mean_squared_error: 7.0325\n",
      "Epoch 791/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8077 - mean_squared_error: 5.2500 - val_loss: 2.1648 - val_mean_squared_error: 6.9918\n",
      "Epoch 792/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8059 - mean_squared_error: 5.2312 - val_loss: 2.1651 - val_mean_squared_error: 7.0042\n",
      "Epoch 793/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8035 - mean_squared_error: 5.2133 - val_loss: 2.1647 - val_mean_squared_error: 6.9863\n",
      "Epoch 794/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7978 - mean_squared_error: 5.2030 - val_loss: 2.1656 - val_mean_squared_error: 7.0018\n",
      "Epoch 795/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8089 - mean_squared_error: 5.2543 - val_loss: 2.1663 - val_mean_squared_error: 6.9934\n",
      "Epoch 796/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8065 - mean_squared_error: 5.2335 - val_loss: 2.1685 - val_mean_squared_error: 7.0044\n",
      "Epoch 797/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8029 - mean_squared_error: 5.2144 - val_loss: 2.1648 - val_mean_squared_error: 6.9797\n",
      "Epoch 798/1000\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 1.8045 - mean_squared_error: 5.2172 - val_loss: 2.1684 - val_mean_squared_error: 7.0241\n",
      "Epoch 799/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7996 - mean_squared_error: 5.2028 - val_loss: 2.1608 - val_mean_squared_error: 6.9686\n",
      "Epoch 800/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8016 - mean_squared_error: 5.2062 - val_loss: 2.1633 - val_mean_squared_error: 6.9819\n",
      "Epoch 801/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8039 - mean_squared_error: 5.2274 - val_loss: 2.1692 - val_mean_squared_error: 7.0137\n",
      "Epoch 802/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8049 - mean_squared_error: 5.2245 - val_loss: 2.1706 - val_mean_squared_error: 7.0334\n",
      "Epoch 803/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8059 - mean_squared_error: 5.2527 - val_loss: 2.1669 - val_mean_squared_error: 7.0164\n",
      "Epoch 804/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8075 - mean_squared_error: 5.2590 - val_loss: 2.1680 - val_mean_squared_error: 7.0366\n",
      "Epoch 805/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8036 - mean_squared_error: 5.2436 - val_loss: 2.1688 - val_mean_squared_error: 7.0376\n",
      "Epoch 806/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8030 - mean_squared_error: 5.2468 - val_loss: 2.1636 - val_mean_squared_error: 6.9815\n",
      "Epoch 807/1000\n",
      "39/39 [==============================] - 0s 13ms/step - loss: 1.8102 - mean_squared_error: 5.2510 - val_loss: 2.1680 - val_mean_squared_error: 7.0188\n",
      "Epoch 808/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8071 - mean_squared_error: 5.2315 - val_loss: 2.1642 - val_mean_squared_error: 6.9929\n",
      "Epoch 809/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8076 - mean_squared_error: 5.2436 - val_loss: 2.1595 - val_mean_squared_error: 6.9794\n",
      "Epoch 810/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8039 - mean_squared_error: 5.2322 - val_loss: 2.1626 - val_mean_squared_error: 6.9805\n",
      "Epoch 811/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7980 - mean_squared_error: 5.2029 - val_loss: 2.1678 - val_mean_squared_error: 7.0229\n",
      "Epoch 812/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8084 - mean_squared_error: 5.2351 - val_loss: 2.1667 - val_mean_squared_error: 7.0102\n",
      "Epoch 813/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7960 - mean_squared_error: 5.1884 - val_loss: 2.1623 - val_mean_squared_error: 6.9937\n",
      "Epoch 814/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7962 - mean_squared_error: 5.2146 - val_loss: 2.1673 - val_mean_squared_error: 6.9990\n",
      "Epoch 815/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8083 - mean_squared_error: 5.2327 - val_loss: 2.1602 - val_mean_squared_error: 6.9697\n",
      "Epoch 816/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7994 - mean_squared_error: 5.1923 - val_loss: 2.1624 - val_mean_squared_error: 6.9823\n",
      "Epoch 817/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8011 - mean_squared_error: 5.1984 - val_loss: 2.1674 - val_mean_squared_error: 7.0198\n",
      "Epoch 818/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8041 - mean_squared_error: 5.2211 - val_loss: 2.1721 - val_mean_squared_error: 7.0402\n",
      "Epoch 819/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7996 - mean_squared_error: 5.1927 - val_loss: 2.1738 - val_mean_squared_error: 7.0435\n",
      "Epoch 820/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8105 - mean_squared_error: 5.2445 - val_loss: 2.1722 - val_mean_squared_error: 7.0397\n",
      "Epoch 821/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8071 - mean_squared_error: 5.2240 - val_loss: 2.1666 - val_mean_squared_error: 6.9858\n",
      "Epoch 822/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7948 - mean_squared_error: 5.2029 - val_loss: 2.1734 - val_mean_squared_error: 7.0390\n",
      "Epoch 823/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8012 - mean_squared_error: 5.2235 - val_loss: 2.1699 - val_mean_squared_error: 7.0135\n",
      "Epoch 824/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8059 - mean_squared_error: 5.2447 - val_loss: 2.1659 - val_mean_squared_error: 6.9928\n",
      "Epoch 825/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7923 - mean_squared_error: 5.1711 - val_loss: 2.1734 - val_mean_squared_error: 7.0523\n",
      "Epoch 826/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8036 - mean_squared_error: 5.2238 - val_loss: 2.1714 - val_mean_squared_error: 7.0232\n",
      "Epoch 827/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8031 - mean_squared_error: 5.2158 - val_loss: 2.1678 - val_mean_squared_error: 7.0075\n",
      "Epoch 828/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8134 - mean_squared_error: 5.2767 - val_loss: 2.1676 - val_mean_squared_error: 6.9933\n",
      "Epoch 829/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7933 - mean_squared_error: 5.1761 - val_loss: 2.1697 - val_mean_squared_error: 7.0263\n",
      "Epoch 830/1000\n",
      "39/39 [==============================] - 1s 14ms/step - loss: 1.7999 - mean_squared_error: 5.1891 - val_loss: 2.1643 - val_mean_squared_error: 6.9752\n",
      "Epoch 831/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8023 - mean_squared_error: 5.2226 - val_loss: 2.1754 - val_mean_squared_error: 7.0378\n",
      "Epoch 832/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7962 - mean_squared_error: 5.2087 - val_loss: 2.1744 - val_mean_squared_error: 7.0427\n",
      "Epoch 833/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7942 - mean_squared_error: 5.1770 - val_loss: 2.1682 - val_mean_squared_error: 7.0157\n",
      "Epoch 834/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8063 - mean_squared_error: 5.2204 - val_loss: 2.1699 - val_mean_squared_error: 7.0007\n",
      "Epoch 835/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8000 - mean_squared_error: 5.1919 - val_loss: 2.1714 - val_mean_squared_error: 7.0087\n",
      "Epoch 836/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7990 - mean_squared_error: 5.2076 - val_loss: 2.1680 - val_mean_squared_error: 7.0079\n",
      "Epoch 837/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8090 - mean_squared_error: 5.2495 - val_loss: 2.1698 - val_mean_squared_error: 7.0101\n",
      "Epoch 838/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8095 - mean_squared_error: 5.2317 - val_loss: 2.1674 - val_mean_squared_error: 7.0174\n",
      "Epoch 839/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8020 - mean_squared_error: 5.2151 - val_loss: 2.1674 - val_mean_squared_error: 7.0033\n",
      "Epoch 840/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8003 - mean_squared_error: 5.2070 - val_loss: 2.1675 - val_mean_squared_error: 7.0148\n",
      "Epoch 841/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8038 - mean_squared_error: 5.2272 - val_loss: 2.1645 - val_mean_squared_error: 6.9786\n",
      "Epoch 842/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7991 - mean_squared_error: 5.2285 - val_loss: 2.1697 - val_mean_squared_error: 7.0246\n",
      "Epoch 843/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8029 - mean_squared_error: 5.2401 - val_loss: 2.1682 - val_mean_squared_error: 6.9949\n",
      "Epoch 844/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7998 - mean_squared_error: 5.1965 - val_loss: 2.1714 - val_mean_squared_error: 7.0329\n",
      "Epoch 845/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7971 - mean_squared_error: 5.1782 - val_loss: 2.1654 - val_mean_squared_error: 6.9927\n",
      "Epoch 846/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8111 - mean_squared_error: 5.2465 - val_loss: 2.1717 - val_mean_squared_error: 7.0441\n",
      "Epoch 847/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7908 - mean_squared_error: 5.1577 - val_loss: 2.1706 - val_mean_squared_error: 7.0184\n",
      "Epoch 848/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7959 - mean_squared_error: 5.1921 - val_loss: 2.1645 - val_mean_squared_error: 6.9981\n",
      "Epoch 849/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8047 - mean_squared_error: 5.2211 - val_loss: 2.1711 - val_mean_squared_error: 6.9978\n",
      "Epoch 850/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7930 - mean_squared_error: 5.1725 - val_loss: 2.1720 - val_mean_squared_error: 7.0337\n",
      "Epoch 851/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8015 - mean_squared_error: 5.2024 - val_loss: 2.1728 - val_mean_squared_error: 7.0116\n",
      "Epoch 852/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8063 - mean_squared_error: 5.2303 - val_loss: 2.1695 - val_mean_squared_error: 6.9977\n",
      "Epoch 853/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7975 - mean_squared_error: 5.1755 - val_loss: 2.1698 - val_mean_squared_error: 6.9948\n",
      "Epoch 854/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8057 - mean_squared_error: 5.2233 - val_loss: 2.1685 - val_mean_squared_error: 7.0189\n",
      "Epoch 855/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8017 - mean_squared_error: 5.2106 - val_loss: 2.1723 - val_mean_squared_error: 7.0265\n",
      "Epoch 856/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7901 - mean_squared_error: 5.1934 - val_loss: 2.1663 - val_mean_squared_error: 7.0022\n",
      "Epoch 857/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7891 - mean_squared_error: 5.1468 - val_loss: 2.1679 - val_mean_squared_error: 6.9940\n",
      "Epoch 858/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8034 - mean_squared_error: 5.2161 - val_loss: 2.1640 - val_mean_squared_error: 6.9695\n",
      "Epoch 859/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7984 - mean_squared_error: 5.2130 - val_loss: 2.1689 - val_mean_squared_error: 6.9980\n",
      "Epoch 860/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7965 - mean_squared_error: 5.1738 - val_loss: 2.1765 - val_mean_squared_error: 7.0491\n",
      "Epoch 861/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7982 - mean_squared_error: 5.1769 - val_loss: 2.1678 - val_mean_squared_error: 7.0121\n",
      "Epoch 862/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7966 - mean_squared_error: 5.1767 - val_loss: 2.1686 - val_mean_squared_error: 7.0149\n",
      "Epoch 863/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7976 - mean_squared_error: 5.2072 - val_loss: 2.1737 - val_mean_squared_error: 7.0533\n",
      "Epoch 864/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8031 - mean_squared_error: 5.2226 - val_loss: 2.1705 - val_mean_squared_error: 7.0147\n",
      "Epoch 865/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8022 - mean_squared_error: 5.1936 - val_loss: 2.1652 - val_mean_squared_error: 6.9771\n",
      "Epoch 866/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7955 - mean_squared_error: 5.1773 - val_loss: 2.1752 - val_mean_squared_error: 7.0492\n",
      "Epoch 867/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7957 - mean_squared_error: 5.1913 - val_loss: 2.1739 - val_mean_squared_error: 7.0373\n",
      "Epoch 868/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7943 - mean_squared_error: 5.1770 - val_loss: 2.1681 - val_mean_squared_error: 7.0083\n",
      "Epoch 869/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7973 - mean_squared_error: 5.1995 - val_loss: 2.1678 - val_mean_squared_error: 7.0081\n",
      "Epoch 870/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7972 - mean_squared_error: 5.1862 - val_loss: 2.1653 - val_mean_squared_error: 6.9858\n",
      "Epoch 871/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7979 - mean_squared_error: 5.1994 - val_loss: 2.1717 - val_mean_squared_error: 7.0229\n",
      "Epoch 872/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7968 - mean_squared_error: 5.1989 - val_loss: 2.1709 - val_mean_squared_error: 6.9989\n",
      "Epoch 873/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7973 - mean_squared_error: 5.1828 - val_loss: 2.1701 - val_mean_squared_error: 7.0061\n",
      "Epoch 874/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8006 - mean_squared_error: 5.2111 - val_loss: 2.1674 - val_mean_squared_error: 6.9976\n",
      "Epoch 875/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7905 - mean_squared_error: 5.1427 - val_loss: 2.1618 - val_mean_squared_error: 6.9814\n",
      "Epoch 876/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8044 - mean_squared_error: 5.2112 - val_loss: 2.1669 - val_mean_squared_error: 6.9975\n",
      "Epoch 877/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7950 - mean_squared_error: 5.1739 - val_loss: 2.1694 - val_mean_squared_error: 6.9940\n",
      "Epoch 878/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7991 - mean_squared_error: 5.1965 - val_loss: 2.1714 - val_mean_squared_error: 7.0100\n",
      "Epoch 879/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7975 - mean_squared_error: 5.1824 - val_loss: 2.1733 - val_mean_squared_error: 7.0007\n",
      "Epoch 880/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7960 - mean_squared_error: 5.1562 - val_loss: 2.1691 - val_mean_squared_error: 6.9892\n",
      "Epoch 881/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7900 - mean_squared_error: 5.1554 - val_loss: 2.1733 - val_mean_squared_error: 7.0265\n",
      "Epoch 882/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7934 - mean_squared_error: 5.1729 - val_loss: 2.1699 - val_mean_squared_error: 7.0129\n",
      "Epoch 883/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7866 - mean_squared_error: 5.1614 - val_loss: 2.1736 - val_mean_squared_error: 7.0283\n",
      "Epoch 884/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7946 - mean_squared_error: 5.1709 - val_loss: 2.1689 - val_mean_squared_error: 7.0113\n",
      "Epoch 885/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7986 - mean_squared_error: 5.1905 - val_loss: 2.1663 - val_mean_squared_error: 6.9922\n",
      "Epoch 886/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7964 - mean_squared_error: 5.1882 - val_loss: 2.1775 - val_mean_squared_error: 7.0477\n",
      "Epoch 887/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7959 - mean_squared_error: 5.1678 - val_loss: 2.1716 - val_mean_squared_error: 7.0126\n",
      "Epoch 888/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.8006 - mean_squared_error: 5.1945 - val_loss: 2.1715 - val_mean_squared_error: 7.0475\n",
      "Epoch 889/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7911 - mean_squared_error: 5.1610 - val_loss: 2.1757 - val_mean_squared_error: 7.0572\n",
      "Epoch 890/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7945 - mean_squared_error: 5.1645 - val_loss: 2.1688 - val_mean_squared_error: 6.9908\n",
      "Epoch 891/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7904 - mean_squared_error: 5.1751 - val_loss: 2.1679 - val_mean_squared_error: 7.0092\n",
      "Epoch 892/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7967 - mean_squared_error: 5.2036 - val_loss: 2.1688 - val_mean_squared_error: 7.0036\n",
      "Epoch 893/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7946 - mean_squared_error: 5.1608 - val_loss: 2.1643 - val_mean_squared_error: 6.9611\n",
      "Epoch 894/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7895 - mean_squared_error: 5.1659 - val_loss: 2.1679 - val_mean_squared_error: 6.9946\n",
      "Epoch 895/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7974 - mean_squared_error: 5.1737 - val_loss: 2.1672 - val_mean_squared_error: 6.9739\n",
      "Epoch 896/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7964 - mean_squared_error: 5.1888 - val_loss: 2.1662 - val_mean_squared_error: 7.0113\n",
      "Epoch 897/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7919 - mean_squared_error: 5.1717 - val_loss: 2.1748 - val_mean_squared_error: 7.0203\n",
      "Epoch 898/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8030 - mean_squared_error: 5.2113 - val_loss: 2.1656 - val_mean_squared_error: 7.0024\n",
      "Epoch 899/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7917 - mean_squared_error: 5.1443 - val_loss: 2.1685 - val_mean_squared_error: 7.0019\n",
      "Epoch 900/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7943 - mean_squared_error: 5.1872 - val_loss: 2.1735 - val_mean_squared_error: 7.0228\n",
      "Epoch 901/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7776 - mean_squared_error: 5.0989 - val_loss: 2.1767 - val_mean_squared_error: 7.0541\n",
      "Epoch 902/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7909 - mean_squared_error: 5.1544 - val_loss: 2.1658 - val_mean_squared_error: 6.9963\n",
      "Epoch 903/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7904 - mean_squared_error: 5.1713 - val_loss: 2.1672 - val_mean_squared_error: 6.9928\n",
      "Epoch 904/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7953 - mean_squared_error: 5.1789 - val_loss: 2.1662 - val_mean_squared_error: 7.0035\n",
      "Epoch 905/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7963 - mean_squared_error: 5.1917 - val_loss: 2.1674 - val_mean_squared_error: 7.0002\n",
      "Epoch 906/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8064 - mean_squared_error: 5.2190 - val_loss: 2.1669 - val_mean_squared_error: 6.9731\n",
      "Epoch 907/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7949 - mean_squared_error: 5.1742 - val_loss: 2.1744 - val_mean_squared_error: 7.0163\n",
      "Epoch 908/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7905 - mean_squared_error: 5.1508 - val_loss: 2.1737 - val_mean_squared_error: 7.0568\n",
      "Epoch 909/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7921 - mean_squared_error: 5.1815 - val_loss: 2.1762 - val_mean_squared_error: 7.0552\n",
      "Epoch 910/1000\n",
      "39/39 [==============================] - 1s 12ms/step - loss: 1.7983 - mean_squared_error: 5.1904 - val_loss: 2.1710 - val_mean_squared_error: 7.0157\n",
      "Epoch 911/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7912 - mean_squared_error: 5.1770 - val_loss: 2.1722 - val_mean_squared_error: 7.0286\n",
      "Epoch 912/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7930 - mean_squared_error: 5.1640 - val_loss: 2.1708 - val_mean_squared_error: 7.0116\n",
      "Epoch 913/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7830 - mean_squared_error: 5.1156 - val_loss: 2.1729 - val_mean_squared_error: 7.0303\n",
      "Epoch 914/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7941 - mean_squared_error: 5.1794 - val_loss: 2.1691 - val_mean_squared_error: 6.9778\n",
      "Epoch 915/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7975 - mean_squared_error: 5.1788 - val_loss: 2.1650 - val_mean_squared_error: 6.9897\n",
      "Epoch 916/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7919 - mean_squared_error: 5.1580 - val_loss: 2.1768 - val_mean_squared_error: 7.0640\n",
      "Epoch 917/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7902 - mean_squared_error: 5.1602 - val_loss: 2.1707 - val_mean_squared_error: 7.0046\n",
      "Epoch 918/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7934 - mean_squared_error: 5.1553 - val_loss: 2.1714 - val_mean_squared_error: 7.0262\n",
      "Epoch 919/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7927 - mean_squared_error: 5.1553 - val_loss: 2.1704 - val_mean_squared_error: 7.0085\n",
      "Epoch 920/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7857 - mean_squared_error: 5.1381 - val_loss: 2.1677 - val_mean_squared_error: 6.9739\n",
      "Epoch 921/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7972 - mean_squared_error: 5.1610 - val_loss: 2.1731 - val_mean_squared_error: 7.0072\n",
      "Epoch 922/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7822 - mean_squared_error: 5.0922 - val_loss: 2.1706 - val_mean_squared_error: 7.0136\n",
      "Epoch 923/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7907 - mean_squared_error: 5.1613 - val_loss: 2.1678 - val_mean_squared_error: 7.0170\n",
      "Epoch 924/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7849 - mean_squared_error: 5.1181 - val_loss: 2.1716 - val_mean_squared_error: 7.0379\n",
      "Epoch 925/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7954 - mean_squared_error: 5.1763 - val_loss: 2.1725 - val_mean_squared_error: 7.0409\n",
      "Epoch 926/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7920 - mean_squared_error: 5.1677 - val_loss: 2.1702 - val_mean_squared_error: 7.0364\n",
      "Epoch 927/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7975 - mean_squared_error: 5.1865 - val_loss: 2.1652 - val_mean_squared_error: 6.9720\n",
      "Epoch 928/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7908 - mean_squared_error: 5.1542 - val_loss: 2.1714 - val_mean_squared_error: 7.0130\n",
      "Epoch 929/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7962 - mean_squared_error: 5.1527 - val_loss: 2.1744 - val_mean_squared_error: 7.0383\n",
      "Epoch 930/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7941 - mean_squared_error: 5.1771 - val_loss: 2.1717 - val_mean_squared_error: 7.0243\n",
      "Epoch 931/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7893 - mean_squared_error: 5.1370 - val_loss: 2.1711 - val_mean_squared_error: 7.0097\n",
      "Epoch 932/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7895 - mean_squared_error: 5.1742 - val_loss: 2.1708 - val_mean_squared_error: 7.0479\n",
      "Epoch 933/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7925 - mean_squared_error: 5.1760 - val_loss: 2.1684 - val_mean_squared_error: 7.0104\n",
      "Epoch 934/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7887 - mean_squared_error: 5.1587 - val_loss: 2.1731 - val_mean_squared_error: 7.0312\n",
      "Epoch 935/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7867 - mean_squared_error: 5.1408 - val_loss: 2.1714 - val_mean_squared_error: 7.0212\n",
      "Epoch 936/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7909 - mean_squared_error: 5.1585 - val_loss: 2.1724 - val_mean_squared_error: 7.0359\n",
      "Epoch 937/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7958 - mean_squared_error: 5.1756 - val_loss: 2.1715 - val_mean_squared_error: 7.0161\n",
      "Epoch 938/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7851 - mean_squared_error: 5.1180 - val_loss: 2.1742 - val_mean_squared_error: 7.0429\n",
      "Epoch 939/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8000 - mean_squared_error: 5.1991 - val_loss: 2.1701 - val_mean_squared_error: 7.0200\n",
      "Epoch 940/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7830 - mean_squared_error: 5.1077 - val_loss: 2.1689 - val_mean_squared_error: 7.0125\n",
      "Epoch 941/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7885 - mean_squared_error: 5.1366 - val_loss: 2.1663 - val_mean_squared_error: 7.0180\n",
      "Epoch 942/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.8023 - mean_squared_error: 5.2111 - val_loss: 2.1697 - val_mean_squared_error: 7.0319\n",
      "Epoch 943/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7875 - mean_squared_error: 5.1335 - val_loss: 2.1659 - val_mean_squared_error: 7.0046\n",
      "Epoch 944/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7859 - mean_squared_error: 5.1289 - val_loss: 2.1678 - val_mean_squared_error: 7.0395\n",
      "Epoch 945/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7834 - mean_squared_error: 5.1137 - val_loss: 2.1669 - val_mean_squared_error: 7.0236\n",
      "Epoch 946/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7897 - mean_squared_error: 5.1269 - val_loss: 2.1713 - val_mean_squared_error: 7.0221\n",
      "Epoch 947/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7811 - mean_squared_error: 5.1139 - val_loss: 2.1703 - val_mean_squared_error: 7.0579\n",
      "Epoch 948/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7872 - mean_squared_error: 5.1614 - val_loss: 2.1674 - val_mean_squared_error: 7.0024\n",
      "Epoch 949/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7877 - mean_squared_error: 5.1446 - val_loss: 2.1713 - val_mean_squared_error: 7.0375\n",
      "Epoch 950/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7881 - mean_squared_error: 5.1219 - val_loss: 2.1724 - val_mean_squared_error: 7.0389\n",
      "Epoch 951/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7895 - mean_squared_error: 5.1572 - val_loss: 2.1659 - val_mean_squared_error: 6.9975\n",
      "Epoch 952/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7811 - mean_squared_error: 5.1169 - val_loss: 2.1719 - val_mean_squared_error: 7.0571\n",
      "Epoch 953/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7910 - mean_squared_error: 5.1375 - val_loss: 2.1714 - val_mean_squared_error: 7.0294\n",
      "Epoch 954/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7995 - mean_squared_error: 5.2042 - val_loss: 2.1706 - val_mean_squared_error: 7.0191\n",
      "Epoch 955/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7901 - mean_squared_error: 5.1439 - val_loss: 2.1731 - val_mean_squared_error: 7.0287\n",
      "Epoch 956/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7893 - mean_squared_error: 5.1337 - val_loss: 2.1692 - val_mean_squared_error: 7.0151\n",
      "Epoch 957/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7941 - mean_squared_error: 5.1835 - val_loss: 2.1743 - val_mean_squared_error: 7.0343\n",
      "Epoch 958/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7901 - mean_squared_error: 5.1668 - val_loss: 2.1680 - val_mean_squared_error: 7.0189\n",
      "Epoch 959/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7803 - mean_squared_error: 5.1136 - val_loss: 2.1659 - val_mean_squared_error: 7.0106\n",
      "Epoch 960/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7946 - mean_squared_error: 5.1666 - val_loss: 2.1772 - val_mean_squared_error: 7.0544\n",
      "Epoch 961/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7941 - mean_squared_error: 5.1828 - val_loss: 2.1679 - val_mean_squared_error: 7.0095\n",
      "Epoch 962/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7920 - mean_squared_error: 5.1402 - val_loss: 2.1745 - val_mean_squared_error: 7.0461\n",
      "Epoch 963/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7897 - mean_squared_error: 5.1228 - val_loss: 2.1753 - val_mean_squared_error: 7.0458\n",
      "Epoch 964/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7855 - mean_squared_error: 5.1293 - val_loss: 2.1687 - val_mean_squared_error: 7.0281\n",
      "Epoch 965/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7898 - mean_squared_error: 5.1357 - val_loss: 2.1688 - val_mean_squared_error: 7.0075\n",
      "Epoch 966/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7838 - mean_squared_error: 5.1306 - val_loss: 2.1743 - val_mean_squared_error: 7.0347\n",
      "Epoch 967/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7832 - mean_squared_error: 5.1326 - val_loss: 2.1733 - val_mean_squared_error: 7.0122\n",
      "Epoch 968/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7872 - mean_squared_error: 5.1514 - val_loss: 2.1790 - val_mean_squared_error: 7.0685\n",
      "Epoch 969/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7839 - mean_squared_error: 5.1076 - val_loss: 2.1759 - val_mean_squared_error: 7.0531\n",
      "Epoch 970/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7882 - mean_squared_error: 5.1325 - val_loss: 2.1706 - val_mean_squared_error: 7.0118\n",
      "Epoch 971/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7843 - mean_squared_error: 5.1219 - val_loss: 2.1711 - val_mean_squared_error: 7.0490\n",
      "Epoch 972/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7880 - mean_squared_error: 5.1230 - val_loss: 2.1757 - val_mean_squared_error: 7.0652\n",
      "Epoch 973/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7910 - mean_squared_error: 5.1608 - val_loss: 2.1713 - val_mean_squared_error: 7.0137\n",
      "Epoch 974/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7933 - mean_squared_error: 5.1639 - val_loss: 2.1814 - val_mean_squared_error: 7.0735\n",
      "Epoch 975/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7850 - mean_squared_error: 5.1379 - val_loss: 2.1766 - val_mean_squared_error: 7.0479\n",
      "Epoch 976/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7891 - mean_squared_error: 5.1477 - val_loss: 2.1756 - val_mean_squared_error: 7.0464\n",
      "Epoch 977/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7879 - mean_squared_error: 5.1239 - val_loss: 2.1737 - val_mean_squared_error: 7.0468\n",
      "Epoch 978/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7863 - mean_squared_error: 5.1463 - val_loss: 2.1807 - val_mean_squared_error: 7.0661\n",
      "Epoch 979/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7898 - mean_squared_error: 5.1345 - val_loss: 2.1702 - val_mean_squared_error: 7.0312\n",
      "Epoch 980/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7820 - mean_squared_error: 5.1126 - val_loss: 2.1748 - val_mean_squared_error: 7.0651\n",
      "Epoch 981/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7881 - mean_squared_error: 5.1286 - val_loss: 2.1766 - val_mean_squared_error: 7.0544\n",
      "Epoch 982/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7884 - mean_squared_error: 5.1333 - val_loss: 2.1779 - val_mean_squared_error: 7.0673\n",
      "Epoch 983/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7943 - mean_squared_error: 5.1594 - val_loss: 2.1766 - val_mean_squared_error: 7.0523\n",
      "Epoch 984/1000\n",
      "39/39 [==============================] - 0s 12ms/step - loss: 1.7894 - mean_squared_error: 5.1632 - val_loss: 2.1748 - val_mean_squared_error: 7.0372\n",
      "Epoch 985/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7858 - mean_squared_error: 5.1195 - val_loss: 2.1755 - val_mean_squared_error: 7.0318\n",
      "Epoch 986/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7803 - mean_squared_error: 5.0972 - val_loss: 2.1750 - val_mean_squared_error: 7.0554\n",
      "Epoch 987/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7893 - mean_squared_error: 5.1368 - val_loss: 2.1778 - val_mean_squared_error: 7.0571\n",
      "Epoch 988/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7809 - mean_squared_error: 5.1002 - val_loss: 2.1752 - val_mean_squared_error: 7.0820\n",
      "Epoch 989/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7827 - mean_squared_error: 5.1211 - val_loss: 2.1738 - val_mean_squared_error: 7.0423\n",
      "Epoch 990/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7829 - mean_squared_error: 5.1100 - val_loss: 2.1733 - val_mean_squared_error: 7.0325\n",
      "Epoch 991/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7762 - mean_squared_error: 5.0809 - val_loss: 2.1704 - val_mean_squared_error: 7.0216\n",
      "Epoch 992/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7906 - mean_squared_error: 5.1529 - val_loss: 2.1810 - val_mean_squared_error: 7.0719\n",
      "Epoch 993/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7846 - mean_squared_error: 5.1072 - val_loss: 2.1719 - val_mean_squared_error: 7.0191\n",
      "Epoch 994/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7955 - mean_squared_error: 5.1906 - val_loss: 2.1762 - val_mean_squared_error: 7.0639\n",
      "Epoch 995/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7854 - mean_squared_error: 5.1353 - val_loss: 2.1689 - val_mean_squared_error: 7.0147\n",
      "Epoch 996/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7796 - mean_squared_error: 5.1062 - val_loss: 2.1716 - val_mean_squared_error: 7.0315\n",
      "Epoch 997/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7797 - mean_squared_error: 5.1009 - val_loss: 2.1703 - val_mean_squared_error: 7.0106\n",
      "Epoch 998/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7856 - mean_squared_error: 5.1314 - val_loss: 2.1750 - val_mean_squared_error: 7.0564\n",
      "Epoch 999/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7875 - mean_squared_error: 5.1281 - val_loss: 2.1783 - val_mean_squared_error: 7.0819\n",
      "Epoch 1000/1000\n",
      "39/39 [==============================] - 0s 11ms/step - loss: 1.7959 - mean_squared_error: 5.1812 - val_loss: 2.1725 - val_mean_squared_error: 7.0450\n"
     ]
    }
   ],
   "source": [
    "model_s.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanSquaredError()])\n",
    "model_v.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanSquaredError()])\n",
    "\n",
    "history_s = model_s.fit(X_train_s, y_train_s, epochs=MAX_EPOCHS, batch_size = 64, validation_split=0.3)\n",
    "history_v = model_v.fit(X_train_v, y_train_v, epochs=MAX_EPOCHS, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "#plot_history(history_s, 'mean_squared_error')\n",
    "#plot_history(history_v, 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_s = model_s.predict(X_test_s)\n",
    "y_pred_v = model_v.predict(X_test_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47960677 0.36778548 0.5654937 ]\n",
      "[0.26936275 0.37231544 0.46762797]\n",
      "0.13171499177391036\n",
      "2.1558378071539264\n"
     ]
    }
   ],
   "source": [
    "model_s.evaluate(X_test_s, y_test_s)\n",
    "model_v.evaluate(X_test_v, y_test_v)\n",
    "\n",
    "print(mean_absolute_error(y_test_s, y_pred_s))\n",
    "print(mean_absolute_error(y_test_v, y_pred_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs'])\n",
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
      "[CV 1/5] END batch_size=32, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=100, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=32, epochs=100, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=32, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=100, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=32, epochs=100, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=32, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=200, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=32, epochs=200, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=32, epochs=200, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=32, epochs=200, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=32, epochs=200, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=300, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=32, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=300, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=32, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=300, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=32, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=300, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=32, epochs=300, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=32, epochs=400, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=32, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=400, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=32, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=500, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=32, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=500, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=500, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=500, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=500, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=32, epochs=500, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=500, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=32, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=600, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=32, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=600, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=32, epochs=600, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=600, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=32, epochs=600, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=600, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=32, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=700, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=32, epochs=700, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=32, epochs=700, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=32, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=32, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=32, epochs=800, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=32, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=800, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=32, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=800, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=32, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=900, optimizer=rmsprop;, score=nan total time=   4.5s\n",
      "[CV 2/5] END batch_size=32, epochs=900, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=32, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=900, optimizer=adam;, score=nan total time=   0.5s\n",
      "[CV 3/5] END batch_size=32, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=32, epochs=900, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=900, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=32, epochs=900, optimizer=SGD;, score=nan total time=   0.5s\n",
      "[CV 4/5] END batch_size=32, epochs=900, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=900, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=32, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=32, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=32, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=32, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=32, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=32, epochs=1000, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=32, epochs=1000, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=32, epochs=1000, optimizer=adam;, score=nan total time=   0.5s\n",
      "[CV 5/5] END batch_size=32, epochs=1000, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=32, epochs=1000, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=32, epochs=1000, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=32, epochs=1000, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=32, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=32, epochs=1000, optimizer=SGD;, score=nan total time=   0.5s\n",
      "[CV 1/5] END batch_size=64, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=100, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=100, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=200, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=200, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=200, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=64, epochs=200, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=200, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=200, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=64, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=200, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=200, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=300, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=64, epochs=300, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=300, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=300, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=64, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=400, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=400, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=64, epochs=400, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=400, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=400, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=64, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=400, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=500, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=500, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=64, epochs=500, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=500, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=500, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=500, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=64, epochs=500, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=64, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=500, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=64, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=600, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=600, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=600, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=600, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=64, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=600, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=600, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=64, epochs=600, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=600, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=600, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=600, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=700, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=700, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=64, epochs=700, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=700, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=700, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=700, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=700, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=700, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=800, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=64, epochs=800, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=800, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=64, epochs=800, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=800, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=800, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=64, epochs=800, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=800, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=800, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=900, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=64, epochs=900, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=900, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=64, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=900, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=64, epochs=900, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=900, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=900, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=64, epochs=900, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=64, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=64, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=64, epochs=1000, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=64, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=64, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=1000, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=64, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=64, epochs=1000, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=64, epochs=1000, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=64, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=64, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=64, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=100, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=100, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=128, epochs=100, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=100, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=100, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=128, epochs=100, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=128, epochs=100, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=128, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=100, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=200, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=200, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=128, epochs=200, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=128, epochs=200, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=200, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=128, epochs=200, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=200, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=128, epochs=200, optimizer=adam;, score=nan total time=   0.6s\n",
      "[CV 4/5] END batch_size=128, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=200, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=200, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=200, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=300, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=128, epochs=300, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=300, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=300, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=300, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=128, epochs=300, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=300, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=300, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=128, epochs=300, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=400, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=400, optimizer=rmsprop;, score=nan total time=   0.5s\n",
      "[CV 5/5] END batch_size=128, epochs=400, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=400, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=400, optimizer=adam;, score=nan total time=   0.5s\n",
      "[CV 1/5] END batch_size=128, epochs=400, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=400, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=128, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=400, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=400, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=128, epochs=500, optimizer=rmsprop;, score=nan total time=   0.5s\n",
      "[CV 2/5] END batch_size=128, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=500, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=500, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=128, epochs=500, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=500, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=128, epochs=500, optimizer=adam;, score=nan total time=   0.5s\n",
      "[CV 4/5] END batch_size=128, epochs=500, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=128, epochs=500, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=500, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=500, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=128, epochs=500, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=128, epochs=500, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=600, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=600, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=128, epochs=600, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=128, epochs=600, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=600, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=600, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=128, epochs=600, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=128, epochs=600, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=600, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 1/5] END batch_size=128, epochs=600, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=600, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 3/5] END batch_size=128, epochs=600, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=600, optimizer=SGD;, score=nan total time=   0.5s\n",
      "[CV 5/5] END batch_size=128, epochs=600, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=700, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=700, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=128, epochs=700, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=700, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=700, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=128, epochs=700, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=128, epochs=700, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=800, optimizer=rmsprop;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=128, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=800, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=800, optimizer=adam;, score=nan total time=   0.4s\n",
      "[CV 2/5] END batch_size=128, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=800, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=800, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=128, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=800, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=800, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 4/5] END batch_size=128, epochs=800, optimizer=SGD;, score=nan total time=   0.4s\n",
      "[CV 5/5] END batch_size=128, epochs=800, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 1/5] END batch_size=128, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=900, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 3/5] END batch_size=128, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=900, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 5/5] END batch_size=128, epochs=900, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=900, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=128, epochs=900, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=900, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 4/5] END batch_size=128, epochs=900, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=900, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 2/5] END batch_size=128, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=1000, optimizer=rmsprop;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=1000, optimizer=adam;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=1000, optimizer=adam;, score=nan total time=   0.3s\n",
      "[CV 1/5] END batch_size=128, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 2/5] END batch_size=128, epochs=1000, optimizer=SGD;, score=nan total time=   0.2s\n",
      "[CV 3/5] END batch_size=128, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 4/5] END batch_size=128, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n",
      "[CV 5/5] END batch_size=128, epochs=1000, optimizer=SGD;, score=nan total time=   0.3s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 450 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc0d6a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725095c40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb2d910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e8fe50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973070ff70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730701220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa7b8e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eec3ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728942520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305bfca0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e6a640>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5cafa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307013a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ba168220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729a3b700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728966e80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5ce7f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5d16a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303a47c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732539250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eeacfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa97040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305552b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f8cab20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa68730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973055df70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732516eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa6cbe0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eeb9430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5cdd30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b727f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc4c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f9f400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5caf70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cdb0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ce4fa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0f3070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fc14f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973253fb50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97332be970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973056e910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733287670>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971c52e070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5ba4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973306f610>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b427880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724da8a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973056ea00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd2f40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f8bd250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733280b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b9857c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725071460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733280670>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9806fad6a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd0dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724da8f10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f95b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973305c2e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730723250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fa6d00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97259f0910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973055df40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973306f1c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f5c700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307232b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fdbf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b94cf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa7b940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717017040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f60f40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a677580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973306f580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96ed60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717afe460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb5fc10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725067fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730ad6df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b94dd00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730ae3a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97173516a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971734daf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728942040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730af8190>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730afcfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725011af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289fa0d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d1a130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96b070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724df48b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725001550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724da88b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289ef400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd27c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa84520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97330499d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289fa4c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc1ed60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b94dd90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a6e3bb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973305cd00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97332a8ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e17f70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d947a90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc5d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a6c1ee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d946d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289df9d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94efa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94e220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97330400a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e130d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca4b50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96e4c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973328b220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca37f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cbf580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728966880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303306a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc126c10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b460d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb5c970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972899f9d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ee90550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97228e7250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97228ccac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ee90100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f17f310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffd3610>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aaac880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97662e40a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730981fa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289664c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27790>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971fb2da00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725097700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728ceaa30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732436130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffd38b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f161040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f670b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9721943b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724872250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289665b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976a830df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d013be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976ac39040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97662e4eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981c3a06a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730996550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97239708e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9821c0e340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971b4da3a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730541550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972355f760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ff0d4430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc126f70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f173bb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d12ba60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976df23700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981741b5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976811eaf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9765cfa040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976ab47730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981206de50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f980cd10040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfff4880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ec8cc40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97226ec370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730541700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ff0d9100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ba83190>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976fb5cd30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97676731c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717683a90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb4dbf70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27a60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724ffc370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730ae5040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724830ee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fe6ca0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f17fdf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc6340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fbe250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972373ef70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97f9272e50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97332b69d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97676736a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971bc17100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f8cab50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fa2e820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc126b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fbc0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9807a20730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fe61c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fbe730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ffe8dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fe66a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97338f23a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ba44d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b451df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0d0820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d12ba30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5d19d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b451880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732415430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767673880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aaac0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717684b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972be9a490>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97227c0400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9809ab7f10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb10280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972894f5e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa97550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973060ac10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97324151f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dcfc70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb8de50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa97940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728999460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97306f0a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64f0d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb4db280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971fb835e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b7da60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa27310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976811ec70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725071b50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffe0b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973072ad00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724d99490>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97227c1940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303a7d90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728965790>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64ff70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d343a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f119520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728966a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730b1d280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730b0a2e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64f610>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973090bbe0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b9adaf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97338f2340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a13a00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303a7970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdf2c160>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffe09d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730b0a940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f4562e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ced72760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cedddac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64fe80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732415c10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ba8d0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97227c79a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97c8e5a100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976772b820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730c11460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981a39e9d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d05c40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717683eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767cf6850>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfcd4ee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9766b7ce50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fe9af40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730bffa00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97c8aedfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc6eb250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730c143a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d97fbe0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f3eed90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728cd8400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f855d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d05e20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdf38760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf72a100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a82fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffe0d90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb8dfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfcd4130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981d22c5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f4560d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d1091f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717683fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97681fc700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f303ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb831c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb83280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976df23bb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f0e340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729209310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717b14760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971b4b41c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdeba400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfff4ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f556df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fac7250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973017db50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e17af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9806be3d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b994c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a954f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a82a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976617bac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976617b670>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9821c17c40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767499b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97256411c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976782d400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976766b6d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733a5eb20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97250715e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973136dee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eca0130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb8d580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824ee80d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94f4c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc17a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981254e250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cde07880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a77460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767cf6dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca3550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981d22c5e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767a2bf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307215e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305d9430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976df23190>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0f37c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b4274c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fac77c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97235c3910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289c2cd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971c52ebb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733a59910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a04df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc1e730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb86820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97c8aed370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5c9400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9731dea2e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb1ef70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b4278e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94f910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb0d0070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971c52ea30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5cdac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976747e100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973253d970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976ac19370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976d837dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0d4c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976dc6c310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94fb80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724df4ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc59d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9806f9f4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96ea90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733075df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb86640>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b91fa30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca3280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976766bd90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cf93a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307075b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97228c8f10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973071b820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973328bf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f98218b1520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972895fa60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289427c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd2b50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728954c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972894d5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc9b400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d963c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96e550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d18fa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728948b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728ba2b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f0e2b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973093d4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b99910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730923850>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d13ea60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289428e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730935400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ff1fe970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729c83be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa94790>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730932d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976614fc10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973091f3a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d95c5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cde07070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aac5b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767480af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d938490>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976748d4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9816843c10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733077310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb0d0460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972894d580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97338fd220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eebe4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d95a520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730721be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305db880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aace220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb86850>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aad1910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305f7880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728964880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d95ca60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973057b2b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdebaf70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733043400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730723640>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b952fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97330433a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b969b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d961af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fac7520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b978b20>. Data may not match loss function!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-359-afb11efa4b4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 450 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc0d6a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725095c40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb2d910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e8fe50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973070ff70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730701220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa7b8e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eec3ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728942520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305bfca0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e6a640>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5cafa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307013a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ba168220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729a3b700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728966e80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5ce7f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5d16a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303a47c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732539250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eeacfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa97040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305552b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f8cab20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa68730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973055df70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732516eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa6cbe0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eeb9430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5cdd30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b727f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc4c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f9f400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5caf70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cdb0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ce4fa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0f3070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fc14f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973253fb50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97332be970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973056e910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733287670>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971c52e070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5ba4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973306f610>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b427880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724da8a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973056ea00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd2f40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f8bd250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733280b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b9857c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725071460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733280670>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9806fad6a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd0dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724da8f10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f95b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973305c2e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730723250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fa6d00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97259f0910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973055df40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973306f1c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f5c700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307232b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fdbf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b94cf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa7b940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717017040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724f60f40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a677580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973306f580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96ed60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717afe460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb5fc10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725067fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730ad6df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b94dd00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730ae3a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97173516a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971734daf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728942040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730af8190>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730afcfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725011af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289fa0d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d1a130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96b070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724df48b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725001550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724da88b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289ef400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd27c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa84520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97330499d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289fa4c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc1ed60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b94dd90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a6e3bb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973305cd00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97332a8ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e17f70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d947a90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc5d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a6c1ee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d946d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289df9d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94efa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94e220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97330400a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e130d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca4b50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96e4c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973328b220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca37f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cbf580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728966880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303306a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc126c10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b460d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb5c970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972899f9d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ee90550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97228e7250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97228ccac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ee90100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f17f310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffd3610>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aaac880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97662e40a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730981fa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289664c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27790>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971fb2da00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725097700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728ceaa30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732436130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffd38b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f161040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f670b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9721943b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724872250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289665b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976a830df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d013be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976ac39040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97662e4eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981c3a06a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730996550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97239708e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9821c0e340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971b4da3a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730541550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972355f760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ff0d4430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc126f70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f173bb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d12ba60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976df23700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981741b5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976811eaf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9765cfa040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976ab47730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981206de50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f980cd10040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfff4880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ec8cc40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97226ec370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730541700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ff0d9100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ba83190>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976fb5cd30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97676731c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717683a90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb4dbf70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27a60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724ffc370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730ae5040>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724830ee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fe6ca0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f27130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f17fdf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc6340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fbe250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972373ef70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97f9272e50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97332b69d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97676736a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971bc17100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f8cab50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fa2e820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc126b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fbc0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9807a20730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730624eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fe61c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fbe730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ffe8dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724fe66a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97338f23a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ba44d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b451df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0d0820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d12ba30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5d19d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b451880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732415430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767673880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aaac0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717684b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972be9a490>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97227c0400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9809ab7f10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb10280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972894f5e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa97550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973060ac10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97324151f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dcfc70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb8de50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa97940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728999460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97306f0a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64f0d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb4db280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971fb835e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b7da60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa27310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976811ec70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725071b50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffe0b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973072ad00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724d99490>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97227c1940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303a7d90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728965790>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64ff70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d343a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f119520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728966a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730b1d280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730b0a2e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64f610>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973090bbe0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b9adaf0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97338f2340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a13a00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97303a7970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdf2c160>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffe09d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730b0a940>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f4562e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ced72760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cedddac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a64fe80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9732415c10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972ba8d0a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97227c79a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97c8e5a100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976772b820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730c11460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981a39e9d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d05c40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717683eb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767cf6850>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfcd4ee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9766b7ce50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fe9af40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730bffa00>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97c8aedfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fc6eb250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730c143a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d97fbe0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f3eed90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728cd8400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f855d60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d05e20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdf38760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf72a100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a82fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cffe0d90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb8dfa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfcd4130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981d22c5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f4560d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d1091f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717683fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97681fc700>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f303ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb831c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb83280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976df23bb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f0e340>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729209310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9717b14760>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971b4b41c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdeba400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cfff4ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972f556df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fac7250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973017db50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724e17af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9806be3d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b994c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a954f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a82a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976617bac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976617b670>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9821c17c40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767499b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97256411c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976782d400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976766b6d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733a5eb20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97250715e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973136dee0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eca0130>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb8d580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824ee80d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94f4c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc17a30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981254e250>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cde07880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a77460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767cf6dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca3550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f981d22c5e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767a2bf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307215e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305d9430>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976df23190>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0f37c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b4274c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fac77c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97235c3910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289c2cd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971c52ebb0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733a59910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9725a04df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc1e730>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb86820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97c8aed370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5c9400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9731dea2e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972bb1ef70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b4278e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94f910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb0d0070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971c52ea30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf5cdac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976747e100>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973253d970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976ac19370>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976d837dc0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972a0d4c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976dc6c310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d94fb80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724df4ac0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9724dc59d0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9806f9f4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96ea90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733075df0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb86640>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b91fa30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729ca3280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976766bd90>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cf93a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97307075b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97228c8f10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973071b820>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973328bf40>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f98218b1520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972895fa60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289427c0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729cd2b50>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728954c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972894d5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972dc9b400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d963c70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b96e550>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9824d18fa0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728948b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728ba2b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9815f0e2b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973093d4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cf598280>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9817b99910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730923850>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d13ea60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97289428e0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730935400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97ff1fe970>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9729c83be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aa94790>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730932d30>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976614fc10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973091f3a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d95c5b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cde07070>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aac5b80>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9767480af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d938490>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f976748d4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9816843c10>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733077310>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97fb0d0460>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972894d580>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97338fd220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972eebe4f0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d95a520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730721be0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305db880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aace220>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdb86850>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f971aad1910>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97305f7880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9728964880>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d95ca60>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f973057b2b0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97cdebaf70>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9733043400>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f9730723640>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b952fd0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f97330433a0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b969b20>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972d961af0>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972fac7520>. Data may not match loss function!\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 929, in _fit\n    self._check_model_compatibility(y)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 571, in _check_model_compatibility\n    raise ValueError(\nValueError: loss=mean_squared_error but model compiled with <keras.losses.MeanAbsoluteError object at 0x7f972b978b20>. Data may not match loss function!\n"
     ]
    }
   ],
   "source": [
    "def create_model_s(optimizer = 'adam'):\n",
    "    model_s = Sequential()\n",
    "\n",
    "    model_s.add(Dense(units=256, activation='relu', input_shape=(dataset.shape[1], dataset.shape[2])))\n",
    "    model_s.add(Dropout(0.2))\n",
    "\n",
    "    model_s.add(Dense(units=128, activation='relu'))\n",
    "    model_s.add(Dropout(0.2))\n",
    "    model_s.add(Dense(units=128, activation='relu'))\n",
    "    model_s.add(Dropout(0.2))\n",
    "    model_s.add(Dense(units=128, activation='linear'))\n",
    "    model_s.add(Dropout(0.2))\n",
    "    model_s.add(Flatten())\n",
    "\n",
    "    model_s.add(Dense(units=y_s.shape[1]))\n",
    "    \n",
    "    model_s.compile(loss=MeanAbsoluteError(), optimizer = optimizer, metrics=[MeanSquaredError()])\n",
    "\n",
    "    return model_s\n",
    "\n",
    "model = KerasRegressor(model=create_model_s, verbose=0, loss='mean_squared_error')\n",
    "print(model.get_params().keys())\n",
    "\n",
    "optimizers = ['rmsprop','adam','SGD']\n",
    "\n",
    "epochs = [100*k for k in range(1, 11)]\n",
    "batches = [32, 64, 128]\n",
    "param_grid = dict(optimizer=optimizers, batch_size=batches, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_absolute_error', verbose=3)\n",
    "grid_result = grid.fit(X_train_s, y_train_s)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_s():\n",
    "    input_s = Input(shape = (dataset.shape[1], dataset.shape[2],))\n",
    "    x = Dense(16, activation=\"relu\")(input_s)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(3, activation=\"linear\")(x)\n",
    "\n",
    "    model = Model(inputs=input_s, outputs=x)\n",
    "\n",
    "    model.compile(loss=MeanAbsoluteError(), optimizer='adam', metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs'])\n",
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "[CV 1/5] END ........batch_size=32, epochs=100;, score=-0.198 total time=   3.1s\n",
      "[CV 2/5] END ........batch_size=32, epochs=100;, score=-0.270 total time=   2.7s\n",
      "[CV 3/5] END ........batch_size=32, epochs=100;, score=-0.246 total time=   2.6s\n",
      "[CV 4/5] END ........batch_size=32, epochs=100;, score=-0.236 total time=   3.0s\n",
      "[CV 5/5] END ........batch_size=32, epochs=100;, score=-0.182 total time=   2.5s\n",
      "[CV 1/5] END ........batch_size=32, epochs=200;, score=-0.191 total time=   4.2s\n",
      "[CV 2/5] END ........batch_size=32, epochs=200;, score=-0.191 total time=   4.4s\n",
      "[CV 3/5] END ........batch_size=32, epochs=200;, score=-0.189 total time=   4.5s\n",
      "[CV 4/5] END ........batch_size=32, epochs=200;, score=-0.195 total time=   4.4s\n",
      "[CV 5/5] END ........batch_size=32, epochs=200;, score=-0.186 total time=   5.5s\n",
      "[CV 1/5] END ........batch_size=32, epochs=300;, score=-0.141 total time=   6.3s\n",
      "[CV 2/5] END ........batch_size=32, epochs=300;, score=-0.221 total time=   6.7s\n",
      "[CV 3/5] END ........batch_size=32, epochs=300;, score=-0.209 total time=   5.7s\n",
      "[CV 4/5] END ........batch_size=32, epochs=300;, score=-0.188 total time=   4.7s\n",
      "[CV 5/5] END ........batch_size=32, epochs=300;, score=-0.232 total time=   4.6s\n",
      "[CV 1/5] END ........batch_size=32, epochs=400;, score=-0.192 total time=   6.0s\n",
      "[CV 2/5] END ........batch_size=32, epochs=400;, score=-0.193 total time=   5.4s\n",
      "[CV 3/5] END ........batch_size=32, epochs=400;, score=-0.187 total time=   5.5s\n",
      "[CV 4/5] END ........batch_size=32, epochs=400;, score=-0.182 total time=   5.7s\n",
      "[CV 5/5] END ........batch_size=32, epochs=400;, score=-0.173 total time=   5.9s\n",
      "[CV 1/5] END ........batch_size=32, epochs=500;, score=-0.162 total time=   6.9s\n",
      "[CV 2/5] END ........batch_size=32, epochs=500;, score=-0.188 total time=   6.5s\n",
      "[CV 3/5] END ........batch_size=32, epochs=500;, score=-0.189 total time=   6.9s\n",
      "[CV 4/5] END ........batch_size=32, epochs=500;, score=-0.186 total time=   6.6s\n",
      "[CV 5/5] END ........batch_size=32, epochs=500;, score=-0.197 total time=   6.3s\n",
      "[CV 1/5] END ........batch_size=32, epochs=600;, score=-0.184 total time=   8.3s\n",
      "[CV 2/5] END ........batch_size=32, epochs=600;, score=-0.192 total time=   8.3s\n",
      "[CV 3/5] END ........batch_size=32, epochs=600;, score=-0.187 total time=   7.8s\n",
      "[CV 4/5] END ........batch_size=32, epochs=600;, score=-0.168 total time=   7.3s\n",
      "[CV 5/5] END ........batch_size=32, epochs=600;, score=-0.186 total time=   7.4s\n",
      "[CV 1/5] END ........batch_size=32, epochs=700;, score=-0.163 total time=   8.9s\n",
      "[CV 2/5] END ........batch_size=32, epochs=700;, score=-0.211 total time=   8.2s\n",
      "[CV 3/5] END ........batch_size=32, epochs=700;, score=-0.188 total time=  12.1s\n",
      "[CV 4/5] END ........batch_size=32, epochs=700;, score=-0.201 total time=   9.4s\n",
      "[CV 5/5] END ........batch_size=32, epochs=700;, score=-0.189 total time=   9.4s\n",
      "[CV 1/5] END ........batch_size=32, epochs=800;, score=-0.146 total time=   9.9s\n",
      "[CV 2/5] END ........batch_size=32, epochs=800;, score=-0.236 total time=  11.8s\n",
      "[CV 3/5] END ........batch_size=32, epochs=800;, score=-0.181 total time=   9.9s\n",
      "[CV 4/5] END ........batch_size=32, epochs=800;, score=-0.186 total time=  10.3s\n",
      "[CV 5/5] END ........batch_size=32, epochs=800;, score=-0.199 total time=  10.2s\n",
      "[CV 1/5] END ........batch_size=32, epochs=900;, score=-0.202 total time=  11.6s\n",
      "[CV 2/5] END ........batch_size=32, epochs=900;, score=-0.221 total time=  11.6s\n",
      "[CV 3/5] END ........batch_size=32, epochs=900;, score=-0.207 total time=  11.8s\n",
      "[CV 4/5] END ........batch_size=32, epochs=900;, score=-0.183 total time=  21.0s\n",
      "[CV 5/5] END ........batch_size=32, epochs=900;, score=-0.202 total time=  11.2s\n",
      "[CV 1/5] END .......batch_size=32, epochs=1000;, score=-0.196 total time=  12.2s\n",
      "[CV 2/5] END .......batch_size=32, epochs=1000;, score=-0.191 total time=  11.8s\n",
      "[CV 3/5] END .......batch_size=32, epochs=1000;, score=-0.187 total time=  11.2s\n",
      "[CV 4/5] END .......batch_size=32, epochs=1000;, score=-0.183 total time=  11.2s\n",
      "[CV 5/5] END .......batch_size=32, epochs=1000;, score=-0.197 total time=  11.2s\n",
      "[CV 1/5] END ........batch_size=64, epochs=100;, score=-0.202 total time=   2.4s\n",
      "[CV 2/5] END ........batch_size=64, epochs=100;, score=-0.182 total time=   2.9s\n",
      "[CV 3/5] END ........batch_size=64, epochs=100;, score=-0.225 total time=   2.4s\n",
      "[CV 4/5] END ........batch_size=64, epochs=100;, score=-0.229 total time=   2.2s\n",
      "[CV 5/5] END ........batch_size=64, epochs=100;, score=-0.192 total time=   2.2s\n",
      "[CV 1/5] END ........batch_size=64, epochs=200;, score=-0.139 total time=   4.2s\n",
      "[CV 2/5] END ........batch_size=64, epochs=200;, score=-0.222 total time=   4.9s\n",
      "[CV 3/5] END ........batch_size=64, epochs=200;, score=-0.207 total time=   3.0s\n",
      "[CV 4/5] END ........batch_size=64, epochs=200;, score=-0.198 total time=   4.8s\n",
      "[CV 5/5] END ........batch_size=64, epochs=200;, score=-0.188 total time=   3.6s\n",
      "[CV 1/5] END ........batch_size=64, epochs=300;, score=-0.164 total time=   4.6s\n",
      "[CV 2/5] END ........batch_size=64, epochs=300;, score=-0.175 total time=   4.0s\n",
      "[CV 3/5] END ........batch_size=64, epochs=300;, score=-0.242 total time=   4.2s\n",
      "[CV 4/5] END ........batch_size=64, epochs=300;, score=-0.167 total time=   3.9s\n",
      "[CV 5/5] END ........batch_size=64, epochs=300;, score=-0.187 total time=   3.5s\n",
      "[CV 1/5] END ........batch_size=64, epochs=400;, score=-0.202 total time=   4.5s\n",
      "[CV 2/5] END ........batch_size=64, epochs=400;, score=-0.183 total time=   7.1s\n",
      "[CV 3/5] END ........batch_size=64, epochs=400;, score=-0.193 total time=   4.7s\n",
      "[CV 4/5] END ........batch_size=64, epochs=400;, score=-0.193 total time=   4.9s\n",
      "[CV 5/5] END ........batch_size=64, epochs=400;, score=-0.213 total time=   4.6s\n",
      "[CV 1/5] END ........batch_size=64, epochs=500;, score=-0.210 total time=   5.7s\n",
      "[CV 2/5] END ........batch_size=64, epochs=500;, score=-0.237 total time=   5.1s\n",
      "[CV 3/5] END ........batch_size=64, epochs=500;, score=-0.170 total time=   6.3s\n",
      "[CV 4/5] END ........batch_size=64, epochs=500;, score=-0.239 total time=   5.7s\n",
      "[CV 5/5] END ........batch_size=64, epochs=500;, score=-0.184 total time=   7.0s\n",
      "[CV 1/5] END ........batch_size=64, epochs=600;, score=-0.185 total time=   6.3s\n",
      "[CV 2/5] END ........batch_size=64, epochs=600;, score=-0.199 total time=   6.1s\n",
      "[CV 3/5] END ........batch_size=64, epochs=600;, score=-0.223 total time=   6.5s\n",
      "[CV 4/5] END ........batch_size=64, epochs=600;, score=-0.183 total time=   6.0s\n",
      "[CV 5/5] END ........batch_size=64, epochs=600;, score=-0.210 total time=   7.0s\n",
      "[CV 1/5] END ........batch_size=64, epochs=700;, score=-0.207 total time=   7.4s\n",
      "[CV 2/5] END ........batch_size=64, epochs=700;, score=-0.196 total time=   7.1s\n",
      "[CV 3/5] END ........batch_size=64, epochs=700;, score=-0.226 total time=   6.8s\n",
      "[CV 4/5] END ........batch_size=64, epochs=700;, score=-0.215 total time=   6.4s\n",
      "[CV 5/5] END ........batch_size=64, epochs=700;, score=-0.193 total time=   6.2s\n",
      "[CV 1/5] END ........batch_size=64, epochs=800;, score=-0.198 total time=   7.1s\n",
      "[CV 2/5] END ........batch_size=64, epochs=800;, score=-0.172 total time=   6.9s\n",
      "[CV 3/5] END ........batch_size=64, epochs=800;, score=-0.183 total time=   6.5s\n",
      "[CV 4/5] END ........batch_size=64, epochs=800;, score=-0.175 total time=   6.3s\n",
      "[CV 5/5] END ........batch_size=64, epochs=800;, score=-0.207 total time=   6.5s\n",
      "[CV 1/5] END ........batch_size=64, epochs=900;, score=-0.174 total time=   7.1s\n",
      "[CV 2/5] END ........batch_size=64, epochs=900;, score=-0.201 total time=   7.3s\n",
      "[CV 3/5] END ........batch_size=64, epochs=900;, score=-0.195 total time=   7.3s\n",
      "[CV 4/5] END ........batch_size=64, epochs=900;, score=-0.191 total time=   7.3s\n",
      "[CV 5/5] END ........batch_size=64, epochs=900;, score=-0.194 total time=   7.2s\n",
      "[CV 1/5] END .......batch_size=64, epochs=1000;, score=-0.168 total time=   7.8s\n",
      "[CV 2/5] END .......batch_size=64, epochs=1000;, score=-0.175 total time=   7.1s\n",
      "[CV 3/5] END .......batch_size=64, epochs=1000;, score=-0.172 total time=   6.9s\n",
      "[CV 4/5] END .......batch_size=64, epochs=1000;, score=-0.176 total time=   7.0s\n",
      "[CV 5/5] END .......batch_size=64, epochs=1000;, score=-0.220 total time=   7.1s\n",
      "[CV 1/5] END .......batch_size=128, epochs=100;, score=-0.185 total time=   1.7s\n",
      "[CV 2/5] END .......batch_size=128, epochs=100;, score=-0.242 total time=   1.7s\n",
      "[CV 3/5] END .......batch_size=128, epochs=100;, score=-0.188 total time=   1.8s\n",
      "[CV 4/5] END .......batch_size=128, epochs=100;, score=-0.160 total time=   2.4s\n",
      "[CV 5/5] END .......batch_size=128, epochs=100;, score=-0.168 total time=   1.9s\n",
      "[CV 1/5] END .......batch_size=128, epochs=200;, score=-0.159 total time=   2.6s\n",
      "[CV 2/5] END .......batch_size=128, epochs=200;, score=-0.182 total time=   2.3s\n",
      "[CV 3/5] END .......batch_size=128, epochs=200;, score=-0.190 total time=   1.8s\n",
      "[CV 4/5] END .......batch_size=128, epochs=200;, score=-0.232 total time=   1.9s\n",
      "[CV 5/5] END .......batch_size=128, epochs=200;, score=-0.177 total time=   2.1s\n",
      "[CV 1/5] END .......batch_size=128, epochs=300;, score=-0.160 total time=   6.1s\n",
      "[CV 2/5] END .......batch_size=128, epochs=300;, score=-0.200 total time=   2.7s\n",
      "[CV 3/5] END .......batch_size=128, epochs=300;, score=-0.188 total time=   2.5s\n",
      "[CV 4/5] END .......batch_size=128, epochs=300;, score=-0.259 total time=   2.3s\n",
      "[CV 5/5] END .......batch_size=128, epochs=300;, score=-0.191 total time=   2.2s\n",
      "[CV 1/5] END .......batch_size=128, epochs=400;, score=-0.196 total time=   3.0s\n",
      "[CV 2/5] END .......batch_size=128, epochs=400;, score=-0.206 total time=   2.9s\n",
      "[CV 3/5] END .......batch_size=128, epochs=400;, score=-0.166 total time=   2.7s\n",
      "[CV 4/5] END .......batch_size=128, epochs=400;, score=-0.209 total time=   3.0s\n",
      "[CV 5/5] END .......batch_size=128, epochs=400;, score=-0.184 total time=   2.8s\n",
      "[CV 1/5] END .......batch_size=128, epochs=500;, score=-0.183 total time=   3.3s\n",
      "[CV 2/5] END .......batch_size=128, epochs=500;, score=-0.191 total time=   4.0s\n",
      "[CV 3/5] END .......batch_size=128, epochs=500;, score=-0.196 total time=   4.1s\n",
      "[CV 4/5] END .......batch_size=128, epochs=500;, score=-0.244 total time=   3.2s\n",
      "[CV 5/5] END .......batch_size=128, epochs=500;, score=-0.189 total time=   3.3s\n",
      "[CV 1/5] END .......batch_size=128, epochs=600;, score=-0.187 total time=   4.8s\n",
      "[CV 2/5] END .......batch_size=128, epochs=600;, score=-0.216 total time=   4.4s\n",
      "[CV 3/5] END .......batch_size=128, epochs=600;, score=-0.185 total time=   5.0s\n",
      "[CV 4/5] END .......batch_size=128, epochs=600;, score=-0.203 total time=   4.2s\n",
      "[CV 5/5] END .......batch_size=128, epochs=600;, score=-0.178 total time=   6.0s\n",
      "[CV 1/5] END .......batch_size=128, epochs=700;, score=-0.182 total time=   4.4s\n",
      "[CV 2/5] END .......batch_size=128, epochs=700;, score=-0.197 total time=   4.1s\n",
      "[CV 3/5] END .......batch_size=128, epochs=700;, score=-0.188 total time=   4.2s\n",
      "[CV 4/5] END .......batch_size=128, epochs=700;, score=-0.185 total time=   4.3s\n",
      "[CV 5/5] END .......batch_size=128, epochs=700;, score=-0.185 total time=   4.2s\n",
      "[CV 1/5] END .......batch_size=128, epochs=800;, score=-0.181 total time=   6.0s\n",
      "[CV 2/5] END .......batch_size=128, epochs=800;, score=-0.197 total time=   4.9s\n",
      "[CV 3/5] END .......batch_size=128, epochs=800;, score=-0.178 total time=   4.4s\n",
      "[CV 4/5] END .......batch_size=128, epochs=800;, score=-0.185 total time=   4.5s\n",
      "[CV 5/5] END .......batch_size=128, epochs=800;, score=-0.200 total time=   4.5s\n",
      "[CV 1/5] END .......batch_size=128, epochs=900;, score=-0.165 total time=   5.4s\n",
      "[CV 2/5] END .......batch_size=128, epochs=900;, score=-0.211 total time=   5.3s\n",
      "[CV 3/5] END .......batch_size=128, epochs=900;, score=-0.187 total time=   6.4s\n",
      "[CV 4/5] END .......batch_size=128, epochs=900;, score=-0.199 total time=   5.6s\n",
      "[CV 5/5] END .......batch_size=128, epochs=900;, score=-0.213 total time=   5.2s\n",
      "[CV 1/5] END ......batch_size=128, epochs=1000;, score=-0.195 total time=   5.6s\n",
      "[CV 2/5] END ......batch_size=128, epochs=1000;, score=-0.198 total time=   5.3s\n",
      "[CV 3/5] END ......batch_size=128, epochs=1000;, score=-0.189 total time=   5.3s\n",
      "[CV 4/5] END ......batch_size=128, epochs=1000;, score=-0.195 total time=   5.4s\n",
      "[CV 5/5] END ......batch_size=128, epochs=1000;, score=-0.207 total time=   5.0s\n",
      "{'batch_size': 64, 'epochs': 1000}\n"
     ]
    }
   ],
   "source": [
    "model = KerasRegressor(model=create_model_s, verbose=0)\n",
    "print(model.get_params().keys())\n",
    "\n",
    "#optimizers = ['rmsprop', 'adam','SGD']\n",
    "\n",
    "epochs = [100*k for k in range(1, 11)]\n",
    "batches = [32, 64, 128]\n",
    "param_grid = dict(batch_size=batches, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_absolute_error', verbose=3)\n",
    "grid_result = grid.fit(X_train_s, y_train_s)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'epochs': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.22630359 -0.19052391 -0.19803073 -0.18549171 -0.18422788 -0.18350874\n",
      " -0.19035495 -0.18946789 -0.2028634  -0.19110078 -0.20638925 -0.19108511\n",
      " -0.18710141 -0.1968804  -0.2078669  -0.19995019 -0.20761048 -0.18694709\n",
      " -0.19090448 -0.18225632 -0.18866515 -0.18794918 -0.19957265 -0.19200184\n",
      " -0.20046999 -0.19362138 -0.18754122 -0.18811319 -0.1951164  -0.19677013]\n",
      "[{'batch_size': 32, 'epochs': 100}, {'batch_size': 32, 'epochs': 200}, {'batch_size': 32, 'epochs': 300}, {'batch_size': 32, 'epochs': 400}, {'batch_size': 32, 'epochs': 500}, {'batch_size': 32, 'epochs': 600}, {'batch_size': 32, 'epochs': 700}, {'batch_size': 32, 'epochs': 800}, {'batch_size': 32, 'epochs': 900}, {'batch_size': 32, 'epochs': 1000}, {'batch_size': 64, 'epochs': 100}, {'batch_size': 64, 'epochs': 200}, {'batch_size': 64, 'epochs': 300}, {'batch_size': 64, 'epochs': 400}, {'batch_size': 64, 'epochs': 500}, {'batch_size': 64, 'epochs': 600}, {'batch_size': 64, 'epochs': 700}, {'batch_size': 64, 'epochs': 800}, {'batch_size': 64, 'epochs': 900}, {'batch_size': 64, 'epochs': 1000}, {'batch_size': 128, 'epochs': 100}, {'batch_size': 128, 'epochs': 200}, {'batch_size': 128, 'epochs': 300}, {'batch_size': 128, 'epochs': 400}, {'batch_size': 128, 'epochs': 500}, {'batch_size': 128, 'epochs': 600}, {'batch_size': 128, 'epochs': 700}, {'batch_size': 128, 'epochs': 800}, {'batch_size': 128, 'epochs': 900}, {'batch_size': 128, 'epochs': 1000}]\n"
     ]
    }
   ],
   "source": [
    "print(means)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epochs=1000, batch_size=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5] END dropout_rate=0.0, learning_rate=0.001;, score=-0.171 total time=   1.1s\n",
      "[CV 2/5] END dropout_rate=0.0, learning_rate=0.001;, score=-0.169 total time=   1.2s\n",
      "[CV 3/5] END dropout_rate=0.0, learning_rate=0.001;, score=-0.195 total time=   1.1s\n",
      "[CV 4/5] END dropout_rate=0.0, learning_rate=0.001;, score=-0.188 total time=   1.0s\n",
      "[CV 5/5] END dropout_rate=0.0, learning_rate=0.001;, score=-0.187 total time=   1.0s\n",
      "[CV 1/5] END dropout_rate=0.0, learning_rate=0.01;, score=-0.168 total time=   1.1s\n",
      "[CV 2/5] END dropout_rate=0.0, learning_rate=0.01;, score=-0.221 total time=   1.0s\n",
      "[CV 3/5] END dropout_rate=0.0, learning_rate=0.01;, score=-0.185 total time=   1.0s\n",
      "[CV 4/5] END dropout_rate=0.0, learning_rate=0.01;, score=-0.201 total time=   1.0s\n",
      "[CV 5/5] END dropout_rate=0.0, learning_rate=0.01;, score=-0.282 total time=   1.0s\n",
      "[CV 1/5] END dropout_rate=0.0, learning_rate=0.1;, score=-0.258 total time=   1.1s\n",
      "[CV 2/5] END dropout_rate=0.0, learning_rate=0.1;, score=-0.242 total time=   1.3s\n",
      "[CV 3/5] END dropout_rate=0.0, learning_rate=0.1;, score=-0.280 total time=   1.3s\n",
      "[CV 4/5] END dropout_rate=0.0, learning_rate=0.1;, score=-0.238 total time=   1.1s\n",
      "[CV 5/5] END dropout_rate=0.0, learning_rate=0.1;, score=-0.296 total time=  11.2s\n",
      "[CV 1/5] END dropout_rate=0.1, learning_rate=0.001;, score=-0.175 total time=   1.5s\n",
      "[CV 2/5] END dropout_rate=0.1, learning_rate=0.001;, score=-0.176 total time=   1.5s\n",
      "[CV 3/5] END dropout_rate=0.1, learning_rate=0.001;, score=-0.160 total time=   1.4s\n",
      "[CV 4/5] END dropout_rate=0.1, learning_rate=0.001;, score=-0.149 total time=   1.5s\n",
      "[CV 5/5] END dropout_rate=0.1, learning_rate=0.001;, score=-0.189 total time=   1.5s\n",
      "[CV 1/5] END dropout_rate=0.1, learning_rate=0.01;, score=-0.168 total time=   1.4s\n",
      "[CV 2/5] END dropout_rate=0.1, learning_rate=0.01;, score=-0.205 total time=   1.3s\n",
      "[CV 3/5] END dropout_rate=0.1, learning_rate=0.01;, score=-0.164 total time=   1.2s\n",
      "[CV 4/5] END dropout_rate=0.1, learning_rate=0.01;, score=-0.148 total time=   1.2s\n",
      "[CV 5/5] END dropout_rate=0.1, learning_rate=0.01;, score=-0.183 total time=   1.2s\n",
      "[CV 1/5] END dropout_rate=0.1, learning_rate=0.1;, score=-0.259 total time=   1.2s\n",
      "[CV 2/5] END dropout_rate=0.1, learning_rate=0.1;, score=-0.245 total time=   1.3s\n",
      "[CV 3/5] END dropout_rate=0.1, learning_rate=0.1;, score=-0.280 total time=   1.3s\n",
      "[CV 4/5] END dropout_rate=0.1, learning_rate=0.1;, score=-0.238 total time=   1.3s\n",
      "[CV 5/5] END dropout_rate=0.1, learning_rate=0.1;, score=-0.299 total time=   1.4s\n",
      "[CV 1/5] END dropout_rate=0.2, learning_rate=0.001;, score=-0.175 total time=   1.2s\n",
      "[CV 2/5] END dropout_rate=0.2, learning_rate=0.001;, score=-0.159 total time=   1.2s\n",
      "[CV 3/5] END dropout_rate=0.2, learning_rate=0.001;, score=-0.211 total time=   1.2s\n",
      "[CV 4/5] END dropout_rate=0.2, learning_rate=0.001;, score=-0.197 total time=   1.5s\n",
      "[CV 5/5] END dropout_rate=0.2, learning_rate=0.001;, score=-0.168 total time=   1.4s\n",
      "[CV 1/5] END dropout_rate=0.2, learning_rate=0.01;, score=-0.154 total time=   1.4s\n",
      "[CV 2/5] END dropout_rate=0.2, learning_rate=0.01;, score=-0.219 total time=   1.2s\n",
      "[CV 3/5] END dropout_rate=0.2, learning_rate=0.01;, score=-0.214 total time=   1.2s\n",
      "[CV 4/5] END dropout_rate=0.2, learning_rate=0.01;, score=-0.179 total time=   1.2s\n",
      "[CV 5/5] END dropout_rate=0.2, learning_rate=0.01;, score=-0.205 total time=   1.2s\n",
      "[CV 1/5] END dropout_rate=0.2, learning_rate=0.1;, score=-0.260 total time=   1.2s\n",
      "[CV 2/5] END dropout_rate=0.2, learning_rate=0.1;, score=-0.245 total time=   1.2s\n",
      "[CV 3/5] END dropout_rate=0.2, learning_rate=0.1;, score=-0.281 total time=   1.2s\n",
      "[CV 4/5] END dropout_rate=0.2, learning_rate=0.1;, score=-0.238 total time=   1.2s\n",
      "[CV 5/5] END dropout_rate=0.2, learning_rate=0.1;, score=-0.298 total time=   1.2s\n",
      "[CV 1/5] END dropout_rate=0.3, learning_rate=0.001;, score=-0.172 total time=   1.4s\n",
      "[CV 2/5] END dropout_rate=0.3, learning_rate=0.001;, score=-0.168 total time=   1.2s\n",
      "[CV 3/5] END dropout_rate=0.3, learning_rate=0.001;, score=-0.213 total time=   1.2s\n",
      "[CV 4/5] END dropout_rate=0.3, learning_rate=0.001;, score=-0.197 total time=   1.2s\n",
      "[CV 5/5] END dropout_rate=0.3, learning_rate=0.001;, score=-0.194 total time=   1.3s\n",
      "[CV 1/5] END dropout_rate=0.3, learning_rate=0.01;, score=-0.191 total time=   1.2s\n",
      "[CV 2/5] END dropout_rate=0.3, learning_rate=0.01;, score=-0.225 total time=   1.3s\n",
      "[CV 3/5] END dropout_rate=0.3, learning_rate=0.01;, score=-0.187 total time=   1.4s\n",
      "[CV 4/5] END dropout_rate=0.3, learning_rate=0.01;, score=-0.212 total time=   1.2s\n",
      "[CV 5/5] END dropout_rate=0.3, learning_rate=0.01;, score=-0.193 total time=   1.4s\n",
      "[CV 1/5] END dropout_rate=0.3, learning_rate=0.1;, score=-0.259 total time=   1.3s\n",
      "[CV 2/5] END dropout_rate=0.3, learning_rate=0.1;, score=-0.245 total time=   1.3s\n",
      "[CV 3/5] END dropout_rate=0.3, learning_rate=0.1;, score=-0.281 total time=   1.4s\n",
      "[CV 4/5] END dropout_rate=0.3, learning_rate=0.1;, score=-0.238 total time=   1.6s\n",
      "[CV 5/5] END dropout_rate=0.3, learning_rate=0.1;, score=-0.298 total time=   1.3s\n",
      "{'dropout_rate': 0.1, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "def create_model_s_rates(dropout_rate, learning_rate):\n",
    "    input_s = Input(shape = (dataset.shape[1], dataset.shape[2],))\n",
    "    x = Dense(16, activation=\"relu\")(input_s)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(3, activation=\"linear\")(x)\n",
    "\n",
    "    model = Model(inputs=input_s, outputs=x)\n",
    "    adam = Adam(learning_rate = learning_rate)\n",
    "\n",
    "    model.compile(loss=MeanAbsoluteError(), optimizer=adam, metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasRegressor(model=create_model_s_rates, verbose=0, batch_size=64, epochs=128, dropout_rate=0.0, learning_rate=0.001)\n",
    "\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2,0.3]\n",
    "\n",
    "param_grid = dict(learning_rate=learning_rate, dropout_rate=dropout_rate)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_absolute_error', verbose=3)\n",
    "grid_result = grid.fit(X_train_s, y_train_s)\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "[-0.18210669 -0.21138303 -0.26293961 -0.16967758 -0.1736602  -0.26425233\n",
      " -0.18190399 -0.1942943  -0.26431329 -0.18872228 -0.20171043 -0.26428445]\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_params_)\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rseau de neurones rcurrent pour les seuils *model_rnn*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_20 (SimpleRNN)    (None, 32)                1152      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 1,251\n",
      "Trainable params: 1,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(32, input_shape=(dataset.shape[1], dataset.shape[2])))\n",
    "model_rnn.add(Dense(units=y_s.shape[1]))\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.7349 - mean_squared_error: 0.7849 - val_loss: 0.7142 - val_mean_squared_error: 0.7486\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6878 - mean_squared_error: 0.7027 - val_loss: 0.6813 - val_mean_squared_error: 0.6770\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6418 - mean_squared_error: 0.6268 - val_loss: 0.6509 - val_mean_squared_error: 0.6096\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5996 - mean_squared_error: 0.5572 - val_loss: 0.6173 - val_mean_squared_error: 0.5457\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5600 - mean_squared_error: 0.4939 - val_loss: 0.5809 - val_mean_squared_error: 0.4857\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.5249 - mean_squared_error: 0.4367 - val_loss: 0.5446 - val_mean_squared_error: 0.4299\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.4922 - mean_squared_error: 0.3853 - val_loss: 0.5088 - val_mean_squared_error: 0.3791\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.4619 - mean_squared_error: 0.3396 - val_loss: 0.4756 - val_mean_squared_error: 0.3330\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4336 - mean_squared_error: 0.2990 - val_loss: 0.4444 - val_mean_squared_error: 0.2917\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4089 - mean_squared_error: 0.26 - 0s 37ms/step - loss: 0.4089 - mean_squared_error: 0.2633 - val_loss: 0.4155 - val_mean_squared_error: 0.2553\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.3855 - mean_squared_error: 0.2323 - val_loss: 0.3886 - val_mean_squared_error: 0.2236\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3653 - mean_squared_error: 0.2056 - val_loss: 0.3654 - val_mean_squared_error: 0.1968\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3477 - mean_squared_error: 0.1834 - val_loss: 0.3449 - val_mean_squared_error: 0.1746\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.3322 - mean_squared_error: 0.1651 - val_loss: 0.3261 - val_mean_squared_error: 0.1568\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3178 - mean_squared_error: 0.1505 - val_loss: 0.3118 - val_mean_squared_error: 0.1431\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.3070 - mean_squared_error: 0.1394 - val_loss: 0.3033 - val_mean_squared_error: 0.1335\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2998 - mean_squared_error: 0.1317 - val_loss: 0.2996 - val_mean_squared_error: 0.1275\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2942 - mean_squared_error: 0.1268 - val_loss: 0.2969 - val_mean_squared_error: 0.1245\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2921 - mean_squared_error: 0.1240 - val_loss: 0.2970 - val_mean_squared_error: 0.1235\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.2908 - mean_squared_error: 0.1227 - val_loss: 0.2990 - val_mean_squared_error: 0.1241\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2907 - mean_squared_error: 0.1223 - val_loss: 0.3027 - val_mean_squared_error: 0.1251\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2907 - mean_squared_error: 0.1220 - val_loss: 0.3054 - val_mean_squared_error: 0.1258\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2905 - mean_squared_error: 0.1215 - val_loss: 0.3065 - val_mean_squared_error: 0.1261\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2894 - mean_squared_error: 0.1206 - val_loss: 0.3065 - val_mean_squared_error: 0.1257\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2878 - mean_squared_error: 0.1189 - val_loss: 0.3055 - val_mean_squared_error: 0.1246\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2854 - mean_squared_error: 0.1167 - val_loss: 0.3037 - val_mean_squared_error: 0.1228\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2823 - mean_squared_error: 0.1140 - val_loss: 0.3009 - val_mean_squared_error: 0.1204\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2787 - mean_squared_error: 0.1109 - val_loss: 0.2971 - val_mean_squared_error: 0.1176\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2751 - mean_squared_error: 0.1077 - val_loss: 0.2926 - val_mean_squared_error: 0.1146\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2718 - mean_squared_error: 0.1045 - val_loss: 0.2876 - val_mean_squared_error: 0.1115\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2691 - mean_squared_error: 0.1016 - val_loss: 0.2828 - val_mean_squared_error: 0.1085\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2664 - mean_squared_error: 0.0990 - val_loss: 0.2784 - val_mean_squared_error: 0.1057\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2637 - mean_squared_error: 0.0967 - val_loss: 0.2741 - val_mean_squared_error: 0.1034\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2616 - mean_squared_error: 0.0948 - val_loss: 0.2704 - val_mean_squared_error: 0.1015\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2598 - mean_squared_error: 0.0934 - val_loss: 0.2672 - val_mean_squared_error: 0.1002\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2580 - mean_squared_error: 0.0923 - val_loss: 0.2651 - val_mean_squared_error: 0.0992\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.2564 - mean_squared_error: 0.0916 - val_loss: 0.2640 - val_mean_squared_error: 0.0986\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2553 - mean_squared_error: 0.0911 - val_loss: 0.2634 - val_mean_squared_error: 0.0984\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2543 - mean_squared_error: 0.0907 - val_loss: 0.2630 - val_mean_squared_error: 0.0983\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2533 - mean_squared_error: 0.0903 - val_loss: 0.2629 - val_mean_squared_error: 0.0983\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2522 - mean_squared_error: 0.0898 - val_loss: 0.2632 - val_mean_squared_error: 0.0985\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2509 - mean_squared_error: 0.0893 - val_loss: 0.2636 - val_mean_squared_error: 0.0987\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2495 - mean_squared_error: 0.0886 - val_loss: 0.2642 - val_mean_squared_error: 0.0990\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2482 - mean_squared_error: 0.0878 - val_loss: 0.2651 - val_mean_squared_error: 0.0995\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2470 - mean_squared_error: 0.0871 - val_loss: 0.2662 - val_mean_squared_error: 0.1000\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2458 - mean_squared_error: 0.0863 - val_loss: 0.2676 - val_mean_squared_error: 0.1006\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2446 - mean_squared_error: 0.0856 - val_loss: 0.2691 - val_mean_squared_error: 0.1011\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2434 - mean_squared_error: 0.0849 - val_loss: 0.2707 - val_mean_squared_error: 0.1015\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2425 - mean_squared_error: 0.0843 - val_loss: 0.2716 - val_mean_squared_error: 0.1016\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2415 - mean_squared_error: 0.0837 - val_loss: 0.2719 - val_mean_squared_error: 0.1013\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2403 - mean_squared_error: 0.0832 - val_loss: 0.2713 - val_mean_squared_error: 0.1005\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2389 - mean_squared_error: 0.0826 - val_loss: 0.2702 - val_mean_squared_error: 0.0996\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2374 - mean_squared_error: 0.0821 - val_loss: 0.2686 - val_mean_squared_error: 0.0985\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2360 - mean_squared_error: 0.0817 - val_loss: 0.2669 - val_mean_squared_error: 0.0975\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2349 - mean_squared_error: 0.0815 - val_loss: 0.2654 - val_mean_squared_error: 0.0966\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2340 - mean_squared_error: 0.0813 - val_loss: 0.2644 - val_mean_squared_error: 0.0960\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2330 - mean_squared_error: 0.0809 - val_loss: 0.2639 - val_mean_squared_error: 0.0959\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2319 - mean_squared_error: 0.0804 - val_loss: 0.2646 - val_mean_squared_error: 0.0961\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.2309 - mean_squared_error: 0.0799 - val_loss: 0.2651 - val_mean_squared_error: 0.0964\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2301 - mean_squared_error: 0.0795 - val_loss: 0.2653 - val_mean_squared_error: 0.0966\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2293 - mean_squared_error: 0.0793 - val_loss: 0.2653 - val_mean_squared_error: 0.0966\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2283 - mean_squared_error: 0.0790 - val_loss: 0.2649 - val_mean_squared_error: 0.0965\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2272 - mean_squared_error: 0.0788 - val_loss: 0.2645 - val_mean_squared_error: 0.0963\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2264 - mean_squared_error: 0.0786 - val_loss: 0.2642 - val_mean_squared_error: 0.0963\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2258 - mean_squared_error: 0.0785 - val_loss: 0.2640 - val_mean_squared_error: 0.0964\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2250 - mean_squared_error: 0.0783 - val_loss: 0.2639 - val_mean_squared_error: 0.0967\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2241 - mean_squared_error: 0.0781 - val_loss: 0.2637 - val_mean_squared_error: 0.0970\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2235 - mean_squared_error: 0.0780 - val_loss: 0.2628 - val_mean_squared_error: 0.0970\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2227 - mean_squared_error: 0.0780 - val_loss: 0.2613 - val_mean_squared_error: 0.0966\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2220 - mean_squared_error: 0.0782 - val_loss: 0.2601 - val_mean_squared_error: 0.0964\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2213 - mean_squared_error: 0.0783 - val_loss: 0.2594 - val_mean_squared_error: 0.0964\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2208 - mean_squared_error: 0.0784 - val_loss: 0.2593 - val_mean_squared_error: 0.0966\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2201 - mean_squared_error: 0.0783 - val_loss: 0.2593 - val_mean_squared_error: 0.0968\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.2196 - mean_squared_error: 0.0780 - val_loss: 0.2597 - val_mean_squared_error: 0.0972\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2190 - mean_squared_error: 0.0778 - val_loss: 0.2602 - val_mean_squared_error: 0.0976\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2185 - mean_squared_error: 0.0775 - val_loss: 0.2600 - val_mean_squared_error: 0.0975\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2179 - mean_squared_error: 0.0773 - val_loss: 0.2595 - val_mean_squared_error: 0.0972\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2173 - mean_squared_error: 0.0770 - val_loss: 0.2587 - val_mean_squared_error: 0.0967\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2166 - mean_squared_error: 0.0767 - val_loss: 0.2584 - val_mean_squared_error: 0.0964\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2160 - mean_squared_error: 0.0763 - val_loss: 0.2587 - val_mean_squared_error: 0.0963\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2155 - mean_squared_error: 0.0759 - val_loss: 0.2584 - val_mean_squared_error: 0.0960\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2150 - mean_squared_error: 0.0756 - val_loss: 0.2575 - val_mean_squared_error: 0.0956\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.2145 - mean_squared_error: 0.0756 - val_loss: 0.2570 - val_mean_squared_error: 0.0954\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2140 - mean_squared_error: 0.0755 - val_loss: 0.2565 - val_mean_squared_error: 0.0953\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2135 - mean_squared_error: 0.0755 - val_loss: 0.2562 - val_mean_squared_error: 0.0953\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2130 - mean_squared_error: 0.0755 - val_loss: 0.2560 - val_mean_squared_error: 0.0953\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2125 - mean_squared_error: 0.0754 - val_loss: 0.2557 - val_mean_squared_error: 0.0951\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2119 - mean_squared_error: 0.0753 - val_loss: 0.2555 - val_mean_squared_error: 0.0948\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2114 - mean_squared_error: 0.0751 - val_loss: 0.2555 - val_mean_squared_error: 0.0948\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2108 - mean_squared_error: 0.0749 - val_loss: 0.2557 - val_mean_squared_error: 0.0949\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2102 - mean_squared_error: 0.0748 - val_loss: 0.2561 - val_mean_squared_error: 0.0952\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.2097 - mean_squared_error: 0.0747 - val_loss: 0.2564 - val_mean_squared_error: 0.0954\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2091 - mean_squared_error: 0.0745 - val_loss: 0.2566 - val_mean_squared_error: 0.0955\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2085 - mean_squared_error: 0.0743 - val_loss: 0.2569 - val_mean_squared_error: 0.0956\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2079 - mean_squared_error: 0.0741 - val_loss: 0.2567 - val_mean_squared_error: 0.0954\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.2073 - mean_squared_error: 0.0740 - val_loss: 0.2568 - val_mean_squared_error: 0.0954\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2066 - mean_squared_error: 0.0740 - val_loss: 0.2575 - val_mean_squared_error: 0.0957\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2062 - mean_squared_error: 0.0739 - val_loss: 0.2578 - val_mean_squared_error: 0.0958\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2055 - mean_squared_error: 0.0738 - val_loss: 0.2578 - val_mean_squared_error: 0.0958\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2049 - mean_squared_error: 0.0736 - val_loss: 0.2580 - val_mean_squared_error: 0.0959\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2044 - mean_squared_error: 0.0734 - val_loss: 0.2585 - val_mean_squared_error: 0.0961\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2038 - mean_squared_error: 0.0733 - val_loss: 0.2594 - val_mean_squared_error: 0.0967\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.2031 - mean_squared_error: 0.0734 - val_loss: 0.2596 - val_mean_squared_error: 0.0968\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2025 - mean_squared_error: 0.0735 - val_loss: 0.2593 - val_mean_squared_error: 0.0964\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.2019 - mean_squared_error: 0.0734 - val_loss: 0.2589 - val_mean_squared_error: 0.0963\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2015 - mean_squared_error: 0.0736 - val_loss: 0.2593 - val_mean_squared_error: 0.0965\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2009 - mean_squared_error: 0.0735 - val_loss: 0.2593 - val_mean_squared_error: 0.0964\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2002 - mean_squared_error: 0.0731 - val_loss: 0.2599 - val_mean_squared_error: 0.0967\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1997 - mean_squared_error: 0.0729 - val_loss: 0.2603 - val_mean_squared_error: 0.0969\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1991 - mean_squared_error: 0.0726 - val_loss: 0.2604 - val_mean_squared_error: 0.0970\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1987 - mean_squared_error: 0.0724 - val_loss: 0.2606 - val_mean_squared_error: 0.0971\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1982 - mean_squared_error: 0.0724 - val_loss: 0.2599 - val_mean_squared_error: 0.0966\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1975 - mean_squared_error: 0.0724 - val_loss: 0.2595 - val_mean_squared_error: 0.0962\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1970 - mean_squared_error: 0.0724 - val_loss: 0.2596 - val_mean_squared_error: 0.0963\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1965 - mean_squared_error: 0.0725 - val_loss: 0.2598 - val_mean_squared_error: 0.0965\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1959 - mean_squared_error: 0.0726 - val_loss: 0.2600 - val_mean_squared_error: 0.0966\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1953 - mean_squared_error: 0.0724 - val_loss: 0.2598 - val_mean_squared_error: 0.0966\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1948 - mean_squared_error: 0.0723 - val_loss: 0.2598 - val_mean_squared_error: 0.0967\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1943 - mean_squared_error: 0.0725 - val_loss: 0.2609 - val_mean_squared_error: 0.0974\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1941 - mean_squared_error: 0.0727 - val_loss: 0.2606 - val_mean_squared_error: 0.0970\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1934 - mean_squared_error: 0.0723 - val_loss: 0.2607 - val_mean_squared_error: 0.0969\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1930 - mean_squared_error: 0.0720 - val_loss: 0.2608 - val_mean_squared_error: 0.0968\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1923 - mean_squared_error: 0.0719 - val_loss: 0.2604 - val_mean_squared_error: 0.0965\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1919 - mean_squared_error: 0.0719 - val_loss: 0.2603 - val_mean_squared_error: 0.0963\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1913 - mean_squared_error: 0.0717 - val_loss: 0.2609 - val_mean_squared_error: 0.0965\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1908 - mean_squared_error: 0.0713 - val_loss: 0.2611 - val_mean_squared_error: 0.0967\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1904 - mean_squared_error: 0.0710 - val_loss: 0.2609 - val_mean_squared_error: 0.0969\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1899 - mean_squared_error: 0.0712 - val_loss: 0.2608 - val_mean_squared_error: 0.0970\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1895 - mean_squared_error: 0.0715 - val_loss: 0.2605 - val_mean_squared_error: 0.0968\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1889 - mean_squared_error: 0.0716 - val_loss: 0.2602 - val_mean_squared_error: 0.0966\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1885 - mean_squared_error: 0.0716 - val_loss: 0.2601 - val_mean_squared_error: 0.0966\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1880 - mean_squared_error: 0.0716 - val_loss: 0.2602 - val_mean_squared_error: 0.0967\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1876 - mean_squared_error: 0.0715 - val_loss: 0.2607 - val_mean_squared_error: 0.0969\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1871 - mean_squared_error: 0.0712 - val_loss: 0.2607 - val_mean_squared_error: 0.0968\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1865 - mean_squared_error: 0.0711 - val_loss: 0.2608 - val_mean_squared_error: 0.0968\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1861 - mean_squared_error: 0.0711 - val_loss: 0.2604 - val_mean_squared_error: 0.0966\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1857 - mean_squared_error: 0.0708 - val_loss: 0.2612 - val_mean_squared_error: 0.0970\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1852 - mean_squared_error: 0.0704 - val_loss: 0.2609 - val_mean_squared_error: 0.0968\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1847 - mean_squared_error: 0.0705 - val_loss: 0.2621 - val_mean_squared_error: 0.0973\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1844 - mean_squared_error: 0.0704 - val_loss: 0.2611 - val_mean_squared_error: 0.0966\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1838 - mean_squared_error: 0.0701 - val_loss: 0.2614 - val_mean_squared_error: 0.0966\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1834 - mean_squared_error: 0.0696 - val_loss: 0.2617 - val_mean_squared_error: 0.0967\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1829 - mean_squared_error: 0.0694 - val_loss: 0.2615 - val_mean_squared_error: 0.0966\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1823 - mean_squared_error: 0.0692 - val_loss: 0.2614 - val_mean_squared_error: 0.0964\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1820 - mean_squared_error: 0.0688 - val_loss: 0.2629 - val_mean_squared_error: 0.0972\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1817 - mean_squared_error: 0.0684 - val_loss: 0.2626 - val_mean_squared_error: 0.0969\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1812 - mean_squared_error: 0.0679 - val_loss: 0.2619 - val_mean_squared_error: 0.0966\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1806 - mean_squared_error: 0.0679 - val_loss: 0.2616 - val_mean_squared_error: 0.0966\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1801 - mean_squared_error: 0.0680 - val_loss: 0.2611 - val_mean_squared_error: 0.0964\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1797 - mean_squared_error: 0.0677 - val_loss: 0.2620 - val_mean_squared_error: 0.0973\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1796 - mean_squared_error: 0.0678 - val_loss: 0.2609 - val_mean_squared_error: 0.0965\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1789 - mean_squared_error: 0.0674 - val_loss: 0.2601 - val_mean_squared_error: 0.0959\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1786 - mean_squared_error: 0.0672 - val_loss: 0.2608 - val_mean_squared_error: 0.0961\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1777 - mean_squared_error: 0.0672 - val_loss: 0.2633 - val_mean_squared_error: 0.0977\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1779 - mean_squared_error: 0.0671 - val_loss: 0.2629 - val_mean_squared_error: 0.0971\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1768 - mean_squared_error: 0.0664 - val_loss: 0.2623 - val_mean_squared_error: 0.0968\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1766 - mean_squared_error: 0.0661 - val_loss: 0.2625 - val_mean_squared_error: 0.0972\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1758 - mean_squared_error: 0.0662 - val_loss: 0.2628 - val_mean_squared_error: 0.0976\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1755 - mean_squared_error: 0.0664 - val_loss: 0.2627 - val_mean_squared_error: 0.0973\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1747 - mean_squared_error: 0.0660 - val_loss: 0.2625 - val_mean_squared_error: 0.0971\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1744 - mean_squared_error: 0.0658 - val_loss: 0.2630 - val_mean_squared_error: 0.0977\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1738 - mean_squared_error: 0.0661 - val_loss: 0.2628 - val_mean_squared_error: 0.0976\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1732 - mean_squared_error: 0.0659 - val_loss: 0.2634 - val_mean_squared_error: 0.0980\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1725 - mean_squared_error: 0.0656 - val_loss: 0.2642 - val_mean_squared_error: 0.0987\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1719 - mean_squared_error: 0.0657 - val_loss: 0.2645 - val_mean_squared_error: 0.0989\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1713 - mean_squared_error: 0.0656 - val_loss: 0.2654 - val_mean_squared_error: 0.0994\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1707 - mean_squared_error: 0.0653 - val_loss: 0.2654 - val_mean_squared_error: 0.0991\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1704 - mean_squared_error: 0.0649 - val_loss: 0.2652 - val_mean_squared_error: 0.0992\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1703 - mean_squared_error: 0.0653 - val_loss: 0.2651 - val_mean_squared_error: 0.0987\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1694 - mean_squared_error: 0.0648 - val_loss: 0.2655 - val_mean_squared_error: 0.0989\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1691 - mean_squared_error: 0.0647 - val_loss: 0.2650 - val_mean_squared_error: 0.0988\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1685 - mean_squared_error: 0.0652 - val_loss: 0.2651 - val_mean_squared_error: 0.0991\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1686 - mean_squared_error: 0.0654 - val_loss: 0.2650 - val_mean_squared_error: 0.0985\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1680 - mean_squared_error: 0.0647 - val_loss: 0.2673 - val_mean_squared_error: 0.0998\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1675 - mean_squared_error: 0.0640 - val_loss: 0.2682 - val_mean_squared_error: 0.1006\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1672 - mean_squared_error: 0.0642 - val_loss: 0.2671 - val_mean_squared_error: 0.1004\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1667 - mean_squared_error: 0.0648 - val_loss: 0.2656 - val_mean_squared_error: 0.0994\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1665 - mean_squared_error: 0.0644 - val_loss: 0.2663 - val_mean_squared_error: 0.1001\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1660 - mean_squared_error: 0.0640 - val_loss: 0.2685 - val_mean_squared_error: 0.1018\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1654 - mean_squared_error: 0.0635 - val_loss: 0.2684 - val_mean_squared_error: 0.1019\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1647 - mean_squared_error: 0.0635 - val_loss: 0.2665 - val_mean_squared_error: 0.1008\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1647 - mean_squared_error: 0.0638 - val_loss: 0.2660 - val_mean_squared_error: 0.1005\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1639 - mean_squared_error: 0.0633 - val_loss: 0.2678 - val_mean_squared_error: 0.1018\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1637 - mean_squared_error: 0.0626 - val_loss: 0.2676 - val_mean_squared_error: 0.1015\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1632 - mean_squared_error: 0.0622 - val_loss: 0.2663 - val_mean_squared_error: 0.1006\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1624 - mean_squared_error: 0.0624 - val_loss: 0.2673 - val_mean_squared_error: 0.1015\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1621 - mean_squared_error: 0.0624 - val_loss: 0.2683 - val_mean_squared_error: 0.1026\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1614 - mean_squared_error: 0.0618 - val_loss: 0.2675 - val_mean_squared_error: 0.1025\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1611 - mean_squared_error: 0.0616 - val_loss: 0.2660 - val_mean_squared_error: 0.1016\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1611 - mean_squared_error: 0.0617 - val_loss: 0.2668 - val_mean_squared_error: 0.1022\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1600 - mean_squared_error: 0.0619 - val_loss: 0.2689 - val_mean_squared_error: 0.1033\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1598 - mean_squared_error: 0.0612 - val_loss: 0.2685 - val_mean_squared_error: 0.1032\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1596 - mean_squared_error: 0.0607 - val_loss: 0.2663 - val_mean_squared_error: 0.1019\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1594 - mean_squared_error: 0.0610 - val_loss: 0.2659 - val_mean_squared_error: 0.1018\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1587 - mean_squared_error: 0.0612 - val_loss: 0.2672 - val_mean_squared_error: 0.1030\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1584 - mean_squared_error: 0.0610 - val_loss: 0.2673 - val_mean_squared_error: 0.1031\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1581 - mean_squared_error: 0.0606 - val_loss: 0.2660 - val_mean_squared_error: 0.1023\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1576 - mean_squared_error: 0.0602 - val_loss: 0.2658 - val_mean_squared_error: 0.1023\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1572 - mean_squared_error: 0.0601 - val_loss: 0.2664 - val_mean_squared_error: 0.1027\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1574 - mean_squared_error: 0.0602 - val_loss: 0.2650 - val_mean_squared_error: 0.1018\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1568 - mean_squared_error: 0.0596 - val_loss: 0.2659 - val_mean_squared_error: 0.1025\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1563 - mean_squared_error: 0.0593 - val_loss: 0.2676 - val_mean_squared_error: 0.1039\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1572 - mean_squared_error: 0.0596 - val_loss: 0.2661 - val_mean_squared_error: 0.1031\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1553 - mean_squared_error: 0.0590 - val_loss: 0.2627 - val_mean_squared_error: 0.1014\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1567 - mean_squared_error: 0.0589 - val_loss: 0.2620 - val_mean_squared_error: 0.1014\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1556 - mean_squared_error: 0.0590 - val_loss: 0.2636 - val_mean_squared_error: 0.1027\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1554 - mean_squared_error: 0.0593 - val_loss: 0.2650 - val_mean_squared_error: 0.1038\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1547 - mean_squared_error: 0.0588 - val_loss: 0.2642 - val_mean_squared_error: 0.1033\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1550 - mean_squared_error: 0.0579 - val_loss: 0.2644 - val_mean_squared_error: 0.1036\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1549 - mean_squared_error: 0.0577 - val_loss: 0.2632 - val_mean_squared_error: 0.1032\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1526 - mean_squared_error: 0.0581 - val_loss: 0.2625 - val_mean_squared_error: 0.1031\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1542 - mean_squared_error: 0.0587 - val_loss: 0.2611 - val_mean_squared_error: 0.1021\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1528 - mean_squared_error: 0.0582 - val_loss: 0.2622 - val_mean_squared_error: 0.1024\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1528 - mean_squared_error: 0.0577 - val_loss: 0.2645 - val_mean_squared_error: 0.1041\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1520 - mean_squared_error: 0.0575 - val_loss: 0.2650 - val_mean_squared_error: 0.1050\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1524 - mean_squared_error: 0.0576 - val_loss: 0.2629 - val_mean_squared_error: 0.1040\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1507 - mean_squared_error: 0.0575 - val_loss: 0.2615 - val_mean_squared_error: 0.1031\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1516 - mean_squared_error: 0.0576 - val_loss: 0.2615 - val_mean_squared_error: 0.1036\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1502 - mean_squared_error: 0.0575 - val_loss: 0.2634 - val_mean_squared_error: 0.1057\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1507 - mean_squared_error: 0.0569 - val_loss: 0.2632 - val_mean_squared_error: 0.1062\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1497 - mean_squared_error: 0.0561 - val_loss: 0.2612 - val_mean_squared_error: 0.1048\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1501 - mean_squared_error: 0.0562 - val_loss: 0.2597 - val_mean_squared_error: 0.1040\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1489 - mean_squared_error: 0.0565 - val_loss: 0.2604 - val_mean_squared_error: 0.1043\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1486 - mean_squared_error: 0.0565 - val_loss: 0.2623 - val_mean_squared_error: 0.1058\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1484 - mean_squared_error: 0.0556 - val_loss: 0.2614 - val_mean_squared_error: 0.1052\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1482 - mean_squared_error: 0.0553 - val_loss: 0.2602 - val_mean_squared_error: 0.1044\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1469 - mean_squared_error: 0.0558 - val_loss: 0.2600 - val_mean_squared_error: 0.1043\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1475 - mean_squared_error: 0.0561 - val_loss: 0.2608 - val_mean_squared_error: 0.1052\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1465 - mean_squared_error: 0.0553 - val_loss: 0.2617 - val_mean_squared_error: 0.1062\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1461 - mean_squared_error: 0.0551 - val_loss: 0.2614 - val_mean_squared_error: 0.1059\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1464 - mean_squared_error: 0.0556 - val_loss: 0.2605 - val_mean_squared_error: 0.1050\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1461 - mean_squared_error: 0.0553 - val_loss: 0.2611 - val_mean_squared_error: 0.1056\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1448 - mean_squared_error: 0.0549 - val_loss: 0.2616 - val_mean_squared_error: 0.1060\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1449 - mean_squared_error: 0.0548 - val_loss: 0.2615 - val_mean_squared_error: 0.1060\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1447 - mean_squared_error: 0.0544 - val_loss: 0.2609 - val_mean_squared_error: 0.1060\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1443 - mean_squared_error: 0.0547 - val_loss: 0.2597 - val_mean_squared_error: 0.1059\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1436 - mean_squared_error: 0.0545 - val_loss: 0.2597 - val_mean_squared_error: 0.1062\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1435 - mean_squared_error: 0.0539 - val_loss: 0.2604 - val_mean_squared_error: 0.1066\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1433 - mean_squared_error: 0.0537 - val_loss: 0.2601 - val_mean_squared_error: 0.1058\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1429 - mean_squared_error: 0.0537 - val_loss: 0.2597 - val_mean_squared_error: 0.1065\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1422 - mean_squared_error: 0.0537 - val_loss: 0.2607 - val_mean_squared_error: 0.1075\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1424 - mean_squared_error: 0.0536 - val_loss: 0.2611 - val_mean_squared_error: 0.1082\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1422 - mean_squared_error: 0.0530 - val_loss: 0.2617 - val_mean_squared_error: 0.1077\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1417 - mean_squared_error: 0.0530 - val_loss: 0.2623 - val_mean_squared_error: 0.1075\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1431 - mean_squared_error: 0.0534 - val_loss: 0.2618 - val_mean_squared_error: 0.1076\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1411 - mean_squared_error: 0.0528 - val_loss: 0.2612 - val_mean_squared_error: 0.1084\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1444 - mean_squared_error: 0.0521 - val_loss: 0.2612 - val_mean_squared_error: 0.1092\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1427 - mean_squared_error: 0.0518 - val_loss: 0.2611 - val_mean_squared_error: 0.1087\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1418 - mean_squared_error: 0.0523 - val_loss: 0.2603 - val_mean_squared_error: 0.1071\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1406 - mean_squared_error: 0.0525 - val_loss: 0.2595 - val_mean_squared_error: 0.1071\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1406 - mean_squared_error: 0.0519 - val_loss: 0.2605 - val_mean_squared_error: 0.1090\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1396 - mean_squared_error: 0.0510 - val_loss: 0.2613 - val_mean_squared_error: 0.1095\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1404 - mean_squared_error: 0.0510 - val_loss: 0.2603 - val_mean_squared_error: 0.1080\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.1382 - mean_squared_error: 0.0512 - val_loss: 0.2597 - val_mean_squared_error: 0.1073\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1404 - mean_squared_error: 0.0512 - val_loss: 0.2606 - val_mean_squared_error: 0.1076\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1390 - mean_squared_error: 0.0510 - val_loss: 0.2615 - val_mean_squared_error: 0.1100\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1386 - mean_squared_error: 0.0504 - val_loss: 0.2605 - val_mean_squared_error: 0.1105\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1393 - mean_squared_error: 0.0501 - val_loss: 0.2582 - val_mean_squared_error: 0.1084\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1384 - mean_squared_error: 0.0505 - val_loss: 0.2581 - val_mean_squared_error: 0.1071\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1375 - mean_squared_error: 0.0508 - val_loss: 0.2598 - val_mean_squared_error: 0.1089\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1372 - mean_squared_error: 0.0501 - val_loss: 0.2603 - val_mean_squared_error: 0.1102\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1364 - mean_squared_error: 0.0494 - val_loss: 0.2588 - val_mean_squared_error: 0.1095\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1357 - mean_squared_error: 0.0496 - val_loss: 0.2575 - val_mean_squared_error: 0.1086\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1363 - mean_squared_error: 0.0502 - val_loss: 0.2574 - val_mean_squared_error: 0.1080\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1353 - mean_squared_error: 0.0499 - val_loss: 0.2590 - val_mean_squared_error: 0.1093\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1353 - mean_squared_error: 0.0489 - val_loss: 0.2597 - val_mean_squared_error: 0.1100\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1348 - mean_squared_error: 0.0485 - val_loss: 0.2593 - val_mean_squared_error: 0.1099\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1344 - mean_squared_error: 0.0486 - val_loss: 0.2581 - val_mean_squared_error: 0.1092\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1344 - mean_squared_error: 0.0488 - val_loss: 0.2578 - val_mean_squared_error: 0.1092\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1337 - mean_squared_error: 0.0486 - val_loss: 0.2589 - val_mean_squared_error: 0.1105\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1333 - mean_squared_error: 0.0480 - val_loss: 0.2603 - val_mean_squared_error: 0.1116\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1341 - mean_squared_error: 0.0473 - val_loss: 0.2594 - val_mean_squared_error: 0.1108\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1330 - mean_squared_error: 0.0474 - val_loss: 0.2574 - val_mean_squared_error: 0.1093\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1328 - mean_squared_error: 0.0480 - val_loss: 0.2559 - val_mean_squared_error: 0.1093\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1332 - mean_squared_error: 0.0480 - val_loss: 0.2562 - val_mean_squared_error: 0.1102\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1325 - mean_squared_error: 0.0478 - val_loss: 0.2580 - val_mean_squared_error: 0.1110\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1323 - mean_squared_error: 0.0474 - val_loss: 0.2585 - val_mean_squared_error: 0.1109\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1317 - mean_squared_error: 0.0471 - val_loss: 0.2575 - val_mean_squared_error: 0.1106\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1307 - mean_squared_error: 0.0470 - val_loss: 0.2565 - val_mean_squared_error: 0.1101\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1322 - mean_squared_error: 0.0475 - val_loss: 0.2561 - val_mean_squared_error: 0.1101\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1314 - mean_squared_error: 0.0476 - val_loss: 0.2569 - val_mean_squared_error: 0.1096\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1313 - mean_squared_error: 0.0472 - val_loss: 0.2582 - val_mean_squared_error: 0.1099\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1308 - mean_squared_error: 0.0466 - val_loss: 0.2593 - val_mean_squared_error: 0.1114\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1312 - mean_squared_error: 0.0461 - val_loss: 0.2589 - val_mean_squared_error: 0.1120\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1311 - mean_squared_error: 0.0460 - val_loss: 0.2566 - val_mean_squared_error: 0.1099\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1291 - mean_squared_error: 0.0465 - val_loss: 0.2561 - val_mean_squared_error: 0.1088\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1305 - mean_squared_error: 0.0469 - val_loss: 0.2567 - val_mean_squared_error: 0.1104\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1286 - mean_squared_error: 0.0463 - val_loss: 0.2579 - val_mean_squared_error: 0.1131\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1299 - mean_squared_error: 0.0455 - val_loss: 0.2572 - val_mean_squared_error: 0.1128\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1299 - mean_squared_error: 0.0451 - val_loss: 0.2551 - val_mean_squared_error: 0.1096\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1276 - mean_squared_error: 0.0454 - val_loss: 0.2534 - val_mean_squared_error: 0.1074\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1295 - mean_squared_error: 0.0461 - val_loss: 0.2536 - val_mean_squared_error: 0.1083\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1278 - mean_squared_error: 0.0457 - val_loss: 0.2554 - val_mean_squared_error: 0.1108\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1276 - mean_squared_error: 0.0449 - val_loss: 0.2560 - val_mean_squared_error: 0.1112\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1269 - mean_squared_error: 0.0445 - val_loss: 0.2556 - val_mean_squared_error: 0.1098\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1264 - mean_squared_error: 0.0448 - val_loss: 0.2552 - val_mean_squared_error: 0.1093\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1263 - mean_squared_error: 0.0450 - val_loss: 0.2562 - val_mean_squared_error: 0.1108\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1256 - mean_squared_error: 0.0446 - val_loss: 0.2571 - val_mean_squared_error: 0.1113\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1261 - mean_squared_error: 0.0442 - val_loss: 0.2550 - val_mean_squared_error: 0.1091\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1249 - mean_squared_error: 0.0442 - val_loss: 0.2538 - val_mean_squared_error: 0.1082\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1253 - mean_squared_error: 0.0444 - val_loss: 0.2552 - val_mean_squared_error: 0.1101\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1246 - mean_squared_error: 0.0439 - val_loss: 0.2570 - val_mean_squared_error: 0.1117\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1243 - mean_squared_error: 0.0435 - val_loss: 0.2566 - val_mean_squared_error: 0.1111\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1237 - mean_squared_error: 0.0436 - val_loss: 0.2565 - val_mean_squared_error: 0.1110\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1235 - mean_squared_error: 0.0438 - val_loss: 0.2573 - val_mean_squared_error: 0.1114\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1233 - mean_squared_error: 0.0437 - val_loss: 0.2556 - val_mean_squared_error: 0.1101\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1227 - mean_squared_error: 0.0436 - val_loss: 0.2554 - val_mean_squared_error: 0.1106\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1224 - mean_squared_error: 0.0432 - val_loss: 0.2562 - val_mean_squared_error: 0.1113\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1223 - mean_squared_error: 0.0427 - val_loss: 0.2554 - val_mean_squared_error: 0.1104\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1219 - mean_squared_error: 0.0429 - val_loss: 0.2543 - val_mean_squared_error: 0.1098\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1216 - mean_squared_error: 0.0432 - val_loss: 0.2550 - val_mean_squared_error: 0.1104\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1211 - mean_squared_error: 0.0429 - val_loss: 0.2550 - val_mean_squared_error: 0.1103\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1206 - mean_squared_error: 0.0428 - val_loss: 0.2541 - val_mean_squared_error: 0.1091\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 130ms/step - loss: 0.1214 - mean_squared_error: 0.0424 - val_loss: 0.2555 - val_mean_squared_error: 0.1104\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1209 - mean_squared_error: 0.0418 - val_loss: 0.2558 - val_mean_squared_error: 0.1107\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1200 - mean_squared_error: 0.0419 - val_loss: 0.2550 - val_mean_squared_error: 0.1102\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1193 - mean_squared_error: 0.0422 - val_loss: 0.2556 - val_mean_squared_error: 0.1104\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1199 - mean_squared_error: 0.0420 - val_loss: 0.2548 - val_mean_squared_error: 0.1099\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1211 - mean_squared_error: 0.0418 - val_loss: 0.2556 - val_mean_squared_error: 0.1103\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1192 - mean_squared_error: 0.0412 - val_loss: 0.2570 - val_mean_squared_error: 0.1111\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1209 - mean_squared_error: 0.0412 - val_loss: 0.2566 - val_mean_squared_error: 0.1108\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1185 - mean_squared_error: 0.0410 - val_loss: 0.2559 - val_mean_squared_error: 0.1102\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1187 - mean_squared_error: 0.0411 - val_loss: 0.2563 - val_mean_squared_error: 0.1103\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1182 - mean_squared_error: 0.0411 - val_loss: 0.2581 - val_mean_squared_error: 0.1118\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1175 - mean_squared_error: 0.0406 - val_loss: 0.2582 - val_mean_squared_error: 0.1116\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1174 - mean_squared_error: 0.0404 - val_loss: 0.2577 - val_mean_squared_error: 0.1110\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1164 - mean_squared_error: 0.0403 - val_loss: 0.2562 - val_mean_squared_error: 0.1095\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1167 - mean_squared_error: 0.0404 - val_loss: 0.2560 - val_mean_squared_error: 0.1096\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1164 - mean_squared_error: 0.0401 - val_loss: 0.2581 - val_mean_squared_error: 0.1113\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1164 - mean_squared_error: 0.0396 - val_loss: 0.2566 - val_mean_squared_error: 0.1105\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1156 - mean_squared_error: 0.0399 - val_loss: 0.2550 - val_mean_squared_error: 0.1093\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1159 - mean_squared_error: 0.0401 - val_loss: 0.2557 - val_mean_squared_error: 0.1097\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1145 - mean_squared_error: 0.0396 - val_loss: 0.2577 - val_mean_squared_error: 0.1106\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.1162 - mean_squared_error: 0.0391 - val_loss: 0.2567 - val_mean_squared_error: 0.1098\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1149 - mean_squared_error: 0.0390 - val_loss: 0.2552 - val_mean_squared_error: 0.1083\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1146 - mean_squared_error: 0.0393 - val_loss: 0.2563 - val_mean_squared_error: 0.1090\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1141 - mean_squared_error: 0.0392 - val_loss: 0.2585 - val_mean_squared_error: 0.1110\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1140 - mean_squared_error: 0.0389 - val_loss: 0.2581 - val_mean_squared_error: 0.1105\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1126 - mean_squared_error: 0.0386 - val_loss: 0.2573 - val_mean_squared_error: 0.1096\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1136 - mean_squared_error: 0.0386 - val_loss: 0.2586 - val_mean_squared_error: 0.1108\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1121 - mean_squared_error: 0.0381 - val_loss: 0.2594 - val_mean_squared_error: 0.1117\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1126 - mean_squared_error: 0.0380 - val_loss: 0.2584 - val_mean_squared_error: 0.1103\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1115 - mean_squared_error: 0.0382 - val_loss: 0.2573 - val_mean_squared_error: 0.1093\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1120 - mean_squared_error: 0.0381 - val_loss: 0.2601 - val_mean_squared_error: 0.1121\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1112 - mean_squared_error: 0.0370 - val_loss: 0.2604 - val_mean_squared_error: 0.1123\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1108 - mean_squared_error: 0.0368 - val_loss: 0.2582 - val_mean_squared_error: 0.1102\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1108 - mean_squared_error: 0.0372 - val_loss: 0.2583 - val_mean_squared_error: 0.1103\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1105 - mean_squared_error: 0.0373 - val_loss: 0.2582 - val_mean_squared_error: 0.1106\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1104 - mean_squared_error: 0.0370 - val_loss: 0.2597 - val_mean_squared_error: 0.1112\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1095 - mean_squared_error: 0.0364 - val_loss: 0.2592 - val_mean_squared_error: 0.1105\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1092 - mean_squared_error: 0.0363 - val_loss: 0.2608 - val_mean_squared_error: 0.1118\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1087 - mean_squared_error: 0.0362 - val_loss: 0.2599 - val_mean_squared_error: 0.1111\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1084 - mean_squared_error: 0.0365 - val_loss: 0.2583 - val_mean_squared_error: 0.1094\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1087 - mean_squared_error: 0.0365 - val_loss: 0.2590 - val_mean_squared_error: 0.1096\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1078 - mean_squared_error: 0.0362 - val_loss: 0.2612 - val_mean_squared_error: 0.1117\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1084 - mean_squared_error: 0.0358 - val_loss: 0.2603 - val_mean_squared_error: 0.1113\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1076 - mean_squared_error: 0.0357 - val_loss: 0.2581 - val_mean_squared_error: 0.1087\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1079 - mean_squared_error: 0.0358 - val_loss: 0.2591 - val_mean_squared_error: 0.1093\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1077 - mean_squared_error: 0.0355 - val_loss: 0.2613 - val_mean_squared_error: 0.1114\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1062 - mean_squared_error: 0.0347 - val_loss: 0.2617 - val_mean_squared_error: 0.1122\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1067 - mean_squared_error: 0.0345 - val_loss: 0.2602 - val_mean_squared_error: 0.1108\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1056 - mean_squared_error: 0.0346 - val_loss: 0.2603 - val_mean_squared_error: 0.1107\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1065 - mean_squared_error: 0.0347 - val_loss: 0.2615 - val_mean_squared_error: 0.1111\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.1045 - mean_squared_error: 0.0346 - val_loss: 0.2622 - val_mean_squared_error: 0.1116\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1046 - mean_squared_error: 0.0344 - val_loss: 0.2619 - val_mean_squared_error: 0.1109\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.1040 - mean_squared_error: 0.0343 - val_loss: 0.2606 - val_mean_squared_error: 0.1098\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1039 - mean_squared_error: 0.0340 - val_loss: 0.2608 - val_mean_squared_error: 0.1105\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1036 - mean_squared_error: 0.0336 - val_loss: 0.2622 - val_mean_squared_error: 0.1119\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1040 - mean_squared_error: 0.0337 - val_loss: 0.2622 - val_mean_squared_error: 0.1113\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1028 - mean_squared_error: 0.0337 - val_loss: 0.2609 - val_mean_squared_error: 0.1103\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1055 - mean_squared_error: 0.0338 - val_loss: 0.2614 - val_mean_squared_error: 0.1104\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.1036 - mean_squared_error: 0.0334 - val_loss: 0.2631 - val_mean_squared_error: 0.1125\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1044 - mean_squared_error: 0.0332 - val_loss: 0.2640 - val_mean_squared_error: 0.1136\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.1048 - mean_squared_error: 0.0330 - val_loss: 0.2626 - val_mean_squared_error: 0.1116\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.1028 - mean_squared_error: 0.0328 - val_loss: 0.2613 - val_mean_squared_error: 0.1096\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.1023 - mean_squared_error: 0.0329 - val_loss: 0.2626 - val_mean_squared_error: 0.1102\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1030 - mean_squared_error: 0.0328 - val_loss: 0.2642 - val_mean_squared_error: 0.1117\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1008 - mean_squared_error: 0.0322 - val_loss: 0.2642 - val_mean_squared_error: 0.1124\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.1028 - mean_squared_error: 0.0322 - val_loss: 0.2636 - val_mean_squared_error: 0.1122\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0995 - mean_squared_error: 0.0322 - val_loss: 0.2642 - val_mean_squared_error: 0.1125\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.1018 - mean_squared_error: 0.0322 - val_loss: 0.2650 - val_mean_squared_error: 0.1125\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0993 - mean_squared_error: 0.0318 - val_loss: 0.2647 - val_mean_squared_error: 0.1123\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0999 - mean_squared_error: 0.0321 - val_loss: 0.2649 - val_mean_squared_error: 0.1125\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0996 - mean_squared_error: 0.0322 - val_loss: 0.2644 - val_mean_squared_error: 0.1123\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0984 - mean_squared_error: 0.0317 - val_loss: 0.2641 - val_mean_squared_error: 0.1119\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0992 - mean_squared_error: 0.0313 - val_loss: 0.2638 - val_mean_squared_error: 0.1115\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0976 - mean_squared_error: 0.0310 - val_loss: 0.2627 - val_mean_squared_error: 0.1108\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0978 - mean_squared_error: 0.0314 - val_loss: 0.2620 - val_mean_squared_error: 0.1103\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0979 - mean_squared_error: 0.0315 - val_loss: 0.2636 - val_mean_squared_error: 0.1114\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0966 - mean_squared_error: 0.0311 - val_loss: 0.2652 - val_mean_squared_error: 0.1118\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0972 - mean_squared_error: 0.0309 - val_loss: 0.2635 - val_mean_squared_error: 0.1102\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0964 - mean_squared_error: 0.0311 - val_loss: 0.2619 - val_mean_squared_error: 0.1094\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0959 - mean_squared_error: 0.0310 - val_loss: 0.2637 - val_mean_squared_error: 0.1111\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0959 - mean_squared_error: 0.0305 - val_loss: 0.2634 - val_mean_squared_error: 0.1107\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0951 - mean_squared_error: 0.0303 - val_loss: 0.2610 - val_mean_squared_error: 0.1083\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0961 - mean_squared_error: 0.0308 - val_loss: 0.2625 - val_mean_squared_error: 0.1090\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0946 - mean_squared_error: 0.0306 - val_loss: 0.2643 - val_mean_squared_error: 0.1108\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0946 - mean_squared_error: 0.0299 - val_loss: 0.2639 - val_mean_squared_error: 0.1107\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0942 - mean_squared_error: 0.0299 - val_loss: 0.2629 - val_mean_squared_error: 0.1096\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0942 - mean_squared_error: 0.0305 - val_loss: 0.2632 - val_mean_squared_error: 0.1103\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0935 - mean_squared_error: 0.0303 - val_loss: 0.2652 - val_mean_squared_error: 0.1121\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0938 - mean_squared_error: 0.0296 - val_loss: 0.2645 - val_mean_squared_error: 0.1112\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0930 - mean_squared_error: 0.0296 - val_loss: 0.2641 - val_mean_squared_error: 0.1106\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0939 - mean_squared_error: 0.0299 - val_loss: 0.2655 - val_mean_squared_error: 0.1114\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0951 - mean_squared_error: 0.0299 - val_loss: 0.2665 - val_mean_squared_error: 0.1129\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0933 - mean_squared_error: 0.0293 - val_loss: 0.2652 - val_mean_squared_error: 0.1118\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0922 - mean_squared_error: 0.0292 - val_loss: 0.2652 - val_mean_squared_error: 0.1109\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0929 - mean_squared_error: 0.0293 - val_loss: 0.2660 - val_mean_squared_error: 0.1116\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0920 - mean_squared_error: 0.0290 - val_loss: 0.2654 - val_mean_squared_error: 0.1113\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0926 - mean_squared_error: 0.0288 - val_loss: 0.2653 - val_mean_squared_error: 0.1102\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0929 - mean_squared_error: 0.0291 - val_loss: 0.2653 - val_mean_squared_error: 0.1107\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0917 - mean_squared_error: 0.0287 - val_loss: 0.2660 - val_mean_squared_error: 0.1121\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0915 - mean_squared_error: 0.0286 - val_loss: 0.2664 - val_mean_squared_error: 0.1112\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0943 - mean_squared_error: 0.0290 - val_loss: 0.2654 - val_mean_squared_error: 0.1105\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0906 - mean_squared_error: 0.0286 - val_loss: 0.2652 - val_mean_squared_error: 0.1094\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0934 - mean_squared_error: 0.0285 - val_loss: 0.2655 - val_mean_squared_error: 0.1091\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0915 - mean_squared_error: 0.0283 - val_loss: 0.2672 - val_mean_squared_error: 0.1109\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0915 - mean_squared_error: 0.0283 - val_loss: 0.2663 - val_mean_squared_error: 0.1116\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0910 - mean_squared_error: 0.0280 - val_loss: 0.2639 - val_mean_squared_error: 0.1096\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0909 - mean_squared_error: 0.0281 - val_loss: 0.2659 - val_mean_squared_error: 0.1107\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0900 - mean_squared_error: 0.0278 - val_loss: 0.2667 - val_mean_squared_error: 0.1114\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0896 - mean_squared_error: 0.0274 - val_loss: 0.2643 - val_mean_squared_error: 0.1097\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0904 - mean_squared_error: 0.0274 - val_loss: 0.2642 - val_mean_squared_error: 0.1092\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0900 - mean_squared_error: 0.0275 - val_loss: 0.2663 - val_mean_squared_error: 0.1106\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0896 - mean_squared_error: 0.0272 - val_loss: 0.2663 - val_mean_squared_error: 0.1114\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0893 - mean_squared_error: 0.0270 - val_loss: 0.2662 - val_mean_squared_error: 0.1112\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0882 - mean_squared_error: 0.0272 - val_loss: 0.2655 - val_mean_squared_error: 0.1099\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0891 - mean_squared_error: 0.0275 - val_loss: 0.2654 - val_mean_squared_error: 0.1102\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0875 - mean_squared_error: 0.0270 - val_loss: 0.2664 - val_mean_squared_error: 0.1111\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0877 - mean_squared_error: 0.0264 - val_loss: 0.2661 - val_mean_squared_error: 0.1104\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0873 - mean_squared_error: 0.0265 - val_loss: 0.2656 - val_mean_squared_error: 0.1102\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0868 - mean_squared_error: 0.0268 - val_loss: 0.2681 - val_mean_squared_error: 0.1121\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0871 - mean_squared_error: 0.0265 - val_loss: 0.2674 - val_mean_squared_error: 0.1118\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0858 - mean_squared_error: 0.0264 - val_loss: 0.2659 - val_mean_squared_error: 0.1103\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0879 - mean_squared_error: 0.0266 - val_loss: 0.2668 - val_mean_squared_error: 0.1106\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0857 - mean_squared_error: 0.0264 - val_loss: 0.2679 - val_mean_squared_error: 0.1115\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0859 - mean_squared_error: 0.0261 - val_loss: 0.2653 - val_mean_squared_error: 0.1094\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0862 - mean_squared_error: 0.0262 - val_loss: 0.2653 - val_mean_squared_error: 0.1096\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0853 - mean_squared_error: 0.0262 - val_loss: 0.2685 - val_mean_squared_error: 0.1125\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0870 - mean_squared_error: 0.0258 - val_loss: 0.2672 - val_mean_squared_error: 0.1115\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0846 - mean_squared_error: 0.0257 - val_loss: 0.2648 - val_mean_squared_error: 0.1087\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0868 - mean_squared_error: 0.0263 - val_loss: 0.2668 - val_mean_squared_error: 0.1102\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0838 - mean_squared_error: 0.0257 - val_loss: 0.2689 - val_mean_squared_error: 0.1113\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0855 - mean_squared_error: 0.0256 - val_loss: 0.2671 - val_mean_squared_error: 0.1102\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0836 - mean_squared_error: 0.0256 - val_loss: 0.2671 - val_mean_squared_error: 0.1105\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0855 - mean_squared_error: 0.0254 - val_loss: 0.2678 - val_mean_squared_error: 0.1116\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0839 - mean_squared_error: 0.0253 - val_loss: 0.2696 - val_mean_squared_error: 0.1127\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0833 - mean_squared_error: 0.0250 - val_loss: 0.2678 - val_mean_squared_error: 0.1110\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0837 - mean_squared_error: 0.0252 - val_loss: 0.2676 - val_mean_squared_error: 0.1108\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0826 - mean_squared_error: 0.0254 - val_loss: 0.2694 - val_mean_squared_error: 0.1121\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0837 - mean_squared_error: 0.0249 - val_loss: 0.2693 - val_mean_squared_error: 0.1122\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0849 - mean_squared_error: 0.0246 - val_loss: 0.2682 - val_mean_squared_error: 0.1105\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0830 - mean_squared_error: 0.0250 - val_loss: 0.2688 - val_mean_squared_error: 0.1105\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0883 - mean_squared_error: 0.0256 - val_loss: 0.2702 - val_mean_squared_error: 0.1115\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0858 - mean_squared_error: 0.0249 - val_loss: 0.2703 - val_mean_squared_error: 0.1118\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0839 - mean_squared_error: 0.0245 - val_loss: 0.2691 - val_mean_squared_error: 0.1114\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0813 - mean_squared_error: 0.0245 - val_loss: 0.2682 - val_mean_squared_error: 0.1112\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0848 - mean_squared_error: 0.0246 - val_loss: 0.2686 - val_mean_squared_error: 0.1117\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0813 - mean_squared_error: 0.0240 - val_loss: 0.2707 - val_mean_squared_error: 0.1125\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0816 - mean_squared_error: 0.0240 - val_loss: 0.2705 - val_mean_squared_error: 0.1123\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0820 - mean_squared_error: 0.0243 - val_loss: 0.2700 - val_mean_squared_error: 0.1122\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0802 - mean_squared_error: 0.0243 - val_loss: 0.2700 - val_mean_squared_error: 0.1124\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0816 - mean_squared_error: 0.0239 - val_loss: 0.2702 - val_mean_squared_error: 0.1125\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0814 - mean_squared_error: 0.0237 - val_loss: 0.2700 - val_mean_squared_error: 0.1119\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0803 - mean_squared_error: 0.0236 - val_loss: 0.2708 - val_mean_squared_error: 0.1114\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0820 - mean_squared_error: 0.0238 - val_loss: 0.2706 - val_mean_squared_error: 0.1111\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0801 - mean_squared_error: 0.0239 - val_loss: 0.2691 - val_mean_squared_error: 0.1110\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0801 - mean_squared_error: 0.0236 - val_loss: 0.2691 - val_mean_squared_error: 0.1115\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0803 - mean_squared_error: 0.0232 - val_loss: 0.2703 - val_mean_squared_error: 0.1124\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0803 - mean_squared_error: 0.0234 - val_loss: 0.2700 - val_mean_squared_error: 0.1121\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0806 - mean_squared_error: 0.0234 - val_loss: 0.2689 - val_mean_squared_error: 0.1110\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0786 - mean_squared_error: 0.0230 - val_loss: 0.2694 - val_mean_squared_error: 0.1106\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0789 - mean_squared_error: 0.0230 - val_loss: 0.2712 - val_mean_squared_error: 0.1115\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0778 - mean_squared_error: 0.0230 - val_loss: 0.2711 - val_mean_squared_error: 0.1121\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0776 - mean_squared_error: 0.0230 - val_loss: 0.2707 - val_mean_squared_error: 0.1116\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0779 - mean_squared_error: 0.0230 - val_loss: 0.2705 - val_mean_squared_error: 0.1113\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0779 - mean_squared_error: 0.0230 - val_loss: 0.2733 - val_mean_squared_error: 0.1130\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0781 - mean_squared_error: 0.0225 - val_loss: 0.2710 - val_mean_squared_error: 0.1119\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0773 - mean_squared_error: 0.0223 - val_loss: 0.2695 - val_mean_squared_error: 0.1111\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0774 - mean_squared_error: 0.0226 - val_loss: 0.2740 - val_mean_squared_error: 0.1133\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0768 - mean_squared_error: 0.0225 - val_loss: 0.2744 - val_mean_squared_error: 0.1134\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0765 - mean_squared_error: 0.0223 - val_loss: 0.2711 - val_mean_squared_error: 0.1119\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0770 - mean_squared_error: 0.0224 - val_loss: 0.2721 - val_mean_squared_error: 0.1126\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0761 - mean_squared_error: 0.0222 - val_loss: 0.2730 - val_mean_squared_error: 0.1125\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0766 - mean_squared_error: 0.0221 - val_loss: 0.2714 - val_mean_squared_error: 0.1118\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0753 - mean_squared_error: 0.0221 - val_loss: 0.2717 - val_mean_squared_error: 0.1119\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0756 - mean_squared_error: 0.0222 - val_loss: 0.2722 - val_mean_squared_error: 0.1115\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0780 - mean_squared_error: 0.0221 - val_loss: 0.2735 - val_mean_squared_error: 0.1122\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0752 - mean_squared_error: 0.0216 - val_loss: 0.2708 - val_mean_squared_error: 0.1109\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0779 - mean_squared_error: 0.0217 - val_loss: 0.2693 - val_mean_squared_error: 0.1096\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0780 - mean_squared_error: 0.0218 - val_loss: 0.2728 - val_mean_squared_error: 0.1111\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0760 - mean_squared_error: 0.0217 - val_loss: 0.2754 - val_mean_squared_error: 0.1131\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0782 - mean_squared_error: 0.0216 - val_loss: 0.2730 - val_mean_squared_error: 0.1127\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0767 - mean_squared_error: 0.0212 - val_loss: 0.2695 - val_mean_squared_error: 0.1105\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0776 - mean_squared_error: 0.0212 - val_loss: 0.2699 - val_mean_squared_error: 0.1102\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0767 - mean_squared_error: 0.0213 - val_loss: 0.2751 - val_mean_squared_error: 0.1126\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0754 - mean_squared_error: 0.0210 - val_loss: 0.2749 - val_mean_squared_error: 0.1129\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0750 - mean_squared_error: 0.0208 - val_loss: 0.2730 - val_mean_squared_error: 0.1115\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0742 - mean_squared_error: 0.0209 - val_loss: 0.2706 - val_mean_squared_error: 0.1108\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0742 - mean_squared_error: 0.0210 - val_loss: 0.2721 - val_mean_squared_error: 0.1119\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0738 - mean_squared_error: 0.0207 - val_loss: 0.2752 - val_mean_squared_error: 0.1131\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0734 - mean_squared_error: 0.0202 - val_loss: 0.2726 - val_mean_squared_error: 0.1114\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0734 - mean_squared_error: 0.0202 - val_loss: 0.2716 - val_mean_squared_error: 0.1107\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0720 - mean_squared_error: 0.0205 - val_loss: 0.2724 - val_mean_squared_error: 0.1114\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0726 - mean_squared_error: 0.0207 - val_loss: 0.2753 - val_mean_squared_error: 0.1129\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0719 - mean_squared_error: 0.0201 - val_loss: 0.2740 - val_mean_squared_error: 0.1123\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0722 - mean_squared_error: 0.0201 - val_loss: 0.2743 - val_mean_squared_error: 0.1122\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0719 - mean_squared_error: 0.0202 - val_loss: 0.2743 - val_mean_squared_error: 0.1115\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0721 - mean_squared_error: 0.0202 - val_loss: 0.2726 - val_mean_squared_error: 0.1106\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0717 - mean_squared_error: 0.0202 - val_loss: 0.2744 - val_mean_squared_error: 0.1116\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0723 - mean_squared_error: 0.0201 - val_loss: 0.2765 - val_mean_squared_error: 0.1125\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0711 - mean_squared_error: 0.0199 - val_loss: 0.2732 - val_mean_squared_error: 0.1111\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0721 - mean_squared_error: 0.0201 - val_loss: 0.2721 - val_mean_squared_error: 0.1118\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0709 - mean_squared_error: 0.0199 - val_loss: 0.2761 - val_mean_squared_error: 0.1139\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0723 - mean_squared_error: 0.0195 - val_loss: 0.2772 - val_mean_squared_error: 0.1134\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0722 - mean_squared_error: 0.0195 - val_loss: 0.2727 - val_mean_squared_error: 0.1107\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0718 - mean_squared_error: 0.0199 - val_loss: 0.2712 - val_mean_squared_error: 0.1106\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0712 - mean_squared_error: 0.0198 - val_loss: 0.2761 - val_mean_squared_error: 0.1134\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0713 - mean_squared_error: 0.0192 - val_loss: 0.2786 - val_mean_squared_error: 0.1139\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0736 - mean_squared_error: 0.0194 - val_loss: 0.2756 - val_mean_squared_error: 0.1119\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0740 - mean_squared_error: 0.0197 - val_loss: 0.2744 - val_mean_squared_error: 0.1114\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0689 - mean_squared_error: 0.0194 - val_loss: 0.2742 - val_mean_squared_error: 0.1119\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0718 - mean_squared_error: 0.0191 - val_loss: 0.2768 - val_mean_squared_error: 0.1130\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0696 - mean_squared_error: 0.0187 - val_loss: 0.2800 - val_mean_squared_error: 0.1147\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0709 - mean_squared_error: 0.0187 - val_loss: 0.2774 - val_mean_squared_error: 0.1136\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0698 - mean_squared_error: 0.0189 - val_loss: 0.2723 - val_mean_squared_error: 0.1112\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0698 - mean_squared_error: 0.0192 - val_loss: 0.2751 - val_mean_squared_error: 0.1125\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0693 - mean_squared_error: 0.0188 - val_loss: 0.2791 - val_mean_squared_error: 0.1138\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0680 - mean_squared_error: 0.0186 - val_loss: 0.2791 - val_mean_squared_error: 0.1134\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0686 - mean_squared_error: 0.0189 - val_loss: 0.2748 - val_mean_squared_error: 0.1117\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0674 - mean_squared_error: 0.0191 - val_loss: 0.2731 - val_mean_squared_error: 0.1119\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0681 - mean_squared_error: 0.0187 - val_loss: 0.2768 - val_mean_squared_error: 0.1140\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0676 - mean_squared_error: 0.0181 - val_loss: 0.2786 - val_mean_squared_error: 0.1137\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0690 - mean_squared_error: 0.0182 - val_loss: 0.2770 - val_mean_squared_error: 0.1125\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0681 - mean_squared_error: 0.0186 - val_loss: 0.2738 - val_mean_squared_error: 0.1116\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0674 - mean_squared_error: 0.0185 - val_loss: 0.2749 - val_mean_squared_error: 0.1121\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0673 - mean_squared_error: 0.0180 - val_loss: 0.2779 - val_mean_squared_error: 0.1130\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0664 - mean_squared_error: 0.0180 - val_loss: 0.2788 - val_mean_squared_error: 0.1135\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0682 - mean_squared_error: 0.0185 - val_loss: 0.2756 - val_mean_squared_error: 0.1127\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0650 - mean_squared_error: 0.0183 - val_loss: 0.2748 - val_mean_squared_error: 0.1130\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0668 - mean_squared_error: 0.0180 - val_loss: 0.2784 - val_mean_squared_error: 0.1146\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0658 - mean_squared_error: 0.0178 - val_loss: 0.2771 - val_mean_squared_error: 0.1136\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0652 - mean_squared_error: 0.0179 - val_loss: 0.2746 - val_mean_squared_error: 0.1118\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0664 - mean_squared_error: 0.0179 - val_loss: 0.2758 - val_mean_squared_error: 0.1125\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0641 - mean_squared_error: 0.0176 - val_loss: 0.2803 - val_mean_squared_error: 0.1149\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0659 - mean_squared_error: 0.0176 - val_loss: 0.2798 - val_mean_squared_error: 0.1149\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0641 - mean_squared_error: 0.0174 - val_loss: 0.2760 - val_mean_squared_error: 0.1126\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0665 - mean_squared_error: 0.0179 - val_loss: 0.2772 - val_mean_squared_error: 0.1129\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0643 - mean_squared_error: 0.0177 - val_loss: 0.2817 - val_mean_squared_error: 0.1152\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0656 - mean_squared_error: 0.0172 - val_loss: 0.2797 - val_mean_squared_error: 0.1143\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0643 - mean_squared_error: 0.0171 - val_loss: 0.2752 - val_mean_squared_error: 0.1119\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0644 - mean_squared_error: 0.0174 - val_loss: 0.2779 - val_mean_squared_error: 0.1130\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0631 - mean_squared_error: 0.0174 - val_loss: 0.2826 - val_mean_squared_error: 0.1158\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0656 - mean_squared_error: 0.0172 - val_loss: 0.2809 - val_mean_squared_error: 0.1150\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0634 - mean_squared_error: 0.0171 - val_loss: 0.2757 - val_mean_squared_error: 0.1127\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0647 - mean_squared_error: 0.0174 - val_loss: 0.2781 - val_mean_squared_error: 0.1141\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0626 - mean_squared_error: 0.0171 - val_loss: 0.2834 - val_mean_squared_error: 0.1160\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0642 - mean_squared_error: 0.0166 - val_loss: 0.2833 - val_mean_squared_error: 0.1158\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0628 - mean_squared_error: 0.0166 - val_loss: 0.2782 - val_mean_squared_error: 0.1134\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0623 - mean_squared_error: 0.0171 - val_loss: 0.2783 - val_mean_squared_error: 0.1135\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0627 - mean_squared_error: 0.0169 - val_loss: 0.2824 - val_mean_squared_error: 0.1153\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0613 - mean_squared_error: 0.0165 - val_loss: 0.2839 - val_mean_squared_error: 0.1161\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0622 - mean_squared_error: 0.0164 - val_loss: 0.2803 - val_mean_squared_error: 0.1145\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0605 - mean_squared_error: 0.0165 - val_loss: 0.2780 - val_mean_squared_error: 0.1138\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0620 - mean_squared_error: 0.0169 - val_loss: 0.2804 - val_mean_squared_error: 0.1147\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0611 - mean_squared_error: 0.0166 - val_loss: 0.2832 - val_mean_squared_error: 0.1165\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0611 - mean_squared_error: 0.0163 - val_loss: 0.2808 - val_mean_squared_error: 0.1150\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0604 - mean_squared_error: 0.0165 - val_loss: 0.2799 - val_mean_squared_error: 0.1139\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0602 - mean_squared_error: 0.0165 - val_loss: 0.2822 - val_mean_squared_error: 0.1154\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0610 - mean_squared_error: 0.0161 - val_loss: 0.2800 - val_mean_squared_error: 0.1150\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0605 - mean_squared_error: 0.0159 - val_loss: 0.2789 - val_mean_squared_error: 0.1147\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0603 - mean_squared_error: 0.0161 - val_loss: 0.2839 - val_mean_squared_error: 0.1169\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0610 - mean_squared_error: 0.0161 - val_loss: 0.2846 - val_mean_squared_error: 0.1169\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0613 - mean_squared_error: 0.0161 - val_loss: 0.2807 - val_mean_squared_error: 0.1148\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0607 - mean_squared_error: 0.0161 - val_loss: 0.2809 - val_mean_squared_error: 0.1153\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0616 - mean_squared_error: 0.0161 - val_loss: 0.2838 - val_mean_squared_error: 0.1161\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0595 - mean_squared_error: 0.0156 - val_loss: 0.2827 - val_mean_squared_error: 0.1151\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0600 - mean_squared_error: 0.0159 - val_loss: 0.2817 - val_mean_squared_error: 0.1149\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0599 - mean_squared_error: 0.0162 - val_loss: 0.2830 - val_mean_squared_error: 0.1155\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0573 - mean_squared_error: 0.0157 - val_loss: 0.2844 - val_mean_squared_error: 0.1164\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0576 - mean_squared_error: 0.0154 - val_loss: 0.2811 - val_mean_squared_error: 0.1146\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0580 - mean_squared_error: 0.0157 - val_loss: 0.2841 - val_mean_squared_error: 0.1159\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0570 - mean_squared_error: 0.0155 - val_loss: 0.2838 - val_mean_squared_error: 0.1157\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0566 - mean_squared_error: 0.0154 - val_loss: 0.2828 - val_mean_squared_error: 0.1155\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0566 - mean_squared_error: 0.0156 - val_loss: 0.2814 - val_mean_squared_error: 0.1151\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0567 - mean_squared_error: 0.0156 - val_loss: 0.2848 - val_mean_squared_error: 0.1171\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0571 - mean_squared_error: 0.0151 - val_loss: 0.2836 - val_mean_squared_error: 0.1163\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0580 - mean_squared_error: 0.0151 - val_loss: 0.2812 - val_mean_squared_error: 0.1154\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0580 - mean_squared_error: 0.0154 - val_loss: 0.2830 - val_mean_squared_error: 0.1159\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0565 - mean_squared_error: 0.0154 - val_loss: 0.2856 - val_mean_squared_error: 0.1168\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0587 - mean_squared_error: 0.0151 - val_loss: 0.2854 - val_mean_squared_error: 0.1172\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0579 - mean_squared_error: 0.0152 - val_loss: 0.2810 - val_mean_squared_error: 0.1150\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0568 - mean_squared_error: 0.0155 - val_loss: 0.2835 - val_mean_squared_error: 0.1164\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0567 - mean_squared_error: 0.0152 - val_loss: 0.2859 - val_mean_squared_error: 0.1176\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0564 - mean_squared_error: 0.0147 - val_loss: 0.2854 - val_mean_squared_error: 0.1175\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0583 - mean_squared_error: 0.0148 - val_loss: 0.2840 - val_mean_squared_error: 0.1156\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0583 - mean_squared_error: 0.0151 - val_loss: 0.2852 - val_mean_squared_error: 0.1161\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0569 - mean_squared_error: 0.0150 - val_loss: 0.2870 - val_mean_squared_error: 0.1183\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0582 - mean_squared_error: 0.0147 - val_loss: 0.2858 - val_mean_squared_error: 0.1173\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0561 - mean_squared_error: 0.0147 - val_loss: 0.2847 - val_mean_squared_error: 0.1157\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0574 - mean_squared_error: 0.0151 - val_loss: 0.2866 - val_mean_squared_error: 0.1173\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0566 - mean_squared_error: 0.0149 - val_loss: 0.2858 - val_mean_squared_error: 0.1175\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0568 - mean_squared_error: 0.0147 - val_loss: 0.2842 - val_mean_squared_error: 0.1165\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0572 - mean_squared_error: 0.0146 - val_loss: 0.2846 - val_mean_squared_error: 0.1168\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0573 - mean_squared_error: 0.0145 - val_loss: 0.2862 - val_mean_squared_error: 0.1181\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0567 - mean_squared_error: 0.0144 - val_loss: 0.2877 - val_mean_squared_error: 0.1183\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0554 - mean_squared_error: 0.0143 - val_loss: 0.2860 - val_mean_squared_error: 0.1165\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0579 - mean_squared_error: 0.0146 - val_loss: 0.2847 - val_mean_squared_error: 0.1160\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0557 - mean_squared_error: 0.0148 - val_loss: 0.2871 - val_mean_squared_error: 0.1185\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0554 - mean_squared_error: 0.0142 - val_loss: 0.2890 - val_mean_squared_error: 0.1195\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0567 - mean_squared_error: 0.0138 - val_loss: 0.2852 - val_mean_squared_error: 0.1174\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0558 - mean_squared_error: 0.0143 - val_loss: 0.2825 - val_mean_squared_error: 0.1163\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0569 - mean_squared_error: 0.0147 - val_loss: 0.2856 - val_mean_squared_error: 0.1178\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0566 - mean_squared_error: 0.0143 - val_loss: 0.2896 - val_mean_squared_error: 0.1192\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0581 - mean_squared_error: 0.0136 - val_loss: 0.2895 - val_mean_squared_error: 0.1193\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0568 - mean_squared_error: 0.0136 - val_loss: 0.2871 - val_mean_squared_error: 0.1183\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0564 - mean_squared_error: 0.0141 - val_loss: 0.2856 - val_mean_squared_error: 0.1165\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0556 - mean_squared_error: 0.0146 - val_loss: 0.2873 - val_mean_squared_error: 0.1164\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0565 - mean_squared_error: 0.0144 - val_loss: 0.2911 - val_mean_squared_error: 0.1188\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0552 - mean_squared_error: 0.0136 - val_loss: 0.2900 - val_mean_squared_error: 0.1191\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0571 - mean_squared_error: 0.0134 - val_loss: 0.2876 - val_mean_squared_error: 0.1175\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0524 - mean_squared_error: 0.0135 - val_loss: 0.2845 - val_mean_squared_error: 0.1157\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0567 - mean_squared_error: 0.0143 - val_loss: 0.2849 - val_mean_squared_error: 0.1165\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0550 - mean_squared_error: 0.0142 - val_loss: 0.2876 - val_mean_squared_error: 0.1183\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0529 - mean_squared_error: 0.0134 - val_loss: 0.2879 - val_mean_squared_error: 0.1181\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0560 - mean_squared_error: 0.0133 - val_loss: 0.2870 - val_mean_squared_error: 0.1174\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0537 - mean_squared_error: 0.0134 - val_loss: 0.2847 - val_mean_squared_error: 0.1166\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0555 - mean_squared_error: 0.0141 - val_loss: 0.2849 - val_mean_squared_error: 0.1162\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0531 - mean_squared_error: 0.0141 - val_loss: 0.2857 - val_mean_squared_error: 0.1170\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0526 - mean_squared_error: 0.0134 - val_loss: 0.2894 - val_mean_squared_error: 0.1190\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0525 - mean_squared_error: 0.0129 - val_loss: 0.2896 - val_mean_squared_error: 0.1188\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0524 - mean_squared_error: 0.0130 - val_loss: 0.2867 - val_mean_squared_error: 0.1168\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0517 - mean_squared_error: 0.0133 - val_loss: 0.2852 - val_mean_squared_error: 0.1162\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0520 - mean_squared_error: 0.0134 - val_loss: 0.2881 - val_mean_squared_error: 0.1174\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0517 - mean_squared_error: 0.0131 - val_loss: 0.2873 - val_mean_squared_error: 0.1171\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0513 - mean_squared_error: 0.0130 - val_loss: 0.2858 - val_mean_squared_error: 0.1173\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0522 - mean_squared_error: 0.0131 - val_loss: 0.2872 - val_mean_squared_error: 0.1180\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0519 - mean_squared_error: 0.0132 - val_loss: 0.2881 - val_mean_squared_error: 0.1179\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0535 - mean_squared_error: 0.0132 - val_loss: 0.2871 - val_mean_squared_error: 0.1174\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0517 - mean_squared_error: 0.0128 - val_loss: 0.2877 - val_mean_squared_error: 0.1175\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0525 - mean_squared_error: 0.0128 - val_loss: 0.2860 - val_mean_squared_error: 0.1159\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0510 - mean_squared_error: 0.0131 - val_loss: 0.2870 - val_mean_squared_error: 0.1159\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0543 - mean_squared_error: 0.0132 - val_loss: 0.2887 - val_mean_squared_error: 0.1175\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0505 - mean_squared_error: 0.0128 - val_loss: 0.2878 - val_mean_squared_error: 0.1184\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0539 - mean_squared_error: 0.0127 - val_loss: 0.2864 - val_mean_squared_error: 0.1175\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0508 - mean_squared_error: 0.0127 - val_loss: 0.2886 - val_mean_squared_error: 0.1174\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0527 - mean_squared_error: 0.0129 - val_loss: 0.2913 - val_mean_squared_error: 0.1189\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0521 - mean_squared_error: 0.0128 - val_loss: 0.2897 - val_mean_squared_error: 0.1188\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0516 - mean_squared_error: 0.0126 - val_loss: 0.2863 - val_mean_squared_error: 0.1167\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0519 - mean_squared_error: 0.0128 - val_loss: 0.2874 - val_mean_squared_error: 0.1167\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0509 - mean_squared_error: 0.0128 - val_loss: 0.2909 - val_mean_squared_error: 0.1189\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0541 - mean_squared_error: 0.0127 - val_loss: 0.2908 - val_mean_squared_error: 0.1191\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0531 - mean_squared_error: 0.0123 - val_loss: 0.2869 - val_mean_squared_error: 0.1168\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0511 - mean_squared_error: 0.0125 - val_loss: 0.2852 - val_mean_squared_error: 0.1155\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0520 - mean_squared_error: 0.0130 - val_loss: 0.2876 - val_mean_squared_error: 0.1169\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0509 - mean_squared_error: 0.0127 - val_loss: 0.2895 - val_mean_squared_error: 0.1181\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0493 - mean_squared_error: 0.0122 - val_loss: 0.2883 - val_mean_squared_error: 0.1175\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0529 - mean_squared_error: 0.0122 - val_loss: 0.2860 - val_mean_squared_error: 0.1166\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0499 - mean_squared_error: 0.0122 - val_loss: 0.2871 - val_mean_squared_error: 0.1170\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0517 - mean_squared_error: 0.0125 - val_loss: 0.2894 - val_mean_squared_error: 0.1177\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0492 - mean_squared_error: 0.0122 - val_loss: 0.2887 - val_mean_squared_error: 0.1177\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0528 - mean_squared_error: 0.0120 - val_loss: 0.2876 - val_mean_squared_error: 0.1174\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0547 - mean_squared_error: 0.0120 - val_loss: 0.2887 - val_mean_squared_error: 0.1178\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0496 - mean_squared_error: 0.0119 - val_loss: 0.2899 - val_mean_squared_error: 0.1178\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0534 - mean_squared_error: 0.0124 - val_loss: 0.2896 - val_mean_squared_error: 0.1174\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0536 - mean_squared_error: 0.0124 - val_loss: 0.2880 - val_mean_squared_error: 0.1171\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0473 - mean_squared_error: 0.0117 - val_loss: 0.2874 - val_mean_squared_error: 0.1175\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0546 - mean_squared_error: 0.0120 - val_loss: 0.2878 - val_mean_squared_error: 0.1175\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0520 - mean_squared_error: 0.0120 - val_loss: 0.2878 - val_mean_squared_error: 0.1169\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0488 - mean_squared_error: 0.0123 - val_loss: 0.2888 - val_mean_squared_error: 0.1172\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0507 - mean_squared_error: 0.0121 - val_loss: 0.2883 - val_mean_squared_error: 0.1171\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0470 - mean_squared_error: 0.0116 - val_loss: 0.2879 - val_mean_squared_error: 0.1169\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0490 - mean_squared_error: 0.0116 - val_loss: 0.2863 - val_mean_squared_error: 0.1155\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0473 - mean_squared_error: 0.0117 - val_loss: 0.2877 - val_mean_squared_error: 0.1161\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0489 - mean_squared_error: 0.0118 - val_loss: 0.2899 - val_mean_squared_error: 0.1177\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0494 - mean_squared_error: 0.0116 - val_loss: 0.2879 - val_mean_squared_error: 0.1171\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0467 - mean_squared_error: 0.0114 - val_loss: 0.2850 - val_mean_squared_error: 0.1155\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0506 - mean_squared_error: 0.0117 - val_loss: 0.2860 - val_mean_squared_error: 0.1154\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0486 - mean_squared_error: 0.0118 - val_loss: 0.2901 - val_mean_squared_error: 0.1176\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0495 - mean_squared_error: 0.0117 - val_loss: 0.2905 - val_mean_squared_error: 0.1178\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0470 - mean_squared_error: 0.0114 - val_loss: 0.2866 - val_mean_squared_error: 0.1159\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0487 - mean_squared_error: 0.0115 - val_loss: 0.2856 - val_mean_squared_error: 0.1148\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0487 - mean_squared_error: 0.0117 - val_loss: 0.2882 - val_mean_squared_error: 0.1160\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0462 - mean_squared_error: 0.0115 - val_loss: 0.2885 - val_mean_squared_error: 0.1164\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0462 - mean_squared_error: 0.0112 - val_loss: 0.2862 - val_mean_squared_error: 0.1153\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0461 - mean_squared_error: 0.0111 - val_loss: 0.2864 - val_mean_squared_error: 0.1153\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0450 - mean_squared_error: 0.0113 - val_loss: 0.2897 - val_mean_squared_error: 0.1173\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0465 - mean_squared_error: 0.0113 - val_loss: 0.2899 - val_mean_squared_error: 0.1177\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0455 - mean_squared_error: 0.0111 - val_loss: 0.2861 - val_mean_squared_error: 0.1157\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0475 - mean_squared_error: 0.0113 - val_loss: 0.2861 - val_mean_squared_error: 0.1149\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0446 - mean_squared_error: 0.0113 - val_loss: 0.2904 - val_mean_squared_error: 0.1170\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0468 - mean_squared_error: 0.0110 - val_loss: 0.2893 - val_mean_squared_error: 0.1163\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0459 - mean_squared_error: 0.0109 - val_loss: 0.2866 - val_mean_squared_error: 0.1151\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0447 - mean_squared_error: 0.0111 - val_loss: 0.2877 - val_mean_squared_error: 0.1161\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0458 - mean_squared_error: 0.0111 - val_loss: 0.2901 - val_mean_squared_error: 0.1172\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0433 - mean_squared_error: 0.0109 - val_loss: 0.2894 - val_mean_squared_error: 0.1170\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0449 - mean_squared_error: 0.0109 - val_loss: 0.2864 - val_mean_squared_error: 0.1157\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0438 - mean_squared_error: 0.0109 - val_loss: 0.2870 - val_mean_squared_error: 0.1161\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0442 - mean_squared_error: 0.0109 - val_loss: 0.2896 - val_mean_squared_error: 0.1170\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0435 - mean_squared_error: 0.0109 - val_loss: 0.2890 - val_mean_squared_error: 0.1169\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0430 - mean_squared_error: 0.0109 - val_loss: 0.2875 - val_mean_squared_error: 0.1161\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0428 - mean_squared_error: 0.0107 - val_loss: 0.2866 - val_mean_squared_error: 0.1151\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0429 - mean_squared_error: 0.0106 - val_loss: 0.2863 - val_mean_squared_error: 0.1147\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0427 - mean_squared_error: 0.0109 - val_loss: 0.2864 - val_mean_squared_error: 0.1152\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0416 - mean_squared_error: 0.0109 - val_loss: 0.2880 - val_mean_squared_error: 0.1168\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0429 - mean_squared_error: 0.0107 - val_loss: 0.2862 - val_mean_squared_error: 0.1157\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0421 - mean_squared_error: 0.0108 - val_loss: 0.2878 - val_mean_squared_error: 0.1160\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0424 - mean_squared_error: 0.0106 - val_loss: 0.2872 - val_mean_squared_error: 0.1157\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0413 - mean_squared_error: 0.0105 - val_loss: 0.2866 - val_mean_squared_error: 0.1157\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0424 - mean_squared_error: 0.0105 - val_loss: 0.2886 - val_mean_squared_error: 0.1165\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0424 - mean_squared_error: 0.0105 - val_loss: 0.2867 - val_mean_squared_error: 0.1150\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0415 - mean_squared_error: 0.0107 - val_loss: 0.2867 - val_mean_squared_error: 0.1154\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0417 - mean_squared_error: 0.0103 - val_loss: 0.2880 - val_mean_squared_error: 0.1162\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0422 - mean_squared_error: 0.0103 - val_loss: 0.2873 - val_mean_squared_error: 0.1157\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0410 - mean_squared_error: 0.0105 - val_loss: 0.2869 - val_mean_squared_error: 0.1151\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0424 - mean_squared_error: 0.0105 - val_loss: 0.2881 - val_mean_squared_error: 0.1156\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0427 - mean_squared_error: 0.0105 - val_loss: 0.2878 - val_mean_squared_error: 0.1155\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0433 - mean_squared_error: 0.0105 - val_loss: 0.2870 - val_mean_squared_error: 0.1155\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0436 - mean_squared_error: 0.0102 - val_loss: 0.2872 - val_mean_squared_error: 0.1157\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0419 - mean_squared_error: 0.0101 - val_loss: 0.2879 - val_mean_squared_error: 0.1157\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0405 - mean_squared_error: 0.0102 - val_loss: 0.2870 - val_mean_squared_error: 0.1152\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0409 - mean_squared_error: 0.0104 - val_loss: 0.2873 - val_mean_squared_error: 0.1159\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0431 - mean_squared_error: 0.0103 - val_loss: 0.2872 - val_mean_squared_error: 0.1157\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0403 - mean_squared_error: 0.0102 - val_loss: 0.2859 - val_mean_squared_error: 0.1149\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0423 - mean_squared_error: 0.0104 - val_loss: 0.2870 - val_mean_squared_error: 0.1155\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0416 - mean_squared_error: 0.0101 - val_loss: 0.2896 - val_mean_squared_error: 0.1164\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0409 - mean_squared_error: 0.0098 - val_loss: 0.2874 - val_mean_squared_error: 0.1153\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0421 - mean_squared_error: 0.0099 - val_loss: 0.2864 - val_mean_squared_error: 0.1153\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0406 - mean_squared_error: 0.0099 - val_loss: 0.2877 - val_mean_squared_error: 0.1156\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0395 - mean_squared_error: 0.0098 - val_loss: 0.2878 - val_mean_squared_error: 0.1155\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0443 - mean_squared_error: 0.0102 - val_loss: 0.2871 - val_mean_squared_error: 0.1152\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0405 - mean_squared_error: 0.0102 - val_loss: 0.2887 - val_mean_squared_error: 0.1168\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0457 - mean_squared_error: 0.0099 - val_loss: 0.2893 - val_mean_squared_error: 0.1170\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0430 - mean_squared_error: 0.0096 - val_loss: 0.2874 - val_mean_squared_error: 0.1154\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0434 - mean_squared_error: 0.0096 - val_loss: 0.2852 - val_mean_squared_error: 0.1138\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0424 - mean_squared_error: 0.0099 - val_loss: 0.2878 - val_mean_squared_error: 0.1152\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0430 - mean_squared_error: 0.0099 - val_loss: 0.2915 - val_mean_squared_error: 0.1172\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0424 - mean_squared_error: 0.0095 - val_loss: 0.2893 - val_mean_squared_error: 0.1165\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0419 - mean_squared_error: 0.0096 - val_loss: 0.2866 - val_mean_squared_error: 0.1153\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0413 - mean_squared_error: 0.0097 - val_loss: 0.2881 - val_mean_squared_error: 0.1156\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0414 - mean_squared_error: 0.0097 - val_loss: 0.2891 - val_mean_squared_error: 0.1156\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0394 - mean_squared_error: 0.0095 - val_loss: 0.2897 - val_mean_squared_error: 0.1164\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0415 - mean_squared_error: 0.0094 - val_loss: 0.2911 - val_mean_squared_error: 0.1176\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0397 - mean_squared_error: 0.0094 - val_loss: 0.2895 - val_mean_squared_error: 0.1167\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0418 - mean_squared_error: 0.0097 - val_loss: 0.2866 - val_mean_squared_error: 0.1148\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0404 - mean_squared_error: 0.0097 - val_loss: 0.2892 - val_mean_squared_error: 0.1161\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0418 - mean_squared_error: 0.0092 - val_loss: 0.2926 - val_mean_squared_error: 0.1179\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0422 - mean_squared_error: 0.0090 - val_loss: 0.2897 - val_mean_squared_error: 0.1163\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0382 - mean_squared_error: 0.0092 - val_loss: 0.2860 - val_mean_squared_error: 0.1148\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0414 - mean_squared_error: 0.0097 - val_loss: 0.2884 - val_mean_squared_error: 0.1164\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0401 - mean_squared_error: 0.0095 - val_loss: 0.2926 - val_mean_squared_error: 0.1182\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0405 - mean_squared_error: 0.0091 - val_loss: 0.2919 - val_mean_squared_error: 0.1175\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0399 - mean_squared_error: 0.0091 - val_loss: 0.2898 - val_mean_squared_error: 0.1168\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0406 - mean_squared_error: 0.0091 - val_loss: 0.2874 - val_mean_squared_error: 0.1155\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0390 - mean_squared_error: 0.0094 - val_loss: 0.2888 - val_mean_squared_error: 0.1162\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0406 - mean_squared_error: 0.0093 - val_loss: 0.2921 - val_mean_squared_error: 0.1180\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0389 - mean_squared_error: 0.0089 - val_loss: 0.2900 - val_mean_squared_error: 0.1171\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0387 - mean_squared_error: 0.0090 - val_loss: 0.2880 - val_mean_squared_error: 0.1159\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0376 - mean_squared_error: 0.0092 - val_loss: 0.2888 - val_mean_squared_error: 0.1165\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0389 - mean_squared_error: 0.0091 - val_loss: 0.2899 - val_mean_squared_error: 0.1169\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0362 - mean_squared_error: 0.0087 - val_loss: 0.2905 - val_mean_squared_error: 0.1170\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0378 - mean_squared_error: 0.0088 - val_loss: 0.2921 - val_mean_squared_error: 0.1177\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0378 - mean_squared_error: 0.0090 - val_loss: 0.2899 - val_mean_squared_error: 0.1168\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0372 - mean_squared_error: 0.0090 - val_loss: 0.2883 - val_mean_squared_error: 0.1158\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0372 - mean_squared_error: 0.0089 - val_loss: 0.2902 - val_mean_squared_error: 0.1167\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0366 - mean_squared_error: 0.0087 - val_loss: 0.2918 - val_mean_squared_error: 0.1177\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0374 - mean_squared_error: 0.0088 - val_loss: 0.2902 - val_mean_squared_error: 0.1171\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0367 - mean_squared_error: 0.0090 - val_loss: 0.2889 - val_mean_squared_error: 0.1164\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0367 - mean_squared_error: 0.0088 - val_loss: 0.2892 - val_mean_squared_error: 0.1159\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0366 - mean_squared_error: 0.0088 - val_loss: 0.2890 - val_mean_squared_error: 0.1159\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0379 - mean_squared_error: 0.0089 - val_loss: 0.2895 - val_mean_squared_error: 0.1169\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0362 - mean_squared_error: 0.0086 - val_loss: 0.2888 - val_mean_squared_error: 0.1169\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0371 - mean_squared_error: 0.0086 - val_loss: 0.2884 - val_mean_squared_error: 0.1163\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0357 - mean_squared_error: 0.0087 - val_loss: 0.2902 - val_mean_squared_error: 0.1174\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0371 - mean_squared_error: 0.0086 - val_loss: 0.2894 - val_mean_squared_error: 0.1171\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0355 - mean_squared_error: 0.0086 - val_loss: 0.2896 - val_mean_squared_error: 0.1171\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0370 - mean_squared_error: 0.0087 - val_loss: 0.2902 - val_mean_squared_error: 0.1172\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0352 - mean_squared_error: 0.0086 - val_loss: 0.2906 - val_mean_squared_error: 0.1168\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0351 - mean_squared_error: 0.0086 - val_loss: 0.2894 - val_mean_squared_error: 0.1160\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0355 - mean_squared_error: 0.0086 - val_loss: 0.2898 - val_mean_squared_error: 0.1167\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0356 - mean_squared_error: 0.0086 - val_loss: 0.2898 - val_mean_squared_error: 0.1168\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0356 - mean_squared_error: 0.0087 - val_loss: 0.2922 - val_mean_squared_error: 0.1182\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0358 - mean_squared_error: 0.0083 - val_loss: 0.2906 - val_mean_squared_error: 0.1170\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0337 - mean_squared_error: 0.0083 - val_loss: 0.2881 - val_mean_squared_error: 0.1157\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0352 - mean_squared_error: 0.0085 - val_loss: 0.2910 - val_mean_squared_error: 0.1173\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0347 - mean_squared_error: 0.0083 - val_loss: 0.2902 - val_mean_squared_error: 0.1166\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0336 - mean_squared_error: 0.0084 - val_loss: 0.2886 - val_mean_squared_error: 0.1161\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0354 - mean_squared_error: 0.0084 - val_loss: 0.2892 - val_mean_squared_error: 0.1163\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0340 - mean_squared_error: 0.0084 - val_loss: 0.2916 - val_mean_squared_error: 0.1172\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0366 - mean_squared_error: 0.0083 - val_loss: 0.2898 - val_mean_squared_error: 0.1161\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0335 - mean_squared_error: 0.0084 - val_loss: 0.2885 - val_mean_squared_error: 0.1156\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0347 - mean_squared_error: 0.0083 - val_loss: 0.2914 - val_mean_squared_error: 0.1170\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0360 - mean_squared_error: 0.0081 - val_loss: 0.2912 - val_mean_squared_error: 0.1171\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0360 - mean_squared_error: 0.0082 - val_loss: 0.2885 - val_mean_squared_error: 0.1161\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0353 - mean_squared_error: 0.0082 - val_loss: 0.2888 - val_mean_squared_error: 0.1163\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0343 - mean_squared_error: 0.0082 - val_loss: 0.2916 - val_mean_squared_error: 0.1175\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0365 - mean_squared_error: 0.0081 - val_loss: 0.2905 - val_mean_squared_error: 0.1167\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0353 - mean_squared_error: 0.0081 - val_loss: 0.2870 - val_mean_squared_error: 0.1148\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0359 - mean_squared_error: 0.0082 - val_loss: 0.2892 - val_mean_squared_error: 0.1157\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0342 - mean_squared_error: 0.0080 - val_loss: 0.2931 - val_mean_squared_error: 0.1180\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0377 - mean_squared_error: 0.0081 - val_loss: 0.2935 - val_mean_squared_error: 0.1183\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0365 - mean_squared_error: 0.0079 - val_loss: 0.2902 - val_mean_squared_error: 0.1165\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0364 - mean_squared_error: 0.0080 - val_loss: 0.2892 - val_mean_squared_error: 0.1158\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0361 - mean_squared_error: 0.0081 - val_loss: 0.2921 - val_mean_squared_error: 0.1175\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0344 - mean_squared_error: 0.0078 - val_loss: 0.2920 - val_mean_squared_error: 0.1176\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0351 - mean_squared_error: 0.0077 - val_loss: 0.2901 - val_mean_squared_error: 0.1167\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0339 - mean_squared_error: 0.0078 - val_loss: 0.2907 - val_mean_squared_error: 0.1167\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0350 - mean_squared_error: 0.0081 - val_loss: 0.2921 - val_mean_squared_error: 0.1171\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0339 - mean_squared_error: 0.0079 - val_loss: 0.2910 - val_mean_squared_error: 0.1168\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0354 - mean_squared_error: 0.0078 - val_loss: 0.2901 - val_mean_squared_error: 0.1170\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0352 - mean_squared_error: 0.0076 - val_loss: 0.2906 - val_mean_squared_error: 0.1171\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0351 - mean_squared_error: 0.0075 - val_loss: 0.2914 - val_mean_squared_error: 0.1167\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0364 - mean_squared_error: 0.0076 - val_loss: 0.2903 - val_mean_squared_error: 0.1161\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0355 - mean_squared_error: 0.0078 - val_loss: 0.2899 - val_mean_squared_error: 0.1163\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0337 - mean_squared_error: 0.0077 - val_loss: 0.2916 - val_mean_squared_error: 0.1175\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0340 - mean_squared_error: 0.0076 - val_loss: 0.2925 - val_mean_squared_error: 0.1176\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0347 - mean_squared_error: 0.0077 - val_loss: 0.2921 - val_mean_squared_error: 0.1173\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0337 - mean_squared_error: 0.0077 - val_loss: 0.2902 - val_mean_squared_error: 0.1165\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0343 - mean_squared_error: 0.0075 - val_loss: 0.2913 - val_mean_squared_error: 0.1173\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0319 - mean_squared_error: 0.0074 - val_loss: 0.2941 - val_mean_squared_error: 0.1187\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0346 - mean_squared_error: 0.0076 - val_loss: 0.2938 - val_mean_squared_error: 0.1183\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0322 - mean_squared_error: 0.0074 - val_loss: 0.2899 - val_mean_squared_error: 0.1163\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0351 - mean_squared_error: 0.0075 - val_loss: 0.2899 - val_mean_squared_error: 0.1160\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0326 - mean_squared_error: 0.0075 - val_loss: 0.2927 - val_mean_squared_error: 0.1177\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0347 - mean_squared_error: 0.0075 - val_loss: 0.2927 - val_mean_squared_error: 0.1178\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0339 - mean_squared_error: 0.0074 - val_loss: 0.2906 - val_mean_squared_error: 0.1168\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0337 - mean_squared_error: 0.0074 - val_loss: 0.2903 - val_mean_squared_error: 0.1162\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0357 - mean_squared_error: 0.0077 - val_loss: 0.2922 - val_mean_squared_error: 0.1167\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0330 - mean_squared_error: 0.0075 - val_loss: 0.2931 - val_mean_squared_error: 0.1177\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0331 - mean_squared_error: 0.0071 - val_loss: 0.2912 - val_mean_squared_error: 0.1174\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0322 - mean_squared_error: 0.0071 - val_loss: 0.2893 - val_mean_squared_error: 0.1161\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0323 - mean_squared_error: 0.0073 - val_loss: 0.2917 - val_mean_squared_error: 0.1169\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0330 - mean_squared_error: 0.0073 - val_loss: 0.2925 - val_mean_squared_error: 0.1175\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0330 - mean_squared_error: 0.0072 - val_loss: 0.2920 - val_mean_squared_error: 0.1179\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0321 - mean_squared_error: 0.0071 - val_loss: 0.2917 - val_mean_squared_error: 0.1176\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0338 - mean_squared_error: 0.0072 - val_loss: 0.2908 - val_mean_squared_error: 0.1166\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0319 - mean_squared_error: 0.0072 - val_loss: 0.2923 - val_mean_squared_error: 0.1174\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0346 - mean_squared_error: 0.0068 - val_loss: 0.2924 - val_mean_squared_error: 0.1177\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0328 - mean_squared_error: 0.0067 - val_loss: 0.2908 - val_mean_squared_error: 0.1171\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0324 - mean_squared_error: 0.0071 - val_loss: 0.2918 - val_mean_squared_error: 0.1171\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0329 - mean_squared_error: 0.0073 - val_loss: 0.2925 - val_mean_squared_error: 0.1171\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0315 - mean_squared_error: 0.0069 - val_loss: 0.2914 - val_mean_squared_error: 0.1165\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0318 - mean_squared_error: 0.0068 - val_loss: 0.2901 - val_mean_squared_error: 0.1161\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0329 - mean_squared_error: 0.0071 - val_loss: 0.2921 - val_mean_squared_error: 0.1176\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0307 - mean_squared_error: 0.0070 - val_loss: 0.2949 - val_mean_squared_error: 0.1190\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0315 - mean_squared_error: 0.0069 - val_loss: 0.2930 - val_mean_squared_error: 0.1181\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0313 - mean_squared_error: 0.0068 - val_loss: 0.2925 - val_mean_squared_error: 0.1177\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0310 - mean_squared_error: 0.0068 - val_loss: 0.2928 - val_mean_squared_error: 0.1176\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0319 - mean_squared_error: 0.0068 - val_loss: 0.2927 - val_mean_squared_error: 0.1179\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0316 - mean_squared_error: 0.0066 - val_loss: 0.2943 - val_mean_squared_error: 0.1188\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0306 - mean_squared_error: 0.0067 - val_loss: 0.2954 - val_mean_squared_error: 0.1194\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0314 - mean_squared_error: 0.0068 - val_loss: 0.2927 - val_mean_squared_error: 0.1181\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0306 - mean_squared_error: 0.0069 - val_loss: 0.2925 - val_mean_squared_error: 0.1178\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0302 - mean_squared_error: 0.0066 - val_loss: 0.2932 - val_mean_squared_error: 0.1180\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0310 - mean_squared_error: 0.0066 - val_loss: 0.2914 - val_mean_squared_error: 0.1172\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0297 - mean_squared_error: 0.0067 - val_loss: 0.2920 - val_mean_squared_error: 0.1180\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0308 - mean_squared_error: 0.0066 - val_loss: 0.2932 - val_mean_squared_error: 0.1182\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0292 - mean_squared_error: 0.0066 - val_loss: 0.2923 - val_mean_squared_error: 0.1174\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0304 - mean_squared_error: 0.0067 - val_loss: 0.2913 - val_mean_squared_error: 0.1175\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0320 - mean_squared_error: 0.0066 - val_loss: 0.2906 - val_mean_squared_error: 0.1172\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0302 - mean_squared_error: 0.0065 - val_loss: 0.2932 - val_mean_squared_error: 0.1184\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0308 - mean_squared_error: 0.0065 - val_loss: 0.2945 - val_mean_squared_error: 0.1192\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0319 - mean_squared_error: 0.0065 - val_loss: 0.2929 - val_mean_squared_error: 0.1185\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0306 - mean_squared_error: 0.0065 - val_loss: 0.2913 - val_mean_squared_error: 0.1176\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0315 - mean_squared_error: 0.0066 - val_loss: 0.2924 - val_mean_squared_error: 0.1182\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0292 - mean_squared_error: 0.0064 - val_loss: 0.2938 - val_mean_squared_error: 0.1192\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0338 - mean_squared_error: 0.0063 - val_loss: 0.2935 - val_mean_squared_error: 0.1186\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0295 - mean_squared_error: 0.0061 - val_loss: 0.2907 - val_mean_squared_error: 0.1169\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0344 - mean_squared_error: 0.0066 - val_loss: 0.2901 - val_mean_squared_error: 0.1167\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0320 - mean_squared_error: 0.0065 - val_loss: 0.2936 - val_mean_squared_error: 0.1189\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0326 - mean_squared_error: 0.0061 - val_loss: 0.2945 - val_mean_squared_error: 0.1193\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0322 - mean_squared_error: 0.0062 - val_loss: 0.2921 - val_mean_squared_error: 0.1179\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0313 - mean_squared_error: 0.0063 - val_loss: 0.2910 - val_mean_squared_error: 0.1174\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0299 - mean_squared_error: 0.0062 - val_loss: 0.2933 - val_mean_squared_error: 0.1186\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0318 - mean_squared_error: 0.0062 - val_loss: 0.2947 - val_mean_squared_error: 0.1193\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0304 - mean_squared_error: 0.0062 - val_loss: 0.2934 - val_mean_squared_error: 0.1187\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0314 - mean_squared_error: 0.0062 - val_loss: 0.2915 - val_mean_squared_error: 0.1180\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0308 - mean_squared_error: 0.0061 - val_loss: 0.2928 - val_mean_squared_error: 0.1181\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0312 - mean_squared_error: 0.0061 - val_loss: 0.2942 - val_mean_squared_error: 0.1186\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0318 - mean_squared_error: 0.0061 - val_loss: 0.2927 - val_mean_squared_error: 0.1182\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0312 - mean_squared_error: 0.0060 - val_loss: 0.2904 - val_mean_squared_error: 0.1176\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0305 - mean_squared_error: 0.0061 - val_loss: 0.2921 - val_mean_squared_error: 0.1187\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0326 - mean_squared_error: 0.0061 - val_loss: 0.2936 - val_mean_squared_error: 0.1190\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0278 - mean_squared_error: 0.0061 - val_loss: 0.2937 - val_mean_squared_error: 0.1189\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0293 - mean_squared_error: 0.0061 - val_loss: 0.2923 - val_mean_squared_error: 0.1179\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0300 - mean_squared_error: 0.0059 - val_loss: 0.2903 - val_mean_squared_error: 0.1170\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0302 - mean_squared_error: 0.0058 - val_loss: 0.2918 - val_mean_squared_error: 0.1179\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0280 - mean_squared_error: 0.0058 - val_loss: 0.2950 - val_mean_squared_error: 0.1194\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0319 - mean_squared_error: 0.0061 - val_loss: 0.2946 - val_mean_squared_error: 0.1194\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0295 - mean_squared_error: 0.0060 - val_loss: 0.2915 - val_mean_squared_error: 0.1184\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0332 - mean_squared_error: 0.0059 - val_loss: 0.2898 - val_mean_squared_error: 0.1171\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0310 - mean_squared_error: 0.0058 - val_loss: 0.2917 - val_mean_squared_error: 0.1174\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0317 - mean_squared_error: 0.0058 - val_loss: 0.2930 - val_mean_squared_error: 0.1180\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0315 - mean_squared_error: 0.0058 - val_loss: 0.2915 - val_mean_squared_error: 0.1177\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0300 - mean_squared_error: 0.0057 - val_loss: 0.2915 - val_mean_squared_error: 0.1181\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0292 - mean_squared_error: 0.0057 - val_loss: 0.2939 - val_mean_squared_error: 0.1191\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0296 - mean_squared_error: 0.0058 - val_loss: 0.2942 - val_mean_squared_error: 0.1189\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0281 - mean_squared_error: 0.0057 - val_loss: 0.2916 - val_mean_squared_error: 0.1176\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0304 - mean_squared_error: 0.0057 - val_loss: 0.2910 - val_mean_squared_error: 0.1174\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0288 - mean_squared_error: 0.0056 - val_loss: 0.2922 - val_mean_squared_error: 0.1180\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0302 - mean_squared_error: 0.0057 - val_loss: 0.2924 - val_mean_squared_error: 0.1184\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0292 - mean_squared_error: 0.0057 - val_loss: 0.2916 - val_mean_squared_error: 0.1179\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0299 - mean_squared_error: 0.0056 - val_loss: 0.2914 - val_mean_squared_error: 0.1180\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0303 - mean_squared_error: 0.0056 - val_loss: 0.2927 - val_mean_squared_error: 0.1183\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0311 - mean_squared_error: 0.0057 - val_loss: 0.2936 - val_mean_squared_error: 0.1186\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0320 - mean_squared_error: 0.0058 - val_loss: 0.2932 - val_mean_squared_error: 0.1188\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0313 - mean_squared_error: 0.0055 - val_loss: 0.2914 - val_mean_squared_error: 0.1185\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0288 - mean_squared_error: 0.0053 - val_loss: 0.2909 - val_mean_squared_error: 0.1184\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0327 - mean_squared_error: 0.0055 - val_loss: 0.2922 - val_mean_squared_error: 0.1186\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0285 - mean_squared_error: 0.0055 - val_loss: 0.2939 - val_mean_squared_error: 0.1196\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0296 - mean_squared_error: 0.0054 - val_loss: 0.2942 - val_mean_squared_error: 0.1202\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0289 - mean_squared_error: 0.0052 - val_loss: 0.2922 - val_mean_squared_error: 0.1185\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0277 - mean_squared_error: 0.0054 - val_loss: 0.2907 - val_mean_squared_error: 0.1170\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0294 - mean_squared_error: 0.0057 - val_loss: 0.2930 - val_mean_squared_error: 0.1185\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0258 - mean_squared_error: 0.0053 - val_loss: 0.2939 - val_mean_squared_error: 0.1199\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0285 - mean_squared_error: 0.0051 - val_loss: 0.2925 - val_mean_squared_error: 0.1191\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0266 - mean_squared_error: 0.0052 - val_loss: 0.2928 - val_mean_squared_error: 0.1186\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0299 - mean_squared_error: 0.0056 - val_loss: 0.2915 - val_mean_squared_error: 0.1177\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0271 - mean_squared_error: 0.0055 - val_loss: 0.2921 - val_mean_squared_error: 0.1187\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0294 - mean_squared_error: 0.0052 - val_loss: 0.2930 - val_mean_squared_error: 0.1191\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0281 - mean_squared_error: 0.0051 - val_loss: 0.2932 - val_mean_squared_error: 0.1186\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0273 - mean_squared_error: 0.0054 - val_loss: 0.2919 - val_mean_squared_error: 0.1183\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0284 - mean_squared_error: 0.0054 - val_loss: 0.2926 - val_mean_squared_error: 0.1196\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0269 - mean_squared_error: 0.0049 - val_loss: 0.2927 - val_mean_squared_error: 0.1196\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0275 - mean_squared_error: 0.0048 - val_loss: 0.2908 - val_mean_squared_error: 0.1177\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0259 - mean_squared_error: 0.0051 - val_loss: 0.2913 - val_mean_squared_error: 0.1179\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0263 - mean_squared_error: 0.0052 - val_loss: 0.2927 - val_mean_squared_error: 0.1190\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0251 - mean_squared_error: 0.0050 - val_loss: 0.2916 - val_mean_squared_error: 0.1186\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0259 - mean_squared_error: 0.0050 - val_loss: 0.2915 - val_mean_squared_error: 0.1182\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0259 - mean_squared_error: 0.0051 - val_loss: 0.2911 - val_mean_squared_error: 0.1177\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0259 - mean_squared_error: 0.0052 - val_loss: 0.2930 - val_mean_squared_error: 0.1190\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0254 - mean_squared_error: 0.0050 - val_loss: 0.2950 - val_mean_squared_error: 0.1201\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0267 - mean_squared_error: 0.0050 - val_loss: 0.2926 - val_mean_squared_error: 0.1186\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0244 - mean_squared_error: 0.0051 - val_loss: 0.2913 - val_mean_squared_error: 0.1181\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0258 - mean_squared_error: 0.0050 - val_loss: 0.2930 - val_mean_squared_error: 0.1195\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0256 - mean_squared_error: 0.0048 - val_loss: 0.2930 - val_mean_squared_error: 0.1198\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0250 - mean_squared_error: 0.0049 - val_loss: 0.2918 - val_mean_squared_error: 0.1190\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0273 - mean_squared_error: 0.0051 - val_loss: 0.2928 - val_mean_squared_error: 0.1193\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0244 - mean_squared_error: 0.0049 - val_loss: 0.2941 - val_mean_squared_error: 0.1197\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0282 - mean_squared_error: 0.0048 - val_loss: 0.2926 - val_mean_squared_error: 0.1187\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0282 - mean_squared_error: 0.0049 - val_loss: 0.2908 - val_mean_squared_error: 0.1179\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0266 - mean_squared_error: 0.0050 - val_loss: 0.2920 - val_mean_squared_error: 0.1191\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0252 - mean_squared_error: 0.0049 - val_loss: 0.2943 - val_mean_squared_error: 0.1207\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0286 - mean_squared_error: 0.0049 - val_loss: 0.2939 - val_mean_squared_error: 0.1200\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0265 - mean_squared_error: 0.0048 - val_loss: 0.2911 - val_mean_squared_error: 0.1181\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0272 - mean_squared_error: 0.0048 - val_loss: 0.2909 - val_mean_squared_error: 0.1176\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0270 - mean_squared_error: 0.0047 - val_loss: 0.2938 - val_mean_squared_error: 0.1190\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0272 - mean_squared_error: 0.0047 - val_loss: 0.2943 - val_mean_squared_error: 0.1196\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0257 - mean_squared_error: 0.0047 - val_loss: 0.2920 - val_mean_squared_error: 0.1188\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0274 - mean_squared_error: 0.0049 - val_loss: 0.2913 - val_mean_squared_error: 0.1186\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0271 - mean_squared_error: 0.0049 - val_loss: 0.2942 - val_mean_squared_error: 0.1200\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0248 - mean_squared_error: 0.0045 - val_loss: 0.2940 - val_mean_squared_error: 0.1194\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0257 - mean_squared_error: 0.0045 - val_loss: 0.2909 - val_mean_squared_error: 0.1178\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0245 - mean_squared_error: 0.0046 - val_loss: 0.2910 - val_mean_squared_error: 0.1184\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0256 - mean_squared_error: 0.0046 - val_loss: 0.2943 - val_mean_squared_error: 0.1201\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0242 - mean_squared_error: 0.0045 - val_loss: 0.2943 - val_mean_squared_error: 0.1199\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0250 - mean_squared_error: 0.0046 - val_loss: 0.2917 - val_mean_squared_error: 0.1188\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0251 - mean_squared_error: 0.0046 - val_loss: 0.2917 - val_mean_squared_error: 0.1189\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0245 - mean_squared_error: 0.0045 - val_loss: 0.2933 - val_mean_squared_error: 0.1195\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0245 - mean_squared_error: 0.0046 - val_loss: 0.2925 - val_mean_squared_error: 0.1189\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0253 - mean_squared_error: 0.0046 - val_loss: 0.2915 - val_mean_squared_error: 0.1187\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0245 - mean_squared_error: 0.0045 - val_loss: 0.2912 - val_mean_squared_error: 0.1185\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0234 - mean_squared_error: 0.0044 - val_loss: 0.2921 - val_mean_squared_error: 0.1186\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0251 - mean_squared_error: 0.0045 - val_loss: 0.2919 - val_mean_squared_error: 0.1183\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0245 - mean_squared_error: 0.0045 - val_loss: 0.2913 - val_mean_squared_error: 0.1187\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0235 - mean_squared_error: 0.0044 - val_loss: 0.2932 - val_mean_squared_error: 0.1202\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0250 - mean_squared_error: 0.0043 - val_loss: 0.2934 - val_mean_squared_error: 0.1195\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0245 - mean_squared_error: 0.0045 - val_loss: 0.2933 - val_mean_squared_error: 0.1191\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0236 - mean_squared_error: 0.0045 - val_loss: 0.2925 - val_mean_squared_error: 0.1196\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0254 - mean_squared_error: 0.0043 - val_loss: 0.2921 - val_mean_squared_error: 0.1196\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0235 - mean_squared_error: 0.0043 - val_loss: 0.2944 - val_mean_squared_error: 0.1204\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0260 - mean_squared_error: 0.0046 - val_loss: 0.2952 - val_mean_squared_error: 0.1208\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.0253 - mean_squared_error: 0.0044 - val_loss: 0.2918 - val_mean_squared_error: 0.1191\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0239 - mean_squared_error: 0.0044 - val_loss: 0.2908 - val_mean_squared_error: 0.1187\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0248 - mean_squared_error: 0.0044 - val_loss: 0.2940 - val_mean_squared_error: 0.1208\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0243 - mean_squared_error: 0.0042 - val_loss: 0.2944 - val_mean_squared_error: 0.1207\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0247 - mean_squared_error: 0.0043 - val_loss: 0.2915 - val_mean_squared_error: 0.1190\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0232 - mean_squared_error: 0.0043 - val_loss: 0.2925 - val_mean_squared_error: 0.1196\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0229 - mean_squared_error: 0.0041 - val_loss: 0.2932 - val_mean_squared_error: 0.1196\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0224 - mean_squared_error: 0.0042 - val_loss: 0.2928 - val_mean_squared_error: 0.1193\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0215 - mean_squared_error: 0.0042 - val_loss: 0.2923 - val_mean_squared_error: 0.1192\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0230 - mean_squared_error: 0.0042 - val_loss: 0.2939 - val_mean_squared_error: 0.1196\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0230 - mean_squared_error: 0.0042 - val_loss: 0.2936 - val_mean_squared_error: 0.1195\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0215 - mean_squared_error: 0.0042 - val_loss: 0.2922 - val_mean_squared_error: 0.1193\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0231 - mean_squared_error: 0.0042 - val_loss: 0.2935 - val_mean_squared_error: 0.1200\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0213 - mean_squared_error: 0.0040 - val_loss: 0.2952 - val_mean_squared_error: 0.1207\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0237 - mean_squared_error: 0.0041 - val_loss: 0.2934 - val_mean_squared_error: 0.1194\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0219 - mean_squared_error: 0.0042 - val_loss: 0.2918 - val_mean_squared_error: 0.1194\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0246 - mean_squared_error: 0.0041 - val_loss: 0.2928 - val_mean_squared_error: 0.1203\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0238 - mean_squared_error: 0.0039 - val_loss: 0.2923 - val_mean_squared_error: 0.1194\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0251 - mean_squared_error: 0.0042 - val_loss: 0.2934 - val_mean_squared_error: 0.1198\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0241 - mean_squared_error: 0.0041 - val_loss: 0.2931 - val_mean_squared_error: 0.1197\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0240 - mean_squared_error: 0.0039 - val_loss: 0.2916 - val_mean_squared_error: 0.1189\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.0230 - mean_squared_error: 0.0040 - val_loss: 0.2931 - val_mean_squared_error: 0.1197\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0225 - mean_squared_error: 0.0041 - val_loss: 0.2943 - val_mean_squared_error: 0.1205\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.0227 - mean_squared_error: 0.0040 - val_loss: 0.2931 - val_mean_squared_error: 0.1200\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0225 - mean_squared_error: 0.0039 - val_loss: 0.2926 - val_mean_squared_error: 0.1194\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0215 - mean_squared_error: 0.0040 - val_loss: 0.2945 - val_mean_squared_error: 0.1202\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.0229 - mean_squared_error: 0.0040 - val_loss: 0.2946 - val_mean_squared_error: 0.1204\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0214 - mean_squared_error: 0.0039 - val_loss: 0.2932 - val_mean_squared_error: 0.1196\n"
     ]
    }
   ],
   "source": [
    "model_rnn.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanSquaredError()])\n",
    "\n",
    "history_rnn = model_rnn.fit(X_train_s, y_train_s, epochs=1000, batch_size = 64, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37807473549980175\n"
     ]
    }
   ],
   "source": [
    "y_pred_s = model_rnn.predict(X_test_s)\n",
    "\n",
    "model_rnn.evaluate(X_test_s, y_test_s)\n",
    "\n",
    "print(mean_absolute_error(y_test_s, y_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rseau de neurones rcurrent pour un seul seuil *model_rnn_sab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_10 (SimpleRNN)    (None, 32)                1120      \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,433\n",
      "Trainable params: 1,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "y_sab = y[:, 1]\n",
    "X_train_sab, X_test_sab, y_train_sab, y_test_sab = train_test_split(dataset, y_sab, train_size = 0.7, shuffle = False)\n",
    "\n",
    "model_rnn_sab = Sequential()\n",
    "model_rnn_sab.add(SimpleRNN(32, input_shape=(dataset.shape[1], dataset.shape[2])))\n",
    "model_rnn_sab.add(Dense(8, activation = 'relu'))\n",
    "model_rnn_sab.add((Dropout(0.3)))\n",
    "model_rnn_sab.add(Dense(4, activation = 'relu'))\n",
    "model_rnn_sab.add((Dropout(0.3)))\n",
    "model_rnn_sab.add(Dense(2, activation = 'relu'))\n",
    "model_rnn_sab.add((Dropout(0.3)))\n",
    "model_rnn_sab.add(Dense(1, activation = 'linear'))\n",
    "model_rnn_sab.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 1s 32ms/step - loss: 0.6622 - mean_squared_error: 0.6579 - val_loss: 0.5040 - val_mean_squared_error: 0.3380\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.5094 - mean_squared_error: 0.3522 - val_loss: 0.4748 - val_mean_squared_error: 0.3110\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4827 - mean_squared_error: 0.3225 - val_loss: 0.4597 - val_mean_squared_error: 0.2968\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4666 - mean_squared_error: 0.3048 - val_loss: 0.4453 - val_mean_squared_error: 0.2830\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.4506 - mean_squared_error: 0.2885 - val_loss: 0.4318 - val_mean_squared_error: 0.2698\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4352 - mean_squared_error: 0.2724 - val_loss: 0.4190 - val_mean_squared_error: 0.2571\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4241 - mean_squared_error: 0.2604 - val_loss: 0.4069 - val_mean_squared_error: 0.2449\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4111 - mean_squared_error: 0.2478 - val_loss: 0.3958 - val_mean_squared_error: 0.2334\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4010 - mean_squared_error: 0.2372 - val_loss: 0.3850 - val_mean_squared_error: 0.2224\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3922 - mean_squared_error: 0.2243 - val_loss: 0.3753 - val_mean_squared_error: 0.2121\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3824 - mean_squared_error: 0.2151 - val_loss: 0.3663 - val_mean_squared_error: 0.2024\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3653 - mean_squared_error: 0.2001 - val_loss: 0.3581 - val_mean_squared_error: 0.1929\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3655 - mean_squared_error: 0.1938 - val_loss: 0.3502 - val_mean_squared_error: 0.1842\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3592 - mean_squared_error: 0.1933 - val_loss: 0.3429 - val_mean_squared_error: 0.1763\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3445 - mean_squared_error: 0.1768 - val_loss: 0.3365 - val_mean_squared_error: 0.1688\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3481 - mean_squared_error: 0.1756 - val_loss: 0.3300 - val_mean_squared_error: 0.1611\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3397 - mean_squared_error: 0.1676 - val_loss: 0.3224 - val_mean_squared_error: 0.1525\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3366 - mean_squared_error: 0.1666 - val_loss: 0.3117 - val_mean_squared_error: 0.1414\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3306 - mean_squared_error: 0.1599 - val_loss: 0.2957 - val_mean_squared_error: 0.1263\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3092 - mean_squared_error: 0.1431 - val_loss: 0.2746 - val_mean_squared_error: 0.1076\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3195 - mean_squared_error: 0.1544 - val_loss: 0.2601 - val_mean_squared_error: 0.0953\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3103 - mean_squared_error: 0.1466 - val_loss: 0.2593 - val_mean_squared_error: 0.0943\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3199 - mean_squared_error: 0.1516 - val_loss: 0.2566 - val_mean_squared_error: 0.0919\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2913 - mean_squared_error: 0.1336 - val_loss: 0.2567 - val_mean_squared_error: 0.0914\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2875 - mean_squared_error: 0.1266 - val_loss: 0.2485 - val_mean_squared_error: 0.0853\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2845 - mean_squared_error: 0.1273 - val_loss: 0.2531 - val_mean_squared_error: 0.0881\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2792 - mean_squared_error: 0.1214 - val_loss: 0.2500 - val_mean_squared_error: 0.0858\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2950 - mean_squared_error: 0.1303 - val_loss: 0.2414 - val_mean_squared_error: 0.0799\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2864 - mean_squared_error: 0.1222 - val_loss: 0.2547 - val_mean_squared_error: 0.0894\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.3010 - mean_squared_error: 0.1359 - val_loss: 0.2511 - val_mean_squared_error: 0.0866\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2795 - mean_squared_error: 0.1198 - val_loss: 0.2444 - val_mean_squared_error: 0.0818\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2755 - mean_squared_error: 0.1189 - val_loss: 0.2471 - val_mean_squared_error: 0.0836\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2651 - mean_squared_error: 0.1117 - val_loss: 0.2418 - val_mean_squared_error: 0.0799\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2734 - mean_squared_error: 0.1177 - val_loss: 0.2439 - val_mean_squared_error: 0.0813\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2801 - mean_squared_error: 0.1202 - val_loss: 0.2442 - val_mean_squared_error: 0.0817\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2689 - mean_squared_error: 0.1133 - val_loss: 0.2400 - val_mean_squared_error: 0.0789\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2689 - mean_squared_error: 0.1105 - val_loss: 0.2474 - val_mean_squared_error: 0.0836\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2681 - mean_squared_error: 0.1105 - val_loss: 0.2332 - val_mean_squared_error: 0.0742\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2590 - mean_squared_error: 0.1067 - val_loss: 0.2389 - val_mean_squared_error: 0.0773\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2639 - mean_squared_error: 0.1060 - val_loss: 0.2375 - val_mean_squared_error: 0.0761\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2599 - mean_squared_error: 0.1056 - val_loss: 0.2293 - val_mean_squared_error: 0.0709\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2538 - mean_squared_error: 0.1045 - val_loss: 0.2405 - val_mean_squared_error: 0.0782\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2680 - mean_squared_error: 0.1078 - val_loss: 0.2470 - val_mean_squared_error: 0.0822\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2644 - mean_squared_error: 0.1055 - val_loss: 0.2340 - val_mean_squared_error: 0.0734\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2566 - mean_squared_error: 0.1013 - val_loss: 0.2316 - val_mean_squared_error: 0.0717\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2644 - mean_squared_error: 0.1079 - val_loss: 0.2325 - val_mean_squared_error: 0.0723\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2667 - mean_squared_error: 0.1073 - val_loss: 0.2399 - val_mean_squared_error: 0.0769\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2521 - mean_squared_error: 0.0956 - val_loss: 0.2364 - val_mean_squared_error: 0.0747\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2483 - mean_squared_error: 0.0957 - val_loss: 0.2316 - val_mean_squared_error: 0.0718\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2556 - mean_squared_error: 0.1021 - val_loss: 0.2352 - val_mean_squared_error: 0.0741\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2572 - mean_squared_error: 0.1019 - val_loss: 0.2406 - val_mean_squared_error: 0.0771\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2645 - mean_squared_error: 0.1072 - val_loss: 0.2296 - val_mean_squared_error: 0.0708\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2585 - mean_squared_error: 0.1017 - val_loss: 0.2365 - val_mean_squared_error: 0.0748\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2502 - mean_squared_error: 0.0952 - val_loss: 0.2403 - val_mean_squared_error: 0.0772\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2666 - mean_squared_error: 0.1052 - val_loss: 0.2359 - val_mean_squared_error: 0.0746\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2561 - mean_squared_error: 0.1006 - val_loss: 0.2296 - val_mean_squared_error: 0.0700\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2567 - mean_squared_error: 0.0990 - val_loss: 0.2365 - val_mean_squared_error: 0.0739\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2463 - mean_squared_error: 0.0943 - val_loss: 0.2337 - val_mean_squared_error: 0.0721\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2461 - mean_squared_error: 0.0921 - val_loss: 0.2282 - val_mean_squared_error: 0.0688\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2548 - mean_squared_error: 0.0990 - val_loss: 0.2367 - val_mean_squared_error: 0.0740\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2527 - mean_squared_error: 0.0947 - val_loss: 0.2303 - val_mean_squared_error: 0.0702\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2489 - mean_squared_error: 0.0967 - val_loss: 0.2347 - val_mean_squared_error: 0.0727\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2493 - mean_squared_error: 0.0959 - val_loss: 0.2261 - val_mean_squared_error: 0.0681\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2540 - mean_squared_error: 0.0978 - val_loss: 0.2341 - val_mean_squared_error: 0.0731\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2481 - mean_squared_error: 0.0941 - val_loss: 0.2385 - val_mean_squared_error: 0.0752\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2470 - mean_squared_error: 0.0962 - val_loss: 0.2236 - val_mean_squared_error: 0.0666\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2363 - mean_squared_error: 0.0851 - val_loss: 0.2285 - val_mean_squared_error: 0.0700\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2526 - mean_squared_error: 0.0991 - val_loss: 0.2368 - val_mean_squared_error: 0.0751\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2484 - mean_squared_error: 0.0935 - val_loss: 0.2197 - val_mean_squared_error: 0.0650\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2427 - mean_squared_error: 0.0883 - val_loss: 0.2315 - val_mean_squared_error: 0.0712\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2411 - mean_squared_error: 0.0889 - val_loss: 0.2356 - val_mean_squared_error: 0.0737\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2547 - mean_squared_error: 0.0974 - val_loss: 0.2265 - val_mean_squared_error: 0.0682\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2497 - mean_squared_error: 0.0930 - val_loss: 0.2268 - val_mean_squared_error: 0.0682\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2582 - mean_squared_error: 0.0987 - val_loss: 0.2306 - val_mean_squared_error: 0.0708\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2406 - mean_squared_error: 0.0869 - val_loss: 0.2262 - val_mean_squared_error: 0.0686\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2407 - mean_squared_error: 0.0891 - val_loss: 0.2264 - val_mean_squared_error: 0.0686\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2398 - mean_squared_error: 0.0883 - val_loss: 0.2282 - val_mean_squared_error: 0.0700\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2425 - mean_squared_error: 0.0899 - val_loss: 0.2354 - val_mean_squared_error: 0.0733\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2347 - mean_squared_error: 0.0831 - val_loss: 0.2243 - val_mean_squared_error: 0.0667\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2553 - mean_squared_error: 0.0974 - val_loss: 0.2259 - val_mean_squared_error: 0.0677\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2409 - mean_squared_error: 0.0885 - val_loss: 0.2352 - val_mean_squared_error: 0.0730\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2421 - mean_squared_error: 0.0875 - val_loss: 0.2289 - val_mean_squared_error: 0.0694\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2342 - mean_squared_error: 0.0837 - val_loss: 0.2255 - val_mean_squared_error: 0.0675\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2440 - mean_squared_error: 0.0936 - val_loss: 0.2301 - val_mean_squared_error: 0.0699\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2368 - mean_squared_error: 0.0869 - val_loss: 0.2229 - val_mean_squared_error: 0.0661\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2401 - mean_squared_error: 0.0890 - val_loss: 0.2248 - val_mean_squared_error: 0.0672\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2345 - mean_squared_error: 0.0830 - val_loss: 0.2275 - val_mean_squared_error: 0.0687\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2243 - mean_squared_error: 0.0784 - val_loss: 0.2259 - val_mean_squared_error: 0.0677\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2292 - mean_squared_error: 0.0820 - val_loss: 0.2214 - val_mean_squared_error: 0.0654\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2417 - mean_squared_error: 0.0890 - val_loss: 0.2273 - val_mean_squared_error: 0.0687\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2445 - mean_squared_error: 0.0896 - val_loss: 0.2287 - val_mean_squared_error: 0.0692\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2340 - mean_squared_error: 0.0827 - val_loss: 0.2217 - val_mean_squared_error: 0.0657\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2293 - mean_squared_error: 0.0800 - val_loss: 0.2240 - val_mean_squared_error: 0.0674\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2380 - mean_squared_error: 0.0881 - val_loss: 0.2323 - val_mean_squared_error: 0.0715\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2347 - mean_squared_error: 0.0856 - val_loss: 0.2186 - val_mean_squared_error: 0.0646\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2315 - mean_squared_error: 0.0818 - val_loss: 0.2170 - val_mean_squared_error: 0.0636\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2264 - mean_squared_error: 0.0818 - val_loss: 0.2225 - val_mean_squared_error: 0.0668\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2301 - mean_squared_error: 0.0805 - val_loss: 0.2178 - val_mean_squared_error: 0.0643\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2314 - mean_squared_error: 0.0826 - val_loss: 0.2255 - val_mean_squared_error: 0.0676\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2310 - mean_squared_error: 0.0825 - val_loss: 0.2238 - val_mean_squared_error: 0.0667\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2444 - mean_squared_error: 0.0931 - val_loss: 0.2248 - val_mean_squared_error: 0.0671\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2324 - mean_squared_error: 0.0843 - val_loss: 0.2259 - val_mean_squared_error: 0.0679\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2244 - mean_squared_error: 0.0768 - val_loss: 0.2239 - val_mean_squared_error: 0.0670\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2300 - mean_squared_error: 0.0807 - val_loss: 0.2160 - val_mean_squared_error: 0.0632\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2272 - mean_squared_error: 0.0798 - val_loss: 0.2151 - val_mean_squared_error: 0.0632\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2288 - mean_squared_error: 0.0827 - val_loss: 0.2172 - val_mean_squared_error: 0.0646\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2210 - mean_squared_error: 0.0787 - val_loss: 0.2103 - val_mean_squared_error: 0.0610\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2246 - mean_squared_error: 0.0800 - val_loss: 0.2154 - val_mean_squared_error: 0.0632\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2385 - mean_squared_error: 0.0887 - val_loss: 0.2157 - val_mean_squared_error: 0.0634\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2254 - mean_squared_error: 0.0803 - val_loss: 0.2132 - val_mean_squared_error: 0.0622\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2394 - mean_squared_error: 0.0849 - val_loss: 0.2148 - val_mean_squared_error: 0.0626\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2289 - mean_squared_error: 0.0804 - val_loss: 0.2203 - val_mean_squared_error: 0.0648\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2299 - mean_squared_error: 0.0799 - val_loss: 0.2108 - val_mean_squared_error: 0.0602\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2277 - mean_squared_error: 0.0801 - val_loss: 0.2182 - val_mean_squared_error: 0.0634\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2226 - mean_squared_error: 0.0771 - val_loss: 0.2168 - val_mean_squared_error: 0.0630\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2368 - mean_squared_error: 0.0859 - val_loss: 0.2153 - val_mean_squared_error: 0.0622\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2283 - mean_squared_error: 0.0796 - val_loss: 0.2172 - val_mean_squared_error: 0.0630\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2283 - mean_squared_error: 0.0798 - val_loss: 0.2160 - val_mean_squared_error: 0.0631\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2254 - mean_squared_error: 0.0790 - val_loss: 0.2184 - val_mean_squared_error: 0.0645\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2358 - mean_squared_error: 0.0819 - val_loss: 0.2161 - val_mean_squared_error: 0.0632\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2402 - mean_squared_error: 0.0894 - val_loss: 0.2139 - val_mean_squared_error: 0.0614\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2318 - mean_squared_error: 0.0801 - val_loss: 0.2112 - val_mean_squared_error: 0.0600\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2206 - mean_squared_error: 0.0764 - val_loss: 0.2131 - val_mean_squared_error: 0.0612\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2180 - mean_squared_error: 0.0745 - val_loss: 0.2078 - val_mean_squared_error: 0.0591\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2258 - mean_squared_error: 0.0782 - val_loss: 0.2102 - val_mean_squared_error: 0.0600\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2150 - mean_squared_error: 0.0737 - val_loss: 0.2039 - val_mean_squared_error: 0.0572\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2270 - mean_squared_error: 0.0788 - val_loss: 0.2062 - val_mean_squared_error: 0.0582\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2241 - mean_squared_error: 0.0779 - val_loss: 0.2132 - val_mean_squared_error: 0.0618\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2179 - mean_squared_error: 0.0706 - val_loss: 0.2119 - val_mean_squared_error: 0.0608\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2214 - mean_squared_error: 0.0757 - val_loss: 0.2074 - val_mean_squared_error: 0.0590\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2257 - mean_squared_error: 0.0799 - val_loss: 0.2057 - val_mean_squared_error: 0.0583\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2212 - mean_squared_error: 0.0764 - val_loss: 0.2077 - val_mean_squared_error: 0.0593\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2266 - mean_squared_error: 0.0786 - val_loss: 0.2064 - val_mean_squared_error: 0.0582\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2254 - mean_squared_error: 0.0772 - val_loss: 0.2050 - val_mean_squared_error: 0.0575\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2120 - mean_squared_error: 0.0693 - val_loss: 0.2048 - val_mean_squared_error: 0.0574\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2089 - mean_squared_error: 0.0688 - val_loss: 0.2068 - val_mean_squared_error: 0.0588\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2307 - mean_squared_error: 0.0793 - val_loss: 0.2075 - val_mean_squared_error: 0.0589\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2126 - mean_squared_error: 0.0720 - val_loss: 0.2048 - val_mean_squared_error: 0.0575\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2211 - mean_squared_error: 0.0753 - val_loss: 0.2059 - val_mean_squared_error: 0.0580\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2139 - mean_squared_error: 0.0700 - val_loss: 0.2089 - val_mean_squared_error: 0.0593\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2110 - mean_squared_error: 0.0689 - val_loss: 0.2055 - val_mean_squared_error: 0.0580\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2310 - mean_squared_error: 0.0802 - val_loss: 0.2045 - val_mean_squared_error: 0.0577\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2190 - mean_squared_error: 0.0726 - val_loss: 0.2036 - val_mean_squared_error: 0.0571\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2189 - mean_squared_error: 0.0734 - val_loss: 0.2067 - val_mean_squared_error: 0.0584\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2238 - mean_squared_error: 0.0744 - val_loss: 0.2065 - val_mean_squared_error: 0.0582\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2215 - mean_squared_error: 0.0749 - val_loss: 0.2053 - val_mean_squared_error: 0.0576\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2184 - mean_squared_error: 0.0732 - val_loss: 0.1981 - val_mean_squared_error: 0.0547\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2170 - mean_squared_error: 0.0733 - val_loss: 0.1971 - val_mean_squared_error: 0.0543\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2144 - mean_squared_error: 0.0696 - val_loss: 0.2027 - val_mean_squared_error: 0.0567\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2222 - mean_squared_error: 0.0742 - val_loss: 0.2057 - val_mean_squared_error: 0.0582\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2332 - mean_squared_error: 0.0806 - val_loss: 0.2087 - val_mean_squared_error: 0.0592\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2275 - mean_squared_error: 0.0762 - val_loss: 0.2089 - val_mean_squared_error: 0.0590\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2116 - mean_squared_error: 0.0701 - val_loss: 0.2079 - val_mean_squared_error: 0.0587\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2218 - mean_squared_error: 0.0733 - val_loss: 0.2043 - val_mean_squared_error: 0.0566\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2145 - mean_squared_error: 0.0701 - val_loss: 0.1966 - val_mean_squared_error: 0.0543\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2174 - mean_squared_error: 0.0718 - val_loss: 0.2018 - val_mean_squared_error: 0.0557\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2188 - mean_squared_error: 0.0734 - val_loss: 0.2039 - val_mean_squared_error: 0.0566\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2197 - mean_squared_error: 0.0739 - val_loss: 0.2035 - val_mean_squared_error: 0.0571\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2183 - mean_squared_error: 0.0730 - val_loss: 0.2027 - val_mean_squared_error: 0.0565\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2148 - mean_squared_error: 0.0713 - val_loss: 0.1986 - val_mean_squared_error: 0.0543\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2222 - mean_squared_error: 0.0740 - val_loss: 0.1974 - val_mean_squared_error: 0.0544\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2101 - mean_squared_error: 0.0680 - val_loss: 0.1976 - val_mean_squared_error: 0.0548\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2217 - mean_squared_error: 0.0730 - val_loss: 0.1941 - val_mean_squared_error: 0.0528\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2103 - mean_squared_error: 0.0692 - val_loss: 0.1928 - val_mean_squared_error: 0.0528\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2208 - mean_squared_error: 0.0740 - val_loss: 0.1951 - val_mean_squared_error: 0.0536\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2201 - mean_squared_error: 0.0737 - val_loss: 0.2009 - val_mean_squared_error: 0.0558\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2195 - mean_squared_error: 0.0723 - val_loss: 0.2012 - val_mean_squared_error: 0.0564\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2268 - mean_squared_error: 0.0778 - val_loss: 0.2007 - val_mean_squared_error: 0.0562\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2089 - mean_squared_error: 0.0678 - val_loss: 0.1973 - val_mean_squared_error: 0.0543\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2244 - mean_squared_error: 0.0747 - val_loss: 0.1964 - val_mean_squared_error: 0.0539\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2152 - mean_squared_error: 0.0701 - val_loss: 0.1989 - val_mean_squared_error: 0.0547\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2181 - mean_squared_error: 0.0724 - val_loss: 0.1989 - val_mean_squared_error: 0.0551\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2073 - mean_squared_error: 0.0661 - val_loss: 0.2012 - val_mean_squared_error: 0.0556\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2188 - mean_squared_error: 0.0720 - val_loss: 0.1975 - val_mean_squared_error: 0.0547\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2162 - mean_squared_error: 0.0703 - val_loss: 0.1962 - val_mean_squared_error: 0.0539\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2118 - mean_squared_error: 0.0678 - val_loss: 0.1971 - val_mean_squared_error: 0.0543\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2059 - mean_squared_error: 0.0657 - val_loss: 0.1985 - val_mean_squared_error: 0.0549\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2127 - mean_squared_error: 0.0704 - val_loss: 0.1980 - val_mean_squared_error: 0.0549\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2152 - mean_squared_error: 0.0718 - val_loss: 0.1943 - val_mean_squared_error: 0.0533\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2126 - mean_squared_error: 0.0683 - val_loss: 0.1977 - val_mean_squared_error: 0.0543\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2200 - mean_squared_error: 0.07 - 0s 9ms/step - loss: 0.2166 - mean_squared_error: 0.0707 - val_loss: 0.1998 - val_mean_squared_error: 0.0553\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2014 - mean_squared_error: 0.0615 - val_loss: 0.1972 - val_mean_squared_error: 0.0545\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2111 - mean_squared_error: 0.0667 - val_loss: 0.1957 - val_mean_squared_error: 0.0538\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2150 - mean_squared_error: 0.0717 - val_loss: 0.1954 - val_mean_squared_error: 0.0537\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2122 - mean_squared_error: 0.0683 - val_loss: 0.1910 - val_mean_squared_error: 0.0519\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2081 - mean_squared_error: 0.0675 - val_loss: 0.1912 - val_mean_squared_error: 0.0522\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2088 - mean_squared_error: 0.0700 - val_loss: 0.1957 - val_mean_squared_error: 0.0541\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2167 - mean_squared_error: 0.0703 - val_loss: 0.1985 - val_mean_squared_error: 0.0549\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2112 - mean_squared_error: 0.0684 - val_loss: 0.1978 - val_mean_squared_error: 0.0549\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2073 - mean_squared_error: 0.0672 - val_loss: 0.1955 - val_mean_squared_error: 0.0537\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2170 - mean_squared_error: 0.0728 - val_loss: 0.1953 - val_mean_squared_error: 0.0534\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2102 - mean_squared_error: 0.0649 - val_loss: 0.1936 - val_mean_squared_error: 0.0527\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2029 - mean_squared_error: 0.0645 - val_loss: 0.1948 - val_mean_squared_error: 0.0533\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2204 - mean_squared_error: 0.0721 - val_loss: 0.1972 - val_mean_squared_error: 0.0544\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2080 - mean_squared_error: 0.0673 - val_loss: 0.1948 - val_mean_squared_error: 0.0535\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2188 - mean_squared_error: 0.0716 - val_loss: 0.1957 - val_mean_squared_error: 0.0536\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2000 - mean_squared_error: 0.0614 - val_loss: 0.1956 - val_mean_squared_error: 0.0536\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2092 - mean_squared_error: 0.0671 - val_loss: 0.1979 - val_mean_squared_error: 0.0549\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2157 - mean_squared_error: 0.0718 - val_loss: 0.1968 - val_mean_squared_error: 0.0540\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2150 - mean_squared_error: 0.0722 - val_loss: 0.1970 - val_mean_squared_error: 0.0543\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2138 - mean_squared_error: 0.0693 - val_loss: 0.1954 - val_mean_squared_error: 0.0534\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2178 - mean_squared_error: 0.0721 - val_loss: 0.1938 - val_mean_squared_error: 0.0527\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2203 - mean_squared_error: 0.0729 - val_loss: 0.1985 - val_mean_squared_error: 0.0542\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2093 - mean_squared_error: 0.0659 - val_loss: 0.1962 - val_mean_squared_error: 0.0537\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2116 - mean_squared_error: 0.0664 - val_loss: 0.1930 - val_mean_squared_error: 0.0526\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2155 - mean_squared_error: 0.0705 - val_loss: 0.1949 - val_mean_squared_error: 0.0527\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2210 - mean_squared_error: 0.0737 - val_loss: 0.1919 - val_mean_squared_error: 0.0516\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2074 - mean_squared_error: 0.0658 - val_loss: 0.1904 - val_mean_squared_error: 0.0514\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2168 - mean_squared_error: 0.0691 - val_loss: 0.1904 - val_mean_squared_error: 0.0514\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2146 - mean_squared_error: 0.0710 - val_loss: 0.1933 - val_mean_squared_error: 0.0523\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2111 - mean_squared_error: 0.0693 - val_loss: 0.1926 - val_mean_squared_error: 0.0521\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2197 - mean_squared_error: 0.0735 - val_loss: 0.1942 - val_mean_squared_error: 0.0532\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2140 - mean_squared_error: 0.0685 - val_loss: 0.1953 - val_mean_squared_error: 0.0530\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2041 - mean_squared_error: 0.0665 - val_loss: 0.1955 - val_mean_squared_error: 0.0530\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2165 - mean_squared_error: 0.0700 - val_loss: 0.1950 - val_mean_squared_error: 0.0530\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2172 - mean_squared_error: 0.0679 - val_loss: 0.1979 - val_mean_squared_error: 0.0540\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2151 - mean_squared_error: 0.0718 - val_loss: 0.1972 - val_mean_squared_error: 0.0539\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2118 - mean_squared_error: 0.0690 - val_loss: 0.1985 - val_mean_squared_error: 0.0544\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2198 - mean_squared_error: 0.0729 - val_loss: 0.1908 - val_mean_squared_error: 0.0517\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2202 - mean_squared_error: 0.0733 - val_loss: 0.1908 - val_mean_squared_error: 0.0519\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2051 - mean_squared_error: 0.0675 - val_loss: 0.1971 - val_mean_squared_error: 0.0544\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2161 - mean_squared_error: 0.0688 - val_loss: 0.1950 - val_mean_squared_error: 0.0533\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2114 - mean_squared_error: 0.0675 - val_loss: 0.1865 - val_mean_squared_error: 0.0499\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2126 - mean_squared_error: 0.0694 - val_loss: 0.1882 - val_mean_squared_error: 0.0504\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2097 - mean_squared_error: 0.0667 - val_loss: 0.1912 - val_mean_squared_error: 0.0521\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2088 - mean_squared_error: 0.0677 - val_loss: 0.1898 - val_mean_squared_error: 0.0514\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2064 - mean_squared_error: 0.0661 - val_loss: 0.1901 - val_mean_squared_error: 0.0515\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2101 - mean_squared_error: 0.0671 - val_loss: 0.1912 - val_mean_squared_error: 0.0518\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2129 - mean_squared_error: 0.0693 - val_loss: 0.1945 - val_mean_squared_error: 0.0531\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2159 - mean_squared_error: 0.0699 - val_loss: 0.1921 - val_mean_squared_error: 0.0524\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2069 - mean_squared_error: 0.0654 - val_loss: 0.1902 - val_mean_squared_error: 0.0516\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2126 - mean_squared_error: 0.0696 - val_loss: 0.1952 - val_mean_squared_error: 0.0532\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2000 - mean_squared_error: 0.0624 - val_loss: 0.1863 - val_mean_squared_error: 0.0500\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2094 - mean_squared_error: 0.0671 - val_loss: 0.1897 - val_mean_squared_error: 0.0509\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2048 - mean_squared_error: 0.0640 - val_loss: 0.1960 - val_mean_squared_error: 0.0539\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2151 - mean_squared_error: 0.0690 - val_loss: 0.1966 - val_mean_squared_error: 0.0541\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2055 - mean_squared_error: 0.0674 - val_loss: 0.1962 - val_mean_squared_error: 0.0536\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2147 - mean_squared_error: 0.0673 - val_loss: 0.1942 - val_mean_squared_error: 0.0530\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2120 - mean_squared_error: 0.0680 - val_loss: 0.1957 - val_mean_squared_error: 0.0543\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2153 - mean_squared_error: 0.0701 - val_loss: 0.1947 - val_mean_squared_error: 0.0533\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2119 - mean_squared_error: 0.0686 - val_loss: 0.1958 - val_mean_squared_error: 0.0537\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2036 - mean_squared_error: 0.0670 - val_loss: 0.1922 - val_mean_squared_error: 0.0526\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2058 - mean_squared_error: 0.0645 - val_loss: 0.1909 - val_mean_squared_error: 0.0517\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2070 - mean_squared_error: 0.0681 - val_loss: 0.1909 - val_mean_squared_error: 0.0516\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2073 - mean_squared_error: 0.0677 - val_loss: 0.1907 - val_mean_squared_error: 0.0515\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2177 - mean_squared_error: 0.0714 - val_loss: 0.1925 - val_mean_squared_error: 0.0519\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2044 - mean_squared_error: 0.0647 - val_loss: 0.1976 - val_mean_squared_error: 0.0541\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2022 - mean_squared_error: 0.0647 - val_loss: 0.1936 - val_mean_squared_error: 0.0522\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1995 - mean_squared_error: 0.0636 - val_loss: 0.1929 - val_mean_squared_error: 0.0521\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2077 - mean_squared_error: 0.0692 - val_loss: 0.1944 - val_mean_squared_error: 0.0528\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2096 - mean_squared_error: 0.0672 - val_loss: 0.1948 - val_mean_squared_error: 0.0528\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2165 - mean_squared_error: 0.0695 - val_loss: 0.1962 - val_mean_squared_error: 0.0532\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2049 - mean_squared_error: 0.0642 - val_loss: 0.1947 - val_mean_squared_error: 0.0528\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2218 - mean_squared_error: 0.0744 - val_loss: 0.1956 - val_mean_squared_error: 0.0529\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2089 - mean_squared_error: 0.0668 - val_loss: 0.1938 - val_mean_squared_error: 0.0527\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2152 - mean_squared_error: 0.0705 - val_loss: 0.1935 - val_mean_squared_error: 0.0527\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2092 - mean_squared_error: 0.0695 - val_loss: 0.1960 - val_mean_squared_error: 0.0537\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1977 - mean_squared_error: 0.0630 - val_loss: 0.1955 - val_mean_squared_error: 0.0534\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2165 - mean_squared_error: 0.0714 - val_loss: 0.1948 - val_mean_squared_error: 0.0533\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2073 - mean_squared_error: 0.0654 - val_loss: 0.1949 - val_mean_squared_error: 0.0529\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2090 - mean_squared_error: 0.0692 - val_loss: 0.1937 - val_mean_squared_error: 0.0527\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2131 - mean_squared_error: 0.0679 - val_loss: 0.1901 - val_mean_squared_error: 0.0511\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2076 - mean_squared_error: 0.0663 - val_loss: 0.1954 - val_mean_squared_error: 0.0531\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2036 - mean_squared_error: 0.0629 - val_loss: 0.1920 - val_mean_squared_error: 0.0517\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2183 - mean_squared_error: 0.0713 - val_loss: 0.1879 - val_mean_squared_error: 0.0503\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2025 - mean_squared_error: 0.0646 - val_loss: 0.1885 - val_mean_squared_error: 0.0510\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2107 - mean_squared_error: 0.0671 - val_loss: 0.2008 - val_mean_squared_error: 0.0564\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2109 - mean_squared_error: 0.0652 - val_loss: 0.1984 - val_mean_squared_error: 0.0555\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2115 - mean_squared_error: 0.0673 - val_loss: 0.1904 - val_mean_squared_error: 0.0521\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2086 - mean_squared_error: 0.0656 - val_loss: 0.1877 - val_mean_squared_error: 0.0506\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2065 - mean_squared_error: 0.0656 - val_loss: 0.1890 - val_mean_squared_error: 0.0508\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2114 - mean_squared_error: 0.0688 - val_loss: 0.1945 - val_mean_squared_error: 0.0533\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2052 - mean_squared_error: 0.0652 - val_loss: 0.1940 - val_mean_squared_error: 0.0532\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2140 - mean_squared_error: 0.0688 - val_loss: 0.1946 - val_mean_squared_error: 0.0532\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2136 - mean_squared_error: 0.0716 - val_loss: 0.1917 - val_mean_squared_error: 0.0521\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2154 - mean_squared_error: 0.0701 - val_loss: 0.1923 - val_mean_squared_error: 0.0522\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2069 - mean_squared_error: 0.0661 - val_loss: 0.1897 - val_mean_squared_error: 0.0512\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2033 - mean_squared_error: 0.0650 - val_loss: 0.1930 - val_mean_squared_error: 0.0521\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1991 - mean_squared_error: 0.0653 - val_loss: 0.1945 - val_mean_squared_error: 0.0542\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2166 - mean_squared_error: 0.0697 - val_loss: 0.1934 - val_mean_squared_error: 0.0531\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2093 - mean_squared_error: 0.0665 - val_loss: 0.1904 - val_mean_squared_error: 0.0521\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2074 - mean_squared_error: 0.0693 - val_loss: 0.1953 - val_mean_squared_error: 0.0537\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2135 - mean_squared_error: 0.0688 - val_loss: 0.1973 - val_mean_squared_error: 0.0543\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2039 - mean_squared_error: 0.0648 - val_loss: 0.1956 - val_mean_squared_error: 0.0529\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2016 - mean_squared_error: 0.0636 - val_loss: 0.1945 - val_mean_squared_error: 0.0535\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2096 - mean_squared_error: 0.0682 - val_loss: 0.1930 - val_mean_squared_error: 0.0529\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2071 - mean_squared_error: 0.0658 - val_loss: 0.1905 - val_mean_squared_error: 0.0515\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1972 - mean_squared_error: 0.0608 - val_loss: 0.1853 - val_mean_squared_error: 0.0497\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2176 - mean_squared_error: 0.0713 - val_loss: 0.1866 - val_mean_squared_error: 0.0499\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2105 - mean_squared_error: 0.0660 - val_loss: 0.1925 - val_mean_squared_error: 0.0520\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2034 - mean_squared_error: 0.0647 - val_loss: 0.1943 - val_mean_squared_error: 0.0530\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1962 - mean_squared_error: 0.0615 - val_loss: 0.1929 - val_mean_squared_error: 0.0523\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2123 - mean_squared_error: 0.0690 - val_loss: 0.1921 - val_mean_squared_error: 0.0524\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2074 - mean_squared_error: 0.0696 - val_loss: 0.1895 - val_mean_squared_error: 0.0514\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2147 - mean_squared_error: 0.0689 - val_loss: 0.1912 - val_mean_squared_error: 0.0513\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2073 - mean_squared_error: 0.0654 - val_loss: 0.1950 - val_mean_squared_error: 0.0527\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2161 - mean_squared_error: 0.0697 - val_loss: 0.1911 - val_mean_squared_error: 0.0519\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2126 - mean_squared_error: 0.0684 - val_loss: 0.1889 - val_mean_squared_error: 0.0511\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2085 - mean_squared_error: 0.0654 - val_loss: 0.1912 - val_mean_squared_error: 0.0520\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2032 - mean_squared_error: 0.0629 - val_loss: 0.1901 - val_mean_squared_error: 0.0516\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2012 - mean_squared_error: 0.0611 - val_loss: 0.1896 - val_mean_squared_error: 0.0514\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2072 - mean_squared_error: 0.0658 - val_loss: 0.1921 - val_mean_squared_error: 0.0522\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1985 - mean_squared_error: 0.0608 - val_loss: 0.1919 - val_mean_squared_error: 0.0514\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2092 - mean_squared_error: 0.0669 - val_loss: 0.1898 - val_mean_squared_error: 0.0516\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2035 - mean_squared_error: 0.0651 - val_loss: 0.1882 - val_mean_squared_error: 0.0502\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2129 - mean_squared_error: 0.0687 - val_loss: 0.1854 - val_mean_squared_error: 0.0496\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2095 - mean_squared_error: 0.0659 - val_loss: 0.1906 - val_mean_squared_error: 0.0516\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2018 - mean_squared_error: 0.0649 - val_loss: 0.1949 - val_mean_squared_error: 0.0529\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2121 - mean_squared_error: 0.0691 - val_loss: 0.1923 - val_mean_squared_error: 0.0523\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2053 - mean_squared_error: 0.0644 - val_loss: 0.1905 - val_mean_squared_error: 0.0511\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1970 - mean_squared_error: 0.0631 - val_loss: 0.1885 - val_mean_squared_error: 0.0511\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1984 - mean_squared_error: 0.0607 - val_loss: 0.1909 - val_mean_squared_error: 0.0518\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2082 - mean_squared_error: 0.0666 - val_loss: 0.1932 - val_mean_squared_error: 0.0525\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2066 - mean_squared_error: 0.0660 - val_loss: 0.1928 - val_mean_squared_error: 0.0522\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2037 - mean_squared_error: 0.0647 - val_loss: 0.1932 - val_mean_squared_error: 0.0526\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2046 - mean_squared_error: 0.0656 - val_loss: 0.1945 - val_mean_squared_error: 0.0522\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2112 - mean_squared_error: 0.0700 - val_loss: 0.1953 - val_mean_squared_error: 0.0534\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2107 - mean_squared_error: 0.0668 - val_loss: 0.1969 - val_mean_squared_error: 0.0544\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2096 - mean_squared_error: 0.0666 - val_loss: 0.1882 - val_mean_squared_error: 0.0505\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2080 - mean_squared_error: 0.0656 - val_loss: 0.1890 - val_mean_squared_error: 0.0515\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2057 - mean_squared_error: 0.0656 - val_loss: 0.1977 - val_mean_squared_error: 0.0545\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2048 - mean_squared_error: 0.0657 - val_loss: 0.1951 - val_mean_squared_error: 0.0537\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2068 - mean_squared_error: 0.0659 - val_loss: 0.1956 - val_mean_squared_error: 0.0538\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2063 - mean_squared_error: 0.0675 - val_loss: 0.1933 - val_mean_squared_error: 0.0528\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2073 - mean_squared_error: 0.0658 - val_loss: 0.1887 - val_mean_squared_error: 0.0508\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2019 - mean_squared_error: 0.0638 - val_loss: 0.1892 - val_mean_squared_error: 0.0509\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2132 - mean_squared_error: 0.0734 - val_loss: 0.1986 - val_mean_squared_error: 0.0540\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2127 - mean_squared_error: 0.0691 - val_loss: 0.2020 - val_mean_squared_error: 0.0555\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2007 - mean_squared_error: 0.0625 - val_loss: 0.1904 - val_mean_squared_error: 0.0511\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2081 - mean_squared_error: 0.0680 - val_loss: 0.1909 - val_mean_squared_error: 0.0519\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2076 - mean_squared_error: 0.0658 - val_loss: 0.1934 - val_mean_squared_error: 0.0526\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2012 - mean_squared_error: 0.0617 - val_loss: 0.1964 - val_mean_squared_error: 0.0534\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2140 - mean_squared_error: 0.0690 - val_loss: 0.1919 - val_mean_squared_error: 0.0518\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2151 - mean_squared_error: 0.0692 - val_loss: 0.1887 - val_mean_squared_error: 0.0509\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2113 - mean_squared_error: 0.0662 - val_loss: 0.1864 - val_mean_squared_error: 0.0498\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2039 - mean_squared_error: 0.0638 - val_loss: 0.1920 - val_mean_squared_error: 0.0522\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2027 - mean_squared_error: 0.0659 - val_loss: 0.1934 - val_mean_squared_error: 0.0527\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2074 - mean_squared_error: 0.0664 - val_loss: 0.1916 - val_mean_squared_error: 0.0518\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2047 - mean_squared_error: 0.0635 - val_loss: 0.1894 - val_mean_squared_error: 0.0513\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2035 - mean_squared_error: 0.0653 - val_loss: 0.1914 - val_mean_squared_error: 0.0517\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2062 - mean_squared_error: 0.0658 - val_loss: 0.1920 - val_mean_squared_error: 0.0519\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2062 - mean_squared_error: 0.0666 - val_loss: 0.1901 - val_mean_squared_error: 0.0515\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2014 - mean_squared_error: 0.0640 - val_loss: 0.1911 - val_mean_squared_error: 0.0519\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2032 - mean_squared_error: 0.0650 - val_loss: 0.1910 - val_mean_squared_error: 0.0511\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2019 - mean_squared_error: 0.0647 - val_loss: 0.1894 - val_mean_squared_error: 0.0507\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2069 - mean_squared_error: 0.0658 - val_loss: 0.1910 - val_mean_squared_error: 0.0522\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2090 - mean_squared_error: 0.0686 - val_loss: 0.1937 - val_mean_squared_error: 0.0527\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2019 - mean_squared_error: 0.0618 - val_loss: 0.1955 - val_mean_squared_error: 0.0531\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2075 - mean_squared_error: 0.0677 - val_loss: 0.1925 - val_mean_squared_error: 0.0526\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2037 - mean_squared_error: 0.0643 - val_loss: 0.1866 - val_mean_squared_error: 0.0507\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2094 - mean_squared_error: 0.0694 - val_loss: 0.1905 - val_mean_squared_error: 0.0521\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2058 - mean_squared_error: 0.0661 - val_loss: 0.1955 - val_mean_squared_error: 0.0530\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2012 - mean_squared_error: 0.0623 - val_loss: 0.1926 - val_mean_squared_error: 0.0523\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2084 - mean_squared_error: 0.0677 - val_loss: 0.1924 - val_mean_squared_error: 0.0522\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2049 - mean_squared_error: 0.0652 - val_loss: 0.1954 - val_mean_squared_error: 0.0529\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2096 - mean_squared_error: 0.0677 - val_loss: 0.1905 - val_mean_squared_error: 0.0514\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2026 - mean_squared_error: 0.0652 - val_loss: 0.1894 - val_mean_squared_error: 0.0516\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2020 - mean_squared_error: 0.0638 - val_loss: 0.1945 - val_mean_squared_error: 0.0531\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1922 - mean_squared_error: 0.0578 - val_loss: 0.1910 - val_mean_squared_error: 0.0520\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2023 - mean_squared_error: 0.0640 - val_loss: 0.1857 - val_mean_squared_error: 0.0504\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2113 - mean_squared_error: 0.0716 - val_loss: 0.1881 - val_mean_squared_error: 0.0510\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2000 - mean_squared_error: 0.0632 - val_loss: 0.1945 - val_mean_squared_error: 0.0528\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2045 - mean_squared_error: 0.0663 - val_loss: 0.1936 - val_mean_squared_error: 0.0528\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2031 - mean_squared_error: 0.0647 - val_loss: 0.1927 - val_mean_squared_error: 0.0527\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2084 - mean_squared_error: 0.0688 - val_loss: 0.1911 - val_mean_squared_error: 0.0522\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2070 - mean_squared_error: 0.0655 - val_loss: 0.1961 - val_mean_squared_error: 0.0537\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2116 - mean_squared_error: 0.0699 - val_loss: 0.1951 - val_mean_squared_error: 0.0536\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2111 - mean_squared_error: 0.0683 - val_loss: 0.1926 - val_mean_squared_error: 0.0528\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2098 - mean_squared_error: 0.0664 - val_loss: 0.1962 - val_mean_squared_error: 0.0535\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2020 - mean_squared_error: 0.0651 - val_loss: 0.1981 - val_mean_squared_error: 0.0545\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2029 - mean_squared_error: 0.0647 - val_loss: 0.1971 - val_mean_squared_error: 0.0541\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2024 - mean_squared_error: 0.0639 - val_loss: 0.1987 - val_mean_squared_error: 0.0546\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2062 - mean_squared_error: 0.0674 - val_loss: 0.1950 - val_mean_squared_error: 0.0534\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2073 - mean_squared_error: 0.0667 - val_loss: 0.1917 - val_mean_squared_error: 0.0516\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2041 - mean_squared_error: 0.0639 - val_loss: 0.1939 - val_mean_squared_error: 0.0529\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1985 - mean_squared_error: 0.0610 - val_loss: 0.1914 - val_mean_squared_error: 0.0523\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2113 - mean_squared_error: 0.0678 - val_loss: 0.1920 - val_mean_squared_error: 0.0515\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2094 - mean_squared_error: 0.0692 - val_loss: 0.1925 - val_mean_squared_error: 0.0528\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2138 - mean_squared_error: 0.0703 - val_loss: 0.1948 - val_mean_squared_error: 0.0547\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2015 - mean_squared_error: 0.0646 - val_loss: 0.1894 - val_mean_squared_error: 0.0508\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2124 - mean_squared_error: 0.0686 - val_loss: 0.1841 - val_mean_squared_error: 0.0498\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2109 - mean_squared_error: 0.0675 - val_loss: 0.1938 - val_mean_squared_error: 0.0538\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2033 - mean_squared_error: 0.0634 - val_loss: 0.1986 - val_mean_squared_error: 0.0549\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2134 - mean_squared_error: 0.0679 - val_loss: 0.1935 - val_mean_squared_error: 0.0531\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2095 - mean_squared_error: 0.0693 - val_loss: 0.1919 - val_mean_squared_error: 0.0530\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2102 - mean_squared_error: 0.0674 - val_loss: 0.1898 - val_mean_squared_error: 0.0518\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2016 - mean_squared_error: 0.0638 - val_loss: 0.1870 - val_mean_squared_error: 0.0497\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2066 - mean_squared_error: 0.0677 - val_loss: 0.1858 - val_mean_squared_error: 0.0504\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2016 - mean_squared_error: 0.0629 - val_loss: 0.1927 - val_mean_squared_error: 0.0526\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2002 - mean_squared_error: 0.0629 - val_loss: 0.1980 - val_mean_squared_error: 0.0544\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2084 - mean_squared_error: 0.0659 - val_loss: 0.1932 - val_mean_squared_error: 0.0533\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1965 - mean_squared_error: 0.0618 - val_loss: 0.1924 - val_mean_squared_error: 0.0521\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2011 - mean_squared_error: 0.0640 - val_loss: 0.1944 - val_mean_squared_error: 0.0530\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2109 - mean_squared_error: 0.0695 - val_loss: 0.1885 - val_mean_squared_error: 0.0514\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2010 - mean_squared_error: 0.0635 - val_loss: 0.1892 - val_mean_squared_error: 0.0512\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2012 - mean_squared_error: 0.0639 - val_loss: 0.1898 - val_mean_squared_error: 0.0513\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2106 - mean_squared_error: 0.0693 - val_loss: 0.1952 - val_mean_squared_error: 0.0537\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2012 - mean_squared_error: 0.0628 - val_loss: 0.1971 - val_mean_squared_error: 0.0541\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2101 - mean_squared_error: 0.0679 - val_loss: 0.1882 - val_mean_squared_error: 0.0509\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2019 - mean_squared_error: 0.0646 - val_loss: 0.1875 - val_mean_squared_error: 0.0508\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1987 - mean_squared_error: 0.0636 - val_loss: 0.1925 - val_mean_squared_error: 0.0523\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2090 - mean_squared_error: 0.0670 - val_loss: 0.1967 - val_mean_squared_error: 0.0543\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2034 - mean_squared_error: 0.0638 - val_loss: 0.1930 - val_mean_squared_error: 0.0533\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1999 - mean_squared_error: 0.0625 - val_loss: 0.1875 - val_mean_squared_error: 0.0512\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2066 - mean_squared_error: 0.0666 - val_loss: 0.1892 - val_mean_squared_error: 0.0515\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2042 - mean_squared_error: 0.0659 - val_loss: 0.1936 - val_mean_squared_error: 0.0526\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2086 - mean_squared_error: 0.0663 - val_loss: 0.1925 - val_mean_squared_error: 0.0525\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1995 - mean_squared_error: 0.0633 - val_loss: 0.1901 - val_mean_squared_error: 0.0519\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2083 - mean_squared_error: 0.0686 - val_loss: 0.1925 - val_mean_squared_error: 0.0533\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2085 - mean_squared_error: 0.0670 - val_loss: 0.1916 - val_mean_squared_error: 0.0526\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2068 - mean_squared_error: 0.0654 - val_loss: 0.1920 - val_mean_squared_error: 0.0519\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2084 - mean_squared_error: 0.0670 - val_loss: 0.1933 - val_mean_squared_error: 0.0522\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2014 - mean_squared_error: 0.0637 - val_loss: 0.1967 - val_mean_squared_error: 0.0538\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2025 - mean_squared_error: 0.0637 - val_loss: 0.1936 - val_mean_squared_error: 0.0531\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2042 - mean_squared_error: 0.0669 - val_loss: 0.1895 - val_mean_squared_error: 0.0517\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2007 - mean_squared_error: 0.0619 - val_loss: 0.1877 - val_mean_squared_error: 0.0511\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2134 - mean_squared_error: 0.0710 - val_loss: 0.1955 - val_mean_squared_error: 0.0533\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1965 - mean_squared_error: 0.0605 - val_loss: 0.1927 - val_mean_squared_error: 0.0527\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1988 - mean_squared_error: 0.0612 - val_loss: 0.1904 - val_mean_squared_error: 0.0519\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2097 - mean_squared_error: 0.0679 - val_loss: 0.1908 - val_mean_squared_error: 0.0522\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2026 - mean_squared_error: 0.0635 - val_loss: 0.1934 - val_mean_squared_error: 0.0531\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1900 - mean_squared_error: 0.0595 - val_loss: 0.1921 - val_mean_squared_error: 0.0523\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1967 - mean_squared_error: 0.0608 - val_loss: 0.1915 - val_mean_squared_error: 0.0521\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2061 - mean_squared_error: 0.0655 - val_loss: 0.1924 - val_mean_squared_error: 0.0525\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2017 - mean_squared_error: 0.0645 - val_loss: 0.1956 - val_mean_squared_error: 0.0536\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2033 - mean_squared_error: 0.0643 - val_loss: 0.1898 - val_mean_squared_error: 0.0524\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2006 - mean_squared_error: 0.0645 - val_loss: 0.1909 - val_mean_squared_error: 0.0523\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2037 - mean_squared_error: 0.0646 - val_loss: 0.1944 - val_mean_squared_error: 0.0529\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2055 - mean_squared_error: 0.0646 - val_loss: 0.1945 - val_mean_squared_error: 0.0522\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2085 - mean_squared_error: 0.0671 - val_loss: 0.1945 - val_mean_squared_error: 0.0527\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2130 - mean_squared_error: 0.0699 - val_loss: 0.1929 - val_mean_squared_error: 0.0522\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2025 - mean_squared_error: 0.0632 - val_loss: 0.1942 - val_mean_squared_error: 0.0527\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2075 - mean_squared_error: 0.0677 - val_loss: 0.1954 - val_mean_squared_error: 0.0533\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2084 - mean_squared_error: 0.0668 - val_loss: 0.1952 - val_mean_squared_error: 0.0534\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1991 - mean_squared_error: 0.0612 - val_loss: 0.1898 - val_mean_squared_error: 0.0513\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2019 - mean_squared_error: 0.0635 - val_loss: 0.1862 - val_mean_squared_error: 0.0509\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2126 - mean_squared_error: 0.0698 - val_loss: 0.1921 - val_mean_squared_error: 0.0519\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1998 - mean_squared_error: 0.0627 - val_loss: 0.1953 - val_mean_squared_error: 0.0531\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1890 - mean_squared_error: 0.0581 - val_loss: 0.1930 - val_mean_squared_error: 0.0534\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2009 - mean_squared_error: 0.0641 - val_loss: 0.1873 - val_mean_squared_error: 0.0509\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2038 - mean_squared_error: 0.0649 - val_loss: 0.1905 - val_mean_squared_error: 0.0514\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2011 - mean_squared_error: 0.0636 - val_loss: 0.1904 - val_mean_squared_error: 0.0518\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1902 - mean_squared_error: 0.0581 - val_loss: 0.1904 - val_mean_squared_error: 0.0517\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2077 - mean_squared_error: 0.0661 - val_loss: 0.1898 - val_mean_squared_error: 0.0513\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2004 - mean_squared_error: 0.0625 - val_loss: 0.1924 - val_mean_squared_error: 0.0523\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2035 - mean_squared_error: 0.0651 - val_loss: 0.1911 - val_mean_squared_error: 0.0524\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1983 - mean_squared_error: 0.0622 - val_loss: 0.1928 - val_mean_squared_error: 0.0525\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2069 - mean_squared_error: 0.0650 - val_loss: 0.1931 - val_mean_squared_error: 0.0527\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2014 - mean_squared_error: 0.0638 - val_loss: 0.1911 - val_mean_squared_error: 0.0526\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1922 - mean_squared_error: 0.0599 - val_loss: 0.1914 - val_mean_squared_error: 0.0516\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2088 - mean_squared_error: 0.0667 - val_loss: 0.1912 - val_mean_squared_error: 0.0521\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1982 - mean_squared_error: 0.0609 - val_loss: 0.1947 - val_mean_squared_error: 0.0528\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2039 - mean_squared_error: 0.0652 - val_loss: 0.1979 - val_mean_squared_error: 0.0543\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2035 - mean_squared_error: 0.0648 - val_loss: 0.1935 - val_mean_squared_error: 0.0531\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2076 - mean_squared_error: 0.0691 - val_loss: 0.1918 - val_mean_squared_error: 0.0521\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2125 - mean_squared_error: 0.0696 - val_loss: 0.1875 - val_mean_squared_error: 0.0510\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2022 - mean_squared_error: 0.0639 - val_loss: 0.1885 - val_mean_squared_error: 0.0515\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2061 - mean_squared_error: 0.0634 - val_loss: 0.1878 - val_mean_squared_error: 0.0510\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2095 - mean_squared_error: 0.0676 - val_loss: 0.1940 - val_mean_squared_error: 0.0523\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2187 - mean_squared_error: 0.0713 - val_loss: 0.1954 - val_mean_squared_error: 0.0532\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2018 - mean_squared_error: 0.0628 - val_loss: 0.1983 - val_mean_squared_error: 0.0550\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2076 - mean_squared_error: 0.0663 - val_loss: 0.1958 - val_mean_squared_error: 0.0544\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1994 - mean_squared_error: 0.0616 - val_loss: 0.1860 - val_mean_squared_error: 0.0510\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2032 - mean_squared_error: 0.0648 - val_loss: 0.1845 - val_mean_squared_error: 0.0499\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1964 - mean_squared_error: 0.0632 - val_loss: 0.1899 - val_mean_squared_error: 0.0513\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1980 - mean_squared_error: 0.0633 - val_loss: 0.1930 - val_mean_squared_error: 0.0523\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1982 - mean_squared_error: 0.0606 - val_loss: 0.1975 - val_mean_squared_error: 0.0542\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2038 - mean_squared_error: 0.0644 - val_loss: 0.1946 - val_mean_squared_error: 0.0529\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2035 - mean_squared_error: 0.0643 - val_loss: 0.1869 - val_mean_squared_error: 0.0511\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2074 - mean_squared_error: 0.0656 - val_loss: 0.1951 - val_mean_squared_error: 0.0537\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2043 - mean_squared_error: 0.0665 - val_loss: 0.1961 - val_mean_squared_error: 0.0544\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2076 - mean_squared_error: 0.0671 - val_loss: 0.1926 - val_mean_squared_error: 0.0527\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1946 - mean_squared_error: 0.0592 - val_loss: 0.1890 - val_mean_squared_error: 0.0513\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2014 - mean_squared_error: 0.0624 - val_loss: 0.1852 - val_mean_squared_error: 0.0500\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2038 - mean_squared_error: 0.0650 - val_loss: 0.1964 - val_mean_squared_error: 0.0535\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2029 - mean_squared_error: 0.0662 - val_loss: 0.1953 - val_mean_squared_error: 0.0541\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2191 - mean_squared_error: 0.0698 - val_loss: 0.1972 - val_mean_squared_error: 0.0550\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2024 - mean_squared_error: 0.0635 - val_loss: 0.1979 - val_mean_squared_error: 0.0546\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2001 - mean_squared_error: 0.0616 - val_loss: 0.1955 - val_mean_squared_error: 0.0533\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1994 - mean_squared_error: 0.0631 - val_loss: 0.1936 - val_mean_squared_error: 0.0530\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2093 - mean_squared_error: 0.0677 - val_loss: 0.1896 - val_mean_squared_error: 0.0520\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2063 - mean_squared_error: 0.0673 - val_loss: 0.1886 - val_mean_squared_error: 0.0515\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1952 - mean_squared_error: 0.0612 - val_loss: 0.1913 - val_mean_squared_error: 0.0519\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2072 - mean_squared_error: 0.0679 - val_loss: 0.1947 - val_mean_squared_error: 0.0532\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1977 - mean_squared_error: 0.0620 - val_loss: 0.1942 - val_mean_squared_error: 0.0528\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1924 - mean_squared_error: 0.0602 - val_loss: 0.1937 - val_mean_squared_error: 0.0526\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2053 - mean_squared_error: 0.0664 - val_loss: 0.1938 - val_mean_squared_error: 0.0530\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2025 - mean_squared_error: 0.0673 - val_loss: 0.1893 - val_mean_squared_error: 0.0514\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2059 - mean_squared_error: 0.0657 - val_loss: 0.1911 - val_mean_squared_error: 0.0514\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2022 - mean_squared_error: 0.0629 - val_loss: 0.1964 - val_mean_squared_error: 0.0533\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2031 - mean_squared_error: 0.0646 - val_loss: 0.1943 - val_mean_squared_error: 0.0529\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2000 - mean_squared_error: 0.0642 - val_loss: 0.1933 - val_mean_squared_error: 0.0527\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1998 - mean_squared_error: 0.0641 - val_loss: 0.1863 - val_mean_squared_error: 0.0501\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2073 - mean_squared_error: 0.0685 - val_loss: 0.1915 - val_mean_squared_error: 0.0516\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2059 - mean_squared_error: 0.0678 - val_loss: 0.1914 - val_mean_squared_error: 0.0522\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1971 - mean_squared_error: 0.0607 - val_loss: 0.1894 - val_mean_squared_error: 0.0512\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1974 - mean_squared_error: 0.0625 - val_loss: 0.1873 - val_mean_squared_error: 0.0505\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2138 - mean_squared_error: 0.0706 - val_loss: 0.1908 - val_mean_squared_error: 0.0519\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2041 - mean_squared_error: 0.0656 - val_loss: 0.1946 - val_mean_squared_error: 0.0532\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2055 - mean_squared_error: 0.0644 - val_loss: 0.1973 - val_mean_squared_error: 0.0541\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2063 - mean_squared_error: 0.0658 - val_loss: 0.1886 - val_mean_squared_error: 0.0510\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1946 - mean_squared_error: 0.0591 - val_loss: 0.1922 - val_mean_squared_error: 0.0517\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2037 - mean_squared_error: 0.0665 - val_loss: 0.1945 - val_mean_squared_error: 0.0528\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2087 - mean_squared_error: 0.0675 - val_loss: 0.1976 - val_mean_squared_error: 0.0537\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2066 - mean_squared_error: 0.0648 - val_loss: 0.1956 - val_mean_squared_error: 0.0529\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1932 - mean_squared_error: 0.0588 - val_loss: 0.1902 - val_mean_squared_error: 0.0512\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1993 - mean_squared_error: 0.0625 - val_loss: 0.1931 - val_mean_squared_error: 0.0524\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2004 - mean_squared_error: 0.0647 - val_loss: 0.1940 - val_mean_squared_error: 0.0529\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2005 - mean_squared_error: 0.0614 - val_loss: 0.1904 - val_mean_squared_error: 0.0510\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1984 - mean_squared_error: 0.0653 - val_loss: 0.1914 - val_mean_squared_error: 0.0515\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2031 - mean_squared_error: 0.0657 - val_loss: 0.1908 - val_mean_squared_error: 0.0514\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2119 - mean_squared_error: 0.0682 - val_loss: 0.1911 - val_mean_squared_error: 0.0521\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1980 - mean_squared_error: 0.0611 - val_loss: 0.1886 - val_mean_squared_error: 0.0512\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2088 - mean_squared_error: 0.0660 - val_loss: 0.1902 - val_mean_squared_error: 0.0513\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2013 - mean_squared_error: 0.0642 - val_loss: 0.1921 - val_mean_squared_error: 0.0522\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1980 - mean_squared_error: 0.0618 - val_loss: 0.1895 - val_mean_squared_error: 0.0510\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1945 - mean_squared_error: 0.0615 - val_loss: 0.1897 - val_mean_squared_error: 0.0505\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1954 - mean_squared_error: 0.0594 - val_loss: 0.1980 - val_mean_squared_error: 0.0539\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1998 - mean_squared_error: 0.0641 - val_loss: 0.1886 - val_mean_squared_error: 0.0510\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1975 - mean_squared_error: 0.0619 - val_loss: 0.1865 - val_mean_squared_error: 0.0506\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.2027 - mean_squared_error: 0.0650 - val_loss: 0.1862 - val_mean_squared_error: 0.0504\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1995 - mean_squared_error: 0.0615 - val_loss: 0.1924 - val_mean_squared_error: 0.0520\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1947 - mean_squared_error: 0.0615 - val_loss: 0.1902 - val_mean_squared_error: 0.0515\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1965 - mean_squared_error: 0.0633 - val_loss: 0.1875 - val_mean_squared_error: 0.0506\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1826 - mean_squared_error: 0.0533 - val_loss: 0.1877 - val_mean_squared_error: 0.0506\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2091 - mean_squared_error: 0.0678 - val_loss: 0.1874 - val_mean_squared_error: 0.0504\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1953 - mean_squared_error: 0.0587 - val_loss: 0.1872 - val_mean_squared_error: 0.0506\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1933 - mean_squared_error: 0.0598 - val_loss: 0.1880 - val_mean_squared_error: 0.0504\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1871 - mean_squared_error: 0.0564 - val_loss: 0.1933 - val_mean_squared_error: 0.0520\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1942 - mean_squared_error: 0.0605 - val_loss: 0.1889 - val_mean_squared_error: 0.0505\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1923 - mean_squared_error: 0.0595 - val_loss: 0.1863 - val_mean_squared_error: 0.0499\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1867 - mean_squared_error: 0.0586 - val_loss: 0.1864 - val_mean_squared_error: 0.0496\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1915 - mean_squared_error: 0.0577 - val_loss: 0.1820 - val_mean_squared_error: 0.0486\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1854 - mean_squared_error: 0.0548 - val_loss: 0.1836 - val_mean_squared_error: 0.0491\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1916 - mean_squared_error: 0.0614 - val_loss: 0.1850 - val_mean_squared_error: 0.0492\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2011 - mean_squared_error: 0.0646 - val_loss: 0.1861 - val_mean_squared_error: 0.0500\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1951 - mean_squared_error: 0.0614 - val_loss: 0.1901 - val_mean_squared_error: 0.0512\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1991 - mean_squared_error: 0.0641 - val_loss: 0.1919 - val_mean_squared_error: 0.0520\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1931 - mean_squared_error: 0.0607 - val_loss: 0.1883 - val_mean_squared_error: 0.0507\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1805 - mean_squared_error: 0.0549 - val_loss: 0.1878 - val_mean_squared_error: 0.0502\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1843 - mean_squared_error: 0.0543 - val_loss: 0.1799 - val_mean_squared_error: 0.0482\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1997 - mean_squared_error: 0.0623 - val_loss: 0.1844 - val_mean_squared_error: 0.0492\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2011 - mean_squared_error: 0.0621 - val_loss: 0.1914 - val_mean_squared_error: 0.0515\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1950 - mean_squared_error: 0.0612 - val_loss: 0.1903 - val_mean_squared_error: 0.0517\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1878 - mean_squared_error: 0.0563 - val_loss: 0.1933 - val_mean_squared_error: 0.0524\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1948 - mean_squared_error: 0.0610 - val_loss: 0.1915 - val_mean_squared_error: 0.0518\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1977 - mean_squared_error: 0.0613 - val_loss: 0.1910 - val_mean_squared_error: 0.0512\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1970 - mean_squared_error: 0.0617 - val_loss: 0.1889 - val_mean_squared_error: 0.0508\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2024 - mean_squared_error: 0.0625 - val_loss: 0.1894 - val_mean_squared_error: 0.0508\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1959 - mean_squared_error: 0.0612 - val_loss: 0.1906 - val_mean_squared_error: 0.0517\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1963 - mean_squared_error: 0.0618 - val_loss: 0.1893 - val_mean_squared_error: 0.0512\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1818 - mean_squared_error: 0.0545 - val_loss: 0.1864 - val_mean_squared_error: 0.0499\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1918 - mean_squared_error: 0.0595 - val_loss: 0.1827 - val_mean_squared_error: 0.0487\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1882 - mean_squared_error: 0.0579 - val_loss: 0.1863 - val_mean_squared_error: 0.0501\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1951 - mean_squared_error: 0.0599 - val_loss: 0.1944 - val_mean_squared_error: 0.0526\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2044 - mean_squared_error: 0.0648 - val_loss: 0.1955 - val_mean_squared_error: 0.0527\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1963 - mean_squared_error: 0.0627 - val_loss: 0.1859 - val_mean_squared_error: 0.0510\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1951 - mean_squared_error: 0.0608 - val_loss: 0.1874 - val_mean_squared_error: 0.0501\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1957 - mean_squared_error: 0.0599 - val_loss: 0.1834 - val_mean_squared_error: 0.0493\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1890 - mean_squared_error: 0.0595 - val_loss: 0.1806 - val_mean_squared_error: 0.0487\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1838 - mean_squared_error: 0.0563 - val_loss: 0.1860 - val_mean_squared_error: 0.0495\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1845 - mean_squared_error: 0.0545 - val_loss: 0.1901 - val_mean_squared_error: 0.0506\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1875 - mean_squared_error: 0.0573 - val_loss: 0.1828 - val_mean_squared_error: 0.0496\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1988 - mean_squared_error: 0.0628 - val_loss: 0.1824 - val_mean_squared_error: 0.0494\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1999 - mean_squared_error: 0.0625 - val_loss: 0.1938 - val_mean_squared_error: 0.0515\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1948 - mean_squared_error: 0.0593 - val_loss: 0.1906 - val_mean_squared_error: 0.0513\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1985 - mean_squared_error: 0.0626 - val_loss: 0.1841 - val_mean_squared_error: 0.0503\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1956 - mean_squared_error: 0.0617 - val_loss: 0.1832 - val_mean_squared_error: 0.0496\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1908 - mean_squared_error: 0.0578 - val_loss: 0.1856 - val_mean_squared_error: 0.0496\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1878 - mean_squared_error: 0.0559 - val_loss: 0.1889 - val_mean_squared_error: 0.0504\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1921 - mean_squared_error: 0.0581 - val_loss: 0.1922 - val_mean_squared_error: 0.0514\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1958 - mean_squared_error: 0.0593 - val_loss: 0.1868 - val_mean_squared_error: 0.0506\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1853 - mean_squared_error: 0.0551 - val_loss: 0.1919 - val_mean_squared_error: 0.0518\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1806 - mean_squared_error: 0.0549 - val_loss: 0.1885 - val_mean_squared_error: 0.0510\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1887 - mean_squared_error: 0.0609 - val_loss: 0.1835 - val_mean_squared_error: 0.0499\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1996 - mean_squared_error: 0.0622 - val_loss: 0.1901 - val_mean_squared_error: 0.0517\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1793 - mean_squared_error: 0.0525 - val_loss: 0.1879 - val_mean_squared_error: 0.0513\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1884 - mean_squared_error: 0.0585 - val_loss: 0.1855 - val_mean_squared_error: 0.0505\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1936 - mean_squared_error: 0.0598 - val_loss: 0.1888 - val_mean_squared_error: 0.0513\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1896 - mean_squared_error: 0.0583 - val_loss: 0.1916 - val_mean_squared_error: 0.0518\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1944 - mean_squared_error: 0.0593 - val_loss: 0.1896 - val_mean_squared_error: 0.0514\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1905 - mean_squared_error: 0.0589 - val_loss: 0.1835 - val_mean_squared_error: 0.0492\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2028 - mean_squared_error: 0.0635 - val_loss: 0.1904 - val_mean_squared_error: 0.0511\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1930 - mean_squared_error: 0.0599 - val_loss: 0.1842 - val_mean_squared_error: 0.0503\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2042 - mean_squared_error: 0.0652 - val_loss: 0.1860 - val_mean_squared_error: 0.0510\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1915 - mean_squared_error: 0.0567 - val_loss: 0.1897 - val_mean_squared_error: 0.0506\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1945 - mean_squared_error: 0.0587 - val_loss: 0.1849 - val_mean_squared_error: 0.0493\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2009 - mean_squared_error: 0.0638 - val_loss: 0.1786 - val_mean_squared_error: 0.0483\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1935 - mean_squared_error: 0.0599 - val_loss: 0.1798 - val_mean_squared_error: 0.0485\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1908 - mean_squared_error: 0.0593 - val_loss: 0.1858 - val_mean_squared_error: 0.0491\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1945 - mean_squared_error: 0.0618 - val_loss: 0.1887 - val_mean_squared_error: 0.0507\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1891 - mean_squared_error: 0.0589 - val_loss: 0.1841 - val_mean_squared_error: 0.0498\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1943 - mean_squared_error: 0.0600 - val_loss: 0.1825 - val_mean_squared_error: 0.0487\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1991 - mean_squared_error: 0.0645 - val_loss: 0.1893 - val_mean_squared_error: 0.0509\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1887 - mean_squared_error: 0.0584 - val_loss: 0.1845 - val_mean_squared_error: 0.0506\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1911 - mean_squared_error: 0.0594 - val_loss: 0.1849 - val_mean_squared_error: 0.0501\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1812 - mean_squared_error: 0.0530 - val_loss: 0.1865 - val_mean_squared_error: 0.0500\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1856 - mean_squared_error: 0.0550 - val_loss: 0.1856 - val_mean_squared_error: 0.0502\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1910 - mean_squared_error: 0.0587 - val_loss: 0.1805 - val_mean_squared_error: 0.0483\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1865 - mean_squared_error: 0.0586 - val_loss: 0.1775 - val_mean_squared_error: 0.0472\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1976 - mean_squared_error: 0.0626 - val_loss: 0.1796 - val_mean_squared_error: 0.0480\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1947 - mean_squared_error: 0.0631 - val_loss: 0.1822 - val_mean_squared_error: 0.0490\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1942 - mean_squared_error: 0.0607 - val_loss: 0.1840 - val_mean_squared_error: 0.0495\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1947 - mean_squared_error: 0.0602 - val_loss: 0.1834 - val_mean_squared_error: 0.0488\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1880 - mean_squared_error: 0.0568 - val_loss: 0.1812 - val_mean_squared_error: 0.0483\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1809 - mean_squared_error: 0.0528 - val_loss: 0.1813 - val_mean_squared_error: 0.0487\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1884 - mean_squared_error: 0.0588 - val_loss: 0.1810 - val_mean_squared_error: 0.0488\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1819 - mean_squared_error: 0.0539 - val_loss: 0.1882 - val_mean_squared_error: 0.0504\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1985 - mean_squared_error: 0.0631 - val_loss: 0.1853 - val_mean_squared_error: 0.0502\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1903 - mean_squared_error: 0.0589 - val_loss: 0.1862 - val_mean_squared_error: 0.0509\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1919 - mean_squared_error: 0.0588 - val_loss: 0.1941 - val_mean_squared_error: 0.0536\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1925 - mean_squared_error: 0.0586 - val_loss: 0.1876 - val_mean_squared_error: 0.0508\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1950 - mean_squared_error: 0.0612 - val_loss: 0.1839 - val_mean_squared_error: 0.0496\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1793 - mean_squared_error: 0.0530 - val_loss: 0.1872 - val_mean_squared_error: 0.0502\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1895 - mean_squared_error: 0.0592 - val_loss: 0.1810 - val_mean_squared_error: 0.0489\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1924 - mean_squared_error: 0.0592 - val_loss: 0.1831 - val_mean_squared_error: 0.0494\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1865 - mean_squared_error: 0.0570 - val_loss: 0.1885 - val_mean_squared_error: 0.0508\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1878 - mean_squared_error: 0.0571 - val_loss: 0.1871 - val_mean_squared_error: 0.0505\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1936 - mean_squared_error: 0.0599 - val_loss: 0.1838 - val_mean_squared_error: 0.0499\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1978 - mean_squared_error: 0.0637 - val_loss: 0.1846 - val_mean_squared_error: 0.0498\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1942 - mean_squared_error: 0.0591 - val_loss: 0.1834 - val_mean_squared_error: 0.0493\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1975 - mean_squared_error: 0.0613 - val_loss: 0.1845 - val_mean_squared_error: 0.0499\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1998 - mean_squared_error: 0.0659 - val_loss: 0.1864 - val_mean_squared_error: 0.0505\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1870 - mean_squared_error: 0.0584 - val_loss: 0.1862 - val_mean_squared_error: 0.0503\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1923 - mean_squared_error: 0.0602 - val_loss: 0.1840 - val_mean_squared_error: 0.0492\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1814 - mean_squared_error: 0.0536 - val_loss: 0.1836 - val_mean_squared_error: 0.0494\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1912 - mean_squared_error: 0.0579 - val_loss: 0.1852 - val_mean_squared_error: 0.0499\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1928 - mean_squared_error: 0.0579 - val_loss: 0.1844 - val_mean_squared_error: 0.0496\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1912 - mean_squared_error: 0.0580 - val_loss: 0.1837 - val_mean_squared_error: 0.0495\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1910 - mean_squared_error: 0.0595 - val_loss: 0.1814 - val_mean_squared_error: 0.0482\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1906 - mean_squared_error: 0.0570 - val_loss: 0.1870 - val_mean_squared_error: 0.0494\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1932 - mean_squared_error: 0.0589 - val_loss: 0.1843 - val_mean_squared_error: 0.0495\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1953 - mean_squared_error: 0.0631 - val_loss: 0.1838 - val_mean_squared_error: 0.0493\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1869 - mean_squared_error: 0.0569 - val_loss: 0.1857 - val_mean_squared_error: 0.0502\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1927 - mean_squared_error: 0.0609 - val_loss: 0.1851 - val_mean_squared_error: 0.0499\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1847 - mean_squared_error: 0.0557 - val_loss: 0.1811 - val_mean_squared_error: 0.0491\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1957 - mean_squared_error: 0.0639 - val_loss: 0.1815 - val_mean_squared_error: 0.0480\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1873 - mean_squared_error: 0.0577 - val_loss: 0.1814 - val_mean_squared_error: 0.0484\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1940 - mean_squared_error: 0.0608 - val_loss: 0.1838 - val_mean_squared_error: 0.0497\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1835 - mean_squared_error: 0.0562 - val_loss: 0.1777 - val_mean_squared_error: 0.0471\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1839 - mean_squared_error: 0.0540 - val_loss: 0.1789 - val_mean_squared_error: 0.0479\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1990 - mean_squared_error: 0.0639 - val_loss: 0.1858 - val_mean_squared_error: 0.0507\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1987 - mean_squared_error: 0.0635 - val_loss: 0.1865 - val_mean_squared_error: 0.0507\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1951 - mean_squared_error: 0.0618 - val_loss: 0.1861 - val_mean_squared_error: 0.0503\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1902 - mean_squared_error: 0.0589 - val_loss: 0.1840 - val_mean_squared_error: 0.0495\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1911 - mean_squared_error: 0.0591 - val_loss: 0.1837 - val_mean_squared_error: 0.0497\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1914 - mean_squared_error: 0.0610 - val_loss: 0.1794 - val_mean_squared_error: 0.0481\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1793 - mean_squared_error: 0.0550 - val_loss: 0.1824 - val_mean_squared_error: 0.0488\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1950 - mean_squared_error: 0.0607 - val_loss: 0.1820 - val_mean_squared_error: 0.0487\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1935 - mean_squared_error: 0.0607 - val_loss: 0.1839 - val_mean_squared_error: 0.0494\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1841 - mean_squared_error: 0.0552 - val_loss: 0.1840 - val_mean_squared_error: 0.0498\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1934 - mean_squared_error: 0.0625 - val_loss: 0.1829 - val_mean_squared_error: 0.0492\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1912 - mean_squared_error: 0.0589 - val_loss: 0.1800 - val_mean_squared_error: 0.0478\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1925 - mean_squared_error: 0.0592 - val_loss: 0.1822 - val_mean_squared_error: 0.0482\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1799 - mean_squared_error: 0.0539 - val_loss: 0.1873 - val_mean_squared_error: 0.0504\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1853 - mean_squared_error: 0.0565 - val_loss: 0.1867 - val_mean_squared_error: 0.0504\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1893 - mean_squared_error: 0.0574 - val_loss: 0.1867 - val_mean_squared_error: 0.0505\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1906 - mean_squared_error: 0.0597 - val_loss: 0.1876 - val_mean_squared_error: 0.0510\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1857 - mean_squared_error: 0.0559 - val_loss: 0.1886 - val_mean_squared_error: 0.0511\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1858 - mean_squared_error: 0.0568 - val_loss: 0.1834 - val_mean_squared_error: 0.0498\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1972 - mean_squared_error: 0.0629 - val_loss: 0.1799 - val_mean_squared_error: 0.0487\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1880 - mean_squared_error: 0.0589 - val_loss: 0.1836 - val_mean_squared_error: 0.0498\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1831 - mean_squared_error: 0.0548 - val_loss: 0.1859 - val_mean_squared_error: 0.0502\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1926 - mean_squared_error: 0.0604 - val_loss: 0.1797 - val_mean_squared_error: 0.0487\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1985 - mean_squared_error: 0.0647 - val_loss: 0.1798 - val_mean_squared_error: 0.0483\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1919 - mean_squared_error: 0.0589 - val_loss: 0.1819 - val_mean_squared_error: 0.0495\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1846 - mean_squared_error: 0.0581 - val_loss: 0.1805 - val_mean_squared_error: 0.0488\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1875 - mean_squared_error: 0.0597 - val_loss: 0.1804 - val_mean_squared_error: 0.0483\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1913 - mean_squared_error: 0.0601 - val_loss: 0.1826 - val_mean_squared_error: 0.0492\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1886 - mean_squared_error: 0.0613 - val_loss: 0.1844 - val_mean_squared_error: 0.0502\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1941 - mean_squared_error: 0.0627 - val_loss: 0.1890 - val_mean_squared_error: 0.0513\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1798 - mean_squared_error: 0.0546 - val_loss: 0.1861 - val_mean_squared_error: 0.0505\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1850 - mean_squared_error: 0.0564 - val_loss: 0.1811 - val_mean_squared_error: 0.0482\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2038 - mean_squared_error: 0.0649 - val_loss: 0.1822 - val_mean_squared_error: 0.0495\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1917 - mean_squared_error: 0.0590 - val_loss: 0.1828 - val_mean_squared_error: 0.0500\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1977 - mean_squared_error: 0.0604 - val_loss: 0.1842 - val_mean_squared_error: 0.0500\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1860 - mean_squared_error: 0.0563 - val_loss: 0.1829 - val_mean_squared_error: 0.0495\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1879 - mean_squared_error: 0.0579 - val_loss: 0.1782 - val_mean_squared_error: 0.0479\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1909 - mean_squared_error: 0.0607 - val_loss: 0.1854 - val_mean_squared_error: 0.0502\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1781 - mean_squared_error: 0.0516 - val_loss: 0.1875 - val_mean_squared_error: 0.0511\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1841 - mean_squared_error: 0.0580 - val_loss: 0.1846 - val_mean_squared_error: 0.0501\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1865 - mean_squared_error: 0.0577 - val_loss: 0.1844 - val_mean_squared_error: 0.0501\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1886 - mean_squared_error: 0.0584 - val_loss: 0.1846 - val_mean_squared_error: 0.0498\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1919 - mean_squared_error: 0.0594 - val_loss: 0.1845 - val_mean_squared_error: 0.0499\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1938 - mean_squared_error: 0.0605 - val_loss: 0.1857 - val_mean_squared_error: 0.0499\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1992 - mean_squared_error: 0.0628 - val_loss: 0.1846 - val_mean_squared_error: 0.0498\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1950 - mean_squared_error: 0.0632 - val_loss: 0.1834 - val_mean_squared_error: 0.0498\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1861 - mean_squared_error: 0.0562 - val_loss: 0.1816 - val_mean_squared_error: 0.0487\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1874 - mean_squared_error: 0.0579 - val_loss: 0.1807 - val_mean_squared_error: 0.0484\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1868 - mean_squared_error: 0.0563 - val_loss: 0.1817 - val_mean_squared_error: 0.0484\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1900 - mean_squared_error: 0.0576 - val_loss: 0.1844 - val_mean_squared_error: 0.0489\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1933 - mean_squared_error: 0.0608 - val_loss: 0.1823 - val_mean_squared_error: 0.0485\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1877 - mean_squared_error: 0.0589 - val_loss: 0.1827 - val_mean_squared_error: 0.0492\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1885 - mean_squared_error: 0.0596 - val_loss: 0.1831 - val_mean_squared_error: 0.0493\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1829 - mean_squared_error: 0.0539 - val_loss: 0.1874 - val_mean_squared_error: 0.0504\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1990 - mean_squared_error: 0.0629 - val_loss: 0.1843 - val_mean_squared_error: 0.0505\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1924 - mean_squared_error: 0.0608 - val_loss: 0.1856 - val_mean_squared_error: 0.0511\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1932 - mean_squared_error: 0.0608 - val_loss: 0.1905 - val_mean_squared_error: 0.0520\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1867 - mean_squared_error: 0.0585 - val_loss: 0.1884 - val_mean_squared_error: 0.0508\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1805 - mean_squared_error: 0.0536 - val_loss: 0.1822 - val_mean_squared_error: 0.0489\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1887 - mean_squared_error: 0.0583 - val_loss: 0.1830 - val_mean_squared_error: 0.0485\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1819 - mean_squared_error: 0.0556 - val_loss: 0.1858 - val_mean_squared_error: 0.0495\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2025 - mean_squared_error: 0.0667 - val_loss: 0.1843 - val_mean_squared_error: 0.0488\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1767 - mean_squared_error: 0.0526 - val_loss: 0.1854 - val_mean_squared_error: 0.0494\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1860 - mean_squared_error: 0.0563 - val_loss: 0.1862 - val_mean_squared_error: 0.0498\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1811 - mean_squared_error: 0.0551 - val_loss: 0.1861 - val_mean_squared_error: 0.0501\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1783 - mean_squared_error: 0.0549 - val_loss: 0.1840 - val_mean_squared_error: 0.0493\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1831 - mean_squared_error: 0.0553 - val_loss: 0.1863 - val_mean_squared_error: 0.0499\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1824 - mean_squared_error: 0.0559 - val_loss: 0.1886 - val_mean_squared_error: 0.0503\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1801 - mean_squared_error: 0.0547 - val_loss: 0.1819 - val_mean_squared_error: 0.0491\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1960 - mean_squared_error: 0.0613 - val_loss: 0.1827 - val_mean_squared_error: 0.0494\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1925 - mean_squared_error: 0.0600 - val_loss: 0.1913 - val_mean_squared_error: 0.0518\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1870 - mean_squared_error: 0.0592 - val_loss: 0.1907 - val_mean_squared_error: 0.0516\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1802 - mean_squared_error: 0.0566 - val_loss: 0.1853 - val_mean_squared_error: 0.0509\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1870 - mean_squared_error: 0.0564 - val_loss: 0.1842 - val_mean_squared_error: 0.0499\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1843 - mean_squared_error: 0.0573 - val_loss: 0.1889 - val_mean_squared_error: 0.0510\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1988 - mean_squared_error: 0.0638 - val_loss: 0.1916 - val_mean_squared_error: 0.0516\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1869 - mean_squared_error: 0.0579 - val_loss: 0.1862 - val_mean_squared_error: 0.0499\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1826 - mean_squared_error: 0.0570 - val_loss: 0.1836 - val_mean_squared_error: 0.0492\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1862 - mean_squared_error: 0.0559 - val_loss: 0.1834 - val_mean_squared_error: 0.0493\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1982 - mean_squared_error: 0.0625 - val_loss: 0.1832 - val_mean_squared_error: 0.0499\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1884 - mean_squared_error: 0.0573 - val_loss: 0.1908 - val_mean_squared_error: 0.0523\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1997 - mean_squared_error: 0.0628 - val_loss: 0.1927 - val_mean_squared_error: 0.0527\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1784 - mean_squared_error: 0.0528 - val_loss: 0.1886 - val_mean_squared_error: 0.0516\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1846 - mean_squared_error: 0.0565 - val_loss: 0.1860 - val_mean_squared_error: 0.0511\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1769 - mean_squared_error: 0.0522 - val_loss: 0.1840 - val_mean_squared_error: 0.0499\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1865 - mean_squared_error: 0.0600 - val_loss: 0.1885 - val_mean_squared_error: 0.0510\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1891 - mean_squared_error: 0.0585 - val_loss: 0.1853 - val_mean_squared_error: 0.0506\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1858 - mean_squared_error: 0.0569 - val_loss: 0.1853 - val_mean_squared_error: 0.0507\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1936 - mean_squared_error: 0.0629 - val_loss: 0.1871 - val_mean_squared_error: 0.0510\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1723 - mean_squared_error: 0.0512 - val_loss: 0.1850 - val_mean_squared_error: 0.0503\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1820 - mean_squared_error: 0.0543 - val_loss: 0.1812 - val_mean_squared_error: 0.0486\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1859 - mean_squared_error: 0.0564 - val_loss: 0.1870 - val_mean_squared_error: 0.0511\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1892 - mean_squared_error: 0.0595 - val_loss: 0.1902 - val_mean_squared_error: 0.0519\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1808 - mean_squared_error: 0.0560 - val_loss: 0.1859 - val_mean_squared_error: 0.0505\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1822 - mean_squared_error: 0.0564 - val_loss: 0.1842 - val_mean_squared_error: 0.0497\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1872 - mean_squared_error: 0.0575 - val_loss: 0.1818 - val_mean_squared_error: 0.0488\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1879 - mean_squared_error: 0.0591 - val_loss: 0.1795 - val_mean_squared_error: 0.0477\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1801 - mean_squared_error: 0.0560 - val_loss: 0.1806 - val_mean_squared_error: 0.0480\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1874 - mean_squared_error: 0.0574 - val_loss: 0.1890 - val_mean_squared_error: 0.0509\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1909 - mean_squared_error: 0.0595 - val_loss: 0.1851 - val_mean_squared_error: 0.0497\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1880 - mean_squared_error: 0.0578 - val_loss: 0.1851 - val_mean_squared_error: 0.0497\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1804 - mean_squared_error: 0.0572 - val_loss: 0.1891 - val_mean_squared_error: 0.0510\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2005 - mean_squared_error: 0.0652 - val_loss: 0.1909 - val_mean_squared_error: 0.0518\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1897 - mean_squared_error: 0.0599 - val_loss: 0.1900 - val_mean_squared_error: 0.0520\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1912 - mean_squared_error: 0.0597 - val_loss: 0.1847 - val_mean_squared_error: 0.0505\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1836 - mean_squared_error: 0.0556 - val_loss: 0.1858 - val_mean_squared_error: 0.0507\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1923 - mean_squared_error: 0.0584 - val_loss: 0.1853 - val_mean_squared_error: 0.0502\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1732 - mean_squared_error: 0.0510 - val_loss: 0.1852 - val_mean_squared_error: 0.0495\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1813 - mean_squared_error: 0.0545 - val_loss: 0.1866 - val_mean_squared_error: 0.0501\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1896 - mean_squared_error: 0.0581 - val_loss: 0.1837 - val_mean_squared_error: 0.0496\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1894 - mean_squared_error: 0.0581 - val_loss: 0.1833 - val_mean_squared_error: 0.0498\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1838 - mean_squared_error: 0.0565 - val_loss: 0.1865 - val_mean_squared_error: 0.0508\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1848 - mean_squared_error: 0.0568 - val_loss: 0.1888 - val_mean_squared_error: 0.0513\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1936 - mean_squared_error: 0.0616 - val_loss: 0.1897 - val_mean_squared_error: 0.0516\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1835 - mean_squared_error: 0.0571 - val_loss: 0.1898 - val_mean_squared_error: 0.0515\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1925 - mean_squared_error: 0.0612 - val_loss: 0.1859 - val_mean_squared_error: 0.0503\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1747 - mean_squared_error: 0.0525 - val_loss: 0.1852 - val_mean_squared_error: 0.0501\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1827 - mean_squared_error: 0.0538 - val_loss: 0.1879 - val_mean_squared_error: 0.0513\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1797 - mean_squared_error: 0.0548 - val_loss: 0.1881 - val_mean_squared_error: 0.0514\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1909 - mean_squared_error: 0.0618 - val_loss: 0.1892 - val_mean_squared_error: 0.0514\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1918 - mean_squared_error: 0.0593 - val_loss: 0.1882 - val_mean_squared_error: 0.0508\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1893 - mean_squared_error: 0.0575 - val_loss: 0.1842 - val_mean_squared_error: 0.0502\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1838 - mean_squared_error: 0.0576 - val_loss: 0.1867 - val_mean_squared_error: 0.0511\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1821 - mean_squared_error: 0.0555 - val_loss: 0.1873 - val_mean_squared_error: 0.0513\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1892 - mean_squared_error: 0.0584 - val_loss: 0.1859 - val_mean_squared_error: 0.0502\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1767 - mean_squared_error: 0.0522 - val_loss: 0.1919 - val_mean_squared_error: 0.0521\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1774 - mean_squared_error: 0.0538 - val_loss: 0.1842 - val_mean_squared_error: 0.0506\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1854 - mean_squared_error: 0.0585 - val_loss: 0.1873 - val_mean_squared_error: 0.0521\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1889 - mean_squared_error: 0.0610 - val_loss: 0.1847 - val_mean_squared_error: 0.0507\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1929 - mean_squared_error: 0.0632 - val_loss: 0.1903 - val_mean_squared_error: 0.0521\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1891 - mean_squared_error: 0.0610 - val_loss: 0.1907 - val_mean_squared_error: 0.0523\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1791 - mean_squared_error: 0.0533 - val_loss: 0.1899 - val_mean_squared_error: 0.0523\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1915 - mean_squared_error: 0.0601 - val_loss: 0.1887 - val_mean_squared_error: 0.0519\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1748 - mean_squared_error: 0.0523 - val_loss: 0.1824 - val_mean_squared_error: 0.0493\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1874 - mean_squared_error: 0.0576 - val_loss: 0.1833 - val_mean_squared_error: 0.0498\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1853 - mean_squared_error: 0.0563 - val_loss: 0.1887 - val_mean_squared_error: 0.0523\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1888 - mean_squared_error: 0.0598 - val_loss: 0.1903 - val_mean_squared_error: 0.0519\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1909 - mean_squared_error: 0.0593 - val_loss: 0.1881 - val_mean_squared_error: 0.0508\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1812 - mean_squared_error: 0.0545 - val_loss: 0.1850 - val_mean_squared_error: 0.0505\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1902 - mean_squared_error: 0.0595 - val_loss: 0.1871 - val_mean_squared_error: 0.0509\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1827 - mean_squared_error: 0.0543 - val_loss: 0.1855 - val_mean_squared_error: 0.0507\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1913 - mean_squared_error: 0.0616 - val_loss: 0.1812 - val_mean_squared_error: 0.0495\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1843 - mean_squared_error: 0.0587 - val_loss: 0.1836 - val_mean_squared_error: 0.0501\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1802 - mean_squared_error: 0.0527 - val_loss: 0.1932 - val_mean_squared_error: 0.0533\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.2299 - mean_squared_error: 0.07 - 0s 7ms/step - loss: 0.1893 - mean_squared_error: 0.0588 - val_loss: 0.1877 - val_mean_squared_error: 0.0513\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1829 - mean_squared_error: 0.0550 - val_loss: 0.1867 - val_mean_squared_error: 0.0515\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1940 - mean_squared_error: 0.0608 - val_loss: 0.1911 - val_mean_squared_error: 0.0528\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1907 - mean_squared_error: 0.0589 - val_loss: 0.1882 - val_mean_squared_error: 0.0517\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1817 - mean_squared_error: 0.0568 - val_loss: 0.1870 - val_mean_squared_error: 0.0509\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1827 - mean_squared_error: 0.0561 - val_loss: 0.1828 - val_mean_squared_error: 0.0490\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1846 - mean_squared_error: 0.0561 - val_loss: 0.1815 - val_mean_squared_error: 0.0491\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1874 - mean_squared_error: 0.0571 - val_loss: 0.1831 - val_mean_squared_error: 0.0491\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1772 - mean_squared_error: 0.0527 - val_loss: 0.1812 - val_mean_squared_error: 0.0485\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1838 - mean_squared_error: 0.0561 - val_loss: 0.1805 - val_mean_squared_error: 0.0488\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1900 - mean_squared_error: 0.0596 - val_loss: 0.1806 - val_mean_squared_error: 0.0490\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1875 - mean_squared_error: 0.0590 - val_loss: 0.1782 - val_mean_squared_error: 0.0478\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1791 - mean_squared_error: 0.0526 - val_loss: 0.1813 - val_mean_squared_error: 0.0486\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1943 - mean_squared_error: 0.0604 - val_loss: 0.1802 - val_mean_squared_error: 0.0480\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1887 - mean_squared_error: 0.0591 - val_loss: 0.1810 - val_mean_squared_error: 0.0484\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1857 - mean_squared_error: 0.0572 - val_loss: 0.1823 - val_mean_squared_error: 0.0495\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1835 - mean_squared_error: 0.0569 - val_loss: 0.1837 - val_mean_squared_error: 0.0501\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1759 - mean_squared_error: 0.0539 - val_loss: 0.1834 - val_mean_squared_error: 0.0494\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1832 - mean_squared_error: 0.0532 - val_loss: 0.1844 - val_mean_squared_error: 0.0497\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1894 - mean_squared_error: 0.0592 - val_loss: 0.1850 - val_mean_squared_error: 0.0503\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1834 - mean_squared_error: 0.0547 - val_loss: 0.1845 - val_mean_squared_error: 0.0500\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1862 - mean_squared_error: 0.0582 - val_loss: 0.1854 - val_mean_squared_error: 0.0507\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1809 - mean_squared_error: 0.0552 - val_loss: 0.1872 - val_mean_squared_error: 0.0514\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1749 - mean_squared_error: 0.0517 - val_loss: 0.1861 - val_mean_squared_error: 0.0502\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1929 - mean_squared_error: 0.0589 - val_loss: 0.1841 - val_mean_squared_error: 0.0498\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1830 - mean_squared_error: 0.0565 - val_loss: 0.1830 - val_mean_squared_error: 0.0495\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1736 - mean_squared_error: 0.0525 - val_loss: 0.1871 - val_mean_squared_error: 0.0503\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1882 - mean_squared_error: 0.0588 - val_loss: 0.1861 - val_mean_squared_error: 0.0500\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1919 - mean_squared_error: 0.0581 - val_loss: 0.1822 - val_mean_squared_error: 0.0499\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1889 - mean_squared_error: 0.0575 - val_loss: 0.1771 - val_mean_squared_error: 0.0483\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1814 - mean_squared_error: 0.0541 - val_loss: 0.1839 - val_mean_squared_error: 0.0493\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1783 - mean_squared_error: 0.0528 - val_loss: 0.1834 - val_mean_squared_error: 0.0491\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1809 - mean_squared_error: 0.0542 - val_loss: 0.1821 - val_mean_squared_error: 0.0491\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1882 - mean_squared_error: 0.0592 - val_loss: 0.1833 - val_mean_squared_error: 0.0496\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1779 - mean_squared_error: 0.0532 - val_loss: 0.1790 - val_mean_squared_error: 0.0478\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1914 - mean_squared_error: 0.0597 - val_loss: 0.1828 - val_mean_squared_error: 0.0483\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1851 - mean_squared_error: 0.0574 - val_loss: 0.1840 - val_mean_squared_error: 0.0495\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1719 - mean_squared_error: 0.0469 - val_loss: 0.1862 - val_mean_squared_error: 0.0507\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1802 - mean_squared_error: 0.0548 - val_loss: 0.1855 - val_mean_squared_error: 0.0499\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1904 - mean_squared_error: 0.0595 - val_loss: 0.1841 - val_mean_squared_error: 0.0500\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1848 - mean_squared_error: 0.0565 - val_loss: 0.1852 - val_mean_squared_error: 0.0502\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1892 - mean_squared_error: 0.0607 - val_loss: 0.1845 - val_mean_squared_error: 0.0500\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1866 - mean_squared_error: 0.0578 - val_loss: 0.1831 - val_mean_squared_error: 0.0492\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1904 - mean_squared_error: 0.0591 - val_loss: 0.1817 - val_mean_squared_error: 0.0489\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1853 - mean_squared_error: 0.0571 - val_loss: 0.1833 - val_mean_squared_error: 0.0493\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1938 - mean_squared_error: 0.0581 - val_loss: 0.1890 - val_mean_squared_error: 0.0504\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1828 - mean_squared_error: 0.0563 - val_loss: 0.1838 - val_mean_squared_error: 0.0488\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1804 - mean_squared_error: 0.0544 - val_loss: 0.1834 - val_mean_squared_error: 0.0483\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1962 - mean_squared_error: 0.0646 - val_loss: 0.1815 - val_mean_squared_error: 0.0478\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1891 - mean_squared_error: 0.0582 - val_loss: 0.1827 - val_mean_squared_error: 0.0494\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1911 - mean_squared_error: 0.0591 - val_loss: 0.1801 - val_mean_squared_error: 0.0485\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1812 - mean_squared_error: 0.0540 - val_loss: 0.1809 - val_mean_squared_error: 0.0484\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1890 - mean_squared_error: 0.0577 - val_loss: 0.1843 - val_mean_squared_error: 0.0493\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1976 - mean_squared_error: 0.0638 - val_loss: 0.1839 - val_mean_squared_error: 0.0497\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1836 - mean_squared_error: 0.0570 - val_loss: 0.1823 - val_mean_squared_error: 0.0488\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1793 - mean_squared_error: 0.0547 - val_loss: 0.1843 - val_mean_squared_error: 0.0498\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1729 - mean_squared_error: 0.0506 - val_loss: 0.1828 - val_mean_squared_error: 0.0494\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1699 - mean_squared_error: 0.0488 - val_loss: 0.1841 - val_mean_squared_error: 0.0495\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1859 - mean_squared_error: 0.0576 - val_loss: 0.1828 - val_mean_squared_error: 0.0494\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1882 - mean_squared_error: 0.0615 - val_loss: 0.1818 - val_mean_squared_error: 0.0491\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1864 - mean_squared_error: 0.0588 - val_loss: 0.1826 - val_mean_squared_error: 0.0501\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1939 - mean_squared_error: 0.0627 - val_loss: 0.1875 - val_mean_squared_error: 0.0507\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1935 - mean_squared_error: 0.0614 - val_loss: 0.1864 - val_mean_squared_error: 0.0508\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1828 - mean_squared_error: 0.0556 - val_loss: 0.1830 - val_mean_squared_error: 0.0493\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1817 - mean_squared_error: 0.0539 - val_loss: 0.1803 - val_mean_squared_error: 0.0477\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1878 - mean_squared_error: 0.0605 - val_loss: 0.1805 - val_mean_squared_error: 0.0481\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1741 - mean_squared_error: 0.0505 - val_loss: 0.1825 - val_mean_squared_error: 0.0492\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1864 - mean_squared_error: 0.0565 - val_loss: 0.1820 - val_mean_squared_error: 0.0493\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1945 - mean_squared_error: 0.0632 - val_loss: 0.1821 - val_mean_squared_error: 0.0494\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1844 - mean_squared_error: 0.0590 - val_loss: 0.1844 - val_mean_squared_error: 0.0500\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1918 - mean_squared_error: 0.0584 - val_loss: 0.1856 - val_mean_squared_error: 0.0498\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1836 - mean_squared_error: 0.0551 - val_loss: 0.1820 - val_mean_squared_error: 0.0492\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1871 - mean_squared_error: 0.0583 - val_loss: 0.1816 - val_mean_squared_error: 0.0490\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1812 - mean_squared_error: 0.0541 - val_loss: 0.1850 - val_mean_squared_error: 0.0499\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1884 - mean_squared_error: 0.0589 - val_loss: 0.1833 - val_mean_squared_error: 0.0499\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1813 - mean_squared_error: 0.0543 - val_loss: 0.1849 - val_mean_squared_error: 0.0501\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1890 - mean_squared_error: 0.0592 - val_loss: 0.1836 - val_mean_squared_error: 0.0500\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1899 - mean_squared_error: 0.0598 - val_loss: 0.1853 - val_mean_squared_error: 0.0504\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1764 - mean_squared_error: 0.0521 - val_loss: 0.1858 - val_mean_squared_error: 0.0509\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1827 - mean_squared_error: 0.0578 - val_loss: 0.1887 - val_mean_squared_error: 0.0522\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1813 - mean_squared_error: 0.0582 - val_loss: 0.1919 - val_mean_squared_error: 0.0528\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1798 - mean_squared_error: 0.0541 - val_loss: 0.1896 - val_mean_squared_error: 0.0519\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1802 - mean_squared_error: 0.0528 - val_loss: 0.1820 - val_mean_squared_error: 0.0497\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1826 - mean_squared_error: 0.0578 - val_loss: 0.1830 - val_mean_squared_error: 0.0493\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1785 - mean_squared_error: 0.0552 - val_loss: 0.1850 - val_mean_squared_error: 0.0498\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1810 - mean_squared_error: 0.0558 - val_loss: 0.1824 - val_mean_squared_error: 0.0491\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1902 - mean_squared_error: 0.0604 - val_loss: 0.1816 - val_mean_squared_error: 0.0494\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1852 - mean_squared_error: 0.0574 - val_loss: 0.1826 - val_mean_squared_error: 0.0491\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1912 - mean_squared_error: 0.0597 - val_loss: 0.1851 - val_mean_squared_error: 0.0497\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1920 - mean_squared_error: 0.0607 - val_loss: 0.1865 - val_mean_squared_error: 0.0502\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1792 - mean_squared_error: 0.0516 - val_loss: 0.1824 - val_mean_squared_error: 0.0496\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1757 - mean_squared_error: 0.0534 - val_loss: 0.1810 - val_mean_squared_error: 0.0485\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.2003 - mean_squared_error: 0.0625 - val_loss: 0.1823 - val_mean_squared_error: 0.0487\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1962 - mean_squared_error: 0.0640 - val_loss: 0.1811 - val_mean_squared_error: 0.0481\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1772 - mean_squared_error: 0.0532 - val_loss: 0.1801 - val_mean_squared_error: 0.0479\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1801 - mean_squared_error: 0.0545 - val_loss: 0.1796 - val_mean_squared_error: 0.0482\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1831 - mean_squared_error: 0.0577 - val_loss: 0.1852 - val_mean_squared_error: 0.0497\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1834 - mean_squared_error: 0.0553 - val_loss: 0.1864 - val_mean_squared_error: 0.0498\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1907 - mean_squared_error: 0.0590 - val_loss: 0.1829 - val_mean_squared_error: 0.0486\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1802 - mean_squared_error: 0.0549 - val_loss: 0.1829 - val_mean_squared_error: 0.0493\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1796 - mean_squared_error: 0.0553 - val_loss: 0.1843 - val_mean_squared_error: 0.0499\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1942 - mean_squared_error: 0.0603 - val_loss: 0.1879 - val_mean_squared_error: 0.0503\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1876 - mean_squared_error: 0.0564 - val_loss: 0.1872 - val_mean_squared_error: 0.0506\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1799 - mean_squared_error: 0.0548 - val_loss: 0.1866 - val_mean_squared_error: 0.0503\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1793 - mean_squared_error: 0.0558 - val_loss: 0.1839 - val_mean_squared_error: 0.0492\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1863 - mean_squared_error: 0.0576 - val_loss: 0.1847 - val_mean_squared_error: 0.0495\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1808 - mean_squared_error: 0.0567 - val_loss: 0.1859 - val_mean_squared_error: 0.0492\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1892 - mean_squared_error: 0.0570 - val_loss: 0.1872 - val_mean_squared_error: 0.0498\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1960 - mean_squared_error: 0.0632 - val_loss: 0.1877 - val_mean_squared_error: 0.0501\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1746 - mean_squared_error: 0.0500 - val_loss: 0.1845 - val_mean_squared_error: 0.0495\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1772 - mean_squared_error: 0.0510 - val_loss: 0.1856 - val_mean_squared_error: 0.0498\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1767 - mean_squared_error: 0.0527 - val_loss: 0.1822 - val_mean_squared_error: 0.0486\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1843 - mean_squared_error: 0.0565 - val_loss: 0.1805 - val_mean_squared_error: 0.0481\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1738 - mean_squared_error: 0.0503 - val_loss: 0.1828 - val_mean_squared_error: 0.0484\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1892 - mean_squared_error: 0.0575 - val_loss: 0.1832 - val_mean_squared_error: 0.0486\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1711 - mean_squared_error: 0.0500 - val_loss: 0.1817 - val_mean_squared_error: 0.0483\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1897 - mean_squared_error: 0.0577 - val_loss: 0.1829 - val_mean_squared_error: 0.0486\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1883 - mean_squared_error: 0.0585 - val_loss: 0.1831 - val_mean_squared_error: 0.0486\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1835 - mean_squared_error: 0.0576 - val_loss: 0.1827 - val_mean_squared_error: 0.0485\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1896 - mean_squared_error: 0.0596 - val_loss: 0.1821 - val_mean_squared_error: 0.0483\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1769 - mean_squared_error: 0.0524 - val_loss: 0.1812 - val_mean_squared_error: 0.0480\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1813 - mean_squared_error: 0.0544 - val_loss: 0.1826 - val_mean_squared_error: 0.0492\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1903 - mean_squared_error: 0.0576 - val_loss: 0.1833 - val_mean_squared_error: 0.0492\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1808 - mean_squared_error: 0.0550 - val_loss: 0.1859 - val_mean_squared_error: 0.0503\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1792 - mean_squared_error: 0.0544 - val_loss: 0.1880 - val_mean_squared_error: 0.0509\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1837 - mean_squared_error: 0.0563 - val_loss: 0.1875 - val_mean_squared_error: 0.0507\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1804 - mean_squared_error: 0.0544 - val_loss: 0.1847 - val_mean_squared_error: 0.0493\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1746 - mean_squared_error: 0.0530 - val_loss: 0.1800 - val_mean_squared_error: 0.0478\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1826 - mean_squared_error: 0.0558 - val_loss: 0.1834 - val_mean_squared_error: 0.0488\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1894 - mean_squared_error: 0.0604 - val_loss: 0.1849 - val_mean_squared_error: 0.0494\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1685 - mean_squared_error: 0.0486 - val_loss: 0.1823 - val_mean_squared_error: 0.0493\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1767 - mean_squared_error: 0.0506 - val_loss: 0.1798 - val_mean_squared_error: 0.0485\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1848 - mean_squared_error: 0.0565 - val_loss: 0.1834 - val_mean_squared_error: 0.0496\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1892 - mean_squared_error: 0.0584 - val_loss: 0.1812 - val_mean_squared_error: 0.0487\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1847 - mean_squared_error: 0.0572 - val_loss: 0.1800 - val_mean_squared_error: 0.0479\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1757 - mean_squared_error: 0.0511 - val_loss: 0.1838 - val_mean_squared_error: 0.0493\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1897 - mean_squared_error: 0.0598 - val_loss: 0.1863 - val_mean_squared_error: 0.0504\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1756 - mean_squared_error: 0.0522 - val_loss: 0.1864 - val_mean_squared_error: 0.0503\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1744 - mean_squared_error: 0.0509 - val_loss: 0.1839 - val_mean_squared_error: 0.0495\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1799 - mean_squared_error: 0.0532 - val_loss: 0.1858 - val_mean_squared_error: 0.0508\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1836 - mean_squared_error: 0.0566 - val_loss: 0.1840 - val_mean_squared_error: 0.0502\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1747 - mean_squared_error: 0.0539 - val_loss: 0.1839 - val_mean_squared_error: 0.0501\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1824 - mean_squared_error: 0.0553 - val_loss: 0.1869 - val_mean_squared_error: 0.0504\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1962 - mean_squared_error: 0.0628 - val_loss: 0.1900 - val_mean_squared_error: 0.0509\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1863 - mean_squared_error: 0.0586 - val_loss: 0.1859 - val_mean_squared_error: 0.0516\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1834 - mean_squared_error: 0.0576 - val_loss: 0.1865 - val_mean_squared_error: 0.0511\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1836 - mean_squared_error: 0.0586 - val_loss: 0.1884 - val_mean_squared_error: 0.0506\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1969 - mean_squared_error: 0.0668 - val_loss: 0.1860 - val_mean_squared_error: 0.0496\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1903 - mean_squared_error: 0.0588 - val_loss: 0.1840 - val_mean_squared_error: 0.0493\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1882 - mean_squared_error: 0.0611 - val_loss: 0.1875 - val_mean_squared_error: 0.0504\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1776 - mean_squared_error: 0.0506 - val_loss: 0.1874 - val_mean_squared_error: 0.0504\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1828 - mean_squared_error: 0.0549 - val_loss: 0.1874 - val_mean_squared_error: 0.0512\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1760 - mean_squared_error: 0.0517 - val_loss: 0.1878 - val_mean_squared_error: 0.0513\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1747 - mean_squared_error: 0.0503 - val_loss: 0.1880 - val_mean_squared_error: 0.0512\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1811 - mean_squared_error: 0.0563 - val_loss: 0.1847 - val_mean_squared_error: 0.0499\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1857 - mean_squared_error: 0.0565 - val_loss: 0.1827 - val_mean_squared_error: 0.0493\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1785 - mean_squared_error: 0.0540 - val_loss: 0.1796 - val_mean_squared_error: 0.0481\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1817 - mean_squared_error: 0.0572 - val_loss: 0.1827 - val_mean_squared_error: 0.0491\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1807 - mean_squared_error: 0.0567 - val_loss: 0.1829 - val_mean_squared_error: 0.0491\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1830 - mean_squared_error: 0.0552 - val_loss: 0.1840 - val_mean_squared_error: 0.0493\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1721 - mean_squared_error: 0.0514 - val_loss: 0.1791 - val_mean_squared_error: 0.0486\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1876 - mean_squared_error: 0.0594 - val_loss: 0.1823 - val_mean_squared_error: 0.0493\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1793 - mean_squared_error: 0.0531 - val_loss: 0.1848 - val_mean_squared_error: 0.0501\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1762 - mean_squared_error: 0.0534 - val_loss: 0.1880 - val_mean_squared_error: 0.0509\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1820 - mean_squared_error: 0.0575 - val_loss: 0.1879 - val_mean_squared_error: 0.0512\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1718 - mean_squared_error: 0.0489 - val_loss: 0.1874 - val_mean_squared_error: 0.0510\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1924 - mean_squared_error: 0.0614 - val_loss: 0.1892 - val_mean_squared_error: 0.0517\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1755 - mean_squared_error: 0.0513 - val_loss: 0.1896 - val_mean_squared_error: 0.0520\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1810 - mean_squared_error: 0.0541 - val_loss: 0.1868 - val_mean_squared_error: 0.0510\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1789 - mean_squared_error: 0.0538 - val_loss: 0.1855 - val_mean_squared_error: 0.0500\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1797 - mean_squared_error: 0.0540 - val_loss: 0.1834 - val_mean_squared_error: 0.0489\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1788 - mean_squared_error: 0.0554 - val_loss: 0.1818 - val_mean_squared_error: 0.0498\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1808 - mean_squared_error: 0.0523 - val_loss: 0.1818 - val_mean_squared_error: 0.0493\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1863 - mean_squared_error: 0.0594 - val_loss: 0.1828 - val_mean_squared_error: 0.0494\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1864 - mean_squared_error: 0.0596 - val_loss: 0.1884 - val_mean_squared_error: 0.0510\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1867 - mean_squared_error: 0.0576 - val_loss: 0.1859 - val_mean_squared_error: 0.0513\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1739 - mean_squared_error: 0.0518 - val_loss: 0.1820 - val_mean_squared_error: 0.0503\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1889 - mean_squared_error: 0.0612 - val_loss: 0.1812 - val_mean_squared_error: 0.0490\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1759 - mean_squared_error: 0.0516 - val_loss: 0.1809 - val_mean_squared_error: 0.0487\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1892 - mean_squared_error: 0.0577 - val_loss: 0.1818 - val_mean_squared_error: 0.0492\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1806 - mean_squared_error: 0.0558 - val_loss: 0.1853 - val_mean_squared_error: 0.0500\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1736 - mean_squared_error: 0.0525 - val_loss: 0.1866 - val_mean_squared_error: 0.0501\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1779 - mean_squared_error: 0.0552 - val_loss: 0.1839 - val_mean_squared_error: 0.0494\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1781 - mean_squared_error: 0.0540 - val_loss: 0.1820 - val_mean_squared_error: 0.0490\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1861 - mean_squared_error: 0.0566 - val_loss: 0.1810 - val_mean_squared_error: 0.0481\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1781 - mean_squared_error: 0.0546 - val_loss: 0.1815 - val_mean_squared_error: 0.0480\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1728 - mean_squared_error: 0.0502 - val_loss: 0.1807 - val_mean_squared_error: 0.0481\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1754 - mean_squared_error: 0.0518 - val_loss: 0.1789 - val_mean_squared_error: 0.0478\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1892 - mean_squared_error: 0.0587 - val_loss: 0.1826 - val_mean_squared_error: 0.0487\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1803 - mean_squared_error: 0.0564 - val_loss: 0.1877 - val_mean_squared_error: 0.0507\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1945 - mean_squared_error: 0.0604 - val_loss: 0.1872 - val_mean_squared_error: 0.0505\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1843 - mean_squared_error: 0.0546 - val_loss: 0.1824 - val_mean_squared_error: 0.0491\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1830 - mean_squared_error: 0.0563 - val_loss: 0.1813 - val_mean_squared_error: 0.0488\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1727 - mean_squared_error: 0.0505 - val_loss: 0.1847 - val_mean_squared_error: 0.0506\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1778 - mean_squared_error: 0.0567 - val_loss: 0.1847 - val_mean_squared_error: 0.0510\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1787 - mean_squared_error: 0.0541 - val_loss: 0.1834 - val_mean_squared_error: 0.0503\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1737 - mean_squared_error: 0.0540 - val_loss: 0.1798 - val_mean_squared_error: 0.0493\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1908 - mean_squared_error: 0.0624 - val_loss: 0.1810 - val_mean_squared_error: 0.0490\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1882 - mean_squared_error: 0.0606 - val_loss: 0.1839 - val_mean_squared_error: 0.0495\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1877 - mean_squared_error: 0.0573 - val_loss: 0.1844 - val_mean_squared_error: 0.0497\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1860 - mean_squared_error: 0.0581 - val_loss: 0.1861 - val_mean_squared_error: 0.0506\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1762 - mean_squared_error: 0.0531 - val_loss: 0.1808 - val_mean_squared_error: 0.0494\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1800 - mean_squared_error: 0.0555 - val_loss: 0.1813 - val_mean_squared_error: 0.0498\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1836 - mean_squared_error: 0.0555 - val_loss: 0.1817 - val_mean_squared_error: 0.0497\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1590 - mean_squared_error: 0.0444 - val_loss: 0.1835 - val_mean_squared_error: 0.0502\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1811 - mean_squared_error: 0.0552 - val_loss: 0.1846 - val_mean_squared_error: 0.0507\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1830 - mean_squared_error: 0.0569 - val_loss: 0.1910 - val_mean_squared_error: 0.0523\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1844 - mean_squared_error: 0.0567 - val_loss: 0.1871 - val_mean_squared_error: 0.0507\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1743 - mean_squared_error: 0.0517 - val_loss: 0.1811 - val_mean_squared_error: 0.0487\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1710 - mean_squared_error: 0.0487 - val_loss: 0.1817 - val_mean_squared_error: 0.0488\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1688 - mean_squared_error: 0.0479 - val_loss: 0.1820 - val_mean_squared_error: 0.0491\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1775 - mean_squared_error: 0.0549 - val_loss: 0.1833 - val_mean_squared_error: 0.0496\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.1929 - mean_squared_error: 0.0610 - val_loss: 0.1824 - val_mean_squared_error: 0.0492\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.1795 - mean_squared_error: 0.0577 - val_loss: 0.1794 - val_mean_squared_error: 0.0482\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1755 - mean_squared_error: 0.0532 - val_loss: 0.1790 - val_mean_squared_error: 0.0481\n"
     ]
    }
   ],
   "source": [
    "model_rnn_sab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanSquaredError()])\n",
    "\n",
    "history_rnn_sab = model_rnn_sab.fit(X_train_sab, y_train_sab, epochs=1000, batch_size = 64, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75118063 0.45268832 0.86766048 0.07141202 0.38640205 0.73308984\n",
      " 0.51343767 0.06773014 0.41213969 0.13173886]\n",
      "[[0.3180623 ]\n",
      " [0.34323132]\n",
      " [0.5920338 ]\n",
      " [0.29822248]\n",
      " [0.36424762]\n",
      " [0.69502807]\n",
      " [0.40871206]\n",
      " [0.41187322]\n",
      " [0.6068244 ]\n",
      " [0.29475382]]\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.1746 - mean_squared_error: 0.0456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17458781599998474, 0.04563155025243759]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sab = model_rnn_sab.predict(X_test_sab)\n",
    "\n",
    "model_rnn_sab.evaluate(X_test_sab, y_test_sab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rseau de neurones LSTM pour un seul seuil *model_rnn_sab_lstm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 10, 4)             112       \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 10, 1)             5         \n",
      "=================================================================\n",
      "Total params: 117\n",
      "Trainable params: 117\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn_sab_lstm = Sequential()\n",
    "model_rnn_sab_lstm.add(LSTM(units = 4, input_shape = (dataset.shape[1], dataset.shape[2])))\n",
    "model_rnn_sab_lstm.add(Dense(units=1))\n",
    "model_rnn_sab_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 3s 106ms/step - loss: 0.5917 - mean_squared_error: 0.4565 - val_loss: 0.5484 - val_mean_squared_error: 0.3999\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5369 - mean_squared_error: 0.3912 - val_loss: 0.4956 - val_mean_squared_error: 0.3406\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4859 - mean_squared_error: 0.3335 - val_loss: 0.4486 - val_mean_squared_error: 0.2892\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.4413 - mean_squared_error: 0.2845 - val_loss: 0.4084 - val_mean_squared_error: 0.2458\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4042 - mean_squared_error: 0.2427 - val_loss: 0.3758 - val_mean_squared_error: 0.2109\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3751 - mean_squared_error: 0.2102 - val_loss: 0.3500 - val_mean_squared_error: 0.1834\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3522 - mean_squared_error: 0.1842 - val_loss: 0.3297 - val_mean_squared_error: 0.1619\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3325 - mean_squared_error: 0.1635 - val_loss: 0.3144 - val_mean_squared_error: 0.1460\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3188 - mean_squared_error: 0.1484 - val_loss: 0.3018 - val_mean_squared_error: 0.1336\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3072 - mean_squared_error: 0.1368 - val_loss: 0.2924 - val_mean_squared_error: 0.1250\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2983 - mean_squared_error: 0.1285 - val_loss: 0.2857 - val_mean_squared_error: 0.1192\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2931 - mean_squared_error: 0.1231 - val_loss: 0.2806 - val_mean_squared_error: 0.1150\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2886 - mean_squared_error: 0.1191 - val_loss: 0.2772 - val_mean_squared_error: 0.1123\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2852 - mean_squared_error: 0.1163 - val_loss: 0.2747 - val_mean_squared_error: 0.1105\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2827 - mean_squared_error: 0.1142 - val_loss: 0.2729 - val_mean_squared_error: 0.1091\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2806 - mean_squared_error: 0.1126 - val_loss: 0.2713 - val_mean_squared_error: 0.1079\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2790 - mean_squared_error: 0.1113 - val_loss: 0.2698 - val_mean_squared_error: 0.1069\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2772 - mean_squared_error: 0.1100 - val_loss: 0.2684 - val_mean_squared_error: 0.1058\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2757 - mean_squared_error: 0.1088 - val_loss: 0.2671 - val_mean_squared_error: 0.1048\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2741 - mean_squared_error: 0.1076 - val_loss: 0.2658 - val_mean_squared_error: 0.1038\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2726 - mean_squared_error: 0.1065 - val_loss: 0.2645 - val_mean_squared_error: 0.1028\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2711 - mean_squared_error: 0.1054 - val_loss: 0.2632 - val_mean_squared_error: 0.1018\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2696 - mean_squared_error: 0.1043 - val_loss: 0.2620 - val_mean_squared_error: 0.1008\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2681 - mean_squared_error: 0.1032 - val_loss: 0.2607 - val_mean_squared_error: 0.0999\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2667 - mean_squared_error: 0.1022 - val_loss: 0.2595 - val_mean_squared_error: 0.0989\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2652 - mean_squared_error: 0.1011 - val_loss: 0.2583 - val_mean_squared_error: 0.0981\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2638 - mean_squared_error: 0.1001 - val_loss: 0.2570 - val_mean_squared_error: 0.0972\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2623 - mean_squared_error: 0.0991 - val_loss: 0.2558 - val_mean_squared_error: 0.0963\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2609 - mean_squared_error: 0.0981 - val_loss: 0.2546 - val_mean_squared_error: 0.0954\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2595 - mean_squared_error: 0.0972 - val_loss: 0.2534 - val_mean_squared_error: 0.0945\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2581 - mean_squared_error: 0.0962 - val_loss: 0.2522 - val_mean_squared_error: 0.0937\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2568 - mean_squared_error: 0.0953 - val_loss: 0.2510 - val_mean_squared_error: 0.0928\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2553 - mean_squared_error: 0.0944 - val_loss: 0.2499 - val_mean_squared_error: 0.0920\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2540 - mean_squared_error: 0.0935 - val_loss: 0.2487 - val_mean_squared_error: 0.0912\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2526 - mean_squared_error: 0.0926 - val_loss: 0.2476 - val_mean_squared_error: 0.0904\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2512 - mean_squared_error: 0.0917 - val_loss: 0.2464 - val_mean_squared_error: 0.0897\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2499 - mean_squared_error: 0.0909 - val_loss: 0.2453 - val_mean_squared_error: 0.0889\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2484 - mean_squared_error: 0.0900 - val_loss: 0.2441 - val_mean_squared_error: 0.0881\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2470 - mean_squared_error: 0.0892 - val_loss: 0.2430 - val_mean_squared_error: 0.0874\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2456 - mean_squared_error: 0.0884 - val_loss: 0.2418 - val_mean_squared_error: 0.0867\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2442 - mean_squared_error: 0.0875 - val_loss: 0.2407 - val_mean_squared_error: 0.0860\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2429 - mean_squared_error: 0.0867 - val_loss: 0.2395 - val_mean_squared_error: 0.0853\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2414 - mean_squared_error: 0.0859 - val_loss: 0.2384 - val_mean_squared_error: 0.0846\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2401 - mean_squared_error: 0.0851 - val_loss: 0.2373 - val_mean_squared_error: 0.0839\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2388 - mean_squared_error: 0.0844 - val_loss: 0.2362 - val_mean_squared_error: 0.0832\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2374 - mean_squared_error: 0.0836 - val_loss: 0.2350 - val_mean_squared_error: 0.0826\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2361 - mean_squared_error: 0.0829 - val_loss: 0.2339 - val_mean_squared_error: 0.0819\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2348 - mean_squared_error: 0.0822 - val_loss: 0.2328 - val_mean_squared_error: 0.0813\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2334 - mean_squared_error: 0.0814 - val_loss: 0.2317 - val_mean_squared_error: 0.0807\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2320 - mean_squared_error: 0.0807 - val_loss: 0.2307 - val_mean_squared_error: 0.0801\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2307 - mean_squared_error: 0.0800 - val_loss: 0.2296 - val_mean_squared_error: 0.0795\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2294 - mean_squared_error: 0.0793 - val_loss: 0.2286 - val_mean_squared_error: 0.0789\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.2281 - mean_squared_error: 0.0787 - val_loss: 0.2276 - val_mean_squared_error: 0.0783\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2268 - mean_squared_error: 0.0780 - val_loss: 0.2266 - val_mean_squared_error: 0.0778\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2255 - mean_squared_error: 0.0774 - val_loss: 0.2257 - val_mean_squared_error: 0.0773\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2242 - mean_squared_error: 0.0767 - val_loss: 0.2247 - val_mean_squared_error: 0.0768\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.2230 - mean_squared_error: 0.0761 - val_loss: 0.2238 - val_mean_squared_error: 0.0762\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2217 - mean_squared_error: 0.0755 - val_loss: 0.2229 - val_mean_squared_error: 0.0758\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2205 - mean_squared_error: 0.0749 - val_loss: 0.2221 - val_mean_squared_error: 0.0753\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2195 - mean_squared_error: 0.0744 - val_loss: 0.2212 - val_mean_squared_error: 0.0749\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2182 - mean_squared_error: 0.0737 - val_loss: 0.2203 - val_mean_squared_error: 0.0744\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2169 - mean_squared_error: 0.0732 - val_loss: 0.2194 - val_mean_squared_error: 0.0740\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2158 - mean_squared_error: 0.0727 - val_loss: 0.2186 - val_mean_squared_error: 0.0735\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2147 - mean_squared_error: 0.0722 - val_loss: 0.2178 - val_mean_squared_error: 0.0731\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2136 - mean_squared_error: 0.0717 - val_loss: 0.2170 - val_mean_squared_error: 0.0728\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2125 - mean_squared_error: 0.0712 - val_loss: 0.2163 - val_mean_squared_error: 0.0725\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2114 - mean_squared_error: 0.0708 - val_loss: 0.2156 - val_mean_squared_error: 0.0721\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2103 - mean_squared_error: 0.0703 - val_loss: 0.2148 - val_mean_squared_error: 0.0718\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2093 - mean_squared_error: 0.0698 - val_loss: 0.2141 - val_mean_squared_error: 0.0715\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2083 - mean_squared_error: 0.0694 - val_loss: 0.2135 - val_mean_squared_error: 0.0712\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2073 - mean_squared_error: 0.0690 - val_loss: 0.2128 - val_mean_squared_error: 0.0709\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2064 - mean_squared_error: 0.0686 - val_loss: 0.2122 - val_mean_squared_error: 0.0707\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2054 - mean_squared_error: 0.0683 - val_loss: 0.2118 - val_mean_squared_error: 0.0705\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2046 - mean_squared_error: 0.0679 - val_loss: 0.2112 - val_mean_squared_error: 0.0703\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2038 - mean_squared_error: 0.0676 - val_loss: 0.2106 - val_mean_squared_error: 0.0701\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2029 - mean_squared_error: 0.0673 - val_loss: 0.2101 - val_mean_squared_error: 0.0699\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.2022 - mean_squared_error: 0.0670 - val_loss: 0.2097 - val_mean_squared_error: 0.0697\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.2015 - mean_squared_error: 0.0667 - val_loss: 0.2094 - val_mean_squared_error: 0.0696\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2008 - mean_squared_error: 0.0664 - val_loss: 0.2089 - val_mean_squared_error: 0.0694\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.2001 - mean_squared_error: 0.0661 - val_loss: 0.2086 - val_mean_squared_error: 0.0693\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1997 - mean_squared_error: 0.0659 - val_loss: 0.2082 - val_mean_squared_error: 0.0691\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1989 - mean_squared_error: 0.0655 - val_loss: 0.2080 - val_mean_squared_error: 0.0690\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1983 - mean_squared_error: 0.0653 - val_loss: 0.2077 - val_mean_squared_error: 0.0688\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1978 - mean_squared_error: 0.0651 - val_loss: 0.2075 - val_mean_squared_error: 0.0687\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1973 - mean_squared_error: 0.0649 - val_loss: 0.2073 - val_mean_squared_error: 0.0686\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1968 - mean_squared_error: 0.0646 - val_loss: 0.2070 - val_mean_squared_error: 0.0685\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1963 - mean_squared_error: 0.0644 - val_loss: 0.2068 - val_mean_squared_error: 0.0684\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1959 - mean_squared_error: 0.0642 - val_loss: 0.2066 - val_mean_squared_error: 0.0682\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1955 - mean_squared_error: 0.0640 - val_loss: 0.2064 - val_mean_squared_error: 0.0681\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1951 - mean_squared_error: 0.0638 - val_loss: 0.2063 - val_mean_squared_error: 0.0680\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1947 - mean_squared_error: 0.0635 - val_loss: 0.2059 - val_mean_squared_error: 0.0678\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1943 - mean_squared_error: 0.0633 - val_loss: 0.2057 - val_mean_squared_error: 0.0677\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1940 - mean_squared_error: 0.0632 - val_loss: 0.2056 - val_mean_squared_error: 0.0676\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1937 - mean_squared_error: 0.0630 - val_loss: 0.2056 - val_mean_squared_error: 0.0676\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1933 - mean_squared_error: 0.0628 - val_loss: 0.2053 - val_mean_squared_error: 0.0674\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1931 - mean_squared_error: 0.0626 - val_loss: 0.2052 - val_mean_squared_error: 0.0673\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1928 - mean_squared_error: 0.0625 - val_loss: 0.2051 - val_mean_squared_error: 0.0673\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1925 - mean_squared_error: 0.0623 - val_loss: 0.2050 - val_mean_squared_error: 0.0672\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1923 - mean_squared_error: 0.0622 - val_loss: 0.2050 - val_mean_squared_error: 0.0672\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1921 - mean_squared_error: 0.0621 - val_loss: 0.2048 - val_mean_squared_error: 0.0670\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1918 - mean_squared_error: 0.0619 - val_loss: 0.2046 - val_mean_squared_error: 0.0669\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1918 - mean_squared_error: 0.0618 - val_loss: 0.2043 - val_mean_squared_error: 0.0667\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1915 - mean_squared_error: 0.0616 - val_loss: 0.2043 - val_mean_squared_error: 0.0667\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1914 - mean_squared_error: 0.0616 - val_loss: 0.2044 - val_mean_squared_error: 0.0667\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1911 - mean_squared_error: 0.0614 - val_loss: 0.2041 - val_mean_squared_error: 0.0665\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1909 - mean_squared_error: 0.0612 - val_loss: 0.2039 - val_mean_squared_error: 0.0664\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1910 - mean_squared_error: 0.0611 - val_loss: 0.2038 - val_mean_squared_error: 0.0663\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1906 - mean_squared_error: 0.0610 - val_loss: 0.2039 - val_mean_squared_error: 0.0663\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1905 - mean_squared_error: 0.0609 - val_loss: 0.2038 - val_mean_squared_error: 0.0662\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1903 - mean_squared_error: 0.0609 - val_loss: 0.2039 - val_mean_squared_error: 0.0662\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1902 - mean_squared_error: 0.0608 - val_loss: 0.2038 - val_mean_squared_error: 0.0662\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1900 - mean_squared_error: 0.0607 - val_loss: 0.2036 - val_mean_squared_error: 0.0661\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1899 - mean_squared_error: 0.0606 - val_loss: 0.2034 - val_mean_squared_error: 0.0660\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1899 - mean_squared_error: 0.0605 - val_loss: 0.2034 - val_mean_squared_error: 0.0659\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1897 - mean_squared_error: 0.0604 - val_loss: 0.2033 - val_mean_squared_error: 0.0659\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1896 - mean_squared_error: 0.0603 - val_loss: 0.2033 - val_mean_squared_error: 0.0658\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1895 - mean_squared_error: 0.0602 - val_loss: 0.2032 - val_mean_squared_error: 0.0658\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1893 - mean_squared_error: 0.0601 - val_loss: 0.2030 - val_mean_squared_error: 0.0656\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1893 - mean_squared_error: 0.0600 - val_loss: 0.2029 - val_mean_squared_error: 0.0655\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1892 - mean_squared_error: 0.0599 - val_loss: 0.2029 - val_mean_squared_error: 0.0655\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1891 - mean_squared_error: 0.0599 - val_loss: 0.2028 - val_mean_squared_error: 0.0654\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1890 - mean_squared_error: 0.0598 - val_loss: 0.2028 - val_mean_squared_error: 0.0654\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1889 - mean_squared_error: 0.0598 - val_loss: 0.2028 - val_mean_squared_error: 0.0654\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1889 - mean_squared_error: 0.0597 - val_loss: 0.2026 - val_mean_squared_error: 0.0653\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1887 - mean_squared_error: 0.0596 - val_loss: 0.2025 - val_mean_squared_error: 0.0652\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1887 - mean_squared_error: 0.0596 - val_loss: 0.2025 - val_mean_squared_error: 0.0651\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1885 - mean_squared_error: 0.0594 - val_loss: 0.2025 - val_mean_squared_error: 0.0652\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1885 - mean_squared_error: 0.0593 - val_loss: 0.2023 - val_mean_squared_error: 0.0651\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1884 - mean_squared_error: 0.0593 - val_loss: 0.2023 - val_mean_squared_error: 0.0650\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1884 - mean_squared_error: 0.0593 - val_loss: 0.2024 - val_mean_squared_error: 0.0650\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1883 - mean_squared_error: 0.0593 - val_loss: 0.2022 - val_mean_squared_error: 0.0650\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1881 - mean_squared_error: 0.0591 - val_loss: 0.2022 - val_mean_squared_error: 0.0649\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1880 - mean_squared_error: 0.0591 - val_loss: 0.2022 - val_mean_squared_error: 0.0649\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1880 - mean_squared_error: 0.0590 - val_loss: 0.2021 - val_mean_squared_error: 0.0648\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1879 - mean_squared_error: 0.0590 - val_loss: 0.2020 - val_mean_squared_error: 0.0648\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1879 - mean_squared_error: 0.0589 - val_loss: 0.2022 - val_mean_squared_error: 0.0648\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1877 - mean_squared_error: 0.0589 - val_loss: 0.2020 - val_mean_squared_error: 0.0647\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1878 - mean_squared_error: 0.0589 - val_loss: 0.2019 - val_mean_squared_error: 0.0647\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1876 - mean_squared_error: 0.0588 - val_loss: 0.2020 - val_mean_squared_error: 0.0647\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1875 - mean_squared_error: 0.0588 - val_loss: 0.2020 - val_mean_squared_error: 0.0646\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1875 - mean_squared_error: 0.0587 - val_loss: 0.2019 - val_mean_squared_error: 0.0646\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1874 - mean_squared_error: 0.0587 - val_loss: 0.2017 - val_mean_squared_error: 0.0645\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1873 - mean_squared_error: 0.0586 - val_loss: 0.2017 - val_mean_squared_error: 0.0645\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1873 - mean_squared_error: 0.0586 - val_loss: 0.2017 - val_mean_squared_error: 0.0645\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1872 - mean_squared_error: 0.0585 - val_loss: 0.2019 - val_mean_squared_error: 0.0645\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1872 - mean_squared_error: 0.0585 - val_loss: 0.2017 - val_mean_squared_error: 0.0644\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1870 - mean_squared_error: 0.0584 - val_loss: 0.2015 - val_mean_squared_error: 0.0644\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1870 - mean_squared_error: 0.0584 - val_loss: 0.2014 - val_mean_squared_error: 0.0643\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1871 - mean_squared_error: 0.0584 - val_loss: 0.2016 - val_mean_squared_error: 0.0644\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1869 - mean_squared_error: 0.0583 - val_loss: 0.2014 - val_mean_squared_error: 0.0643\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1868 - mean_squared_error: 0.0582 - val_loss: 0.2015 - val_mean_squared_error: 0.0642\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1868 - mean_squared_error: 0.0582 - val_loss: 0.2015 - val_mean_squared_error: 0.0642\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1867 - mean_squared_error: 0.0582 - val_loss: 0.2014 - val_mean_squared_error: 0.0642\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1866 - mean_squared_error: 0.0581 - val_loss: 0.2013 - val_mean_squared_error: 0.0641\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1866 - mean_squared_error: 0.0581 - val_loss: 0.2014 - val_mean_squared_error: 0.0641\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1866 - mean_squared_error: 0.0581 - val_loss: 0.2013 - val_mean_squared_error: 0.0641\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1866 - mean_squared_error: 0.0581 - val_loss: 0.2011 - val_mean_squared_error: 0.0640\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1865 - mean_squared_error: 0.0580 - val_loss: 0.2011 - val_mean_squared_error: 0.0640\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1864 - mean_squared_error: 0.0579 - val_loss: 0.2010 - val_mean_squared_error: 0.0639\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1863 - mean_squared_error: 0.0579 - val_loss: 0.2010 - val_mean_squared_error: 0.0638\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1863 - mean_squared_error: 0.0578 - val_loss: 0.2010 - val_mean_squared_error: 0.0638\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1863 - mean_squared_error: 0.0578 - val_loss: 0.2011 - val_mean_squared_error: 0.0638\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1863 - mean_squared_error: 0.0578 - val_loss: 0.2007 - val_mean_squared_error: 0.0637\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1862 - mean_squared_error: 0.0577 - val_loss: 0.2008 - val_mean_squared_error: 0.0637\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1863 - mean_squared_error: 0.0577 - val_loss: 0.2007 - val_mean_squared_error: 0.0637\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1861 - mean_squared_error: 0.0577 - val_loss: 0.2009 - val_mean_squared_error: 0.0637\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1860 - mean_squared_error: 0.0577 - val_loss: 0.2009 - val_mean_squared_error: 0.0637\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1860 - mean_squared_error: 0.0577 - val_loss: 0.2008 - val_mean_squared_error: 0.0637\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1859 - mean_squared_error: 0.0577 - val_loss: 0.2008 - val_mean_squared_error: 0.0637\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1859 - mean_squared_error: 0.0576 - val_loss: 0.2009 - val_mean_squared_error: 0.0636\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1859 - mean_squared_error: 0.0576 - val_loss: 0.2007 - val_mean_squared_error: 0.0636\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1858 - mean_squared_error: 0.0575 - val_loss: 0.2006 - val_mean_squared_error: 0.0636\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1857 - mean_squared_error: 0.0575 - val_loss: 0.2006 - val_mean_squared_error: 0.0636\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1857 - mean_squared_error: 0.0575 - val_loss: 0.2006 - val_mean_squared_error: 0.0636\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1856 - mean_squared_error: 0.0575 - val_loss: 0.2006 - val_mean_squared_error: 0.0636\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1857 - mean_squared_error: 0.0576 - val_loss: 0.2007 - val_mean_squared_error: 0.0636\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1857 - mean_squared_error: 0.0576 - val_loss: 0.2007 - val_mean_squared_error: 0.0636\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1855 - mean_squared_error: 0.0574 - val_loss: 0.2005 - val_mean_squared_error: 0.0636\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1856 - mean_squared_error: 0.0575 - val_loss: 0.2005 - val_mean_squared_error: 0.0636\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1855 - mean_squared_error: 0.0574 - val_loss: 0.2005 - val_mean_squared_error: 0.0636\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1854 - mean_squared_error: 0.0574 - val_loss: 0.2005 - val_mean_squared_error: 0.0635\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1855 - mean_squared_error: 0.0575 - val_loss: 0.2005 - val_mean_squared_error: 0.0635\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1853 - mean_squared_error: 0.0573 - val_loss: 0.2003 - val_mean_squared_error: 0.0634\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1853 - mean_squared_error: 0.0573 - val_loss: 0.2003 - val_mean_squared_error: 0.0634\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1854 - mean_squared_error: 0.0573 - val_loss: 0.2002 - val_mean_squared_error: 0.0634\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1853 - mean_squared_error: 0.0573 - val_loss: 0.2002 - val_mean_squared_error: 0.0634\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1853 - mean_squared_error: 0.0573 - val_loss: 0.2006 - val_mean_squared_error: 0.0634\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1853 - mean_squared_error: 0.0573 - val_loss: 0.2002 - val_mean_squared_error: 0.0633\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1852 - mean_squared_error: 0.0572 - val_loss: 0.2001 - val_mean_squared_error: 0.0633\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1852 - mean_squared_error: 0.0572 - val_loss: 0.2002 - val_mean_squared_error: 0.0633\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1851 - mean_squared_error: 0.0572 - val_loss: 0.2001 - val_mean_squared_error: 0.0633\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1852 - mean_squared_error: 0.0572 - val_loss: 0.2002 - val_mean_squared_error: 0.0632\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1850 - mean_squared_error: 0.0572 - val_loss: 0.2001 - val_mean_squared_error: 0.0632\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1850 - mean_squared_error: 0.0571 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1850 - mean_squared_error: 0.0571 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1850 - mean_squared_error: 0.0571 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1851 - mean_squared_error: 0.0572 - val_loss: 0.2001 - val_mean_squared_error: 0.0632\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1850 - mean_squared_error: 0.0572 - val_loss: 0.2000 - val_mean_squared_error: 0.0632\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1849 - mean_squared_error: 0.0571 - val_loss: 0.2002 - val_mean_squared_error: 0.0632\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1849 - mean_squared_error: 0.0572 - val_loss: 0.2002 - val_mean_squared_error: 0.0633\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1849 - mean_squared_error: 0.0571 - val_loss: 0.1999 - val_mean_squared_error: 0.0633\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1849 - mean_squared_error: 0.0572 - val_loss: 0.2000 - val_mean_squared_error: 0.0632\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1848 - mean_squared_error: 0.0571 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1849 - mean_squared_error: 0.0571 - val_loss: 0.2001 - val_mean_squared_error: 0.0632\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1847 - mean_squared_error: 0.0571 - val_loss: 0.2001 - val_mean_squared_error: 0.0632\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1847 - mean_squared_error: 0.0570 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1847 - mean_squared_error: 0.0570 - val_loss: 0.1998 - val_mean_squared_error: 0.0632\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1847 - mean_squared_error: 0.0570 - val_loss: 0.2000 - val_mean_squared_error: 0.0632\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1847 - mean_squared_error: 0.0571 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1848 - mean_squared_error: 0.0572 - val_loss: 0.2003 - val_mean_squared_error: 0.0633\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1846 - mean_squared_error: 0.0571 - val_loss: 0.2000 - val_mean_squared_error: 0.0632\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1849 - mean_squared_error: 0.0572 - val_loss: 0.1998 - val_mean_squared_error: 0.0632\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1845 - mean_squared_error: 0.0570 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1846 - mean_squared_error: 0.0570 - val_loss: 0.1999 - val_mean_squared_error: 0.0631\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1845 - mean_squared_error: 0.0570 - val_loss: 0.1998 - val_mean_squared_error: 0.0631\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1845 - mean_squared_error: 0.0569 - val_loss: 0.1998 - val_mean_squared_error: 0.0631\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1844 - mean_squared_error: 0.0570 - val_loss: 0.2000 - val_mean_squared_error: 0.0632\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1844 - mean_squared_error: 0.0570 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1844 - mean_squared_error: 0.0570 - val_loss: 0.1999 - val_mean_squared_error: 0.0632\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1844 - mean_squared_error: 0.0570 - val_loss: 0.1997 - val_mean_squared_error: 0.0631\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1843 - mean_squared_error: 0.0569 - val_loss: 0.1998 - val_mean_squared_error: 0.0631\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1844 - mean_squared_error: 0.0569 - val_loss: 0.1998 - val_mean_squared_error: 0.0631\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1842 - mean_squared_error: 0.0569 - val_loss: 0.1996 - val_mean_squared_error: 0.0631\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1843 - mean_squared_error: 0.0569 - val_loss: 0.1996 - val_mean_squared_error: 0.0631\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1845 - mean_squared_error: 0.0570 - val_loss: 0.1999 - val_mean_squared_error: 0.0631\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1842 - mean_squared_error: 0.0569 - val_loss: 0.1996 - val_mean_squared_error: 0.0630\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1843 - mean_squared_error: 0.0568 - val_loss: 0.1997 - val_mean_squared_error: 0.0630\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1842 - mean_squared_error: 0.0568 - val_loss: 0.1996 - val_mean_squared_error: 0.0630\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1842 - mean_squared_error: 0.0568 - val_loss: 0.1997 - val_mean_squared_error: 0.0630\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1841 - mean_squared_error: 0.0568 - val_loss: 0.1997 - val_mean_squared_error: 0.0630\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1841 - mean_squared_error: 0.0568 - val_loss: 0.1997 - val_mean_squared_error: 0.0630\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1842 - mean_squared_error: 0.0568 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1841 - mean_squared_error: 0.0568 - val_loss: 0.1996 - val_mean_squared_error: 0.0630\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1841 - mean_squared_error: 0.0568 - val_loss: 0.1997 - val_mean_squared_error: 0.0631\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1841 - mean_squared_error: 0.0569 - val_loss: 0.1998 - val_mean_squared_error: 0.0631\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1840 - mean_squared_error: 0.0569 - val_loss: 0.1997 - val_mean_squared_error: 0.0632\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1840 - mean_squared_error: 0.0568 - val_loss: 0.1996 - val_mean_squared_error: 0.0631\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1840 - mean_squared_error: 0.0568 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1841 - mean_squared_error: 0.0568 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1840 - mean_squared_error: 0.0567 - val_loss: 0.1994 - val_mean_squared_error: 0.0630\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1840 - mean_squared_error: 0.0567 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1840 - mean_squared_error: 0.0568 - val_loss: 0.1996 - val_mean_squared_error: 0.0630\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1841 - mean_squared_error: 0.0568 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1839 - mean_squared_error: 0.0568 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1839 - mean_squared_error: 0.0568 - val_loss: 0.1997 - val_mean_squared_error: 0.0631\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1838 - mean_squared_error: 0.0568 - val_loss: 0.1995 - val_mean_squared_error: 0.0631\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1839 - mean_squared_error: 0.0568 - val_loss: 0.1994 - val_mean_squared_error: 0.0630\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1838 - mean_squared_error: 0.0567 - val_loss: 0.1995 - val_mean_squared_error: 0.0631\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1838 - mean_squared_error: 0.0568 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1839 - mean_squared_error: 0.0568 - val_loss: 0.1994 - val_mean_squared_error: 0.0631\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1839 - mean_squared_error: 0.0568 - val_loss: 0.1998 - val_mean_squared_error: 0.0630\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1838 - mean_squared_error: 0.0567 - val_loss: 0.1994 - val_mean_squared_error: 0.0629\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1840 - mean_squared_error: 0.0568 - val_loss: 0.1991 - val_mean_squared_error: 0.0630\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1995 - val_mean_squared_error: 0.0630\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1994 - val_mean_squared_error: 0.0630\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1836 - mean_squared_error: 0.0567 - val_loss: 0.1994 - val_mean_squared_error: 0.0630\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1991 - val_mean_squared_error: 0.0630\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1992 - val_mean_squared_error: 0.0630\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1837 - mean_squared_error: 0.0567 - val_loss: 0.1994 - val_mean_squared_error: 0.0629\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1836 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1835 - mean_squared_error: 0.0565 - val_loss: 0.1990 - val_mean_squared_error: 0.0628\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1836 - mean_squared_error: 0.0566 - val_loss: 0.1990 - val_mean_squared_error: 0.0629\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1835 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0630\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1835 - mean_squared_error: 0.0567 - val_loss: 0.1994 - val_mean_squared_error: 0.0630\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1835 - mean_squared_error: 0.0566 - val_loss: 0.1993 - val_mean_squared_error: 0.0629\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1835 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1834 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1835 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0630\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1835 - mean_squared_error: 0.0566 - val_loss: 0.1993 - val_mean_squared_error: 0.0630\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1835 - mean_squared_error: 0.0567 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1834 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 275/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1834 - mean_squared_error: 0.0565 - val_loss: 0.1990 - val_mean_squared_error: 0.0628\n",
      "Epoch 276/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1834 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0630\n",
      "Epoch 277/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1834 - mean_squared_error: 0.0566 - val_loss: 0.1991 - val_mean_squared_error: 0.0629\n",
      "Epoch 278/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1834 - mean_squared_error: 0.0566 - val_loss: 0.1993 - val_mean_squared_error: 0.0629\n",
      "Epoch 279/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1834 - mean_squared_error: 0.0567 - val_loss: 0.1992 - val_mean_squared_error: 0.0630\n",
      "Epoch 280/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1833 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0630\n",
      "Epoch 281/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1833 - mean_squared_error: 0.0566 - val_loss: 0.1991 - val_mean_squared_error: 0.0629\n",
      "Epoch 282/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1833 - mean_squared_error: 0.0566 - val_loss: 0.1990 - val_mean_squared_error: 0.0629\n",
      "Epoch 283/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1833 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 284/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1833 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0630\n",
      "Epoch 285/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1833 - mean_squared_error: 0.0566 - val_loss: 0.1991 - val_mean_squared_error: 0.0629\n",
      "Epoch 286/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1836 - mean_squared_error: 0.0567 - val_loss: 0.1995 - val_mean_squared_error: 0.0629\n",
      "Epoch 287/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1833 - mean_squared_error: 0.0565 - val_loss: 0.1991 - val_mean_squared_error: 0.0629\n",
      "Epoch 288/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1832 - mean_squared_error: 0.0565 - val_loss: 0.1989 - val_mean_squared_error: 0.0629\n",
      "Epoch 289/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1833 - mean_squared_error: 0.0565 - val_loss: 0.1990 - val_mean_squared_error: 0.0629\n",
      "Epoch 290/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1832 - mean_squared_error: 0.0565 - val_loss: 0.1991 - val_mean_squared_error: 0.0629\n",
      "Epoch 291/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1832 - mean_squared_error: 0.0565 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 292/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1832 - mean_squared_error: 0.0566 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 293/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1832 - mean_squared_error: 0.0565 - val_loss: 0.1989 - val_mean_squared_error: 0.0629\n",
      "Epoch 294/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1832 - mean_squared_error: 0.0565 - val_loss: 0.1989 - val_mean_squared_error: 0.0628\n",
      "Epoch 295/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1988 - val_mean_squared_error: 0.0628\n",
      "Epoch 296/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1990 - val_mean_squared_error: 0.0628\n",
      "Epoch 297/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1832 - mean_squared_error: 0.0565 - val_loss: 0.1988 - val_mean_squared_error: 0.0627\n",
      "Epoch 298/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1989 - val_mean_squared_error: 0.0629\n",
      "Epoch 299/1000\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1990 - val_mean_squared_error: 0.0628\n",
      "Epoch 300/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1834 - mean_squared_error: 0.0567 - val_loss: 0.1992 - val_mean_squared_error: 0.0629\n",
      "Epoch 301/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1988 - val_mean_squared_error: 0.0629\n",
      "Epoch 302/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1987 - val_mean_squared_error: 0.0629\n",
      "Epoch 303/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1989 - val_mean_squared_error: 0.0627\n",
      "Epoch 304/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1831 - mean_squared_error: 0.0564 - val_loss: 0.1990 - val_mean_squared_error: 0.0628\n",
      "Epoch 305/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1830 - mean_squared_error: 0.0564 - val_loss: 0.1987 - val_mean_squared_error: 0.0628\n",
      "Epoch 306/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1831 - mean_squared_error: 0.0565 - val_loss: 0.1987 - val_mean_squared_error: 0.0628\n",
      "Epoch 307/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1830 - mean_squared_error: 0.0564 - val_loss: 0.1987 - val_mean_squared_error: 0.0629\n",
      "Epoch 308/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1830 - mean_squared_error: 0.0565 - val_loss: 0.1988 - val_mean_squared_error: 0.0628\n",
      "Epoch 309/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1829 - mean_squared_error: 0.0564 - val_loss: 0.1989 - val_mean_squared_error: 0.0629\n",
      "Epoch 310/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1830 - mean_squared_error: 0.0564 - val_loss: 0.1987 - val_mean_squared_error: 0.0628\n",
      "Epoch 311/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1830 - mean_squared_error: 0.0564 - val_loss: 0.1989 - val_mean_squared_error: 0.0628\n",
      "Epoch 312/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1830 - mean_squared_error: 0.0565 - val_loss: 0.1988 - val_mean_squared_error: 0.0629\n",
      "Epoch 313/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1829 - mean_squared_error: 0.0565 - val_loss: 0.1989 - val_mean_squared_error: 0.0629\n",
      "Epoch 314/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1829 - mean_squared_error: 0.0564 - val_loss: 0.1988 - val_mean_squared_error: 0.0628\n",
      "Epoch 315/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1829 - mean_squared_error: 0.0564 - val_loss: 0.1988 - val_mean_squared_error: 0.0628\n",
      "Epoch 316/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1829 - mean_squared_error: 0.0564 - val_loss: 0.1986 - val_mean_squared_error: 0.0628\n",
      "Epoch 317/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1829 - mean_squared_error: 0.0564 - val_loss: 0.1986 - val_mean_squared_error: 0.0628\n",
      "Epoch 318/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1830 - mean_squared_error: 0.0565 - val_loss: 0.1988 - val_mean_squared_error: 0.0628\n",
      "Epoch 319/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1830 - mean_squared_error: 0.0565 - val_loss: 0.1988 - val_mean_squared_error: 0.0628\n",
      "Epoch 320/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1828 - mean_squared_error: 0.0564 - val_loss: 0.1985 - val_mean_squared_error: 0.0628\n",
      "Epoch 321/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1829 - mean_squared_error: 0.0563 - val_loss: 0.1984 - val_mean_squared_error: 0.0627\n",
      "Epoch 322/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1828 - mean_squared_error: 0.0563 - val_loss: 0.1987 - val_mean_squared_error: 0.0627\n",
      "Epoch 323/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1828 - mean_squared_error: 0.0563 - val_loss: 0.1987 - val_mean_squared_error: 0.0627\n",
      "Epoch 324/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1827 - mean_squared_error: 0.0563 - val_loss: 0.1986 - val_mean_squared_error: 0.0628\n",
      "Epoch 325/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1827 - mean_squared_error: 0.0564 - val_loss: 0.1985 - val_mean_squared_error: 0.0628\n",
      "Epoch 326/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1828 - mean_squared_error: 0.0564 - val_loss: 0.1986 - val_mean_squared_error: 0.0627\n",
      "Epoch 327/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1827 - mean_squared_error: 0.0564 - val_loss: 0.1986 - val_mean_squared_error: 0.0628\n",
      "Epoch 328/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1827 - mean_squared_error: 0.0564 - val_loss: 0.1986 - val_mean_squared_error: 0.0628\n",
      "Epoch 329/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1827 - mean_squared_error: 0.0563 - val_loss: 0.1985 - val_mean_squared_error: 0.0627\n",
      "Epoch 330/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1827 - mean_squared_error: 0.0563 - val_loss: 0.1985 - val_mean_squared_error: 0.0628\n",
      "Epoch 331/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1984 - val_mean_squared_error: 0.0628\n",
      "Epoch 332/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1827 - mean_squared_error: 0.0564 - val_loss: 0.1982 - val_mean_squared_error: 0.0627\n",
      "Epoch 333/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1983 - val_mean_squared_error: 0.0627\n",
      "Epoch 334/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1827 - mean_squared_error: 0.0563 - val_loss: 0.1984 - val_mean_squared_error: 0.0627\n",
      "Epoch 335/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1827 - mean_squared_error: 0.0564 - val_loss: 0.1983 - val_mean_squared_error: 0.0627\n",
      "Epoch 336/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1984 - val_mean_squared_error: 0.0627\n",
      "Epoch 337/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1984 - val_mean_squared_error: 0.0627\n",
      "Epoch 338/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1984 - val_mean_squared_error: 0.0627\n",
      "Epoch 339/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1827 - mean_squared_error: 0.0563 - val_loss: 0.1983 - val_mean_squared_error: 0.0628\n",
      "Epoch 340/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1985 - val_mean_squared_error: 0.0628\n",
      "Epoch 341/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1986 - val_mean_squared_error: 0.0628\n",
      "Epoch 342/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1985 - val_mean_squared_error: 0.0627\n",
      "Epoch 343/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1825 - mean_squared_error: 0.0563 - val_loss: 0.1983 - val_mean_squared_error: 0.0627\n",
      "Epoch 344/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1825 - mean_squared_error: 0.0563 - val_loss: 0.1983 - val_mean_squared_error: 0.0628\n",
      "Epoch 345/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - mean_squared_error: 0.0564 - val_loss: 0.1985 - val_mean_squared_error: 0.0628\n",
      "Epoch 346/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1825 - mean_squared_error: 0.0564 - val_loss: 0.1986 - val_mean_squared_error: 0.0628\n",
      "Epoch 347/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1825 - mean_squared_error: 0.0563 - val_loss: 0.1982 - val_mean_squared_error: 0.0628\n",
      "Epoch 348/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1981 - val_mean_squared_error: 0.0627\n",
      "Epoch 349/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1824 - mean_squared_error: 0.0562 - val_loss: 0.1983 - val_mean_squared_error: 0.0627\n",
      "Epoch 350/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1825 - mean_squared_error: 0.0563 - val_loss: 0.1985 - val_mean_squared_error: 0.0627\n",
      "Epoch 351/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1824 - mean_squared_error: 0.0563 - val_loss: 0.1982 - val_mean_squared_error: 0.0627\n",
      "Epoch 352/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1824 - mean_squared_error: 0.0562 - val_loss: 0.1981 - val_mean_squared_error: 0.0627\n",
      "Epoch 353/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1824 - mean_squared_error: 0.0562 - val_loss: 0.1981 - val_mean_squared_error: 0.0626\n",
      "Epoch 354/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1824 - mean_squared_error: 0.0562 - val_loss: 0.1982 - val_mean_squared_error: 0.0626\n",
      "Epoch 355/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.1824 - mean_squared_error: 0.0562 - val_loss: 0.1982 - val_mean_squared_error: 0.0626\n",
      "Epoch 356/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1824 - mean_squared_error: 0.0562 - val_loss: 0.1980 - val_mean_squared_error: 0.0627\n",
      "Epoch 357/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1824 - mean_squared_error: 0.0562 - val_loss: 0.1981 - val_mean_squared_error: 0.0626\n",
      "Epoch 358/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1823 - mean_squared_error: 0.0561 - val_loss: 0.1980 - val_mean_squared_error: 0.0626\n",
      "Epoch 359/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1823 - mean_squared_error: 0.0562 - val_loss: 0.1982 - val_mean_squared_error: 0.0626\n",
      "Epoch 360/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1823 - mean_squared_error: 0.0561 - val_loss: 0.1981 - val_mean_squared_error: 0.0625\n",
      "Epoch 361/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1826 - mean_squared_error: 0.0563 - val_loss: 0.1978 - val_mean_squared_error: 0.0626\n",
      "Epoch 362/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1823 - mean_squared_error: 0.0561 - val_loss: 0.1982 - val_mean_squared_error: 0.0626\n",
      "Epoch 363/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1823 - mean_squared_error: 0.0561 - val_loss: 0.1982 - val_mean_squared_error: 0.0625\n",
      "Epoch 364/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1822 - mean_squared_error: 0.0561 - val_loss: 0.1979 - val_mean_squared_error: 0.0626\n",
      "Epoch 365/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1823 - mean_squared_error: 0.0562 - val_loss: 0.1979 - val_mean_squared_error: 0.0626\n",
      "Epoch 366/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1822 - mean_squared_error: 0.0561 - val_loss: 0.1979 - val_mean_squared_error: 0.0626\n",
      "Epoch 367/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1822 - mean_squared_error: 0.0561 - val_loss: 0.1980 - val_mean_squared_error: 0.0625\n",
      "Epoch 368/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1822 - mean_squared_error: 0.0561 - val_loss: 0.1981 - val_mean_squared_error: 0.0625\n",
      "Epoch 369/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1822 - mean_squared_error: 0.0561 - val_loss: 0.1978 - val_mean_squared_error: 0.0625\n",
      "Epoch 370/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1821 - mean_squared_error: 0.0561 - val_loss: 0.1979 - val_mean_squared_error: 0.0625\n",
      "Epoch 371/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1821 - mean_squared_error: 0.0561 - val_loss: 0.1979 - val_mean_squared_error: 0.0626\n",
      "Epoch 372/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1821 - mean_squared_error: 0.0561 - val_loss: 0.1978 - val_mean_squared_error: 0.0626\n",
      "Epoch 373/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1821 - mean_squared_error: 0.0561 - val_loss: 0.1979 - val_mean_squared_error: 0.0627\n",
      "Epoch 374/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1821 - mean_squared_error: 0.0562 - val_loss: 0.1980 - val_mean_squared_error: 0.0626\n",
      "Epoch 375/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1822 - mean_squared_error: 0.0562 - val_loss: 0.1980 - val_mean_squared_error: 0.0626\n",
      "Epoch 376/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1821 - mean_squared_error: 0.0562 - val_loss: 0.1977 - val_mean_squared_error: 0.0626\n",
      "Epoch 377/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1821 - mean_squared_error: 0.0561 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 378/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1820 - mean_squared_error: 0.0560 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 379/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1821 - mean_squared_error: 0.0560 - val_loss: 0.1975 - val_mean_squared_error: 0.0624\n",
      "Epoch 380/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1820 - mean_squared_error: 0.0560 - val_loss: 0.1976 - val_mean_squared_error: 0.0624\n",
      "Epoch 381/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1820 - mean_squared_error: 0.0560 - val_loss: 0.1978 - val_mean_squared_error: 0.0625\n",
      "Epoch 382/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1821 - mean_squared_error: 0.0561 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 383/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1820 - mean_squared_error: 0.0560 - val_loss: 0.1978 - val_mean_squared_error: 0.0625\n",
      "Epoch 384/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1819 - mean_squared_error: 0.0560 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 385/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1820 - mean_squared_error: 0.0560 - val_loss: 0.1975 - val_mean_squared_error: 0.0626\n",
      "Epoch 386/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1819 - mean_squared_error: 0.0560 - val_loss: 0.1975 - val_mean_squared_error: 0.0625\n",
      "Epoch 387/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1819 - mean_squared_error: 0.0560 - val_loss: 0.1979 - val_mean_squared_error: 0.0625\n",
      "Epoch 388/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1819 - mean_squared_error: 0.0560 - val_loss: 0.1975 - val_mean_squared_error: 0.0624\n",
      "Epoch 389/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1819 - mean_squared_error: 0.0560 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 390/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1818 - mean_squared_error: 0.0560 - val_loss: 0.1976 - val_mean_squared_error: 0.0625\n",
      "Epoch 391/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1818 - mean_squared_error: 0.0560 - val_loss: 0.1976 - val_mean_squared_error: 0.0626\n",
      "Epoch 392/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1819 - mean_squared_error: 0.0561 - val_loss: 0.1977 - val_mean_squared_error: 0.0626\n",
      "Epoch 393/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1817 - mean_squared_error: 0.0560 - val_loss: 0.1978 - val_mean_squared_error: 0.0625\n",
      "Epoch 394/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1817 - mean_squared_error: 0.0560 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 395/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1817 - mean_squared_error: 0.0560 - val_loss: 0.1976 - val_mean_squared_error: 0.0625\n",
      "Epoch 396/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1817 - mean_squared_error: 0.0559 - val_loss: 0.1974 - val_mean_squared_error: 0.0624\n",
      "Epoch 397/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1818 - mean_squared_error: 0.0560 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 398/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1818 - mean_squared_error: 0.0560 - val_loss: 0.1974 - val_mean_squared_error: 0.0625\n",
      "Epoch 399/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1817 - mean_squared_error: 0.0560 - val_loss: 0.1975 - val_mean_squared_error: 0.0626\n",
      "Epoch 400/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1816 - mean_squared_error: 0.0560 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 401/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1817 - mean_squared_error: 0.0560 - val_loss: 0.1978 - val_mean_squared_error: 0.0626\n",
      "Epoch 402/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1817 - mean_squared_error: 0.0560 - val_loss: 0.1975 - val_mean_squared_error: 0.0625\n",
      "Epoch 403/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1816 - mean_squared_error: 0.0559 - val_loss: 0.1975 - val_mean_squared_error: 0.0625\n",
      "Epoch 404/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1817 - mean_squared_error: 0.0560 - val_loss: 0.1977 - val_mean_squared_error: 0.0625\n",
      "Epoch 405/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1815 - mean_squared_error: 0.0558 - val_loss: 0.1973 - val_mean_squared_error: 0.0624\n",
      "Epoch 406/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1817 - mean_squared_error: 0.0559 - val_loss: 0.1971 - val_mean_squared_error: 0.0625\n",
      "Epoch 407/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1819 - mean_squared_error: 0.0560 - val_loss: 0.1970 - val_mean_squared_error: 0.0624\n",
      "Epoch 408/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1816 - mean_squared_error: 0.0558 - val_loss: 0.1976 - val_mean_squared_error: 0.0623\n",
      "Epoch 409/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1815 - mean_squared_error: 0.0558 - val_loss: 0.1974 - val_mean_squared_error: 0.0623\n",
      "Epoch 410/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1815 - mean_squared_error: 0.0558 - val_loss: 0.1973 - val_mean_squared_error: 0.0624\n",
      "Epoch 411/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1816 - mean_squared_error: 0.0559 - val_loss: 0.1971 - val_mean_squared_error: 0.0624\n",
      "Epoch 412/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1816 - mean_squared_error: 0.0559 - val_loss: 0.1974 - val_mean_squared_error: 0.0623\n",
      "Epoch 413/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1814 - mean_squared_error: 0.0558 - val_loss: 0.1971 - val_mean_squared_error: 0.0624\n",
      "Epoch 414/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1816 - mean_squared_error: 0.0558 - val_loss: 0.1969 - val_mean_squared_error: 0.0624\n",
      "Epoch 415/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1814 - mean_squared_error: 0.0559 - val_loss: 0.1974 - val_mean_squared_error: 0.0624\n",
      "Epoch 416/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1813 - mean_squared_error: 0.0558 - val_loss: 0.1973 - val_mean_squared_error: 0.0624\n",
      "Epoch 417/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1813 - mean_squared_error: 0.0558 - val_loss: 0.1972 - val_mean_squared_error: 0.0624\n",
      "Epoch 418/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1814 - mean_squared_error: 0.0558 - val_loss: 0.1969 - val_mean_squared_error: 0.0622\n",
      "Epoch 419/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1813 - mean_squared_error: 0.0557 - val_loss: 0.1970 - val_mean_squared_error: 0.0623\n",
      "Epoch 420/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1812 - mean_squared_error: 0.0558 - val_loss: 0.1971 - val_mean_squared_error: 0.0623\n",
      "Epoch 421/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1812 - mean_squared_error: 0.0558 - val_loss: 0.1974 - val_mean_squared_error: 0.0625\n",
      "Epoch 422/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1812 - mean_squared_error: 0.0558 - val_loss: 0.1972 - val_mean_squared_error: 0.0623\n",
      "Epoch 423/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1812 - mean_squared_error: 0.0557 - val_loss: 0.1968 - val_mean_squared_error: 0.0623\n",
      "Epoch 424/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1812 - mean_squared_error: 0.0558 - val_loss: 0.1970 - val_mean_squared_error: 0.0623\n",
      "Epoch 425/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1811 - mean_squared_error: 0.0557 - val_loss: 0.1968 - val_mean_squared_error: 0.0622\n",
      "Epoch 426/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1811 - mean_squared_error: 0.0557 - val_loss: 0.1967 - val_mean_squared_error: 0.0623\n",
      "Epoch 427/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1811 - mean_squared_error: 0.0557 - val_loss: 0.1968 - val_mean_squared_error: 0.0623\n",
      "Epoch 428/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1811 - mean_squared_error: 0.0557 - val_loss: 0.1970 - val_mean_squared_error: 0.0622\n",
      "Epoch 429/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1810 - mean_squared_error: 0.0556 - val_loss: 0.1967 - val_mean_squared_error: 0.0622\n",
      "Epoch 430/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1810 - mean_squared_error: 0.0556 - val_loss: 0.1966 - val_mean_squared_error: 0.0622\n",
      "Epoch 431/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1810 - mean_squared_error: 0.0556 - val_loss: 0.1967 - val_mean_squared_error: 0.0621\n",
      "Epoch 432/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1810 - mean_squared_error: 0.0556 - val_loss: 0.1967 - val_mean_squared_error: 0.0621\n",
      "Epoch 433/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1809 - mean_squared_error: 0.0555 - val_loss: 0.1966 - val_mean_squared_error: 0.0621\n",
      "Epoch 434/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1810 - mean_squared_error: 0.0556 - val_loss: 0.1964 - val_mean_squared_error: 0.0623\n",
      "Epoch 435/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1811 - mean_squared_error: 0.0557 - val_loss: 0.1967 - val_mean_squared_error: 0.0622\n",
      "Epoch 436/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1808 - mean_squared_error: 0.0556 - val_loss: 0.1967 - val_mean_squared_error: 0.0623\n",
      "Epoch 437/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1808 - mean_squared_error: 0.0555 - val_loss: 0.1966 - val_mean_squared_error: 0.0621\n",
      "Epoch 438/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1809 - mean_squared_error: 0.0555 - val_loss: 0.1964 - val_mean_squared_error: 0.0621\n",
      "Epoch 439/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1808 - mean_squared_error: 0.0555 - val_loss: 0.1965 - val_mean_squared_error: 0.0621\n",
      "Epoch 440/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1807 - mean_squared_error: 0.0554 - val_loss: 0.1964 - val_mean_squared_error: 0.0620\n",
      "Epoch 441/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1808 - mean_squared_error: 0.0555 - val_loss: 0.1966 - val_mean_squared_error: 0.0622\n",
      "Epoch 442/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1807 - mean_squared_error: 0.0555 - val_loss: 0.1964 - val_mean_squared_error: 0.0621\n",
      "Epoch 443/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1808 - mean_squared_error: 0.0556 - val_loss: 0.1963 - val_mean_squared_error: 0.0622\n",
      "Epoch 444/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1807 - mean_squared_error: 0.0555 - val_loss: 0.1965 - val_mean_squared_error: 0.0621\n",
      "Epoch 445/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1806 - mean_squared_error: 0.0555 - val_loss: 0.1966 - val_mean_squared_error: 0.0621\n",
      "Epoch 446/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1806 - mean_squared_error: 0.0554 - val_loss: 0.1964 - val_mean_squared_error: 0.0621\n",
      "Epoch 447/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1805 - mean_squared_error: 0.0554 - val_loss: 0.1962 - val_mean_squared_error: 0.0620\n",
      "Epoch 448/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1806 - mean_squared_error: 0.0554 - val_loss: 0.1960 - val_mean_squared_error: 0.0619\n",
      "Epoch 449/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1805 - mean_squared_error: 0.0553 - val_loss: 0.1961 - val_mean_squared_error: 0.0620\n",
      "Epoch 450/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1804 - mean_squared_error: 0.0553 - val_loss: 0.1963 - val_mean_squared_error: 0.0619\n",
      "Epoch 451/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1804 - mean_squared_error: 0.0553 - val_loss: 0.1963 - val_mean_squared_error: 0.0619\n",
      "Epoch 452/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1805 - mean_squared_error: 0.0553 - val_loss: 0.1961 - val_mean_squared_error: 0.0619\n",
      "Epoch 453/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1804 - mean_squared_error: 0.0553 - val_loss: 0.1959 - val_mean_squared_error: 0.0618\n",
      "Epoch 454/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1805 - mean_squared_error: 0.0553 - val_loss: 0.1962 - val_mean_squared_error: 0.0619\n",
      "Epoch 455/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1804 - mean_squared_error: 0.0553 - val_loss: 0.1960 - val_mean_squared_error: 0.0619\n",
      "Epoch 456/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1804 - mean_squared_error: 0.0553 - val_loss: 0.1957 - val_mean_squared_error: 0.0619\n",
      "Epoch 457/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1804 - mean_squared_error: 0.0553 - val_loss: 0.1959 - val_mean_squared_error: 0.0618\n",
      "Epoch 458/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1802 - mean_squared_error: 0.0552 - val_loss: 0.1957 - val_mean_squared_error: 0.0618\n",
      "Epoch 459/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1802 - mean_squared_error: 0.0552 - val_loss: 0.1958 - val_mean_squared_error: 0.0618\n",
      "Epoch 460/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1802 - mean_squared_error: 0.0552 - val_loss: 0.1957 - val_mean_squared_error: 0.0618\n",
      "Epoch 461/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1803 - mean_squared_error: 0.0553 - val_loss: 0.1959 - val_mean_squared_error: 0.0619\n",
      "Epoch 462/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1802 - mean_squared_error: 0.0552 - val_loss: 0.1955 - val_mean_squared_error: 0.0618\n",
      "Epoch 463/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1802 - mean_squared_error: 0.0552 - val_loss: 0.1958 - val_mean_squared_error: 0.0619\n",
      "Epoch 464/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1800 - mean_squared_error: 0.0552 - val_loss: 0.1958 - val_mean_squared_error: 0.0619\n",
      "Epoch 465/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1800 - mean_squared_error: 0.0552 - val_loss: 0.1957 - val_mean_squared_error: 0.0618\n",
      "Epoch 466/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1802 - mean_squared_error: 0.0553 - val_loss: 0.1956 - val_mean_squared_error: 0.0619\n",
      "Epoch 467/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1798 - mean_squared_error: 0.0552 - val_loss: 0.1960 - val_mean_squared_error: 0.0620\n",
      "Epoch 468/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1801 - mean_squared_error: 0.0553 - val_loss: 0.1962 - val_mean_squared_error: 0.0619\n",
      "Epoch 469/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1798 - mean_squared_error: 0.0552 - val_loss: 0.1956 - val_mean_squared_error: 0.0620\n",
      "Epoch 470/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1798 - mean_squared_error: 0.0552 - val_loss: 0.1955 - val_mean_squared_error: 0.0620\n",
      "Epoch 471/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1798 - mean_squared_error: 0.0552 - val_loss: 0.1954 - val_mean_squared_error: 0.0619\n",
      "Epoch 472/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1799 - mean_squared_error: 0.0552 - val_loss: 0.1956 - val_mean_squared_error: 0.0618\n",
      "Epoch 473/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1797 - mean_squared_error: 0.0551 - val_loss: 0.1954 - val_mean_squared_error: 0.0619\n",
      "Epoch 474/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1799 - mean_squared_error: 0.0552 - val_loss: 0.1956 - val_mean_squared_error: 0.0618\n",
      "Epoch 475/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1797 - mean_squared_error: 0.0550 - val_loss: 0.1953 - val_mean_squared_error: 0.0617\n",
      "Epoch 476/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1796 - mean_squared_error: 0.0550 - val_loss: 0.1954 - val_mean_squared_error: 0.0617\n",
      "Epoch 477/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1796 - mean_squared_error: 0.0550 - val_loss: 0.1955 - val_mean_squared_error: 0.0618\n",
      "Epoch 478/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1796 - mean_squared_error: 0.0551 - val_loss: 0.1953 - val_mean_squared_error: 0.0619\n",
      "Epoch 479/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1795 - mean_squared_error: 0.0551 - val_loss: 0.1954 - val_mean_squared_error: 0.0618\n",
      "Epoch 480/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1796 - mean_squared_error: 0.0551 - val_loss: 0.1953 - val_mean_squared_error: 0.0618\n",
      "Epoch 481/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1795 - mean_squared_error: 0.0550 - val_loss: 0.1950 - val_mean_squared_error: 0.0618\n",
      "Epoch 482/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1794 - mean_squared_error: 0.0550 - val_loss: 0.1952 - val_mean_squared_error: 0.0617\n",
      "Epoch 483/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1794 - mean_squared_error: 0.0549 - val_loss: 0.1953 - val_mean_squared_error: 0.0616\n",
      "Epoch 484/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1793 - mean_squared_error: 0.0549 - val_loss: 0.1949 - val_mean_squared_error: 0.0617\n",
      "Epoch 485/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1793 - mean_squared_error: 0.0549 - val_loss: 0.1949 - val_mean_squared_error: 0.0616\n",
      "Epoch 486/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1793 - mean_squared_error: 0.0548 - val_loss: 0.1947 - val_mean_squared_error: 0.0616\n",
      "Epoch 487/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1792 - mean_squared_error: 0.0549 - val_loss: 0.1948 - val_mean_squared_error: 0.0617\n",
      "Epoch 488/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1793 - mean_squared_error: 0.0549 - val_loss: 0.1951 - val_mean_squared_error: 0.0617\n",
      "Epoch 489/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1794 - mean_squared_error: 0.0549 - val_loss: 0.1946 - val_mean_squared_error: 0.0615\n",
      "Epoch 490/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1791 - mean_squared_error: 0.0549 - val_loss: 0.1950 - val_mean_squared_error: 0.0617\n",
      "Epoch 491/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1790 - mean_squared_error: 0.0548 - val_loss: 0.1947 - val_mean_squared_error: 0.0616\n",
      "Epoch 492/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1791 - mean_squared_error: 0.0548 - val_loss: 0.1946 - val_mean_squared_error: 0.0616\n",
      "Epoch 493/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1790 - mean_squared_error: 0.0548 - val_loss: 0.1949 - val_mean_squared_error: 0.0617\n",
      "Epoch 494/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1790 - mean_squared_error: 0.0548 - val_loss: 0.1947 - val_mean_squared_error: 0.0616\n",
      "Epoch 495/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1789 - mean_squared_error: 0.0549 - val_loss: 0.1945 - val_mean_squared_error: 0.0617\n",
      "Epoch 496/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1789 - mean_squared_error: 0.0548 - val_loss: 0.1944 - val_mean_squared_error: 0.0616\n",
      "Epoch 497/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1788 - mean_squared_error: 0.0548 - val_loss: 0.1945 - val_mean_squared_error: 0.0616\n",
      "Epoch 498/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1792 - mean_squared_error: 0.0549 - val_loss: 0.1950 - val_mean_squared_error: 0.0616\n",
      "Epoch 499/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1789 - mean_squared_error: 0.0548 - val_loss: 0.1940 - val_mean_squared_error: 0.0616\n",
      "Epoch 500/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1788 - mean_squared_error: 0.0547 - val_loss: 0.1940 - val_mean_squared_error: 0.0614\n",
      "Epoch 501/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1787 - mean_squared_error: 0.0546 - val_loss: 0.1943 - val_mean_squared_error: 0.0614\n",
      "Epoch 502/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1787 - mean_squared_error: 0.0546 - val_loss: 0.1944 - val_mean_squared_error: 0.0614\n",
      "Epoch 503/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1787 - mean_squared_error: 0.0546 - val_loss: 0.1939 - val_mean_squared_error: 0.0615\n",
      "Epoch 504/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1786 - mean_squared_error: 0.0546 - val_loss: 0.1943 - val_mean_squared_error: 0.0615\n",
      "Epoch 505/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1788 - mean_squared_error: 0.0548 - val_loss: 0.1947 - val_mean_squared_error: 0.0615\n",
      "Epoch 506/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1785 - mean_squared_error: 0.0547 - val_loss: 0.1940 - val_mean_squared_error: 0.0615\n",
      "Epoch 507/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1785 - mean_squared_error: 0.0546 - val_loss: 0.1938 - val_mean_squared_error: 0.0615\n",
      "Epoch 508/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1784 - mean_squared_error: 0.0546 - val_loss: 0.1941 - val_mean_squared_error: 0.0614\n",
      "Epoch 509/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1784 - mean_squared_error: 0.0546 - val_loss: 0.1943 - val_mean_squared_error: 0.0615\n",
      "Epoch 510/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1784 - mean_squared_error: 0.0545 - val_loss: 0.1938 - val_mean_squared_error: 0.0612\n",
      "Epoch 511/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1783 - mean_squared_error: 0.0544 - val_loss: 0.1937 - val_mean_squared_error: 0.0613\n",
      "Epoch 512/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1783 - mean_squared_error: 0.0545 - val_loss: 0.1935 - val_mean_squared_error: 0.0612\n",
      "Epoch 513/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1782 - mean_squared_error: 0.0544 - val_loss: 0.1938 - val_mean_squared_error: 0.0612\n",
      "Epoch 514/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1782 - mean_squared_error: 0.0544 - val_loss: 0.1936 - val_mean_squared_error: 0.0611\n",
      "Epoch 515/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1783 - mean_squared_error: 0.0545 - val_loss: 0.1933 - val_mean_squared_error: 0.0613\n",
      "Epoch 516/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1781 - mean_squared_error: 0.0544 - val_loss: 0.1934 - val_mean_squared_error: 0.0611\n",
      "Epoch 517/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1783 - mean_squared_error: 0.0544 - val_loss: 0.1937 - val_mean_squared_error: 0.0612\n",
      "Epoch 518/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1780 - mean_squared_error: 0.0543 - val_loss: 0.1932 - val_mean_squared_error: 0.0611\n",
      "Epoch 519/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1780 - mean_squared_error: 0.0544 - val_loss: 0.1934 - val_mean_squared_error: 0.0613\n",
      "Epoch 520/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1779 - mean_squared_error: 0.0544 - val_loss: 0.1938 - val_mean_squared_error: 0.0612\n",
      "Epoch 521/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1780 - mean_squared_error: 0.0544 - val_loss: 0.1934 - val_mean_squared_error: 0.0612\n",
      "Epoch 522/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1779 - mean_squared_error: 0.0544 - val_loss: 0.1931 - val_mean_squared_error: 0.0611\n",
      "Epoch 523/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1780 - mean_squared_error: 0.0543 - val_loss: 0.1935 - val_mean_squared_error: 0.0611\n",
      "Epoch 524/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1777 - mean_squared_error: 0.0542 - val_loss: 0.1930 - val_mean_squared_error: 0.0610\n",
      "Epoch 525/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1778 - mean_squared_error: 0.0542 - val_loss: 0.1928 - val_mean_squared_error: 0.0609\n",
      "Epoch 526/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1777 - mean_squared_error: 0.0541 - val_loss: 0.1928 - val_mean_squared_error: 0.0609\n",
      "Epoch 527/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1777 - mean_squared_error: 0.0542 - val_loss: 0.1933 - val_mean_squared_error: 0.0612\n",
      "Epoch 528/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1777 - mean_squared_error: 0.0543 - val_loss: 0.1931 - val_mean_squared_error: 0.0612\n",
      "Epoch 529/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1779 - mean_squared_error: 0.0544 - val_loss: 0.1932 - val_mean_squared_error: 0.0610\n",
      "Epoch 530/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1775 - mean_squared_error: 0.0542 - val_loss: 0.1927 - val_mean_squared_error: 0.0611\n",
      "Epoch 531/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1775 - mean_squared_error: 0.0542 - val_loss: 0.1927 - val_mean_squared_error: 0.0610\n",
      "Epoch 532/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1774 - mean_squared_error: 0.0542 - val_loss: 0.1929 - val_mean_squared_error: 0.0611\n",
      "Epoch 533/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1774 - mean_squared_error: 0.0542 - val_loss: 0.1928 - val_mean_squared_error: 0.0610\n",
      "Epoch 534/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1773 - mean_squared_error: 0.0542 - val_loss: 0.1927 - val_mean_squared_error: 0.0611\n",
      "Epoch 535/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1773 - mean_squared_error: 0.0541 - val_loss: 0.1927 - val_mean_squared_error: 0.0608\n",
      "Epoch 536/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1772 - mean_squared_error: 0.0540 - val_loss: 0.1929 - val_mean_squared_error: 0.0610\n",
      "Epoch 537/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1772 - mean_squared_error: 0.0540 - val_loss: 0.1926 - val_mean_squared_error: 0.0608\n",
      "Epoch 538/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1774 - mean_squared_error: 0.0541 - val_loss: 0.1921 - val_mean_squared_error: 0.0609\n",
      "Epoch 539/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1770 - mean_squared_error: 0.0539 - val_loss: 0.1924 - val_mean_squared_error: 0.0607\n",
      "Epoch 540/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1772 - mean_squared_error: 0.0540 - val_loss: 0.1929 - val_mean_squared_error: 0.0608\n",
      "Epoch 541/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1771 - mean_squared_error: 0.0539 - val_loss: 0.1921 - val_mean_squared_error: 0.0607\n",
      "Epoch 542/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1770 - mean_squared_error: 0.0539 - val_loss: 0.1920 - val_mean_squared_error: 0.0608\n",
      "Epoch 543/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1769 - mean_squared_error: 0.0539 - val_loss: 0.1922 - val_mean_squared_error: 0.0608\n",
      "Epoch 544/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1770 - mean_squared_error: 0.0538 - val_loss: 0.1919 - val_mean_squared_error: 0.0604\n",
      "Epoch 545/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1769 - mean_squared_error: 0.0538 - val_loss: 0.1919 - val_mean_squared_error: 0.0606\n",
      "Epoch 546/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1768 - mean_squared_error: 0.0538 - val_loss: 0.1919 - val_mean_squared_error: 0.0606\n",
      "Epoch 547/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1768 - mean_squared_error: 0.0538 - val_loss: 0.1921 - val_mean_squared_error: 0.0608\n",
      "Epoch 548/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1767 - mean_squared_error: 0.0539 - val_loss: 0.1923 - val_mean_squared_error: 0.0608\n",
      "Epoch 549/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1767 - mean_squared_error: 0.0538 - val_loss: 0.1917 - val_mean_squared_error: 0.0605\n",
      "Epoch 550/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1766 - mean_squared_error: 0.0537 - val_loss: 0.1918 - val_mean_squared_error: 0.0605\n",
      "Epoch 551/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1766 - mean_squared_error: 0.0538 - val_loss: 0.1916 - val_mean_squared_error: 0.0607\n",
      "Epoch 552/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1767 - mean_squared_error: 0.0537 - val_loss: 0.1919 - val_mean_squared_error: 0.0605\n",
      "Epoch 553/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1765 - mean_squared_error: 0.0536 - val_loss: 0.1917 - val_mean_squared_error: 0.0605\n",
      "Epoch 554/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1765 - mean_squared_error: 0.0537 - val_loss: 0.1913 - val_mean_squared_error: 0.0607\n",
      "Epoch 555/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1765 - mean_squared_error: 0.0537 - val_loss: 0.1916 - val_mean_squared_error: 0.0605\n",
      "Epoch 556/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1763 - mean_squared_error: 0.0536 - val_loss: 0.1915 - val_mean_squared_error: 0.0605\n",
      "Epoch 557/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1762 - mean_squared_error: 0.0536 - val_loss: 0.1915 - val_mean_squared_error: 0.0605\n",
      "Epoch 558/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1762 - mean_squared_error: 0.0536 - val_loss: 0.1911 - val_mean_squared_error: 0.0606\n",
      "Epoch 559/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1762 - mean_squared_error: 0.0537 - val_loss: 0.1913 - val_mean_squared_error: 0.0606\n",
      "Epoch 560/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1761 - mean_squared_error: 0.0535 - val_loss: 0.1914 - val_mean_squared_error: 0.0604\n",
      "Epoch 561/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1761 - mean_squared_error: 0.0535 - val_loss: 0.1911 - val_mean_squared_error: 0.0604\n",
      "Epoch 562/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1760 - mean_squared_error: 0.0535 - val_loss: 0.1913 - val_mean_squared_error: 0.0604\n",
      "Epoch 563/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1761 - mean_squared_error: 0.0536 - val_loss: 0.1915 - val_mean_squared_error: 0.0605\n",
      "Epoch 564/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1760 - mean_squared_error: 0.0536 - val_loss: 0.1909 - val_mean_squared_error: 0.0606\n",
      "Epoch 565/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1759 - mean_squared_error: 0.0536 - val_loss: 0.1910 - val_mean_squared_error: 0.0603\n",
      "Epoch 566/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1759 - mean_squared_error: 0.0533 - val_loss: 0.1906 - val_mean_squared_error: 0.0600\n",
      "Epoch 567/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1760 - mean_squared_error: 0.0534 - val_loss: 0.1909 - val_mean_squared_error: 0.0601\n",
      "Epoch 568/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1758 - mean_squared_error: 0.0534 - val_loss: 0.1906 - val_mean_squared_error: 0.0602\n",
      "Epoch 569/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1757 - mean_squared_error: 0.0535 - val_loss: 0.1908 - val_mean_squared_error: 0.0605\n",
      "Epoch 570/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1757 - mean_squared_error: 0.0536 - val_loss: 0.1908 - val_mean_squared_error: 0.0606\n",
      "Epoch 571/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1758 - mean_squared_error: 0.0537 - val_loss: 0.1909 - val_mean_squared_error: 0.0605\n",
      "Epoch 572/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1755 - mean_squared_error: 0.0534 - val_loss: 0.1906 - val_mean_squared_error: 0.0604\n",
      "Epoch 573/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1755 - mean_squared_error: 0.0533 - val_loss: 0.1908 - val_mean_squared_error: 0.0602\n",
      "Epoch 574/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1754 - mean_squared_error: 0.0532 - val_loss: 0.1907 - val_mean_squared_error: 0.0601\n",
      "Epoch 575/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1753 - mean_squared_error: 0.0532 - val_loss: 0.1906 - val_mean_squared_error: 0.0603\n",
      "Epoch 576/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1756 - mean_squared_error: 0.0535 - val_loss: 0.1904 - val_mean_squared_error: 0.0605\n",
      "Epoch 577/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1752 - mean_squared_error: 0.0534 - val_loss: 0.1907 - val_mean_squared_error: 0.0605\n",
      "Epoch 578/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1756 - mean_squared_error: 0.0535 - val_loss: 0.1911 - val_mean_squared_error: 0.0605\n",
      "Epoch 579/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1760 - mean_squared_error: 0.0536 - val_loss: 0.1899 - val_mean_squared_error: 0.0604\n",
      "Epoch 580/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1753 - mean_squared_error: 0.0533 - val_loss: 0.1906 - val_mean_squared_error: 0.0602\n",
      "Epoch 581/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1752 - mean_squared_error: 0.0531 - val_loss: 0.1907 - val_mean_squared_error: 0.0600\n",
      "Epoch 582/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1754 - mean_squared_error: 0.0532 - val_loss: 0.1898 - val_mean_squared_error: 0.0601\n",
      "Epoch 583/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1751 - mean_squared_error: 0.0531 - val_loss: 0.1902 - val_mean_squared_error: 0.0601\n",
      "Epoch 584/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1750 - mean_squared_error: 0.0531 - val_loss: 0.1906 - val_mean_squared_error: 0.0603\n",
      "Epoch 585/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1752 - mean_squared_error: 0.0533 - val_loss: 0.1908 - val_mean_squared_error: 0.0605\n",
      "Epoch 586/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1751 - mean_squared_error: 0.0533 - val_loss: 0.1898 - val_mean_squared_error: 0.0603\n",
      "Epoch 587/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1749 - mean_squared_error: 0.0533 - val_loss: 0.1900 - val_mean_squared_error: 0.0602\n",
      "Epoch 588/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1747 - mean_squared_error: 0.0530 - val_loss: 0.1904 - val_mean_squared_error: 0.0600\n",
      "Epoch 589/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1750 - mean_squared_error: 0.0531 - val_loss: 0.1902 - val_mean_squared_error: 0.0600\n",
      "Epoch 590/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1750 - mean_squared_error: 0.0531 - val_loss: 0.1900 - val_mean_squared_error: 0.0600\n",
      "Epoch 591/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1748 - mean_squared_error: 0.0531 - val_loss: 0.1892 - val_mean_squared_error: 0.0601\n",
      "Epoch 592/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1749 - mean_squared_error: 0.0532 - val_loss: 0.1895 - val_mean_squared_error: 0.0602\n",
      "Epoch 593/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1748 - mean_squared_error: 0.0532 - val_loss: 0.1905 - val_mean_squared_error: 0.0603\n",
      "Epoch 594/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1747 - mean_squared_error: 0.0532 - val_loss: 0.1900 - val_mean_squared_error: 0.0602\n",
      "Epoch 595/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1749 - mean_squared_error: 0.0532 - val_loss: 0.1895 - val_mean_squared_error: 0.0602\n",
      "Epoch 596/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1745 - mean_squared_error: 0.0530 - val_loss: 0.1900 - val_mean_squared_error: 0.0601\n",
      "Epoch 597/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1746 - mean_squared_error: 0.0529 - val_loss: 0.1898 - val_mean_squared_error: 0.0599\n",
      "Epoch 598/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1746 - mean_squared_error: 0.0530 - val_loss: 0.1893 - val_mean_squared_error: 0.0600\n",
      "Epoch 599/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1744 - mean_squared_error: 0.0531 - val_loss: 0.1900 - val_mean_squared_error: 0.0603\n",
      "Epoch 600/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1744 - mean_squared_error: 0.0531 - val_loss: 0.1896 - val_mean_squared_error: 0.0602\n",
      "Epoch 601/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1744 - mean_squared_error: 0.0531 - val_loss: 0.1891 - val_mean_squared_error: 0.0600\n",
      "Epoch 602/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1743 - mean_squared_error: 0.0529 - val_loss: 0.1895 - val_mean_squared_error: 0.0601\n",
      "Epoch 603/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1743 - mean_squared_error: 0.0531 - val_loss: 0.1902 - val_mean_squared_error: 0.0603\n",
      "Epoch 604/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1742 - mean_squared_error: 0.0530 - val_loss: 0.1897 - val_mean_squared_error: 0.0603\n",
      "Epoch 605/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1743 - mean_squared_error: 0.0532 - val_loss: 0.1891 - val_mean_squared_error: 0.0603\n",
      "Epoch 606/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1743 - mean_squared_error: 0.0530 - val_loss: 0.1890 - val_mean_squared_error: 0.0599\n",
      "Epoch 607/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1741 - mean_squared_error: 0.0529 - val_loss: 0.1894 - val_mean_squared_error: 0.0599\n",
      "Epoch 608/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1742 - mean_squared_error: 0.0529 - val_loss: 0.1896 - val_mean_squared_error: 0.0601\n",
      "Epoch 609/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1740 - mean_squared_error: 0.0529 - val_loss: 0.1888 - val_mean_squared_error: 0.0601\n",
      "Epoch 610/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1743 - mean_squared_error: 0.0529 - val_loss: 0.1895 - val_mean_squared_error: 0.0599\n",
      "Epoch 611/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1740 - mean_squared_error: 0.0529 - val_loss: 0.1890 - val_mean_squared_error: 0.0600\n",
      "Epoch 612/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1741 - mean_squared_error: 0.0530 - val_loss: 0.1888 - val_mean_squared_error: 0.0601\n",
      "Epoch 613/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1739 - mean_squared_error: 0.0530 - val_loss: 0.1894 - val_mean_squared_error: 0.0601\n",
      "Epoch 614/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1739 - mean_squared_error: 0.0530 - val_loss: 0.1897 - val_mean_squared_error: 0.0602\n",
      "Epoch 615/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1737 - mean_squared_error: 0.0529 - val_loss: 0.1889 - val_mean_squared_error: 0.0602\n",
      "Epoch 616/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1739 - mean_squared_error: 0.0531 - val_loss: 0.1887 - val_mean_squared_error: 0.0602\n",
      "Epoch 617/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1740 - mean_squared_error: 0.0529 - val_loss: 0.1892 - val_mean_squared_error: 0.0599\n",
      "Epoch 618/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1737 - mean_squared_error: 0.0529 - val_loss: 0.1888 - val_mean_squared_error: 0.0601\n",
      "Epoch 619/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1738 - mean_squared_error: 0.0530 - val_loss: 0.1892 - val_mean_squared_error: 0.0602\n",
      "Epoch 620/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1737 - mean_squared_error: 0.0530 - val_loss: 0.1885 - val_mean_squared_error: 0.0601\n",
      "Epoch 621/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1737 - mean_squared_error: 0.0529 - val_loss: 0.1891 - val_mean_squared_error: 0.0600\n",
      "Epoch 622/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1736 - mean_squared_error: 0.0529 - val_loss: 0.1889 - val_mean_squared_error: 0.0601\n",
      "Epoch 623/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1735 - mean_squared_error: 0.0528 - val_loss: 0.1886 - val_mean_squared_error: 0.0599\n",
      "Epoch 624/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1734 - mean_squared_error: 0.0527 - val_loss: 0.1885 - val_mean_squared_error: 0.0599\n",
      "Epoch 625/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1734 - mean_squared_error: 0.0527 - val_loss: 0.1886 - val_mean_squared_error: 0.0599\n",
      "Epoch 626/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1733 - mean_squared_error: 0.0527 - val_loss: 0.1890 - val_mean_squared_error: 0.0600\n",
      "Epoch 627/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1734 - mean_squared_error: 0.0528 - val_loss: 0.1890 - val_mean_squared_error: 0.0602\n",
      "Epoch 628/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1733 - mean_squared_error: 0.0528 - val_loss: 0.1887 - val_mean_squared_error: 0.0600\n",
      "Epoch 629/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1734 - mean_squared_error: 0.0527 - val_loss: 0.1884 - val_mean_squared_error: 0.0596\n",
      "Epoch 630/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1733 - mean_squared_error: 0.0527 - val_loss: 0.1885 - val_mean_squared_error: 0.0600\n",
      "Epoch 631/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1733 - mean_squared_error: 0.0526 - val_loss: 0.1886 - val_mean_squared_error: 0.0597\n",
      "Epoch 632/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1732 - mean_squared_error: 0.0526 - val_loss: 0.1882 - val_mean_squared_error: 0.0597\n",
      "Epoch 633/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1732 - mean_squared_error: 0.0528 - val_loss: 0.1883 - val_mean_squared_error: 0.0601\n",
      "Epoch 634/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1733 - mean_squared_error: 0.0528 - val_loss: 0.1883 - val_mean_squared_error: 0.0600\n",
      "Epoch 635/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1735 - mean_squared_error: 0.0529 - val_loss: 0.1891 - val_mean_squared_error: 0.0600\n",
      "Epoch 636/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1730 - mean_squared_error: 0.0526 - val_loss: 0.1882 - val_mean_squared_error: 0.0597\n",
      "Epoch 637/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1733 - mean_squared_error: 0.0527 - val_loss: 0.1877 - val_mean_squared_error: 0.0596\n",
      "Epoch 638/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1731 - mean_squared_error: 0.0527 - val_loss: 0.1881 - val_mean_squared_error: 0.0598\n",
      "Epoch 639/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1732 - mean_squared_error: 0.0527 - val_loss: 0.1891 - val_mean_squared_error: 0.0599\n",
      "Epoch 640/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1731 - mean_squared_error: 0.0526 - val_loss: 0.1881 - val_mean_squared_error: 0.0596\n",
      "Epoch 641/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1732 - mean_squared_error: 0.0527 - val_loss: 0.1876 - val_mean_squared_error: 0.0597\n",
      "Epoch 642/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1737 - mean_squared_error: 0.0529 - val_loss: 0.1888 - val_mean_squared_error: 0.0598\n",
      "Epoch 643/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1730 - mean_squared_error: 0.0528 - val_loss: 0.1875 - val_mean_squared_error: 0.0599\n",
      "Epoch 644/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1733 - mean_squared_error: 0.0527 - val_loss: 0.1883 - val_mean_squared_error: 0.0596\n",
      "Epoch 645/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1727 - mean_squared_error: 0.0525 - val_loss: 0.1880 - val_mean_squared_error: 0.0597\n",
      "Epoch 646/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1729 - mean_squared_error: 0.0526 - val_loss: 0.1876 - val_mean_squared_error: 0.0598\n",
      "Epoch 647/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1727 - mean_squared_error: 0.0526 - val_loss: 0.1881 - val_mean_squared_error: 0.0598\n",
      "Epoch 648/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1726 - mean_squared_error: 0.0525 - val_loss: 0.1885 - val_mean_squared_error: 0.0597\n",
      "Epoch 649/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1728 - mean_squared_error: 0.0526 - val_loss: 0.1877 - val_mean_squared_error: 0.0595\n",
      "Epoch 650/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1728 - mean_squared_error: 0.0524 - val_loss: 0.1877 - val_mean_squared_error: 0.0595\n",
      "Epoch 651/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1726 - mean_squared_error: 0.0523 - val_loss: 0.1881 - val_mean_squared_error: 0.0595\n",
      "Epoch 652/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1726 - mean_squared_error: 0.0524 - val_loss: 0.1876 - val_mean_squared_error: 0.0597\n",
      "Epoch 653/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1725 - mean_squared_error: 0.0525 - val_loss: 0.1879 - val_mean_squared_error: 0.0597\n",
      "Epoch 654/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1724 - mean_squared_error: 0.0525 - val_loss: 0.1879 - val_mean_squared_error: 0.0596\n",
      "Epoch 655/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1725 - mean_squared_error: 0.0523 - val_loss: 0.1874 - val_mean_squared_error: 0.0593\n",
      "Epoch 656/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1726 - mean_squared_error: 0.0523 - val_loss: 0.1877 - val_mean_squared_error: 0.0594\n",
      "Epoch 657/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1727 - mean_squared_error: 0.0525 - val_loss: 0.1872 - val_mean_squared_error: 0.0597\n",
      "Epoch 658/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1725 - mean_squared_error: 0.0524 - val_loss: 0.1880 - val_mean_squared_error: 0.0595\n",
      "Epoch 659/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1723 - mean_squared_error: 0.0523 - val_loss: 0.1874 - val_mean_squared_error: 0.0595\n",
      "Epoch 660/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1725 - mean_squared_error: 0.0524 - val_loss: 0.1871 - val_mean_squared_error: 0.0594\n",
      "Epoch 661/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1724 - mean_squared_error: 0.0523 - val_loss: 0.1877 - val_mean_squared_error: 0.0595\n",
      "Epoch 662/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1726 - mean_squared_error: 0.0525 - val_loss: 0.1873 - val_mean_squared_error: 0.0595\n",
      "Epoch 663/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1721 - mean_squared_error: 0.0522 - val_loss: 0.1878 - val_mean_squared_error: 0.0593\n",
      "Epoch 664/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1724 - mean_squared_error: 0.0522 - val_loss: 0.1878 - val_mean_squared_error: 0.0594\n",
      "Epoch 665/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1723 - mean_squared_error: 0.0524 - val_loss: 0.1871 - val_mean_squared_error: 0.0599\n",
      "Epoch 666/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1726 - mean_squared_error: 0.0526 - val_loss: 0.1879 - val_mean_squared_error: 0.0596\n",
      "Epoch 667/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1720 - mean_squared_error: 0.0522 - val_loss: 0.1870 - val_mean_squared_error: 0.0594\n",
      "Epoch 668/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1722 - mean_squared_error: 0.0522 - val_loss: 0.1868 - val_mean_squared_error: 0.0592\n",
      "Epoch 669/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1722 - mean_squared_error: 0.0522 - val_loss: 0.1866 - val_mean_squared_error: 0.0591\n",
      "Epoch 670/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1719 - mean_squared_error: 0.0520 - val_loss: 0.1870 - val_mean_squared_error: 0.0591\n",
      "Epoch 671/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1720 - mean_squared_error: 0.0521 - val_loss: 0.1876 - val_mean_squared_error: 0.0594\n",
      "Epoch 672/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1720 - mean_squared_error: 0.0521 - val_loss: 0.1871 - val_mean_squared_error: 0.0595\n",
      "Epoch 673/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1719 - mean_squared_error: 0.0524 - val_loss: 0.1870 - val_mean_squared_error: 0.0597\n",
      "Epoch 674/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1719 - mean_squared_error: 0.0522 - val_loss: 0.1869 - val_mean_squared_error: 0.0592\n",
      "Epoch 675/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1726 - mean_squared_error: 0.0521 - val_loss: 0.1877 - val_mean_squared_error: 0.0592\n",
      "Epoch 676/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1721 - mean_squared_error: 0.0520 - val_loss: 0.1863 - val_mean_squared_error: 0.0593\n",
      "Epoch 677/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1720 - mean_squared_error: 0.0522 - val_loss: 0.1867 - val_mean_squared_error: 0.0590\n",
      "Epoch 678/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1718 - mean_squared_error: 0.0520 - val_loss: 0.1869 - val_mean_squared_error: 0.0592\n",
      "Epoch 679/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1718 - mean_squared_error: 0.0521 - val_loss: 0.1865 - val_mean_squared_error: 0.0593\n",
      "Epoch 680/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1719 - mean_squared_error: 0.0520 - val_loss: 0.1868 - val_mean_squared_error: 0.0590\n",
      "Epoch 681/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1717 - mean_squared_error: 0.0519 - val_loss: 0.1869 - val_mean_squared_error: 0.0593\n",
      "Epoch 682/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1718 - mean_squared_error: 0.0522 - val_loss: 0.1869 - val_mean_squared_error: 0.0595\n",
      "Epoch 683/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1717 - mean_squared_error: 0.0523 - val_loss: 0.1870 - val_mean_squared_error: 0.0596\n",
      "Epoch 684/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1717 - mean_squared_error: 0.0523 - val_loss: 0.1868 - val_mean_squared_error: 0.0594\n",
      "Epoch 685/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1715 - mean_squared_error: 0.0520 - val_loss: 0.1872 - val_mean_squared_error: 0.0591\n",
      "Epoch 686/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1719 - mean_squared_error: 0.0520 - val_loss: 0.1870 - val_mean_squared_error: 0.0590\n",
      "Epoch 687/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1720 - mean_squared_error: 0.0521 - val_loss: 0.1861 - val_mean_squared_error: 0.0592\n",
      "Epoch 688/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1717 - mean_squared_error: 0.0521 - val_loss: 0.1865 - val_mean_squared_error: 0.0591\n",
      "Epoch 689/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1715 - mean_squared_error: 0.0518 - val_loss: 0.1865 - val_mean_squared_error: 0.0588\n",
      "Epoch 690/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1717 - mean_squared_error: 0.0518 - val_loss: 0.1870 - val_mean_squared_error: 0.0592\n",
      "Epoch 691/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1718 - mean_squared_error: 0.0522 - val_loss: 0.1861 - val_mean_squared_error: 0.0593\n",
      "Epoch 692/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1715 - mean_squared_error: 0.0521 - val_loss: 0.1870 - val_mean_squared_error: 0.0592\n",
      "Epoch 693/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1715 - mean_squared_error: 0.0520 - val_loss: 0.1871 - val_mean_squared_error: 0.0592\n",
      "Epoch 694/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1714 - mean_squared_error: 0.0518 - val_loss: 0.1865 - val_mean_squared_error: 0.0590\n",
      "Epoch 695/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1714 - mean_squared_error: 0.0520 - val_loss: 0.1861 - val_mean_squared_error: 0.0592\n",
      "Epoch 696/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1716 - mean_squared_error: 0.0522 - val_loss: 0.1863 - val_mean_squared_error: 0.0591\n",
      "Epoch 697/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1714 - mean_squared_error: 0.0519 - val_loss: 0.1868 - val_mean_squared_error: 0.0589\n",
      "Epoch 698/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1713 - mean_squared_error: 0.0517 - val_loss: 0.1862 - val_mean_squared_error: 0.0588\n",
      "Epoch 699/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1713 - mean_squared_error: 0.0518 - val_loss: 0.1862 - val_mean_squared_error: 0.0589\n",
      "Epoch 700/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1713 - mean_squared_error: 0.0519 - val_loss: 0.1859 - val_mean_squared_error: 0.0590\n",
      "Epoch 701/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1712 - mean_squared_error: 0.0519 - val_loss: 0.1863 - val_mean_squared_error: 0.0591\n",
      "Epoch 702/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1715 - mean_squared_error: 0.0520 - val_loss: 0.1861 - val_mean_squared_error: 0.0589\n",
      "Epoch 703/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1712 - mean_squared_error: 0.0518 - val_loss: 0.1865 - val_mean_squared_error: 0.0589\n",
      "Epoch 704/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1712 - mean_squared_error: 0.0519 - val_loss: 0.1865 - val_mean_squared_error: 0.0591\n",
      "Epoch 705/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1711 - mean_squared_error: 0.0517 - val_loss: 0.1857 - val_mean_squared_error: 0.0586\n",
      "Epoch 706/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1712 - mean_squared_error: 0.0516 - val_loss: 0.1856 - val_mean_squared_error: 0.0584\n",
      "Epoch 707/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1712 - mean_squared_error: 0.0515 - val_loss: 0.1861 - val_mean_squared_error: 0.0585\n",
      "Epoch 708/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1711 - mean_squared_error: 0.0516 - val_loss: 0.1860 - val_mean_squared_error: 0.0587\n",
      "Epoch 709/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1710 - mean_squared_error: 0.0517 - val_loss: 0.1858 - val_mean_squared_error: 0.0588\n",
      "Epoch 710/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1710 - mean_squared_error: 0.0517 - val_loss: 0.1859 - val_mean_squared_error: 0.0588\n",
      "Epoch 711/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1711 - mean_squared_error: 0.0517 - val_loss: 0.1856 - val_mean_squared_error: 0.0587\n",
      "Epoch 712/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1710 - mean_squared_error: 0.0517 - val_loss: 0.1862 - val_mean_squared_error: 0.0588\n",
      "Epoch 713/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1710 - mean_squared_error: 0.0516 - val_loss: 0.1860 - val_mean_squared_error: 0.0586\n",
      "Epoch 714/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1709 - mean_squared_error: 0.0516 - val_loss: 0.1853 - val_mean_squared_error: 0.0587\n",
      "Epoch 715/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1710 - mean_squared_error: 0.0517 - val_loss: 0.1860 - val_mean_squared_error: 0.0588\n",
      "Epoch 716/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1710 - mean_squared_error: 0.0517 - val_loss: 0.1859 - val_mean_squared_error: 0.0587\n",
      "Epoch 717/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1711 - mean_squared_error: 0.0518 - val_loss: 0.1853 - val_mean_squared_error: 0.0588\n",
      "Epoch 718/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1709 - mean_squared_error: 0.0517 - val_loss: 0.1856 - val_mean_squared_error: 0.0587\n",
      "Epoch 719/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1708 - mean_squared_error: 0.0516 - val_loss: 0.1858 - val_mean_squared_error: 0.0585\n",
      "Epoch 720/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1708 - mean_squared_error: 0.0515 - val_loss: 0.1861 - val_mean_squared_error: 0.0587\n",
      "Epoch 721/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1707 - mean_squared_error: 0.0515 - val_loss: 0.1855 - val_mean_squared_error: 0.0587\n",
      "Epoch 722/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1708 - mean_squared_error: 0.0518 - val_loss: 0.1854 - val_mean_squared_error: 0.0588\n",
      "Epoch 723/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1707 - mean_squared_error: 0.0516 - val_loss: 0.1854 - val_mean_squared_error: 0.0584\n",
      "Epoch 724/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1707 - mean_squared_error: 0.0514 - val_loss: 0.1855 - val_mean_squared_error: 0.0583\n",
      "Epoch 725/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1707 - mean_squared_error: 0.0514 - val_loss: 0.1857 - val_mean_squared_error: 0.0583\n",
      "Epoch 726/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1707 - mean_squared_error: 0.0515 - val_loss: 0.1854 - val_mean_squared_error: 0.0586\n",
      "Epoch 727/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1707 - mean_squared_error: 0.0516 - val_loss: 0.1854 - val_mean_squared_error: 0.0585\n",
      "Epoch 728/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1708 - mean_squared_error: 0.0515 - val_loss: 0.1849 - val_mean_squared_error: 0.0586\n",
      "Epoch 729/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1708 - mean_squared_error: 0.0514 - val_loss: 0.1856 - val_mean_squared_error: 0.0581\n",
      "Epoch 730/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1706 - mean_squared_error: 0.0512 - val_loss: 0.1852 - val_mean_squared_error: 0.0583\n",
      "Epoch 731/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1707 - mean_squared_error: 0.0516 - val_loss: 0.1853 - val_mean_squared_error: 0.0587\n",
      "Epoch 732/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1705 - mean_squared_error: 0.0516 - val_loss: 0.1855 - val_mean_squared_error: 0.0587\n",
      "Epoch 733/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1705 - mean_squared_error: 0.0514 - val_loss: 0.1850 - val_mean_squared_error: 0.0583\n",
      "Epoch 734/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1706 - mean_squared_error: 0.0514 - val_loss: 0.1851 - val_mean_squared_error: 0.0583\n",
      "Epoch 735/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1705 - mean_squared_error: 0.0513 - val_loss: 0.1851 - val_mean_squared_error: 0.0581\n",
      "Epoch 736/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1705 - mean_squared_error: 0.0512 - val_loss: 0.1854 - val_mean_squared_error: 0.0582\n",
      "Epoch 737/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1704 - mean_squared_error: 0.0513 - val_loss: 0.1850 - val_mean_squared_error: 0.0583\n",
      "Epoch 738/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1705 - mean_squared_error: 0.0514 - val_loss: 0.1849 - val_mean_squared_error: 0.0583\n",
      "Epoch 739/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1703 - mean_squared_error: 0.0513 - val_loss: 0.1849 - val_mean_squared_error: 0.0582\n",
      "Epoch 740/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1703 - mean_squared_error: 0.0512 - val_loss: 0.1851 - val_mean_squared_error: 0.0582\n",
      "Epoch 741/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1704 - mean_squared_error: 0.0514 - val_loss: 0.1849 - val_mean_squared_error: 0.0584\n",
      "Epoch 742/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1703 - mean_squared_error: 0.0513 - val_loss: 0.1853 - val_mean_squared_error: 0.0583\n",
      "Epoch 743/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1705 - mean_squared_error: 0.0514 - val_loss: 0.1850 - val_mean_squared_error: 0.0584\n",
      "Epoch 744/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1703 - mean_squared_error: 0.0513 - val_loss: 0.1854 - val_mean_squared_error: 0.0583\n",
      "Epoch 745/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1705 - mean_squared_error: 0.0515 - val_loss: 0.1847 - val_mean_squared_error: 0.0585\n",
      "Epoch 746/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1703 - mean_squared_error: 0.0514 - val_loss: 0.1850 - val_mean_squared_error: 0.0582\n",
      "Epoch 747/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1703 - mean_squared_error: 0.0512 - val_loss: 0.1848 - val_mean_squared_error: 0.0581\n",
      "Epoch 748/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1702 - mean_squared_error: 0.0511 - val_loss: 0.1846 - val_mean_squared_error: 0.0579\n",
      "Epoch 749/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1702 - mean_squared_error: 0.0512 - val_loss: 0.1843 - val_mean_squared_error: 0.0579\n",
      "Epoch 750/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1701 - mean_squared_error: 0.0510 - val_loss: 0.1851 - val_mean_squared_error: 0.0579\n",
      "Epoch 751/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1702 - mean_squared_error: 0.0510 - val_loss: 0.1847 - val_mean_squared_error: 0.0580\n",
      "Epoch 752/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1700 - mean_squared_error: 0.0511 - val_loss: 0.1846 - val_mean_squared_error: 0.0582\n",
      "Epoch 753/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1704 - mean_squared_error: 0.0515 - val_loss: 0.1847 - val_mean_squared_error: 0.0584\n",
      "Epoch 754/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1698 - mean_squared_error: 0.0513 - val_loss: 0.1851 - val_mean_squared_error: 0.0581\n",
      "Epoch 755/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1701 - mean_squared_error: 0.0510 - val_loss: 0.1848 - val_mean_squared_error: 0.0577\n",
      "Epoch 756/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1700 - mean_squared_error: 0.0509 - val_loss: 0.1841 - val_mean_squared_error: 0.0577\n",
      "Epoch 757/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1700 - mean_squared_error: 0.0510 - val_loss: 0.1844 - val_mean_squared_error: 0.0579\n",
      "Epoch 758/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1701 - mean_squared_error: 0.0512 - val_loss: 0.1846 - val_mean_squared_error: 0.0580\n",
      "Epoch 759/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1704 - mean_squared_error: 0.0513 - val_loss: 0.1853 - val_mean_squared_error: 0.0582\n",
      "Epoch 760/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1697 - mean_squared_error: 0.0509 - val_loss: 0.1842 - val_mean_squared_error: 0.0581\n",
      "Epoch 761/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1706 - mean_squared_error: 0.0515 - val_loss: 0.1840 - val_mean_squared_error: 0.0582\n",
      "Epoch 762/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1700 - mean_squared_error: 0.0511 - val_loss: 0.1848 - val_mean_squared_error: 0.0577\n",
      "Epoch 763/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1699 - mean_squared_error: 0.0510 - val_loss: 0.1846 - val_mean_squared_error: 0.0580\n",
      "Epoch 764/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1700 - mean_squared_error: 0.0512 - val_loss: 0.1842 - val_mean_squared_error: 0.0581\n",
      "Epoch 765/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1701 - mean_squared_error: 0.0512 - val_loss: 0.1848 - val_mean_squared_error: 0.0579\n",
      "Epoch 766/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1700 - mean_squared_error: 0.0511 - val_loss: 0.1839 - val_mean_squared_error: 0.0578\n",
      "Epoch 767/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1698 - mean_squared_error: 0.0509 - val_loss: 0.1841 - val_mean_squared_error: 0.0575\n",
      "Epoch 768/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1699 - mean_squared_error: 0.0509 - val_loss: 0.1844 - val_mean_squared_error: 0.0579\n",
      "Epoch 769/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1698 - mean_squared_error: 0.0509 - val_loss: 0.1844 - val_mean_squared_error: 0.0578\n",
      "Epoch 770/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1700 - mean_squared_error: 0.0512 - val_loss: 0.1840 - val_mean_squared_error: 0.0581\n",
      "Epoch 771/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1701 - mean_squared_error: 0.0512 - val_loss: 0.1841 - val_mean_squared_error: 0.0577\n",
      "Epoch 772/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1704 - mean_squared_error: 0.0510 - val_loss: 0.1853 - val_mean_squared_error: 0.0579\n",
      "Epoch 773/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1697 - mean_squared_error: 0.0508 - val_loss: 0.1838 - val_mean_squared_error: 0.0577\n",
      "Epoch 774/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1698 - mean_squared_error: 0.0510 - val_loss: 0.1841 - val_mean_squared_error: 0.0577\n",
      "Epoch 775/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1697 - mean_squared_error: 0.0509 - val_loss: 0.1842 - val_mean_squared_error: 0.0577\n",
      "Epoch 776/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1697 - mean_squared_error: 0.0510 - val_loss: 0.1840 - val_mean_squared_error: 0.0579\n",
      "Epoch 777/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1697 - mean_squared_error: 0.0509 - val_loss: 0.1840 - val_mean_squared_error: 0.0575\n",
      "Epoch 778/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1696 - mean_squared_error: 0.0508 - val_loss: 0.1840 - val_mean_squared_error: 0.0577\n",
      "Epoch 779/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1697 - mean_squared_error: 0.0508 - val_loss: 0.1839 - val_mean_squared_error: 0.0577\n",
      "Epoch 780/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1699 - mean_squared_error: 0.0510 - val_loss: 0.1844 - val_mean_squared_error: 0.0578\n",
      "Epoch 781/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1700 - mean_squared_error: 0.0512 - val_loss: 0.1838 - val_mean_squared_error: 0.0579\n",
      "Epoch 782/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1697 - mean_squared_error: 0.0508 - val_loss: 0.1850 - val_mean_squared_error: 0.0577\n",
      "Epoch 783/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1697 - mean_squared_error: 0.0508 - val_loss: 0.1841 - val_mean_squared_error: 0.0576\n",
      "Epoch 784/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1694 - mean_squared_error: 0.0508 - val_loss: 0.1837 - val_mean_squared_error: 0.0577\n",
      "Epoch 785/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1698 - mean_squared_error: 0.0508 - val_loss: 0.1838 - val_mean_squared_error: 0.0573\n",
      "Epoch 786/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1697 - mean_squared_error: 0.0508 - val_loss: 0.1838 - val_mean_squared_error: 0.0578\n",
      "Epoch 787/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1694 - mean_squared_error: 0.0509 - val_loss: 0.1839 - val_mean_squared_error: 0.0578\n",
      "Epoch 788/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1695 - mean_squared_error: 0.0510 - val_loss: 0.1843 - val_mean_squared_error: 0.0579\n",
      "Epoch 789/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1694 - mean_squared_error: 0.0508 - val_loss: 0.1835 - val_mean_squared_error: 0.0574\n",
      "Epoch 790/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1695 - mean_squared_error: 0.0507 - val_loss: 0.1834 - val_mean_squared_error: 0.0574\n",
      "Epoch 791/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1693 - mean_squared_error: 0.0506 - val_loss: 0.1840 - val_mean_squared_error: 0.0573\n",
      "Epoch 792/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1707 - mean_squared_error: 0.0509 - val_loss: 0.1848 - val_mean_squared_error: 0.0575\n",
      "Epoch 793/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1695 - mean_squared_error: 0.0508 - val_loss: 0.1836 - val_mean_squared_error: 0.0581\n",
      "Epoch 794/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1699 - mean_squared_error: 0.0511 - val_loss: 0.1839 - val_mean_squared_error: 0.0577\n",
      "Epoch 795/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1693 - mean_squared_error: 0.0508 - val_loss: 0.1837 - val_mean_squared_error: 0.0575\n",
      "Epoch 796/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1697 - mean_squared_error: 0.0510 - val_loss: 0.1835 - val_mean_squared_error: 0.0574\n",
      "Epoch 797/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1694 - mean_squared_error: 0.0507 - val_loss: 0.1839 - val_mean_squared_error: 0.0574\n",
      "Epoch 798/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1697 - mean_squared_error: 0.0510 - val_loss: 0.1837 - val_mean_squared_error: 0.0578\n",
      "Epoch 799/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1695 - mean_squared_error: 0.0508 - val_loss: 0.1839 - val_mean_squared_error: 0.0574\n",
      "Epoch 800/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1695 - mean_squared_error: 0.0508 - val_loss: 0.1831 - val_mean_squared_error: 0.0574\n",
      "Epoch 801/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1695 - mean_squared_error: 0.0507 - val_loss: 0.1838 - val_mean_squared_error: 0.0573\n",
      "Epoch 802/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1692 - mean_squared_error: 0.0506 - val_loss: 0.1834 - val_mean_squared_error: 0.0574\n",
      "Epoch 803/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1692 - mean_squared_error: 0.0506 - val_loss: 0.1835 - val_mean_squared_error: 0.0574\n",
      "Epoch 804/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1694 - mean_squared_error: 0.0507 - val_loss: 0.1838 - val_mean_squared_error: 0.0574\n",
      "Epoch 805/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1691 - mean_squared_error: 0.0506 - val_loss: 0.1832 - val_mean_squared_error: 0.0575\n",
      "Epoch 806/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1695 - mean_squared_error: 0.0509 - val_loss: 0.1837 - val_mean_squared_error: 0.0574\n",
      "Epoch 807/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1692 - mean_squared_error: 0.0506 - val_loss: 0.1836 - val_mean_squared_error: 0.0573\n",
      "Epoch 808/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1694 - mean_squared_error: 0.0508 - val_loss: 0.1835 - val_mean_squared_error: 0.0576\n",
      "Epoch 809/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1692 - mean_squared_error: 0.0506 - val_loss: 0.1836 - val_mean_squared_error: 0.0571\n",
      "Epoch 810/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1692 - mean_squared_error: 0.0506 - val_loss: 0.1833 - val_mean_squared_error: 0.0573\n",
      "Epoch 811/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1692 - mean_squared_error: 0.0505 - val_loss: 0.1833 - val_mean_squared_error: 0.0571\n",
      "Epoch 812/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1691 - mean_squared_error: 0.0506 - val_loss: 0.1834 - val_mean_squared_error: 0.0576\n",
      "Epoch 813/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1692 - mean_squared_error: 0.0508 - val_loss: 0.1837 - val_mean_squared_error: 0.0574\n",
      "Epoch 814/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1691 - mean_squared_error: 0.0507 - val_loss: 0.1833 - val_mean_squared_error: 0.0574\n",
      "Epoch 815/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1690 - mean_squared_error: 0.0506 - val_loss: 0.1834 - val_mean_squared_error: 0.0573\n",
      "Epoch 816/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1692 - mean_squared_error: 0.0504 - val_loss: 0.1833 - val_mean_squared_error: 0.0569\n",
      "Epoch 817/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1690 - mean_squared_error: 0.0503 - val_loss: 0.1830 - val_mean_squared_error: 0.0569\n",
      "Epoch 818/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1691 - mean_squared_error: 0.0505 - val_loss: 0.1831 - val_mean_squared_error: 0.0572\n",
      "Epoch 819/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1691 - mean_squared_error: 0.0505 - val_loss: 0.1831 - val_mean_squared_error: 0.0570\n",
      "Epoch 820/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1691 - mean_squared_error: 0.0505 - val_loss: 0.1831 - val_mean_squared_error: 0.0573\n",
      "Epoch 821/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1688 - mean_squared_error: 0.0504 - val_loss: 0.1837 - val_mean_squared_error: 0.0573\n",
      "Epoch 822/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1691 - mean_squared_error: 0.0504 - val_loss: 0.1831 - val_mean_squared_error: 0.0571\n",
      "Epoch 823/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1690 - mean_squared_error: 0.0504 - val_loss: 0.1831 - val_mean_squared_error: 0.0570\n",
      "Epoch 824/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1691 - mean_squared_error: 0.0504 - val_loss: 0.1826 - val_mean_squared_error: 0.0570\n",
      "Epoch 825/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1689 - mean_squared_error: 0.0504 - val_loss: 0.1831 - val_mean_squared_error: 0.0570\n",
      "Epoch 826/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1691 - mean_squared_error: 0.0504 - val_loss: 0.1832 - val_mean_squared_error: 0.0571\n",
      "Epoch 827/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1695 - mean_squared_error: 0.0506 - val_loss: 0.1823 - val_mean_squared_error: 0.0568\n",
      "Epoch 828/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1688 - mean_squared_error: 0.0504 - val_loss: 0.1833 - val_mean_squared_error: 0.0571\n",
      "Epoch 829/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1690 - mean_squared_error: 0.0504 - val_loss: 0.1836 - val_mean_squared_error: 0.0571\n",
      "Epoch 830/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1693 - mean_squared_error: 0.0506 - val_loss: 0.1826 - val_mean_squared_error: 0.0573\n",
      "Epoch 831/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1690 - mean_squared_error: 0.0506 - val_loss: 0.1834 - val_mean_squared_error: 0.0573\n",
      "Epoch 832/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1688 - mean_squared_error: 0.0503 - val_loss: 0.1831 - val_mean_squared_error: 0.0570\n",
      "Epoch 833/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1688 - mean_squared_error: 0.0503 - val_loss: 0.1829 - val_mean_squared_error: 0.0568\n",
      "Epoch 834/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1690 - mean_squared_error: 0.0503 - val_loss: 0.1824 - val_mean_squared_error: 0.0569\n",
      "Epoch 835/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1688 - mean_squared_error: 0.0503 - val_loss: 0.1830 - val_mean_squared_error: 0.0571\n",
      "Epoch 836/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1687 - mean_squared_error: 0.0503 - val_loss: 0.1831 - val_mean_squared_error: 0.0569\n",
      "Epoch 837/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1689 - mean_squared_error: 0.0503 - val_loss: 0.1825 - val_mean_squared_error: 0.0568\n",
      "Epoch 838/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1690 - mean_squared_error: 0.0503 - val_loss: 0.1829 - val_mean_squared_error: 0.0567\n",
      "Epoch 839/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1689 - mean_squared_error: 0.0504 - val_loss: 0.1826 - val_mean_squared_error: 0.0570\n",
      "Epoch 840/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0503 - val_loss: 0.1831 - val_mean_squared_error: 0.0569\n",
      "Epoch 841/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1687 - mean_squared_error: 0.0502 - val_loss: 0.1830 - val_mean_squared_error: 0.0569\n",
      "Epoch 842/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1686 - mean_squared_error: 0.0503 - val_loss: 0.1827 - val_mean_squared_error: 0.0570\n",
      "Epoch 843/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1687 - mean_squared_error: 0.0503 - val_loss: 0.1827 - val_mean_squared_error: 0.0569\n",
      "Epoch 844/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1686 - mean_squared_error: 0.0502 - val_loss: 0.1827 - val_mean_squared_error: 0.0567\n",
      "Epoch 845/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1687 - mean_squared_error: 0.0502 - val_loss: 0.1826 - val_mean_squared_error: 0.0569\n",
      "Epoch 846/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0502 - val_loss: 0.1831 - val_mean_squared_error: 0.0570\n",
      "Epoch 847/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1688 - mean_squared_error: 0.0504 - val_loss: 0.1827 - val_mean_squared_error: 0.0570\n",
      "Epoch 848/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1688 - mean_squared_error: 0.0502 - val_loss: 0.1828 - val_mean_squared_error: 0.0565\n",
      "Epoch 849/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1691 - mean_squared_error: 0.0504 - val_loss: 0.1824 - val_mean_squared_error: 0.0569\n",
      "Epoch 850/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1685 - mean_squared_error: 0.0502 - val_loss: 0.1834 - val_mean_squared_error: 0.0570\n",
      "Epoch 851/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1688 - mean_squared_error: 0.0501 - val_loss: 0.1826 - val_mean_squared_error: 0.0566\n",
      "Epoch 852/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1688 - mean_squared_error: 0.0502 - val_loss: 0.1820 - val_mean_squared_error: 0.0568\n",
      "Epoch 853/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1685 - mean_squared_error: 0.0501 - val_loss: 0.1827 - val_mean_squared_error: 0.0568\n",
      "Epoch 854/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1687 - mean_squared_error: 0.0503 - val_loss: 0.1828 - val_mean_squared_error: 0.0569\n",
      "Epoch 855/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0502 - val_loss: 0.1829 - val_mean_squared_error: 0.0568\n",
      "Epoch 856/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0501 - val_loss: 0.1821 - val_mean_squared_error: 0.0566\n",
      "Epoch 857/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1685 - mean_squared_error: 0.0501 - val_loss: 0.1825 - val_mean_squared_error: 0.0566\n",
      "Epoch 858/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1686 - mean_squared_error: 0.0501 - val_loss: 0.1825 - val_mean_squared_error: 0.0567\n",
      "Epoch 859/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0502 - val_loss: 0.1826 - val_mean_squared_error: 0.0566\n",
      "Epoch 860/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1686 - mean_squared_error: 0.0501 - val_loss: 0.1823 - val_mean_squared_error: 0.0566\n",
      "Epoch 861/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1686 - mean_squared_error: 0.0502 - val_loss: 0.1825 - val_mean_squared_error: 0.0568\n",
      "Epoch 862/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1686 - mean_squared_error: 0.0503 - val_loss: 0.1828 - val_mean_squared_error: 0.0569\n",
      "Epoch 863/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1686 - mean_squared_error: 0.0502 - val_loss: 0.1820 - val_mean_squared_error: 0.0566\n",
      "Epoch 864/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1685 - mean_squared_error: 0.0500 - val_loss: 0.1822 - val_mean_squared_error: 0.0562\n",
      "Epoch 865/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1685 - mean_squared_error: 0.0500 - val_loss: 0.1824 - val_mean_squared_error: 0.0567\n",
      "Epoch 866/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1685 - mean_squared_error: 0.0501 - val_loss: 0.1827 - val_mean_squared_error: 0.0568\n",
      "Epoch 867/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1684 - mean_squared_error: 0.0501 - val_loss: 0.1821 - val_mean_squared_error: 0.0567\n",
      "Epoch 868/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1685 - mean_squared_error: 0.0501 - val_loss: 0.1824 - val_mean_squared_error: 0.0565\n",
      "Epoch 869/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0500 - val_loss: 0.1816 - val_mean_squared_error: 0.0565\n",
      "Epoch 870/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1683 - mean_squared_error: 0.0500 - val_loss: 0.1823 - val_mean_squared_error: 0.0565\n",
      "Epoch 871/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0500 - val_loss: 0.1824 - val_mean_squared_error: 0.0565\n",
      "Epoch 872/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1683 - mean_squared_error: 0.0501 - val_loss: 0.1820 - val_mean_squared_error: 0.0568\n",
      "Epoch 873/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1686 - mean_squared_error: 0.0502 - val_loss: 0.1818 - val_mean_squared_error: 0.0563\n",
      "Epoch 874/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1687 - mean_squared_error: 0.0500 - val_loss: 0.1822 - val_mean_squared_error: 0.0561\n",
      "Epoch 875/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1686 - mean_squared_error: 0.0499 - val_loss: 0.1817 - val_mean_squared_error: 0.0564\n",
      "Epoch 876/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1684 - mean_squared_error: 0.0500 - val_loss: 0.1821 - val_mean_squared_error: 0.0563\n",
      "Epoch 877/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1684 - mean_squared_error: 0.0500 - val_loss: 0.1820 - val_mean_squared_error: 0.0564\n",
      "Epoch 878/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0500 - val_loss: 0.1822 - val_mean_squared_error: 0.0566\n",
      "Epoch 879/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1683 - mean_squared_error: 0.0500 - val_loss: 0.1822 - val_mean_squared_error: 0.0565\n",
      "Epoch 880/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1684 - mean_squared_error: 0.0500 - val_loss: 0.1819 - val_mean_squared_error: 0.0565\n",
      "Epoch 881/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0500 - val_loss: 0.1817 - val_mean_squared_error: 0.0564\n",
      "Epoch 882/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0499 - val_loss: 0.1819 - val_mean_squared_error: 0.0562\n",
      "Epoch 883/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1682 - mean_squared_error: 0.0499 - val_loss: 0.1818 - val_mean_squared_error: 0.0564\n",
      "Epoch 884/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1683 - mean_squared_error: 0.0500 - val_loss: 0.1820 - val_mean_squared_error: 0.0565\n",
      "Epoch 885/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1687 - mean_squared_error: 0.0500 - val_loss: 0.1819 - val_mean_squared_error: 0.0562\n",
      "Epoch 886/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1690 - mean_squared_error: 0.0502 - val_loss: 0.1812 - val_mean_squared_error: 0.0565\n",
      "Epoch 887/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1681 - mean_squared_error: 0.0497 - val_loss: 0.1822 - val_mean_squared_error: 0.0562\n",
      "Epoch 888/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1685 - mean_squared_error: 0.0499 - val_loss: 0.1825 - val_mean_squared_error: 0.0563\n",
      "Epoch 889/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1683 - mean_squared_error: 0.0498 - val_loss: 0.1819 - val_mean_squared_error: 0.0565\n",
      "Epoch 890/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1682 - mean_squared_error: 0.0501 - val_loss: 0.1816 - val_mean_squared_error: 0.0565\n",
      "Epoch 891/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0499 - val_loss: 0.1818 - val_mean_squared_error: 0.0562\n",
      "Epoch 892/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1681 - mean_squared_error: 0.0498 - val_loss: 0.1819 - val_mean_squared_error: 0.0563\n",
      "Epoch 893/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1682 - mean_squared_error: 0.0497 - val_loss: 0.1817 - val_mean_squared_error: 0.0560\n",
      "Epoch 894/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0496 - val_loss: 0.1816 - val_mean_squared_error: 0.0560\n",
      "Epoch 895/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0499 - val_loss: 0.1815 - val_mean_squared_error: 0.0565\n",
      "Epoch 896/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1682 - mean_squared_error: 0.0500 - val_loss: 0.1820 - val_mean_squared_error: 0.0563\n",
      "Epoch 897/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1681 - mean_squared_error: 0.0498 - val_loss: 0.1815 - val_mean_squared_error: 0.0561\n",
      "Epoch 898/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1680 - mean_squared_error: 0.0498 - val_loss: 0.1814 - val_mean_squared_error: 0.0562\n",
      "Epoch 899/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1684 - mean_squared_error: 0.0500 - val_loss: 0.1812 - val_mean_squared_error: 0.0565\n",
      "Epoch 900/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1683 - mean_squared_error: 0.0500 - val_loss: 0.1822 - val_mean_squared_error: 0.0561\n",
      "Epoch 901/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1681 - mean_squared_error: 0.0497 - val_loss: 0.1813 - val_mean_squared_error: 0.0560\n",
      "Epoch 902/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1680 - mean_squared_error: 0.0499 - val_loss: 0.1817 - val_mean_squared_error: 0.0564\n",
      "Epoch 903/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1680 - mean_squared_error: 0.0498 - val_loss: 0.1816 - val_mean_squared_error: 0.0561\n",
      "Epoch 904/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0500 - val_loss: 0.1815 - val_mean_squared_error: 0.0564\n",
      "Epoch 905/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1687 - mean_squared_error: 0.0500 - val_loss: 0.1821 - val_mean_squared_error: 0.0562\n",
      "Epoch 906/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1681 - mean_squared_error: 0.0498 - val_loss: 0.1811 - val_mean_squared_error: 0.0561\n",
      "Epoch 907/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1680 - mean_squared_error: 0.0497 - val_loss: 0.1813 - val_mean_squared_error: 0.0559\n",
      "Epoch 908/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1680 - mean_squared_error: 0.0496 - val_loss: 0.1815 - val_mean_squared_error: 0.0559\n",
      "Epoch 909/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1682 - mean_squared_error: 0.0499 - val_loss: 0.1815 - val_mean_squared_error: 0.0564\n",
      "Epoch 910/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1680 - mean_squared_error: 0.0498 - val_loss: 0.1818 - val_mean_squared_error: 0.0561\n",
      "Epoch 911/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1683 - mean_squared_error: 0.0497 - val_loss: 0.1810 - val_mean_squared_error: 0.0561\n",
      "Epoch 912/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1679 - mean_squared_error: 0.0497 - val_loss: 0.1816 - val_mean_squared_error: 0.0560\n",
      "Epoch 913/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1679 - mean_squared_error: 0.0497 - val_loss: 0.1816 - val_mean_squared_error: 0.0561\n",
      "Epoch 914/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1680 - mean_squared_error: 0.0497 - val_loss: 0.1812 - val_mean_squared_error: 0.0560\n",
      "Epoch 915/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1679 - mean_squared_error: 0.0496 - val_loss: 0.1811 - val_mean_squared_error: 0.0559\n",
      "Epoch 916/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1679 - mean_squared_error: 0.0497 - val_loss: 0.1814 - val_mean_squared_error: 0.0561\n",
      "Epoch 917/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1685 - mean_squared_error: 0.0498 - val_loss: 0.1817 - val_mean_squared_error: 0.0561\n",
      "Epoch 918/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1680 - mean_squared_error: 0.0497 - val_loss: 0.1811 - val_mean_squared_error: 0.0562\n",
      "Epoch 919/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1678 - mean_squared_error: 0.0497 - val_loss: 0.1813 - val_mean_squared_error: 0.0561\n",
      "Epoch 920/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1678 - mean_squared_error: 0.0497 - val_loss: 0.1815 - val_mean_squared_error: 0.0561\n",
      "Epoch 921/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1679 - mean_squared_error: 0.0497 - val_loss: 0.1812 - val_mean_squared_error: 0.0560\n",
      "Epoch 922/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1678 - mean_squared_error: 0.0496 - val_loss: 0.1810 - val_mean_squared_error: 0.0560\n",
      "Epoch 923/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1678 - mean_squared_error: 0.0497 - val_loss: 0.1811 - val_mean_squared_error: 0.0561\n",
      "Epoch 924/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1679 - mean_squared_error: 0.0496 - val_loss: 0.1812 - val_mean_squared_error: 0.0558\n",
      "Epoch 925/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1677 - mean_squared_error: 0.0495 - val_loss: 0.1812 - val_mean_squared_error: 0.0558\n",
      "Epoch 926/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1679 - mean_squared_error: 0.0497 - val_loss: 0.1811 - val_mean_squared_error: 0.0561\n",
      "Epoch 927/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1677 - mean_squared_error: 0.0497 - val_loss: 0.1814 - val_mean_squared_error: 0.0560\n",
      "Epoch 928/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1678 - mean_squared_error: 0.0496 - val_loss: 0.1811 - val_mean_squared_error: 0.0558\n",
      "Epoch 929/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1679 - mean_squared_error: 0.0495 - val_loss: 0.1814 - val_mean_squared_error: 0.0558\n",
      "Epoch 930/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1677 - mean_squared_error: 0.0495 - val_loss: 0.1808 - val_mean_squared_error: 0.0559\n",
      "Epoch 931/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1679 - mean_squared_error: 0.0496 - val_loss: 0.1813 - val_mean_squared_error: 0.0559\n",
      "Epoch 932/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1676 - mean_squared_error: 0.0495 - val_loss: 0.1809 - val_mean_squared_error: 0.0559\n",
      "Epoch 933/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1678 - mean_squared_error: 0.0496 - val_loss: 0.1808 - val_mean_squared_error: 0.0559\n",
      "Epoch 934/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1677 - mean_squared_error: 0.0496 - val_loss: 0.1809 - val_mean_squared_error: 0.0558\n",
      "Epoch 935/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1677 - mean_squared_error: 0.0494 - val_loss: 0.1811 - val_mean_squared_error: 0.0557\n",
      "Epoch 936/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1676 - mean_squared_error: 0.0494 - val_loss: 0.1805 - val_mean_squared_error: 0.0555\n",
      "Epoch 937/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1678 - mean_squared_error: 0.0495 - val_loss: 0.1804 - val_mean_squared_error: 0.0556\n",
      "Epoch 938/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1677 - mean_squared_error: 0.0494 - val_loss: 0.1810 - val_mean_squared_error: 0.0556\n",
      "Epoch 939/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1677 - mean_squared_error: 0.0494 - val_loss: 0.1807 - val_mean_squared_error: 0.0557\n",
      "Epoch 940/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1678 - mean_squared_error: 0.0495 - val_loss: 0.1812 - val_mean_squared_error: 0.0558\n",
      "Epoch 941/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1678 - mean_squared_error: 0.0497 - val_loss: 0.1809 - val_mean_squared_error: 0.0560\n",
      "Epoch 942/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1676 - mean_squared_error: 0.0495 - val_loss: 0.1812 - val_mean_squared_error: 0.0558\n",
      "Epoch 943/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1677 - mean_squared_error: 0.0494 - val_loss: 0.1806 - val_mean_squared_error: 0.0556\n",
      "Epoch 944/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1676 - mean_squared_error: 0.0496 - val_loss: 0.1807 - val_mean_squared_error: 0.0560\n",
      "Epoch 945/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1681 - mean_squared_error: 0.0499 - val_loss: 0.1805 - val_mean_squared_error: 0.0558\n",
      "Epoch 946/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1675 - mean_squared_error: 0.0495 - val_loss: 0.1820 - val_mean_squared_error: 0.0560\n",
      "Epoch 947/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1678 - mean_squared_error: 0.0495 - val_loss: 0.1807 - val_mean_squared_error: 0.0558\n",
      "Epoch 948/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1676 - mean_squared_error: 0.0495 - val_loss: 0.1803 - val_mean_squared_error: 0.0556\n",
      "Epoch 949/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1674 - mean_squared_error: 0.0493 - val_loss: 0.1812 - val_mean_squared_error: 0.0557\n",
      "Epoch 950/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1675 - mean_squared_error: 0.0494 - val_loss: 0.1812 - val_mean_squared_error: 0.0559\n",
      "Epoch 951/1000\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1675 - mean_squared_error: 0.0496 - val_loss: 0.1808 - val_mean_squared_error: 0.0560\n",
      "Epoch 952/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1678 - mean_squared_error: 0.0497 - val_loss: 0.1809 - val_mean_squared_error: 0.0557\n",
      "Epoch 953/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1681 - mean_squared_error: 0.0496 - val_loss: 0.1802 - val_mean_squared_error: 0.0555\n",
      "Epoch 954/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1673 - mean_squared_error: 0.0492 - val_loss: 0.1812 - val_mean_squared_error: 0.0556\n",
      "Epoch 955/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1676 - mean_squared_error: 0.0494 - val_loss: 0.1807 - val_mean_squared_error: 0.0558\n",
      "Epoch 956/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1676 - mean_squared_error: 0.0496 - val_loss: 0.1804 - val_mean_squared_error: 0.0557\n",
      "Epoch 957/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1678 - mean_squared_error: 0.0496 - val_loss: 0.1815 - val_mean_squared_error: 0.0558\n",
      "Epoch 958/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1675 - mean_squared_error: 0.0494 - val_loss: 0.1803 - val_mean_squared_error: 0.0557\n",
      "Epoch 959/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1676 - mean_squared_error: 0.0494 - val_loss: 0.1805 - val_mean_squared_error: 0.0555\n",
      "Epoch 960/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1675 - mean_squared_error: 0.0493 - val_loss: 0.1805 - val_mean_squared_error: 0.0557\n",
      "Epoch 961/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1676 - mean_squared_error: 0.0495 - val_loss: 0.1801 - val_mean_squared_error: 0.0556\n",
      "Epoch 962/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1674 - mean_squared_error: 0.0493 - val_loss: 0.1805 - val_mean_squared_error: 0.0554\n",
      "Epoch 963/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1675 - mean_squared_error: 0.0495 - val_loss: 0.1805 - val_mean_squared_error: 0.0557\n",
      "Epoch 964/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1674 - mean_squared_error: 0.0493 - val_loss: 0.1809 - val_mean_squared_error: 0.0555\n",
      "Epoch 965/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1673 - mean_squared_error: 0.0493 - val_loss: 0.1806 - val_mean_squared_error: 0.0556\n",
      "Epoch 966/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1674 - mean_squared_error: 0.0495 - val_loss: 0.1803 - val_mean_squared_error: 0.0558\n",
      "Epoch 967/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1677 - mean_squared_error: 0.0494 - val_loss: 0.1807 - val_mean_squared_error: 0.0555\n",
      "Epoch 968/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1674 - mean_squared_error: 0.0494 - val_loss: 0.1802 - val_mean_squared_error: 0.0556\n",
      "Epoch 969/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1674 - mean_squared_error: 0.0494 - val_loss: 0.1807 - val_mean_squared_error: 0.0556\n",
      "Epoch 970/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1674 - mean_squared_error: 0.0494 - val_loss: 0.1801 - val_mean_squared_error: 0.0554\n",
      "Epoch 971/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1672 - mean_squared_error: 0.0492 - val_loss: 0.1806 - val_mean_squared_error: 0.0555\n",
      "Epoch 972/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1673 - mean_squared_error: 0.0493 - val_loss: 0.1809 - val_mean_squared_error: 0.0556\n",
      "Epoch 973/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1672 - mean_squared_error: 0.0492 - val_loss: 0.1802 - val_mean_squared_error: 0.0555\n",
      "Epoch 974/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1673 - mean_squared_error: 0.0493 - val_loss: 0.1803 - val_mean_squared_error: 0.0556\n",
      "Epoch 975/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1672 - mean_squared_error: 0.0492 - val_loss: 0.1805 - val_mean_squared_error: 0.0553\n",
      "Epoch 976/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1673 - mean_squared_error: 0.0491 - val_loss: 0.1804 - val_mean_squared_error: 0.0553\n",
      "Epoch 977/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1673 - mean_squared_error: 0.0493 - val_loss: 0.1801 - val_mean_squared_error: 0.0557\n",
      "Epoch 978/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1671 - mean_squared_error: 0.0492 - val_loss: 0.1805 - val_mean_squared_error: 0.0553\n",
      "Epoch 979/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1676 - mean_squared_error: 0.0493 - val_loss: 0.1806 - val_mean_squared_error: 0.0554\n",
      "Epoch 980/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1671 - mean_squared_error: 0.0492 - val_loss: 0.1799 - val_mean_squared_error: 0.0556\n",
      "Epoch 981/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1671 - mean_squared_error: 0.0493 - val_loss: 0.1804 - val_mean_squared_error: 0.0554\n",
      "Epoch 982/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1680 - mean_squared_error: 0.0494 - val_loss: 0.1807 - val_mean_squared_error: 0.0552\n",
      "Epoch 983/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1673 - mean_squared_error: 0.0493 - val_loss: 0.1798 - val_mean_squared_error: 0.0557\n",
      "Epoch 984/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1672 - mean_squared_error: 0.0493 - val_loss: 0.1809 - val_mean_squared_error: 0.0555\n",
      "Epoch 985/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1673 - mean_squared_error: 0.0492 - val_loss: 0.1808 - val_mean_squared_error: 0.0554\n",
      "Epoch 986/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1669 - mean_squared_error: 0.0492 - val_loss: 0.1801 - val_mean_squared_error: 0.0557\n",
      "Epoch 987/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1674 - mean_squared_error: 0.0493 - val_loss: 0.1803 - val_mean_squared_error: 0.0554\n",
      "Epoch 988/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1674 - mean_squared_error: 0.0493 - val_loss: 0.1801 - val_mean_squared_error: 0.0554\n",
      "Epoch 989/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1671 - mean_squared_error: 0.0491 - val_loss: 0.1807 - val_mean_squared_error: 0.0552\n",
      "Epoch 990/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1672 - mean_squared_error: 0.0490 - val_loss: 0.1802 - val_mean_squared_error: 0.0551\n",
      "Epoch 991/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.1671 - mean_squared_error: 0.0491 - val_loss: 0.1796 - val_mean_squared_error: 0.0555\n",
      "Epoch 992/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1671 - mean_squared_error: 0.0492 - val_loss: 0.1808 - val_mean_squared_error: 0.0556\n",
      "Epoch 993/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1675 - mean_squared_error: 0.0494 - val_loss: 0.1807 - val_mean_squared_error: 0.0557\n",
      "Epoch 994/1000\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1675 - mean_squared_error: 0.0495 - val_loss: 0.1796 - val_mean_squared_error: 0.0556\n",
      "Epoch 995/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1675 - mean_squared_error: 0.0494 - val_loss: 0.1810 - val_mean_squared_error: 0.0554\n",
      "Epoch 996/1000\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.1671 - mean_squared_error: 0.0491 - val_loss: 0.1798 - val_mean_squared_error: 0.0553\n",
      "Epoch 997/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1669 - mean_squared_error: 0.0491 - val_loss: 0.1800 - val_mean_squared_error: 0.0555\n",
      "Epoch 998/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1671 - mean_squared_error: 0.0493 - val_loss: 0.1804 - val_mean_squared_error: 0.0556\n",
      "Epoch 999/1000\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.1669 - mean_squared_error: 0.0491 - val_loss: 0.1796 - val_mean_squared_error: 0.0552\n",
      "Epoch 1000/1000\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.1677 - mean_squared_error: 0.0495 - val_loss: 0.1795 - val_mean_squared_error: 0.0552\n"
     ]
    }
   ],
   "source": [
    "model_rnn_sab_lstm.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanSquaredError()])\n",
    "\n",
    "history_rnn_sab_lstm = model_rnn_sab_lstm.fit(X_train_sab, y_train_sab, epochs=1000, batch_size = 64, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75118063 0.45268832 0.86766048 0.07141202 0.38640205 0.73308984\n",
      " 0.51343767 0.06773014 0.41213969 0.13173886]\n",
      "[[[0.5258635 ]\n",
      "  [0.5072272 ]\n",
      "  [0.44086733]\n",
      "  [0.3785783 ]\n",
      "  [0.14119187]\n",
      "  [0.22729665]\n",
      "  [0.18374458]\n",
      "  [0.18418533]\n",
      "  [0.18059209]\n",
      "  [0.18097076]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.21338949]\n",
      "  [0.19535144]\n",
      "  [0.18268816]\n",
      "  [0.17148077]\n",
      "  [0.17377713]\n",
      "  [0.17832723]\n",
      "  [0.19732882]\n",
      "  [0.23232324]\n",
      "  [0.23965411]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.5072272 ]\n",
      "  [0.44086733]\n",
      "  [0.3785783 ]\n",
      "  [0.32260758]\n",
      "  [0.5453842 ]\n",
      "  [0.44603777]\n",
      "  [0.4901899 ]\n",
      "  [0.40648717]\n",
      "  [0.57174456]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.12441817]\n",
      "  [0.09232467]\n",
      "  [0.2002886 ]\n",
      "  [0.08425954]\n",
      "  [0.16067599]\n",
      "  [0.20657784]\n",
      "  [0.23760933]\n",
      "  [0.2532969 ]\n",
      "  [0.23994486]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.3195238 ]\n",
      "  [0.2815116 ]\n",
      "  [0.48985597]\n",
      "  [0.44425893]\n",
      "  [0.46274725]\n",
      "  [0.497223  ]\n",
      "  [0.54754794]\n",
      "  [0.5413821 ]\n",
      "  [0.5308859 ]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.55248106]\n",
      "  [0.5377258 ]\n",
      "  [0.59055376]\n",
      "  [0.67385054]\n",
      "  [0.75785124]\n",
      "  [0.75717914]\n",
      "  [0.7074052 ]\n",
      "  [0.7492876 ]\n",
      "  [0.77369237]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.7499851 ]\n",
      "  [0.579826  ]\n",
      "  [0.45073843]\n",
      "  [0.36105385]\n",
      "  [0.28425694]\n",
      "  [0.23012885]\n",
      "  [0.19626293]\n",
      "  [0.17642   ]\n",
      "  [0.16656321]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.57210374]\n",
      "  [0.59176993]\n",
      "  [0.54726434]\n",
      "  [0.44759482]\n",
      "  [0.38401043]\n",
      "  [0.3395175 ]\n",
      "  [0.38093746]\n",
      "  [0.43672103]\n",
      "  [0.43779457]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.5072272 ]\n",
      "  [0.5459366 ]\n",
      "  [0.556167  ]\n",
      "  [0.44887143]\n",
      "  [0.43949357]\n",
      "  [0.43912697]\n",
      "  [0.42629036]\n",
      "  [0.45666897]\n",
      "  [0.41285223]]\n",
      "\n",
      " [[0.5258635 ]\n",
      "  [0.16854104]\n",
      "  [0.17115004]\n",
      "  [0.15313414]\n",
      "  [0.16678748]\n",
      "  [0.09038416]\n",
      "  [0.1185191 ]\n",
      "  [0.12757698]\n",
      "  [0.1494599 ]\n",
      "  [0.1529136 ]]]\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1803 - mean_squared_error: 0.0537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18027937412261963, 0.05370888486504555]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_sab = model_rnn_sab_lstm.predict(X_test_sab)\n",
    "\n",
    "model_rnn_sab_lstm.evaluate(X_test_sab, y_test_sab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rseau de neurones  nb-1 entres pour le seuil ab *model_ab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ab = np.zeros((n_sim, nb-1, 2, 2))\n",
    "\n",
    "for k1 in range(n_sim):\n",
    "    for k2 in range(nb-1):\n",
    "        dataset_ab[k1, k2, 0, 0] = dataset[k1, k2, 0]\n",
    "        dataset_ab[k1, k2, 1, 0] = dataset[k1, k2+1, 0]\n",
    "        dataset_ab[k1, k2, 0, 1] = dataset[k1, k2, 1]\n",
    "        dataset_ab[k1, k2, 1, 1] = dataset[k1, k2+1, 1]\n",
    "\n",
    "X_train_ab, X_test_ab, y_train_ab, y_test_ab = train_test_split(dataset_ab, y[:, 1], train_size = 0.7, shuffle = False)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for k in range (nb-1):\n",
    "    X_train += [X_train_ab[:, k, :]]\n",
    "    X_test += [X_test_ab[:, k, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500\n",
      "(3500, 99, 2, 2)\n",
      "3500\n",
      "[[0.5        0.7       ]\n",
      " [0.30129454 0.77527517]]\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "print(np.shape(X_train_ab))\n",
    "print(len(y_train_ab))\n",
    "print(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = [0]*(3500)\n",
    "X_test_2 = [0]*(1500)\n",
    "for k in range (len(X_train[0])):\n",
    "    X_train_2[k] = []\n",
    "    for i in range(nb-1):\n",
    "        X_train_2[k] += [X_train_ab[k, i, :]]\n",
    "for k in range (len(X_test[0])):\n",
    "    X_test_2[k] = []\n",
    "    for i in range(nb-1):\n",
    "        X_test_2[k] += [X_test_ab[k, i, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "39/39 [==============================] - 116s 399ms/step - loss: 0.4870 - mean_absolute_error: 0.4869 - val_loss: 0.4538 - val_mean_absolute_error: 0.4545\n",
      "Epoch 2/1000\n",
      "39/39 [==============================] - 3s 82ms/step - loss: 0.4447 - mean_absolute_error: 0.4419 - val_loss: 0.4211 - val_mean_absolute_error: 0.4218\n",
      "Epoch 3/1000\n",
      "39/39 [==============================] - 3s 81ms/step - loss: 0.4142 - mean_absolute_error: 0.4145 - val_loss: 0.3930 - val_mean_absolute_error: 0.3936\n",
      "Epoch 4/1000\n",
      "39/39 [==============================] - 3s 84ms/step - loss: 0.3877 - mean_absolute_error: 0.3877 - val_loss: 0.3684 - val_mean_absolute_error: 0.3690\n",
      "Epoch 5/1000\n",
      "39/39 [==============================] - 4s 95ms/step - loss: 0.3649 - mean_absolute_error: 0.3641 - val_loss: 0.3472 - val_mean_absolute_error: 0.3478\n",
      "Epoch 6/1000\n",
      "39/39 [==============================] - 3s 85ms/step - loss: 0.3451 - mean_absolute_error: 0.3464 - val_loss: 0.3288 - val_mean_absolute_error: 0.3295\n",
      "Epoch 7/1000\n",
      "39/39 [==============================] - 5s 124ms/step - loss: 0.3279 - mean_absolute_error: 0.3281 - val_loss: 0.3128 - val_mean_absolute_error: 0.3135\n",
      "Epoch 8/1000\n",
      "39/39 [==============================] - 3s 89ms/step - loss: 0.3129 - mean_absolute_error: 0.3127 - val_loss: 0.2996 - val_mean_absolute_error: 0.3002\n",
      "Epoch 9/1000\n",
      "39/39 [==============================] - 3s 82ms/step - loss: 0.2999 - mean_absolute_error: 0.2984 - val_loss: 0.2881 - val_mean_absolute_error: 0.2887\n",
      "Epoch 10/1000\n",
      "39/39 [==============================] - 3s 87ms/step - loss: 0.2888 - mean_absolute_error: 0.2872 - val_loss: 0.2792 - val_mean_absolute_error: 0.2798\n",
      "Epoch 11/1000\n",
      "39/39 [==============================] - 3s 88ms/step - loss: 0.2799 - mean_absolute_error: 0.2795 - val_loss: 0.2714 - val_mean_absolute_error: 0.2720\n",
      "Epoch 12/1000\n",
      "39/39 [==============================] - 3s 87ms/step - loss: 0.2721 - mean_absolute_error: 0.2710 - val_loss: 0.2653 - val_mean_absolute_error: 0.2660\n",
      "Epoch 13/1000\n",
      "39/39 [==============================] - 3s 83ms/step - loss: 0.2660 - mean_absolute_error: 0.2668 - val_loss: 0.2606 - val_mean_absolute_error: 0.2612\n",
      "Epoch 14/1000\n",
      "39/39 [==============================] - 3s 82ms/step - loss: 0.2612 - mean_absolute_error: 0.2605 - val_loss: 0.2569 - val_mean_absolute_error: 0.2575\n",
      "Epoch 15/1000\n",
      "39/39 [==============================] - 3s 84ms/step - loss: 0.2577 - mean_absolute_error: 0.2568 - val_loss: 0.2541 - val_mean_absolute_error: 0.2548\n",
      "Epoch 16/1000\n",
      "39/39 [==============================] - 3s 85ms/step - loss: 0.2550 - mean_absolute_error: 0.2540 - val_loss: 0.2521 - val_mean_absolute_error: 0.2528\n",
      "Epoch 17/1000\n",
      "39/39 [==============================] - 3s 82ms/step - loss: 0.2529 - mean_absolute_error: 0.2525 - val_loss: 0.2507 - val_mean_absolute_error: 0.2514\n",
      "Epoch 18/1000\n",
      "39/39 [==============================] - 3s 88ms/step - loss: 0.2514 - mean_absolute_error: 0.2509 - val_loss: 0.2497 - val_mean_absolute_error: 0.2504\n",
      "Epoch 19/1000\n",
      "39/39 [==============================] - 3s 84ms/step - loss: 0.2503 - mean_absolute_error: 0.2503 - val_loss: 0.2489 - val_mean_absolute_error: 0.2496\n",
      "Epoch 20/1000\n",
      "39/39 [==============================] - 3s 85ms/step - loss: 0.2494 - mean_absolute_error: 0.2496 - val_loss: 0.2484 - val_mean_absolute_error: 0.2491\n",
      "Epoch 21/1000\n",
      "39/39 [==============================] - 3s 84ms/step - loss: 0.2489 - mean_absolute_error: 0.2490 - val_loss: 0.2481 - val_mean_absolute_error: 0.2488\n",
      "Epoch 22/1000\n",
      "39/39 [==============================] - 3s 83ms/step - loss: 0.2485 - mean_absolute_error: 0.2483 - val_loss: 0.2478 - val_mean_absolute_error: 0.2485\n",
      "Epoch 23/1000\n",
      "39/39 [==============================] - 4s 106ms/step - loss: 0.2482 - mean_absolute_error: 0.2501 - val_loss: 0.2476 - val_mean_absolute_error: 0.2484\n",
      "Epoch 24/1000\n",
      "39/39 [==============================] - 4s 112ms/step - loss: 0.2480 - mean_absolute_error: 0.2480 - val_loss: 0.2475 - val_mean_absolute_error: 0.2483\n",
      "Epoch 25/1000\n",
      "39/39 [==============================] - 3s 88ms/step - loss: 0.2479 - mean_absolute_error: 0.2477 - val_loss: 0.2475 - val_mean_absolute_error: 0.2483\n",
      "Epoch 26/1000\n",
      "39/39 [==============================] - 4s 92ms/step - loss: 0.2478 - mean_absolute_error: 0.2463 - val_loss: 0.2475 - val_mean_absolute_error: 0.2483\n",
      "Epoch 27/1000\n",
      "39/39 [==============================] - 4s 93ms/step - loss: 0.2477 - mean_absolute_error: 0.2477 - val_loss: 0.2475 - val_mean_absolute_error: 0.2483\n",
      "Epoch 28/1000\n",
      "39/39 [==============================] - 4s 101ms/step - loss: 0.2477 - mean_absolute_error: 0.2477 - val_loss: 0.2475 - val_mean_absolute_error: 0.2483\n",
      "Epoch 29/1000\n",
      "39/39 [==============================] - 4s 102ms/step - loss: 0.2477 - mean_absolute_error: 0.2472 - val_loss: 0.2475 - val_mean_absolute_error: 0.2483\n",
      "Epoch 30/1000\n",
      "39/39 [==============================] - 4s 93ms/step - loss: 0.2476 - mean_absolute_error: 0.2473 - val_loss: 0.2475 - val_mean_absolute_error: 0.2483\n",
      "Epoch 31/1000\n",
      "39/39 [==============================] - 3s 86ms/step - loss: 0.2476 - mean_absolute_error: 0.2489 - val_loss: 0.2476 - val_mean_absolute_error: 0.2484\n",
      "Epoch 32/1000\n",
      "39/39 [==============================] - 3s 87ms/step - loss: 0.2476 - mean_absolute_error: 0.2470 - val_loss: 0.2476 - val_mean_absolute_error: 0.2484\n",
      "Epoch 33/1000\n",
      "39/39 [==============================] - 3s 88ms/step - loss: 0.2476 - mean_absolute_error: 0.2483 - val_loss: 0.2476 - val_mean_absolute_error: 0.2484\n",
      "Epoch 34/1000\n",
      "39/39 [==============================] - 4s 94ms/step - loss: 0.2476 - mean_absolute_error: 0.2472 - val_loss: 0.2476 - val_mean_absolute_error: 0.2484\n",
      "Epoch 35/1000\n",
      "12/39 [========>.....................] - ETA: 2s - loss: 0.2440 - mean_absolute_error: 0.2440"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-431-675a07fe9591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMeanAbsoluteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMeanAbsoluteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_ab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0my_pred_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_input = []\n",
    "list_output = []\n",
    "for k in range (nb-1):\n",
    "    input_k = Input(shape = (2, 2,))\n",
    "    x = SimpleRNN(32)(input_k)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Model(inputs=input_k, outputs=x)\n",
    "    list_output += [x.output]\n",
    "    list_input += [x.input]\n",
    "\n",
    "output_N1 = concatenate(list_output)\n",
    "\n",
    "z = Dense(4, activation=\"relu\")(output_N1)\n",
    "z = Dense(2, activation=\"relu\")(z)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])\n",
    "\n",
    "history_ab = model_ab.fit(x=X_train, y=y_train_ab, epochs=1000, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "y_pred_ab = model_ab.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_pred_ab, y_test_ab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search pour les paramtres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [99, 3500]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-439-aa0d88cca2ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [99, 3500]"
     ]
    }
   ],
   "source": [
    "def create_model(batch_size=64, epochs=1000):\n",
    "    list_input = []\n",
    "    list_output = []\n",
    "    for k in range (nb-1):\n",
    "        input_k = Input(shape=(2, 2,))\n",
    "        x = SimpleRNN(32)(input_k)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=input_k, outputs=x)\n",
    "        list_output += [x.output]\n",
    "        list_input += [x.input]\n",
    "\n",
    "    output_N1 = concatenate(list_output)\n",
    "\n",
    "    z = Dense(4, activation=\"relu\")(output_N1)\n",
    "    z = Dense(2, activation=\"relu\")(z)\n",
    "    z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "    model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "    model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    return model_ab\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "batch_sizes = [32, 64, 128]\n",
    "epochs = [500, 1000, 2000, 3000, 4000, 5000]\n",
    "param_grid = dict(batch_size=batch_sizes, epochs=epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1, verbose=3)\n",
    "grid_result = grid.fit([X_train[k] for k in range(nb-1)], y_train_ab)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[0.5       , 0.7       ],\n",
       "         [0.30129454, 0.77527517]],\n",
       " \n",
       "        [[0.5       , 0.7       ],\n",
       "         [0.39897608, 0.79912604]],\n",
       " \n",
       "        [[0.5       , 0.7       ],\n",
       "         [0.46690502, 0.70407693]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.5       , 0.7       ],\n",
       "         [0.44965728, 0.75086266]],\n",
       " \n",
       "        [[0.5       , 0.7       ],\n",
       "         [0.62967044, 0.88335049]],\n",
       " \n",
       "        [[0.5       , 0.7       ],\n",
       "         [0.45495482, 0.57778251]]]),\n",
       " array([[[0.30129454, 0.77527517],\n",
       "         [0.3733772 , 0.85055034]],\n",
       " \n",
       "        [[0.39897608, 0.79912604],\n",
       "         [0.29795215, 0.89825208]],\n",
       " \n",
       "        [[0.46690502, 0.70407693],\n",
       "         [0.43381004, 0.70815387]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.44965728, 0.75086266],\n",
       "         [0.39931456, 0.80172531]],\n",
       " \n",
       "        [[0.62967044, 0.88335049],\n",
       "         [0.77566823, 0.79094437]],\n",
       " \n",
       "        [[0.45495482, 0.57778251],\n",
       "         [0.40990963, 0.45556502]]]),\n",
       " array([[[0.3733772 , 0.85055034],\n",
       "         [0.44840825, 0.9258255 ]],\n",
       " \n",
       "        [[0.29795215, 0.89825208],\n",
       "         [0.19692823, 0.99737812]],\n",
       " \n",
       "        [[0.43381004, 0.70815387],\n",
       "         [0.40071506, 0.7122308 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.39931456, 0.80172531],\n",
       "         [0.34897184, 0.85258797]],\n",
       " \n",
       "        [[0.77566823, 0.79094437],\n",
       "         [0.88879494, 0.58613285]],\n",
       " \n",
       "        [[0.40990963, 0.45556502],\n",
       "         [0.36486445, 0.33334753]]]),\n",
       " array([[[0.44840825, 0.9258255 ],\n",
       "         [0.5234393 , 1.        ]],\n",
       " \n",
       "        [[0.19692823, 0.99737812],\n",
       "         [0.0959043 , 1.        ]],\n",
       " \n",
       "        [[0.40071506, 0.7122308 ],\n",
       "         [0.41023487, 0.71630774]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.34897184, 0.85258797],\n",
       "         [0.29862912, 0.90345062]],\n",
       " \n",
       "        [[0.88879494, 0.58613285],\n",
       "         [1.        , 0.40294656]],\n",
       " \n",
       "        [[0.36486445, 0.33334753],\n",
       "         [0.28363951, 0.28905943]]]),\n",
       " array([[[0.5234393 , 1.        ],\n",
       "         [0.59847035, 1.        ]],\n",
       " \n",
       "        [[0.0959043 , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.41023487, 0.71630774],\n",
       "         [0.45078485, 0.72038467]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.29862912, 0.90345062],\n",
       "         [0.2482864 , 0.95431328]],\n",
       " \n",
       "        [[1.        , 0.40294656],\n",
       "         [1.        , 0.24421954]],\n",
       " \n",
       "        [[0.28363951, 0.28905943],\n",
       "         [0.16854188, 0.31773144]]]),\n",
       " array([[[0.59847035, 1.        ],\n",
       "         [0.71583745, 0.9148628 ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.45078485, 0.72038467],\n",
       "         [0.49133482, 0.72446161]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.2482864 , 0.95431328],\n",
       "         [0.19794368, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.24421954],\n",
       "         [1.        , 0.08549253]],\n",
       " \n",
       "        [[0.16854188, 0.31773144],\n",
       "         [0.05344424, 0.34640344]]]),\n",
       " array([[[0.71583745, 0.9148628 ],\n",
       "         [0.87267631, 0.75034846]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.49133482, 0.72446161],\n",
       "         [0.5318848 , 0.72853854]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.19794368, 1.        ],\n",
       "         [0.14760096, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.08549253],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.05344424, 0.34640344],\n",
       "         [0.        , 0.37507545]]]),\n",
       " array([[[0.87267631, 0.75034846],\n",
       "         [1.        , 0.58583412]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.5318848 , 0.72853854],\n",
       "         [0.57243478, 0.73261548]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.14760096, 1.        ],\n",
       "         [0.09725824, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.37507545],\n",
       "         [0.        , 0.40374746]]]),\n",
       " array([[[1.        , 0.58583412],\n",
       "         [1.        , 0.42131977]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.57243478, 0.73261548],\n",
       "         [0.61298476, 0.73669241]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.09725824, 1.        ],\n",
       "         [0.04691552, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.40374746],\n",
       "         [0.        , 0.43241946]]]),\n",
       " array([[[1.        , 0.42131977],\n",
       "         [1.        , 0.25680543]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.61298476, 0.73669241],\n",
       "         [0.65353474, 0.74076935]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.04691552, 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.43241946],\n",
       "         [0.        , 0.46109147]]]),\n",
       " array([[[1.        , 0.25680543],\n",
       "         [1.        , 0.13537917]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.65353474, 0.74076935],\n",
       "         [0.69408472, 0.74484628]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.46109147],\n",
       "         [0.        , 0.48976348]]]),\n",
       " array([[[1.        , 0.13537917],\n",
       "         [1.        , 0.02465917]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.69408472, 0.74484628],\n",
       "         [0.7346347 , 0.74892322]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.48976348],\n",
       "         [0.        , 0.51843548]]]),\n",
       " array([[[1.        , 0.02465917],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.7346347 , 0.74892322],\n",
       "         [0.77518468, 0.75300015]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.06860034, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.51843548],\n",
       "         [0.        , 0.54710749]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.77518468, 0.75300015],\n",
       "         [0.8204967 , 0.74106532]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.06860034, 1.        ],\n",
       "         [0.14027391, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.54710749],\n",
       "         [0.        , 0.5757795 ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.8204967 , 0.74106532],\n",
       "         [0.86644875, 0.72697847]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.14027391, 1.        ],\n",
       "         [0.21194749, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.5757795 ],\n",
       "         [0.        , 0.60445151]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.86644875, 0.72697847],\n",
       "         [0.91240081, 0.71289162]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.21194749, 1.        ],\n",
       "         [0.28362106, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.60445151],\n",
       "         [0.        , 0.63312351]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.91240081, 0.71289162],\n",
       "         [0.95835286, 0.69880477]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.28362106, 1.        ],\n",
       "         [0.35529463, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.63312351],\n",
       "         [0.        , 0.66179552]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.95835286, 0.69880477],\n",
       "         [1.        , 0.68471792]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.35529463, 1.        ],\n",
       "         [0.42696821, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.66179552],\n",
       "         [0.        , 0.69046753]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.68471792],\n",
       "         [1.        , 0.67063107]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.42696821, 1.        ],\n",
       "         [0.49864178, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.69046753],\n",
       "         [0.        , 0.71913953]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.67063107],\n",
       "         [1.        , 0.65654422]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.49864178, 1.        ],\n",
       "         [0.57031535, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.71913953],\n",
       "         [0.        , 0.74781154]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.65654422],\n",
       "         [1.        , 0.64245737]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.57031535, 1.        ],\n",
       "         [0.64198893, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.74781154],\n",
       "         [0.        , 0.77648355]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.64245737],\n",
       "         [1.        , 0.62837052]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.64198893, 1.        ],\n",
       "         [0.7136625 , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.77648355],\n",
       "         [0.        , 0.83411645]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.62837052],\n",
       "         [1.        , 0.61428367]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.7136625 , 1.        ],\n",
       "         [0.78533608, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.83411645],\n",
       "         [0.        , 0.91573028]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.61428367],\n",
       "         [1.        , 0.60019682]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.78533608, 1.        ],\n",
       "         [0.85700965, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.91573028],\n",
       "         [0.        , 0.9973441 ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.04321228, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.60019682],\n",
       "         [1.        , 0.58610996]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.85700965, 1.        ],\n",
       "         [0.92868322, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.9973441 ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.04321228, 1.        ],\n",
       "         [0.11169587, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.58610996],\n",
       "         [1.        , 0.57202311]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.92868322, 1.        ],\n",
       "         [0.94366242, 0.97977043]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.11169587, 1.        ],\n",
       "         [0.18017946, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.57202311],\n",
       "         [1.        , 0.55793626]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.94366242, 0.97977043],\n",
       "         [0.95283131, 0.95746764]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.18017946, 1.        ],\n",
       "         [0.24866304, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.55793626],\n",
       "         [1.        , 0.54384941]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.95283131, 0.95746764],\n",
       "         [0.96200021, 0.93516484]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.24866304, 1.        ],\n",
       "         [0.31714663, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.54384941],\n",
       "         [1.        , 0.52976256]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.96200021, 0.93516484],\n",
       "         [0.9711691 , 0.91286205]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.31714663, 1.        ],\n",
       "         [0.38563021, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.52976256],\n",
       "         [1.        , 0.51567571]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.9711691 , 0.91286205],\n",
       "         [0.980338  , 0.89055926]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.01476876, 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.38563021, 1.        ],\n",
       "         [0.4541138 , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.51567571],\n",
       "         [1.        , 0.50158886]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.980338  , 0.89055926],\n",
       "         [0.98950689, 0.86825647]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.01476876, 1.        ],\n",
       "         [0.13195698, 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.4541138 , 1.        ],\n",
       "         [0.52259739, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.50158886],\n",
       "         [1.        , 0.48750201]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.98950689, 0.86825647],\n",
       "         [0.99867578, 0.84595368]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.13195698, 1.        ],\n",
       "         [0.24914519, 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.52259739, 1.        ],\n",
       "         [0.59108097, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.48750201],\n",
       "         [1.        , 0.47341516]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.99867578, 0.84595368],\n",
       "         [1.        , 0.82365088]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [0.92686962, 0.        ]],\n",
       " \n",
       "        [[0.24914519, 1.        ],\n",
       "         [0.36617812, 0.9780289 ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.59108097, 1.        ],\n",
       "         [0.65956456, 1.        ]],\n",
       " \n",
       "        [[1.        , 0.47341516],\n",
       "         [1.        , 0.45932831]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.82365088],\n",
       "         [1.        , 0.80134809]],\n",
       " \n",
       "        [[0.92686962, 0.        ],\n",
       "         [0.69014009, 0.00303424]],\n",
       " \n",
       "        [[0.36617812, 0.9780289 ],\n",
       "         [0.48258363, 0.86728587]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.65956456, 1.        ],\n",
       "         [0.72712739, 0.98675224]],\n",
       " \n",
       "        [[1.        , 0.45932831],\n",
       "         [1.        , 0.44524146]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.80134809],\n",
       "         [1.        , 0.7790453 ]],\n",
       " \n",
       "        [[0.69014009, 0.00303424],\n",
       "         [0.51002522, 0.10892514]],\n",
       " \n",
       "        [[0.48258363, 0.86728587],\n",
       "         [0.59898914, 0.75313103]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.72712739, 0.98675224],\n",
       "         [0.78307213, 0.80634343]],\n",
       " \n",
       "        [[1.        , 0.44524146],\n",
       "         [1.        , 0.39430025]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.7790453 ],\n",
       "         [1.        , 0.75674251]],\n",
       " \n",
       "        [[0.51002522, 0.10892514],\n",
       "         [0.32991035, 0.21481604]],\n",
       " \n",
       "        [[0.59898914, 0.75313103],\n",
       "         [0.71539464, 0.63091354]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.78307213, 0.80634343],\n",
       "         [0.83901688, 0.62593462]],\n",
       " \n",
       "        [[1.        , 0.39430025],\n",
       "         [1.        , 0.29759352]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.75674251],\n",
       "         [1.        , 0.73443971]],\n",
       " \n",
       "        [[0.32991035, 0.21481604],\n",
       "         [0.14979548, 0.32070694]],\n",
       " \n",
       "        [[0.71539464, 0.63091354],\n",
       "         [0.83180015, 0.50869605]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.83901688, 0.62593462],\n",
       "         [0.89496162, 0.44552581]],\n",
       " \n",
       "        [[1.        , 0.29759352],\n",
       "         [1.        , 0.20088679]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.73443971],\n",
       "         [1.        , 0.71213692]],\n",
       " \n",
       "        [[0.14979548, 0.32070694],\n",
       "         [0.        , 0.42659784]],\n",
       " \n",
       "        [[0.83180015, 0.50869605],\n",
       "         [0.94820566, 0.38647856]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.89496162, 0.44552581],\n",
       "         [0.95090636, 0.26511699]],\n",
       " \n",
       "        [[1.        , 0.20088679],\n",
       "         [1.        , 0.10418007]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.71213692],\n",
       "         [1.        , 0.68983413]],\n",
       " \n",
       "        [[0.        , 0.42659784],\n",
       "         [0.        , 0.57276481]],\n",
       " \n",
       "        [[0.94820566, 0.38647856],\n",
       "         [1.        , 0.26426107]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [0.97761506, 0.        ]],\n",
       " \n",
       "        [[0.95090636, 0.26511699],\n",
       "         [1.        , 0.10163182]],\n",
       " \n",
       "        [[1.        , 0.10418007],\n",
       "         [1.        , 0.00747334]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.68983413],\n",
       "         [1.        , 0.66753134]],\n",
       " \n",
       "        [[0.        , 0.57276481],\n",
       "         [0.12058917, 0.7561153 ]],\n",
       " \n",
       "        [[1.        , 0.26426107],\n",
       "         [1.        , 0.14204357]]]),\n",
       " array([[[0.97761506, 0.        ],\n",
       "         [0.94643993, 0.        ]],\n",
       " \n",
       "        [[1.        , 0.10163182],\n",
       "         [1.        , 0.00133313]],\n",
       " \n",
       "        [[1.        , 0.00747334],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.66753134],\n",
       "         [1.        , 0.64522855]],\n",
       " \n",
       "        [[0.12058917, 0.7561153 ],\n",
       "         [0.34722738, 0.93946578]],\n",
       " \n",
       "        [[1.        , 0.14204357],\n",
       "         [0.99504337, 0.01982608]]]),\n",
       " array([[[0.94643993, 0.        ],\n",
       "         [0.9152648 , 0.        ]],\n",
       " \n",
       "        [[1.        , 0.00133313],\n",
       "         [0.9780048 , 0.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.64522855],\n",
       "         [1.        , 0.62292575]],\n",
       " \n",
       "        [[0.34722738, 0.93946578],\n",
       "         [0.57386559, 1.        ]],\n",
       " \n",
       "        [[0.99504337, 0.01982608],\n",
       "         [0.94999818, 0.        ]]]),\n",
       " array([[[0.9152648 , 0.        ],\n",
       "         [0.88408967, 0.        ]],\n",
       " \n",
       "        [[0.9780048 , 0.        ],\n",
       "         [0.92288547, 0.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [0.98426635, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.62292575],\n",
       "         [1.        , 0.60062296]],\n",
       " \n",
       "        [[0.57386559, 1.        ],\n",
       "         [0.74781318, 0.90492905]],\n",
       " \n",
       "        [[0.94999818, 0.        ],\n",
       "         [0.904953  , 0.        ]]]),\n",
       " array([[[0.88408967, 0.        ],\n",
       "         [0.85291454, 0.        ]],\n",
       " \n",
       "        [[0.92288547, 0.        ],\n",
       "         [0.86776614, 0.        ]],\n",
       " \n",
       "        [[0.98426635, 0.        ],\n",
       "         [0.95304698, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.60062296],\n",
       "         [1.        , 0.57832017]],\n",
       " \n",
       "        [[0.74781318, 0.90492905],\n",
       "         [0.86093989, 0.70011753]],\n",
       " \n",
       "        [[0.904953  , 0.        ],\n",
       "         [0.85990782, 0.        ]]]),\n",
       " array([[[0.85291454, 0.        ],\n",
       "         [0.82173941, 0.        ]],\n",
       " \n",
       "        [[0.86776614, 0.        ],\n",
       "         [0.81264681, 0.        ]],\n",
       " \n",
       "        [[0.95304698, 0.        ],\n",
       "         [0.92182761, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.57832017],\n",
       "         [1.        , 0.55601738]],\n",
       " \n",
       "        [[0.86093989, 0.70011753],\n",
       "         [0.9740666 , 0.49530601]],\n",
       " \n",
       "        [[0.85990782, 0.        ],\n",
       "         [0.81486263, 0.        ]]]),\n",
       " array([[[0.82173941, 0.        ],\n",
       "         [0.79056428, 0.        ]],\n",
       " \n",
       "        [[0.81264681, 0.        ],\n",
       "         [0.75752748, 0.        ]],\n",
       " \n",
       "        [[0.92182761, 0.        ],\n",
       "         [0.89060824, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.55601738],\n",
       "         [1.        , 0.53371459]],\n",
       " \n",
       "        [[0.9740666 , 0.49530601],\n",
       "         [1.        , 0.33255661]],\n",
       " \n",
       "        [[0.81486263, 0.        ],\n",
       "         [0.76981745, 0.        ]]]),\n",
       " array([[[0.79056428, 0.        ],\n",
       "         [0.75938915, 0.        ]],\n",
       " \n",
       "        [[0.75752748, 0.        ],\n",
       "         [0.68524275, 0.01224908]],\n",
       " \n",
       "        [[0.89060824, 0.        ],\n",
       "         [0.85938887, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.53371459],\n",
       "         [1.        , 0.51141179]],\n",
       " \n",
       "        [[1.        , 0.33255661],\n",
       "         [1.        , 0.17382959]],\n",
       " \n",
       "        [[0.76981745, 0.        ],\n",
       "         [0.72477226, 0.        ]]]),\n",
       " array([[[0.75938915, 0.        ],\n",
       "         [0.72821402, 0.        ]],\n",
       " \n",
       "        [[0.68524275, 0.01224908],\n",
       "         [0.58421883, 0.04500621]],\n",
       " \n",
       "        [[0.85938887, 0.        ],\n",
       "         [0.8281695 , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.51141179],\n",
       "         [1.        , 0.489109  ]],\n",
       " \n",
       "        [[1.        , 0.17382959],\n",
       "         [1.        , 0.01510258]],\n",
       " \n",
       "        [[0.72477226, 0.        ],\n",
       "         [0.67972708, 0.        ]]]),\n",
       " array([[[0.72821402, 0.        ],\n",
       "         [0.69703889, 0.        ]],\n",
       " \n",
       "        [[0.58421883, 0.04500621],\n",
       "         [0.4831949 , 0.07776335]],\n",
       " \n",
       "        [[0.8281695 , 0.        ],\n",
       "         [0.79695013, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.489109  ],\n",
       "         [1.        , 0.46680621]],\n",
       " \n",
       "        [[1.        , 0.01510258],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.67972708, 0.        ],\n",
       "         [0.6346819 , 0.        ]]]),\n",
       " array([[[0.69703889, 0.        ],\n",
       "         [0.66586376, 0.        ]],\n",
       " \n",
       "        [[0.4831949 , 0.07776335],\n",
       "         [0.38217098, 0.11052048]],\n",
       " \n",
       "        [[0.79695013, 0.        ],\n",
       "         [0.76487414, 0.02756619]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.46680621],\n",
       "         [1.        , 0.44450342]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.6346819 , 0.        ],\n",
       "         [0.58963671, 0.        ]]]),\n",
       " array([[[0.66586376, 0.        ],\n",
       "         [0.63468863, 0.        ]],\n",
       " \n",
       "        [[0.38217098, 0.11052048],\n",
       "         [0.28114706, 0.18472581]],\n",
       " \n",
       "        [[0.76487414, 0.02756619],\n",
       "         [0.73177916, 0.08792425]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.44450342],\n",
       "         [1.        , 0.42220062]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.58963671, 0.        ],\n",
       "         [0.54459153, 0.        ]]]),\n",
       " array([[[0.63468863, 0.        ],\n",
       "         [0.43607061, 0.18196471]],\n",
       " \n",
       "        [[0.28114706, 0.18472581],\n",
       "         [0.18012313, 0.28385185]],\n",
       " \n",
       "        [[0.73177916, 0.08792425],\n",
       "         [0.69868419, 0.1482823 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.42220062],\n",
       "         [1.        , 0.39989783]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.54459153, 0.        ],\n",
       "         [0.49954634, 0.        ]]]),\n",
       " array([[[0.43607061, 0.18196471],\n",
       "         [0.23736514, 0.28193231]],\n",
       " \n",
       "        [[0.18012313, 0.28385185],\n",
       "         [0.07909921, 0.3829779 ]],\n",
       " \n",
       "        [[0.69868419, 0.1482823 ],\n",
       "         [0.66558921, 0.20864036]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.39989783],\n",
       "         [1.        , 0.37759504]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.49954634, 0.        ],\n",
       "         [0.45450116, 0.        ]]]),\n",
       " array([[[0.23736514, 0.28193231],\n",
       "         [0.03865968, 0.35720748]],\n",
       " \n",
       "        [[0.07909921, 0.3829779 ],\n",
       "         [0.        , 0.48210394]],\n",
       " \n",
       "        [[0.66558921, 0.20864036],\n",
       "         [0.63249423, 0.26899842]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.37759504],\n",
       "         [1.        , 0.35529225]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.45450116, 0.        ],\n",
       "         [0.40945597, 0.        ]]]),\n",
       " array([[[0.03865968, 0.35720748],\n",
       "         [0.05480255, 0.43248265]],\n",
       " \n",
       "        [[0.        , 0.48210394],\n",
       "         [0.        , 0.58122998]],\n",
       " \n",
       "        [[0.63249423, 0.26899842],\n",
       "         [0.59939925, 0.32935648]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.35529225],\n",
       "         [1.        , 0.33298946]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.40945597, 0.        ],\n",
       "         [0.36441079, 0.        ]]]),\n",
       " array([[[0.05480255, 0.43248265],\n",
       "         [0.12983359, 0.50775781]],\n",
       " \n",
       "        [[0.        , 0.58122998],\n",
       "         [0.        , 0.68035602]],\n",
       " \n",
       "        [[0.59939925, 0.32935648],\n",
       "         [0.56630427, 0.38971453]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.33298946],\n",
       "         [1.        , 0.32157605]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.36441079, 0.        ],\n",
       "         [0.28248034, 0.0150969 ]]]),\n",
       " array([[[0.12983359, 0.50775781],\n",
       "         [0.20486464, 0.58303298]],\n",
       " \n",
       "        [[0.        , 0.68035602],\n",
       "         [0.        , 0.77948206]],\n",
       " \n",
       "        [[0.56630427, 0.38971453],\n",
       "         [0.53320929, 0.43829174]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.32157605],\n",
       "         [1.        , 0.31372447]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.28248034, 0.0150969 ],\n",
       "         [0.16738271, 0.0437689 ]]]),\n",
       " array([[[0.20486464, 0.58303298],\n",
       "         [0.27989569, 0.65830815]],\n",
       " \n",
       "        [[0.        , 0.77948206],\n",
       "         [0.        , 0.8786081 ]],\n",
       " \n",
       "        [[0.53320929, 0.43829174],\n",
       "         [0.50011431, 0.44236867]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.31372447],\n",
       "         [1.        , 0.30587289]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.16738271, 0.0437689 ],\n",
       "         [0.05228507, 0.07244091]]]),\n",
       " array([[[0.27989569, 0.65830815],\n",
       "         [0.35492674, 0.73358332]],\n",
       " \n",
       "        [[0.        , 0.8786081 ],\n",
       "         [0.        , 0.97773414]],\n",
       " \n",
       "        [[0.50011431, 0.44236867],\n",
       "         [0.46701933, 0.44644561]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.30587289],\n",
       "         [1.        , 0.2980213 ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.05228507, 0.07244091],\n",
       "         [0.        , 0.10111292]]]),\n",
       " array([[[0.35492674, 0.73358332],\n",
       "         [0.42995778, 0.80885848]],\n",
       " \n",
       "        [[0.        , 0.97773414],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.46701933, 0.44644561],\n",
       "         [0.46102283, 0.45052254]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.2980213 ],\n",
       "         [1.        , 0.29016972]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.10111292],\n",
       "         [0.        , 0.12978492]]]),\n",
       " array([[[0.42995778, 0.80885848],\n",
       "         [0.50498883, 0.88413365]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.46102283, 0.45052254],\n",
       "         [0.5015728 , 0.45459948]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.29016972],\n",
       "         [1.        , 0.28231814]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.12978492],\n",
       "         [0.        , 0.15845693]]]),\n",
       " array([[[0.50498883, 0.88413365],\n",
       "         [0.58001988, 0.95940882]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.5015728 , 0.45459948],\n",
       "         [0.54212278, 0.45867641]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.28231814],\n",
       "         [0.93945229, 0.27446655]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.15845693],\n",
       "         [0.        , 0.18712894]]]),\n",
       " array([[[0.58001988, 0.95940882],\n",
       "         [0.67727008, 0.95531761]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.54212278, 0.45867641],\n",
       "         [0.58267276, 0.46275335]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.93945229, 0.27446655],\n",
       "         [0.88827305, 0.29299281]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.18712894],\n",
       "         [0.        , 0.21580095]]]),\n",
       " array([[[0.67727008, 0.95531761],\n",
       "         [0.83410894, 0.79080326]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.58267276, 0.46275335],\n",
       "         [0.62322274, 0.46683028]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.88827305, 0.29299281],\n",
       "         [0.83793033, 0.31335142]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.21580095],\n",
       "         [0.        , 0.24447295]]]),\n",
       " array([[[0.83410894, 0.79080326],\n",
       "         [0.99094781, 0.62628892]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.62322274, 0.46683028],\n",
       "         [0.66377272, 0.47090722]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.83793033, 0.31335142],\n",
       "         [0.78758761, 0.34302605]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.24447295],\n",
       "         [0.        , 0.27314496]]]),\n",
       " array([[[0.99094781, 0.62628892],\n",
       "         [1.        , 0.46177458]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.66377272, 0.47090722],\n",
       "         [0.7043227 , 0.47498415]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.78758761, 0.34302605],\n",
       "         [0.73724489, 0.39388871]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.27314496],\n",
       "         [0.        , 0.30181697]]]),\n",
       " array([[[1.        , 0.46177458],\n",
       "         [1.        , 0.29726023]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.7043227 , 0.47498415],\n",
       "         [0.74487268, 0.47906109]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.73724489, 0.39388871],\n",
       "         [0.68690217, 0.44475136]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.30181697],\n",
       "         [0.        , 0.33048897]]]),\n",
       " array([[[1.        , 0.29726023],\n",
       "         [1.        , 0.16260571]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.74487268, 0.47906109],\n",
       "         [0.78614653, 0.48070408]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.68690217, 0.44475136],\n",
       "         [0.73930147, 0.49561402]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.33048897],\n",
       "         [0.        , 0.35916098]]]),\n",
       " array([[[1.        , 0.16260571],\n",
       "         [1.        , 0.0518857 ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.78614653, 0.48070408],\n",
       "         [0.83209859, 0.46661723]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.73930147, 0.49561402],\n",
       "         [0.81097504, 0.54647668]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.35916098],\n",
       "         [0.        , 0.38783299]]]),\n",
       " array([[[1.        , 0.0518857 ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.83209859, 0.46661723],\n",
       "         [0.87805064, 0.45253038]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.81097504, 0.54647668],\n",
       "         [0.88264862, 0.59733933]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.38783299],\n",
       "         [0.        , 0.41650499]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.87805064, 0.45253038],\n",
       "         [0.92400269, 0.43844353]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.88264862, 0.59733933],\n",
       "         [0.93777341, 0.62883066]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.41650499],\n",
       "         [0.        , 0.445177  ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.92400269, 0.43844353],\n",
       "         [0.96995475, 0.34763224]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.93777341, 0.62883066],\n",
       "         [0.9469423 , 0.60652786]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.445177  ],\n",
       "         [0.        , 0.47384901]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.96995475, 0.34763224],\n",
       "         [1.        , 0.25092551]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.9469423 , 0.60652786],\n",
       "         [0.9561112 , 0.58422507]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.47384901],\n",
       "         [0.        , 0.50252102]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.25092551],\n",
       "         [1.        , 0.15421879]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.9561112 , 0.58422507],\n",
       "         [0.96528009, 0.56192228]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.50252102],\n",
       "         [0.        , 0.53119302]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.15421879],\n",
       "         [1.        , 0.05751206]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.96528009, 0.56192228],\n",
       "         [0.97444899, 0.53961949]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.53119302],\n",
       "         [0.        , 0.55986503]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.05751206],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.97444899, 0.53961949],\n",
       "         [0.98361788, 0.5173167 ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.55986503],\n",
       "         [0.        , 0.58853704]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.98361788, 0.5173167 ],\n",
       "         [0.99278677, 0.4950139 ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.58853704],\n",
       "         [0.        , 0.61720904]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.99278677, 0.4950139 ],\n",
       "         [1.        , 0.47271111]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.61720904],\n",
       "         [0.        , 0.64588105]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [0.96920074, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.47271111],\n",
       "         [1.        , 0.45040832]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.64588105],\n",
       "         [0.        , 0.67455306]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.96920074, 0.        ],\n",
       "         [0.93798137, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.45040832],\n",
       "         [1.        , 0.42810553]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.67455306],\n",
       "         [0.        , 0.70322506]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.93798137, 0.        ],\n",
       "         [0.906762  , 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.42810553],\n",
       "         [1.        , 0.40580273]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.70322506],\n",
       "         [0.        , 0.73189707]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.906762  , 0.        ],\n",
       "         [0.87554263, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.40580273],\n",
       "         [1.        , 0.38349994]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.73189707],\n",
       "         [0.        , 0.76056908]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]],\n",
       " \n",
       "        [[0.87554263, 0.        ],\n",
       "         [0.84432326, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.38349994],\n",
       "         [1.        , 0.36119715]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.76056908],\n",
       "         [0.        , 0.78924109]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.04412254, 1.        ]],\n",
       " \n",
       "        [[0.84432326, 0.        ],\n",
       "         [0.81310389, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.36119715],\n",
       "         [1.        , 0.33889436]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.78924109],\n",
       "         [0.        , 0.87043032]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.04412254, 1.        ],\n",
       "         [0.11260613, 1.        ]],\n",
       " \n",
       "        [[0.81310389, 0.        ],\n",
       "         [0.78188452, 0.        ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.33889436],\n",
       "         [1.        , 0.32365484]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.87043032],\n",
       "         [0.        , 0.95204414]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.11260613, 1.        ],\n",
       "         [0.18108971, 1.        ]],\n",
       " \n",
       "        [[0.78188452, 0.        ],\n",
       "         [0.74890342, 0.05669333]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.32365484],\n",
       "         [1.        , 0.31580326]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 0.95204414],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.18108971, 1.        ],\n",
       "         [0.2495733 , 1.        ]],\n",
       " \n",
       "        [[0.74890342, 0.05669333],\n",
       "         [0.71580844, 0.11705138]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.31580326],\n",
       "         [1.        , 0.30795168]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.2495733 , 1.        ],\n",
       "         [0.31805688, 1.        ]],\n",
       " \n",
       "        [[0.71580844, 0.11705138],\n",
       "         [0.68271346, 0.17740944]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.30795168],\n",
       "         [1.        , 0.30010009]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.31805688, 1.        ],\n",
       "         [0.38654047, 1.        ]],\n",
       " \n",
       "        [[0.68271346, 0.17740944],\n",
       "         [0.64961848, 0.2377675 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.30010009],\n",
       "         [1.        , 0.29224851]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.38654047, 1.        ],\n",
       "         [0.45502406, 1.        ]],\n",
       " \n",
       "        [[0.64961848, 0.2377675 ],\n",
       "         [0.6165235 , 0.29812556]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.29224851],\n",
       "         [1.        , 0.28439693]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.45502406, 1.        ],\n",
       "         [0.52350764, 1.        ]],\n",
       " \n",
       "        [[0.6165235 , 0.29812556],\n",
       "         [0.58342852, 0.35848361]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[1.        , 0.28439693],\n",
       "         [0.95619091, 0.27654534]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.        , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.52350764, 1.        ],\n",
       "         [0.59199123, 1.        ]],\n",
       " \n",
       "        [[0.58342852, 0.35848361],\n",
       "         [0.55033354, 0.41884167]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.95619091, 0.27654534],\n",
       "         [0.90160182, 0.28760266]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.        , 1.        ],\n",
       "         [0.06691137, 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.59199123, 1.        ],\n",
       "         [0.66047481, 1.        ]],\n",
       " \n",
       "        [[0.55033354, 0.41884167],\n",
       "         [0.51723856, 0.44025916]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.90160182, 0.28760266],\n",
       "         [0.8512591 , 0.30796126]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.06691137, 1.        ],\n",
       "         [0.18409958, 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.66047481, 1.        ],\n",
       "         [0.72787099, 0.98435432]],\n",
       " \n",
       "        [[0.51723856, 0.44025916],\n",
       "         [0.48414358, 0.44433609]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.8512591 , 0.30796126],\n",
       "         [0.80091638, 0.32955962]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.18409958, 1.        ],\n",
       "         [0.3012878 , 1.        ]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.72787099, 0.98435432],\n",
       "         [0.78381573, 0.80394551]],\n",
       " \n",
       "        [[0.48414358, 0.44433609],\n",
       "         [0.4510486 , 0.44841303]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.80091638, 0.32955962],\n",
       "         [0.75057366, 0.38042228]],\n",
       " \n",
       "        [[1.        , 0.        ],\n",
       "         [0.9670003 , 0.        ]],\n",
       " \n",
       "        [[0.3012878 , 1.        ],\n",
       "         [0.41797246, 0.92875406]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [1.        , 0.        ]],\n",
       " \n",
       "        [[0.78381573, 0.80394551],\n",
       "         [0.83976047, 0.6235367 ]],\n",
       " \n",
       "        [[0.4510486 , 0.44841303],\n",
       "         [0.48059113, 0.45248996]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.75057366, 0.38042228],\n",
       "         [0.70023094, 0.43128493]],\n",
       " \n",
       "        [[0.9670003 , 0.        ],\n",
       "         [0.72860065, 0.        ]],\n",
       " \n",
       "        [[0.41797246, 0.92875406],\n",
       "         [0.53437797, 0.81801103]]]),\n",
       " array([[[1.        , 0.        ],\n",
       "         [0.99672255, 0.        ]],\n",
       " \n",
       "        [[0.83976047, 0.6235367 ],\n",
       "         [0.89570521, 0.44312789]],\n",
       " \n",
       "        [[0.48059113, 0.45248996],\n",
       "         [0.52114111, 0.4565669 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.70023094, 0.43128493],\n",
       "         [0.72032512, 0.48214759]],\n",
       " \n",
       "        [[0.72860065, 0.        ],\n",
       "         [0.54034461, 0.09110014]],\n",
       " \n",
       "        [[0.53437797, 0.81801103],\n",
       "         [0.65078348, 0.69875066]]]),\n",
       " array([[[0.99672255, 0.        ],\n",
       "         [0.96554742, 0.        ]],\n",
       " \n",
       "        [[0.89570521, 0.44312789],\n",
       "         [0.95164995, 0.26271908]],\n",
       " \n",
       "        [[0.52114111, 0.4565669 ],\n",
       "         [0.56169109, 0.46064383]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.72032512, 0.48214759],\n",
       "         [0.7919987 , 0.53301025]],\n",
       " \n",
       "        [[0.54034461, 0.09110014],\n",
       "         [0.36022974, 0.19699104]],\n",
       " \n",
       "        [[0.65078348, 0.69875066],\n",
       "         [0.76718898, 0.57653317]]]),\n",
       " array([[[0.96554742, 0.        ],\n",
       "         [0.93437229, 0.        ]],\n",
       " \n",
       "        [[0.95164995, 0.26271908],\n",
       "         [1.        , 0.10029869]],\n",
       " \n",
       "        [[0.56169109, 0.46064383],\n",
       "         [0.60224107, 0.46472076]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.7919987 , 0.53301025],\n",
       "         [0.86367227, 0.5838729 ]],\n",
       " \n",
       "        [[0.36022974, 0.19699104],\n",
       "         [0.18011487, 0.30288194]],\n",
       " \n",
       "        [[0.76718898, 0.57653317],\n",
       "         [0.88359449, 0.45431568]]])]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[X_train[k] for k in range(nb-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dropout_rate=0.3, learning_rate=0.001):\n",
    "    list_input = []\n",
    "    list_output = []\n",
    "    for k in range (nb-1):\n",
    "        input_k = Input(shape=(2, 2,))\n",
    "        x = SimpleRNN(32)(input_k)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=input_k, outputs=x)\n",
    "        list_output += [x.output]\n",
    "        list_input += [x.input]\n",
    "\n",
    "    output_N1 = concatenate(list_output)\n",
    "\n",
    "    z = Dense(4, activation=\"relu\")(output_N1)\n",
    "    z = Dense(2, activation=\"relu\")(z)\n",
    "    z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "    model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model_ab.compile(loss=MeanAbsoluteError(), optimizer=optimizer, metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    history_ab = model_ab.fit(x=X_train, y=y_train_ab, epochs=1000, batch_size=64, validation_split=0.3)\n",
    "\n",
    "    return model_ab\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "dropout_rates = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "param_grid = dict(dropout_rate=dropout_rates, learning_rate=learning_rates)\n",
    "\n",
    "# Utiliser GridSearchCV pour effectuer la recherche de grille\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train_ab)\n",
    "\n",
    "# Afficher les rsultats de la recherche de grille\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='adam'):\n",
    "    list_input = []\n",
    "    list_output = []\n",
    "    for k in range (nb-1):\n",
    "        input_k = Input(shape = (2, 2,))\n",
    "        x = SimpleRNN(32)(input_k)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=input_k, outputs=x)\n",
    "        list_output += [x.output]\n",
    "        list_input += [x.input]\n",
    "\n",
    "    output_N1 = concatenate(list_output)\n",
    "\n",
    "    z = Dense(4, activation=\"relu\")(output_N1)\n",
    "    z = Dense(2, activation=\"relu\")(z)\n",
    "    z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "    model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "    model_ab.compile(loss=MeanAbsoluteError(), optimizer=optimizer, metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    return model_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs'])\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_99\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_199\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_299\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_399\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_499\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_599\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_699\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_799\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_899\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_999\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-379-77ac5300d9aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 40 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_99\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_199\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_299\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_399\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_499\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_599\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_699\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_799\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_899\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 762, in fit\n    self._fit(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 931, in _fit\n    self._fit_keras_model(\n  File \"/opt/anaconda3/lib/python3.8/site-packages/scikeras/wrappers.py\", line 526, in _fit_keras_model\n    hist = self.model_.fit(x=X, y=y, **fit_args)\n  File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\", line 1129, in autograph_handler\n    raise e.ag_error_metadata.to_exception(e)\nValueError: in user code:\n\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/anaconda3/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 199, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"model_999\" expects 99 input(s), but it received 1 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, 99, 2, 2) dtype=float32>]\n\n"
     ]
    }
   ],
   "source": [
    "epochs = [1000*k for k in range(1,5)]\n",
    "batch_size = [32, 64]\n",
    "param_grid = {'epochs' : epochs, 'batch_size' : batch_size}\n",
    "\n",
    "model = KerasRegressor(model=create_model, verbose=0, loss='mean_absolute_error')\n",
    "print(model.get_params().keys())\n",
    "\n",
    "grid_result = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, scoring='neg_mean_absolute_error', verbose=3).fit(X_train_2, y_train_ab)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE en fonction du nombre de simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_mae = []\n",
    "#list_sim = [100, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "list_sim = [100, 500, 1000]\n",
    "for nsim in list_sim:\n",
    "    dataset_ab = np.zeros((nsim, nb-1, 2, 2))\n",
    "\n",
    "    for k1 in range(nsim):\n",
    "        for k2 in range(nb-1):\n",
    "            dataset_ab[k1, k2, 0, 0] = dataset[k1, k2, 0]\n",
    "            dataset_ab[k1, k2, 1, 0] = dataset[k1, k2+1, 0]\n",
    "            dataset_ab[k1, k2, 0, 1] = dataset[k1, k2, 1]\n",
    "            dataset_ab[k1, k2, 1, 1] = dataset[k1, k2+1, 1]\n",
    "            \n",
    "    X_train_ab, X_test_ab, y_train_ab, y_test_ab = train_test_split(dataset_ab, y[:nsim, 1], train_size = 0.7, shuffle = False)\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "\n",
    "    for k in range (nb-1):\n",
    "        X_train += [X_train_ab[:, k, :]]\n",
    "        X_test += [X_test_ab[:, k, :]]\n",
    "    \n",
    "    list_input = []\n",
    "    list_output = []\n",
    "    for k in range (nb-1):\n",
    "        input_k = Input(shape = (2, 2,))\n",
    "        x = SimpleRNN(32)(input_k)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=input_k, outputs=x)\n",
    "        list_output += [x.output]\n",
    "        list_input += [x.input]\n",
    "\n",
    "    output_N1 = concatenate(list_output)\n",
    "\n",
    "    z = Dense(4, activation=\"relu\")(output_N1)\n",
    "    z = Dense(2, activation=\"relu\")(z)\n",
    "    z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "    model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "    model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    history_ab = model_ab.fit(x=X_train, y=y_train_ab, epochs=5000, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "    y_pred_ab = model_ab.predict(X_test)\n",
    "    \n",
    "    list_mae += [mean_absolute_error(y_pred_ab, y_test_ab)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_sim, list_mae)\n",
    "plt.xlabel('Nombre de simulations')\n",
    "plt.ylabel('Erreur absolue moyenne sur le test set')\n",
    "plt.title('Sans bruit')\n",
    "#plt.savefig('mae_sans_bruit',dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tat initial et bruit alatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "n_sim = 2000\n",
    "nb = 100\n",
    "\n",
    "col2 = [\"sca\", \"sab\", \"sbc\", \"vac0a0\", \"vac0a1\", \n",
    "       \"vac1a0\", \"vac1a1\", \"vba0b0\", \"vba0b1\", \"vba1b0\", \"vba1b1\", \"vcb0c0\", \n",
    "       \"vcb0c1\", \"vcb1c0\", \"vcb1c1\"]\n",
    "dataset = np.zeros((n_sim, nb, 3))\n",
    "y = np.zeros((n_sim, len(col2)))\n",
    "param = np.zeros((n_sim, 6))\n",
    "\n",
    "for k in range(n_sim):\n",
    "    print(k)\n",
    "    list_entite = ['a','b','c']\n",
    "    max_level = dict()\n",
    "    max_level['a'] = 1\n",
    "    max_level['b'] = 1\n",
    "    max_level['c'] = 1\n",
    "\n",
    "    list_colums = []\n",
    "    list_colums = list_colums + list_entite\n",
    "    for one_ele in list_entite:\n",
    "        list_colums = list_colums + ['c_'+one_ele]\n",
    "    celerities = pd.DataFrame(columns=list_colums)\n",
    "\n",
    "    sca = random.uniform(0, 1)\n",
    "    scmax = 1\n",
    "    sab = random.uniform(0, 1)\n",
    "    samax = 1\n",
    "    sbc = random.uniform(0, 1)\n",
    "    sbmax = 1\n",
    "\n",
    "    vac0a0=random.uniform(0, 10)\n",
    "    vac0a1=random.uniform(0, 10)\n",
    "    vac1a0=random.uniform(0, 10)\n",
    "    vac1a1=random.uniform(0, 10)\n",
    "    vba0b0=random.uniform(0, 10)\n",
    "    vba0b1=random.uniform(0, 10)\n",
    "    vba1b0=random.uniform(0, 10)\n",
    "    vba1b1=random.uniform(0, 10)\n",
    "    vcb0c0=random.uniform(0, 10)\n",
    "    vcb0c1=random.uniform(0, 10)\n",
    "    vcb1c0=random.uniform(0, 10)\n",
    "    vcb1c1=random.uniform(0, 10)\n",
    "\n",
    "    num = 20\n",
    "    initial_state  = (random.uniform(0, 1),random.uniform(0, 1),random.uniform(0, 1))\n",
    "\n",
    "    noise1 = random.uniform(0, 0.4)\n",
    "    noise2 = random.uniform(0, 0.4)\n",
    "    noise3 = random.uniform(0, 0.4)\n",
    "\n",
    "    cac0a0=vac0a0/(sab - 0)\n",
    "    cac0a1=vac0a1/(samax - sab)\n",
    "    cac1a0=vac1a0/(sab - 0)\n",
    "    cac1a1=vac1a1/(samax - sab)\n",
    "    cba0b0=vba0b0/(sbc - 0)\n",
    "    cba0b1=vba0b1/(sbmax - sbc)\n",
    "    cba1b0=vba1b0/(sbc - 0)\n",
    "    cba1b1=vba1b1/(sbmax - sbc)\n",
    "    ccb0c0=vcb0c0/(sca - 0)\n",
    "    ccb0c1=vcb0c1/(scmax -sca)\n",
    "    ccb1c0=vcb1c0/(sca - 0)\n",
    "    ccb1c1=vcb1c1/(scmax -sca)\n",
    "\n",
    "    df1 = pd.DataFrame([[0,0,0,cac0a0,cba0b0,ccb0c0]],columns=list_colums)\n",
    "    df2 = pd.DataFrame([[0,0,1,-cac1a0,cba0b0,ccb0c1]],columns=list_colums)\n",
    "    df3 = pd.DataFrame([[0,1,0,cac0a0,cba0b1,-ccb1c0]],columns=list_colums)\n",
    "    df4 = pd.DataFrame([[0,1,1,-cac1a0,cba0b1,-ccb1c1]],columns=list_colums)\n",
    "    df5 = pd.DataFrame([[1,0,0,cac0a1,-cba1b0,ccb0c0]],columns=list_colums)\n",
    "    df6 = pd.DataFrame([[1,0,1,-cac1a1,-cba1b0,ccb0c1]],columns=list_colums)\n",
    "    df7 = pd.DataFrame([[1,1,0,cac0a1,-cba1b1,-ccb1c0]],columns=list_colums)\n",
    "    df8 = pd.DataFrame([[1,1,1,-cac1a1,-cba1b1,-ccb1c1]],columns=list_colums)\n",
    "\n",
    "    celerities = celerities.append(df1)\n",
    "    celerities = celerities.append(df2)\n",
    "    celerities = celerities.append(df3)\n",
    "    celerities = celerities.append(df4)\n",
    "    celerities = celerities.append(df5)\n",
    "    celerities = celerities.append(df6)\n",
    "    celerities = celerities.append(df7)\n",
    "    celerities = celerities.append(df8)\n",
    "    celerities['signature'] = celerities.apply(get_signature,axis=1)\n",
    "\n",
    "    ini_discrete = ''\n",
    "    ini_fractional = []\n",
    "    if initial_state[0]>=sab:\n",
    "        ini_discrete = ini_discrete+'1'\n",
    "        ini_fractional = ini_fractional + [(initial_state[0]-sab)/(samax - sab)]\n",
    "    elif initial_state[0]<sab:\n",
    "        ini_discrete = ini_discrete+'0'\n",
    "        ini_fractional = ini_fractional + [initial_state[0]/sab]\n",
    "\n",
    "    if initial_state[1]>=sbc:\n",
    "        ini_discrete = ini_discrete+'1'\n",
    "        ini_fractional = ini_fractional + [(initial_state[1]-sbc)/(sbmax - sbc)]\n",
    "    elif initial_state[1]<sbc:\n",
    "        ini_discrete = ini_discrete+'0'\n",
    "        ini_fractional = ini_fractional + [initial_state[1]/sbc]\n",
    "\n",
    "    if initial_state[2]>=sca:\n",
    "        ini_discrete = ini_discrete+'1'\n",
    "        ini_fractional = ini_fractional + [(initial_state[2]-sca)/(scmax - sca)]\n",
    "    elif initial_state[2]<sca:\n",
    "        ini_discrete = ini_discrete+'0'\n",
    "        ini_fractional = ini_fractional + [initial_state[2]/sca]\n",
    "\n",
    "    data,t = simulation(ini_discrete,ini_fractional,num)\n",
    "    real_data = dc(data)\n",
    "    for i in range(data.shape[0]):\n",
    "        if data[i][0] < 1:\n",
    "            real_data[i][0] = data[i][0]*sab\n",
    "        elif data[i][0] >= 1:\n",
    "            real_data[i][0] = (data[i][0] - 1)*(samax - sab) + sab\n",
    "        if data[i][1] < 1:\n",
    "            real_data[i][1] = data[i][1]*sbc\n",
    "        elif data[i][1] >= 1:\n",
    "            real_data[i][1] = (data[i][1] - 1)*(sbmax - sbc) + sbc\n",
    "        if data[i][2] < 1:\n",
    "            real_data[i][2] = data[i][2]*sca\n",
    "        elif data[i][2] >= 1:\n",
    "            real_data[i][2] = (data[i][2] - 1)*(scmax - sca) + sca\n",
    "    noise_data = np.zeros((nb+1,3))\n",
    "    delta_t = t[-1][0]/nb\n",
    "    new_t = np.zeros((nb+1,1))\n",
    "    for i in range(nb+1):\n",
    "        new_t[i][0] = i*delta_t\n",
    "        for j in range(t.shape[0]-1):\n",
    "            if t[j][0] <= new_t[i][0] and t[j+1][0] >= new_t[i][0]:\n",
    "                noise_data[i][0] = random.gauss(0,noise1) + real_data[j][0] + (real_data[j+1][0] - real_data[j][0])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                noise_data[i][1] = random.gauss(0,noise2) + real_data[j][1] + (real_data[j+1][1] - real_data[j][1])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                noise_data[i][2] = random.gauss(0,noise3) + real_data[j][2] + (real_data[j+1][2] - real_data[j][2])*(new_t[i][0] - t[j][0])/(t[j+1][0] - t[j][0])\n",
    "                break\n",
    "    #plt.plot(new_t[0:nb],noise_data[0:nb,0],label='a')\n",
    "    #plt.plot(new_t[0:nb],noise_data[0:nb,1],label='b')\n",
    "    #plt.plot(new_t[0:nb],noise_data[0:nb,2],label='c')\n",
    "    #plt.legend()\n",
    "    #plt.savefig('simu1',dpi=1200)\n",
    "    \n",
    "    dataset[k, :, 0] = noise_data[0:nb,0]\n",
    "    dataset[k, :, 1] = noise_data[0:nb,1]\n",
    "    dataset[k, :, 2] = noise_data[0:nb,2]\n",
    "    \n",
    "    param[k, :] = [initial_state[0], initial_state[1], initial_state[2], noise1, noise2, noise3]\n",
    "    y[k, :] = [sca, sab, sbc, vac0a0, vac0a1, vac1a0, vac1a1, \n",
    "            vba0b0, vba0b1, vba1b0, vba1b1, vcb0c0, vcb0c1, vcb1c0, vcb1c1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ab = np.zeros((n_sim, nb-1, 2, 2))\n",
    "\n",
    "for k1 in range(n_sim):\n",
    "    for k2 in range(nb-1):\n",
    "        dataset_ab[k1, k2, 0, 0] = dataset[k1, k2, 0]\n",
    "        dataset_ab[k1, k2, 1, 0] = dataset[k1, k2+1, 0]\n",
    "        dataset_ab[k1, k2, 0, 1] = dataset[k1, k2, 1]\n",
    "        dataset_ab[k1, k2, 1, 1] = dataset[k1, k2+1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ab, X_test_ab, y_train_ab, y_test_ab = train_test_split(dataset_ab, y[:, 1], train_size = 0.7, shuffle = False)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "for k in range (nb-1):\n",
    "    X_train += [X_train_ab[:, k, :]]\n",
    "    X_test += [X_test_ab[:, k, :]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(dataset_ab[:, 0, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-a6f9b8bd7219>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0minput_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m   1020\u001b[0m                                                 input_list)\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1159\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1161\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    883\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    933\u001b[0m       self._set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    934\u001b[0m                               build_graph=False)\n\u001b[0;32m--> 935\u001b[0;31m       outputs = tf.nest.map_structure(\n\u001b[0m\u001b[1;32m    936\u001b[0m           keras_tensor.keras_tensor_from_tensor, outputs)\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    866\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m   return pack_sequence_as(\n\u001b[0m\u001b[1;32m    869\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m   \"\"\"\n\u001b[0;32m--> 757\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    619\u001b[0m         .format(truncate(flat_sequence, 100), type(flat_sequence)))\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m       raise ValueError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_input = []\n",
    "list_output = []\n",
    "for k in range (nb-1):\n",
    "    input_k = Input(shape = (2, 2,))\n",
    "    x = SimpleRNN(32)(input_k)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Model(inputs=input_k, outputs=x)\n",
    "    list_output += [x.output]\n",
    "    list_input += [x.input]\n",
    "\n",
    "output_N1 = concatenate(list_output)\n",
    "\n",
    "z = Dense(4, activation=\"relu\")(output_N1)\n",
    "z = Dense(2, activation=\"relu\")(z)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])\n",
    "\n",
    "history_ab = model_ab.fit(x=X_train, y=y_train_ab, epochs=5000, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "y_pred_ab = model_ab.predict(X_test)\n",
    "\n",
    "print(mean_absolute_error(y_pred_ab, y_test_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(batch_size=64, epochs=1000):\n",
    "    list_input = []\n",
    "    list_output = []\n",
    "    for k in range (nb-1):\n",
    "        input_k = Input(shape=(2, 2,))\n",
    "        x = SimpleRNN(32)(input_k)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=input_k, outputs=x)\n",
    "        list_output += [x.output]\n",
    "        list_input += [x.input]\n",
    "\n",
    "    output_N1 = concatenate(list_output)\n",
    "\n",
    "    z = Dense(4, activation=\"relu\")(output_N1)\n",
    "    z = Dense(2, activation=\"relu\")(z)\n",
    "    z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "    model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "    model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    history_ab = model_ab.fit(x=X_train, y=y_train_ab, epochs=epochs, batch_size=batch_size, validation_split=0.3)\n",
    "\n",
    "    return model_ab\n",
    "\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Dfinir les hyperparamtres pour GridSearchCV\n",
    "batch_sizes = [32, 64, 128]\n",
    "epochs = [500, 1000, 2000, 3000, 4000, 5000]\n",
    "param_grid = dict(batch_size=batch_sizes, epochs=epochs)\n",
    "\n",
    "# Utiliser GridSearchCV pour effectuer la recherche de grille\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train_ab)\n",
    "\n",
    "# Afficher les rsultats de la recherche de grille\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Dropout, Dense, Flatten, concatenate\n",
    "from tensorflow.keras.losses import MeanAbsoluteError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Dfinir une fonction qui cre le modle Keras avec les hyperparamtres donns\n",
    "def create_model(dropout_rate=0.3, learning_rate=0.001):\n",
    "    list_input = []\n",
    "    list_output = []\n",
    "    for k in range (nb-1):\n",
    "        input_k = Input(shape=(2, 2,))\n",
    "        x = SimpleRNN(32)(input_k)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Dense(16, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Dense(8, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        x = Flatten()(x)\n",
    "        x = Model(inputs=input_k, outputs=x)\n",
    "        list_output += [x.output]\n",
    "        list_input += [x.input]\n",
    "\n",
    "    output_N1 = concatenate(list_output)\n",
    "\n",
    "    z = Dense(4, activation=\"relu\")(output_N1)\n",
    "    z = Dense(2, activation=\"relu\")(z)\n",
    "    z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "    model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model_ab.compile(loss=MeanAbsoluteError(), optimizer=optimizer, metrics=[MeanAbsoluteError()])\n",
    "\n",
    "    history_ab = model_ab.fit(x=X_train, y=y_train_ab, epochs=1000, batch_size=64, validation_split=0.3)\n",
    "\n",
    "    return model_ab\n",
    "\n",
    "# Crer un modle Keras Wrapper pour tre utilis avec GridSearchCV\n",
    "model = KerasRegressor(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Dfinir les hyperparamtres pour GridSearchCV\n",
    "dropout_rates = [0.1, 0.3, 0.5]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "param_grid = dict(dropout_rate=dropout_rates, learning_rate=learning_rates)\n",
    "\n",
    "# Utiliser GridSearchCV pour effectuer la recherche de grille\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "grid_result = grid.fit(X_train, y_train_ab)\n",
    "\n",
    "# Afficher les rsultats de la recherche de grille\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*nb* entres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liste_dataset_ab_2 = [0]*n_sim\n",
    "for s in range(n_sim):\n",
    "    param_array = np.zeros((4))\n",
    "    param_array[0] = param[s, 0] # tat initial a \n",
    "    param_array[1] = param[s, 1] # tat initial b\n",
    "    param_array[2] = param[s, 3] # bruit a \n",
    "    param_array[3] = param[s, 4] # bruit b \n",
    "    liste_dataset_ab_2[s] = [param_array]\n",
    "    liste_dataset_ab_2[s] += [dataset_ab[s, :, :, :]]\n",
    "       \n",
    "X_train_ab_2, X_test_ab_2, y_train_ab_2, y_test_ab_2 = train_test_split(liste_dataset_ab_2, y[:, 1], train_size = 0.7, shuffle = False)\n",
    "\n",
    "X_train_2 = [0]*nb\n",
    "X_test_2 = [0]*nb\n",
    "\n",
    "X_train_2[0] = np.zeros((len(X_train_ab_2), 4))\n",
    "X_test_2[0] = np.zeros((len(X_test_ab_2), 4))\n",
    "\n",
    "for s in range(len(X_train_ab_2)):\n",
    "    X_train_2[0][s] = X_train_ab_2[s][0]\n",
    "\n",
    "for k in range(nb-1):\n",
    "    array_k = np.zeros((len(X_train_ab_2), 2, 2))\n",
    "    for s in range(len(X_train_ab_2)):\n",
    "        array_k[s, :, :] = X_train_ab_2[s][1][k]\n",
    "    X_train_2[k+1] = array_k\n",
    "\n",
    "for k in range(nb-1):\n",
    "    array_k = np.zeros((len(X_test_ab_2), 2, 2))\n",
    "    for s in range(len(X_test_ab_2)):\n",
    "        array_k[s, :, :] = X_test_ab_2[s][1][k]\n",
    "    X_test_2[k+1] = array_k      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-306-ef80596dadd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0minput_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     \u001b[0;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1019\u001b[0;31m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[1;32m   1020\u001b[0m                                                 input_list)\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1158\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[1;32m   1159\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[1;32m   1161\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    883\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    928\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_call_info_injected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1609\u001b[0;31m     return super(SimpleRNN, self).call(\n\u001b[0m\u001b[1;32m   1610\u001b[0m         inputs, mask=mask, training=training, initial_state=initial_state)\n\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state, constants)\u001b[0m\n\u001b[1;32m    814\u001b[0m           \u001b[0mnew_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 816\u001b[0;31m     last_output, outputs, states = backend.rnn(\n\u001b[0m\u001b[1;32m    817\u001b[0m         \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(step_function, inputs, initial_states, go_backwards, mask, constants, unroll, input_length, time_major, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   4652\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta_t\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4654\u001b[0;31m       final_outputs = tf.compat.v1.while_loop(\n\u001b[0m\u001b[1;32m   4655\u001b[0m           \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4656\u001b[0m           \u001b[0mloop_vars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_ta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2744\u001b[0m   if (util.EnableControlFlowV2(ops.get_default_graph()) and\n\u001b[1;32m   2745\u001b[0m       not executing_eagerly):\n\u001b[0;32m-> 2746\u001b[0;31m     return while_v2.while_loop(\n\u001b[0m\u001b[1;32m   2747\u001b[0m         \u001b[0mcond\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2748\u001b[0m         \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, maximum_iterations, name, return_same_structure, back_prop)\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0mcond_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_fn_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cond\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m       \u001b[0mbody_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_fn_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"body\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     maximum_iterations_loop_var = _build_maximum_iterations_loop_var(\n\u001b[0m\u001b[1;32m    120\u001b[0m         maximum_iterations)\n\u001b[1;32m    121\u001b[0m     loop_counter = constant_op.constant(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/while_v2.py\u001b[0m in \u001b[0;36m_build_maximum_iterations_loop_var\u001b[0;34m(maximum_iterations)\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0mmaximum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m   \u001b[0;31m# EmptyTensorList expects `max_num_elements` to be of type int32.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m   return ops.convert_to_tensor(\n\u001b[0m\u001b[1;32m   1404\u001b[0m       maximum_iterations, dtype=dtypes.int32, name=\"maximum_iterations\")\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    294\u001b[0m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         compute_device)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3698\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2111\u001b[0m       \u001b[0mtf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m       \u001b[0moutput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationOutputType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2113\u001b[0;31m       \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_with_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2114\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_with_tf_output\u001b[0;34m(op, value_index, dtype, tf_output)\u001b[0m\n\u001b[1;32m    444\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_with_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, op, value_index, dtype)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# to easily navigate a computation graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consumers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36muid\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;34m\"\"\"A unique (within this program execution) integer.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_Py_UID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_input = []\n",
    "list_output = []\n",
    "\n",
    "input_param = Input(shape = (4,)) # tat initial et bruit\n",
    "x = Dense(16, activation=\"relu\")(input_param)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Model(inputs=input_param, outputs=x)\n",
    "list_output += [x.output]\n",
    "list_input += [x.input]\n",
    "\n",
    "for k in range (nb-1):\n",
    "    input_k = Input(shape = (2, 2,))\n",
    "    x = SimpleRNN(32)(input_k)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Model(inputs=input_k, outputs=x)\n",
    "    list_output += [x.output]\n",
    "    list_input += [x.input]\n",
    "\n",
    "output_N1 = concatenate(list_output)\n",
    "\n",
    "z = Dense(4, activation=\"relu\")(output_N1)\n",
    "z = Dense(2, activation=\"relu\")(z)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1365\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1263 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1264 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1265 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1266 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1267 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1268 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1269 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1270 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1271 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1272 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1273 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1274 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1275 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1276 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1277 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1278 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1279 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1280 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1281 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1282 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1283 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1284 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1285 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1286 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1287 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1288 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1289 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1290 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1291 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1292 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1293 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1294 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1295 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1296 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1297 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1298 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1299 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1300 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1301 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1302 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1303 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1304 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1305 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1306 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1307 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1308 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1309 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1310 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1311 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1312 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1313 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1314 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1315 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1316 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1317 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1318 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1319 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1320 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1321 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1322 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1323 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1324 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1325 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1326 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1327 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1328 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1329 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1330 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1331 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1332 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1333 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1334 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1335 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1336 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1337 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1338 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1339 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1340 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1341 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1342 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1343 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1344 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1345 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1346 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1347 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1348 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1349 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1350 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1351 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1352 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1353 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1354 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1355 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1356 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1357 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1358 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1359 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1360 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " input_1361 (InputLayer)        [(None, 2, 2)]       0           []                               \n",
      "                                                                                                  \n",
      " simple_rnn_1232 (SimpleRNN)    (None, 32)           1120        ['input_1263[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1233 (SimpleRNN)    (None, 32)           1120        ['input_1264[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1234 (SimpleRNN)    (None, 32)           1120        ['input_1265[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1235 (SimpleRNN)    (None, 32)           1120        ['input_1266[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1236 (SimpleRNN)    (None, 32)           1120        ['input_1267[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1237 (SimpleRNN)    (None, 32)           1120        ['input_1268[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1238 (SimpleRNN)    (None, 32)           1120        ['input_1269[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1239 (SimpleRNN)    (None, 32)           1120        ['input_1270[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1240 (SimpleRNN)    (None, 32)           1120        ['input_1271[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1241 (SimpleRNN)    (None, 32)           1120        ['input_1272[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1242 (SimpleRNN)    (None, 32)           1120        ['input_1273[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1243 (SimpleRNN)    (None, 32)           1120        ['input_1274[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1244 (SimpleRNN)    (None, 32)           1120        ['input_1275[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1245 (SimpleRNN)    (None, 32)           1120        ['input_1276[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1246 (SimpleRNN)    (None, 32)           1120        ['input_1277[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1247 (SimpleRNN)    (None, 32)           1120        ['input_1278[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1248 (SimpleRNN)    (None, 32)           1120        ['input_1279[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1249 (SimpleRNN)    (None, 32)           1120        ['input_1280[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1250 (SimpleRNN)    (None, 32)           1120        ['input_1281[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1251 (SimpleRNN)    (None, 32)           1120        ['input_1282[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1252 (SimpleRNN)    (None, 32)           1120        ['input_1283[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1253 (SimpleRNN)    (None, 32)           1120        ['input_1284[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1254 (SimpleRNN)    (None, 32)           1120        ['input_1285[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1255 (SimpleRNN)    (None, 32)           1120        ['input_1286[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1256 (SimpleRNN)    (None, 32)           1120        ['input_1287[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1257 (SimpleRNN)    (None, 32)           1120        ['input_1288[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1258 (SimpleRNN)    (None, 32)           1120        ['input_1289[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1259 (SimpleRNN)    (None, 32)           1120        ['input_1290[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1260 (SimpleRNN)    (None, 32)           1120        ['input_1291[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1261 (SimpleRNN)    (None, 32)           1120        ['input_1292[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1262 (SimpleRNN)    (None, 32)           1120        ['input_1293[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1263 (SimpleRNN)    (None, 32)           1120        ['input_1294[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1264 (SimpleRNN)    (None, 32)           1120        ['input_1295[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1265 (SimpleRNN)    (None, 32)           1120        ['input_1296[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1266 (SimpleRNN)    (None, 32)           1120        ['input_1297[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1267 (SimpleRNN)    (None, 32)           1120        ['input_1298[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1268 (SimpleRNN)    (None, 32)           1120        ['input_1299[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1269 (SimpleRNN)    (None, 32)           1120        ['input_1300[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1270 (SimpleRNN)    (None, 32)           1120        ['input_1301[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1271 (SimpleRNN)    (None, 32)           1120        ['input_1302[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1272 (SimpleRNN)    (None, 32)           1120        ['input_1303[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1273 (SimpleRNN)    (None, 32)           1120        ['input_1304[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1274 (SimpleRNN)    (None, 32)           1120        ['input_1305[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1275 (SimpleRNN)    (None, 32)           1120        ['input_1306[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1276 (SimpleRNN)    (None, 32)           1120        ['input_1307[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1277 (SimpleRNN)    (None, 32)           1120        ['input_1308[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1278 (SimpleRNN)    (None, 32)           1120        ['input_1309[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1279 (SimpleRNN)    (None, 32)           1120        ['input_1310[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1280 (SimpleRNN)    (None, 32)           1120        ['input_1311[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1281 (SimpleRNN)    (None, 32)           1120        ['input_1312[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1282 (SimpleRNN)    (None, 32)           1120        ['input_1313[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1283 (SimpleRNN)    (None, 32)           1120        ['input_1314[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1284 (SimpleRNN)    (None, 32)           1120        ['input_1315[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1285 (SimpleRNN)    (None, 32)           1120        ['input_1316[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1286 (SimpleRNN)    (None, 32)           1120        ['input_1317[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1287 (SimpleRNN)    (None, 32)           1120        ['input_1318[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1288 (SimpleRNN)    (None, 32)           1120        ['input_1319[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1289 (SimpleRNN)    (None, 32)           1120        ['input_1320[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1290 (SimpleRNN)    (None, 32)           1120        ['input_1321[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1291 (SimpleRNN)    (None, 32)           1120        ['input_1322[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1292 (SimpleRNN)    (None, 32)           1120        ['input_1323[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1293 (SimpleRNN)    (None, 32)           1120        ['input_1324[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1294 (SimpleRNN)    (None, 32)           1120        ['input_1325[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1295 (SimpleRNN)    (None, 32)           1120        ['input_1326[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1296 (SimpleRNN)    (None, 32)           1120        ['input_1327[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1297 (SimpleRNN)    (None, 32)           1120        ['input_1328[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1298 (SimpleRNN)    (None, 32)           1120        ['input_1329[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1299 (SimpleRNN)    (None, 32)           1120        ['input_1330[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1300 (SimpleRNN)    (None, 32)           1120        ['input_1331[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1301 (SimpleRNN)    (None, 32)           1120        ['input_1332[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1302 (SimpleRNN)    (None, 32)           1120        ['input_1333[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1303 (SimpleRNN)    (None, 32)           1120        ['input_1334[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1304 (SimpleRNN)    (None, 32)           1120        ['input_1335[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1305 (SimpleRNN)    (None, 32)           1120        ['input_1336[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1306 (SimpleRNN)    (None, 32)           1120        ['input_1337[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1307 (SimpleRNN)    (None, 32)           1120        ['input_1338[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1308 (SimpleRNN)    (None, 32)           1120        ['input_1339[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1309 (SimpleRNN)    (None, 32)           1120        ['input_1340[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1310 (SimpleRNN)    (None, 32)           1120        ['input_1341[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1311 (SimpleRNN)    (None, 32)           1120        ['input_1342[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1312 (SimpleRNN)    (None, 32)           1120        ['input_1343[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1313 (SimpleRNN)    (None, 32)           1120        ['input_1344[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1314 (SimpleRNN)    (None, 32)           1120        ['input_1345[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1315 (SimpleRNN)    (None, 32)           1120        ['input_1346[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1316 (SimpleRNN)    (None, 32)           1120        ['input_1347[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1317 (SimpleRNN)    (None, 32)           1120        ['input_1348[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1318 (SimpleRNN)    (None, 32)           1120        ['input_1349[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1319 (SimpleRNN)    (None, 32)           1120        ['input_1350[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1320 (SimpleRNN)    (None, 32)           1120        ['input_1351[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1321 (SimpleRNN)    (None, 32)           1120        ['input_1352[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1322 (SimpleRNN)    (None, 32)           1120        ['input_1353[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1323 (SimpleRNN)    (None, 32)           1120        ['input_1354[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1324 (SimpleRNN)    (None, 32)           1120        ['input_1355[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1325 (SimpleRNN)    (None, 32)           1120        ['input_1356[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1326 (SimpleRNN)    (None, 32)           1120        ['input_1357[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1327 (SimpleRNN)    (None, 32)           1120        ['input_1358[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1328 (SimpleRNN)    (None, 32)           1120        ['input_1359[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1329 (SimpleRNN)    (None, 32)           1120        ['input_1360[0][0]']             \n",
      "                                                                                                  \n",
      " simple_rnn_1330 (SimpleRNN)    (None, 32)           1120        ['input_1361[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3739 (Dropout)         (None, 32)           0           ['simple_rnn_1232[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3742 (Dropout)         (None, 32)           0           ['simple_rnn_1233[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3745 (Dropout)         (None, 32)           0           ['simple_rnn_1234[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3748 (Dropout)         (None, 32)           0           ['simple_rnn_1235[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3751 (Dropout)         (None, 32)           0           ['simple_rnn_1236[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3754 (Dropout)         (None, 32)           0           ['simple_rnn_1237[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3757 (Dropout)         (None, 32)           0           ['simple_rnn_1238[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3760 (Dropout)         (None, 32)           0           ['simple_rnn_1239[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3763 (Dropout)         (None, 32)           0           ['simple_rnn_1240[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3766 (Dropout)         (None, 32)           0           ['simple_rnn_1241[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3769 (Dropout)         (None, 32)           0           ['simple_rnn_1242[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3772 (Dropout)         (None, 32)           0           ['simple_rnn_1243[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3775 (Dropout)         (None, 32)           0           ['simple_rnn_1244[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3778 (Dropout)         (None, 32)           0           ['simple_rnn_1245[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3781 (Dropout)         (None, 32)           0           ['simple_rnn_1246[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3784 (Dropout)         (None, 32)           0           ['simple_rnn_1247[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3787 (Dropout)         (None, 32)           0           ['simple_rnn_1248[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3790 (Dropout)         (None, 32)           0           ['simple_rnn_1249[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3793 (Dropout)         (None, 32)           0           ['simple_rnn_1250[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3796 (Dropout)         (None, 32)           0           ['simple_rnn_1251[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3799 (Dropout)         (None, 32)           0           ['simple_rnn_1252[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3802 (Dropout)         (None, 32)           0           ['simple_rnn_1253[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3805 (Dropout)         (None, 32)           0           ['simple_rnn_1254[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3808 (Dropout)         (None, 32)           0           ['simple_rnn_1255[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3811 (Dropout)         (None, 32)           0           ['simple_rnn_1256[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3814 (Dropout)         (None, 32)           0           ['simple_rnn_1257[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3817 (Dropout)         (None, 32)           0           ['simple_rnn_1258[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3820 (Dropout)         (None, 32)           0           ['simple_rnn_1259[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3823 (Dropout)         (None, 32)           0           ['simple_rnn_1260[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3826 (Dropout)         (None, 32)           0           ['simple_rnn_1261[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3829 (Dropout)         (None, 32)           0           ['simple_rnn_1262[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3832 (Dropout)         (None, 32)           0           ['simple_rnn_1263[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3835 (Dropout)         (None, 32)           0           ['simple_rnn_1264[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3838 (Dropout)         (None, 32)           0           ['simple_rnn_1265[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3841 (Dropout)         (None, 32)           0           ['simple_rnn_1266[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3844 (Dropout)         (None, 32)           0           ['simple_rnn_1267[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3847 (Dropout)         (None, 32)           0           ['simple_rnn_1268[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3850 (Dropout)         (None, 32)           0           ['simple_rnn_1269[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3853 (Dropout)         (None, 32)           0           ['simple_rnn_1270[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3856 (Dropout)         (None, 32)           0           ['simple_rnn_1271[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3859 (Dropout)         (None, 32)           0           ['simple_rnn_1272[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3862 (Dropout)         (None, 32)           0           ['simple_rnn_1273[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3865 (Dropout)         (None, 32)           0           ['simple_rnn_1274[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3868 (Dropout)         (None, 32)           0           ['simple_rnn_1275[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3871 (Dropout)         (None, 32)           0           ['simple_rnn_1276[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3874 (Dropout)         (None, 32)           0           ['simple_rnn_1277[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3877 (Dropout)         (None, 32)           0           ['simple_rnn_1278[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3880 (Dropout)         (None, 32)           0           ['simple_rnn_1279[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3883 (Dropout)         (None, 32)           0           ['simple_rnn_1280[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3886 (Dropout)         (None, 32)           0           ['simple_rnn_1281[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3889 (Dropout)         (None, 32)           0           ['simple_rnn_1282[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3892 (Dropout)         (None, 32)           0           ['simple_rnn_1283[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3895 (Dropout)         (None, 32)           0           ['simple_rnn_1284[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3898 (Dropout)         (None, 32)           0           ['simple_rnn_1285[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3901 (Dropout)         (None, 32)           0           ['simple_rnn_1286[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3904 (Dropout)         (None, 32)           0           ['simple_rnn_1287[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3907 (Dropout)         (None, 32)           0           ['simple_rnn_1288[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3910 (Dropout)         (None, 32)           0           ['simple_rnn_1289[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3913 (Dropout)         (None, 32)           0           ['simple_rnn_1290[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3916 (Dropout)         (None, 32)           0           ['simple_rnn_1291[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3919 (Dropout)         (None, 32)           0           ['simple_rnn_1292[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3922 (Dropout)         (None, 32)           0           ['simple_rnn_1293[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3925 (Dropout)         (None, 32)           0           ['simple_rnn_1294[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3928 (Dropout)         (None, 32)           0           ['simple_rnn_1295[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3931 (Dropout)         (None, 32)           0           ['simple_rnn_1296[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3934 (Dropout)         (None, 32)           0           ['simple_rnn_1297[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3937 (Dropout)         (None, 32)           0           ['simple_rnn_1298[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3940 (Dropout)         (None, 32)           0           ['simple_rnn_1299[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3943 (Dropout)         (None, 32)           0           ['simple_rnn_1300[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3946 (Dropout)         (None, 32)           0           ['simple_rnn_1301[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3949 (Dropout)         (None, 32)           0           ['simple_rnn_1302[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3952 (Dropout)         (None, 32)           0           ['simple_rnn_1303[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3955 (Dropout)         (None, 32)           0           ['simple_rnn_1304[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3958 (Dropout)         (None, 32)           0           ['simple_rnn_1305[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3961 (Dropout)         (None, 32)           0           ['simple_rnn_1306[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3964 (Dropout)         (None, 32)           0           ['simple_rnn_1307[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3967 (Dropout)         (None, 32)           0           ['simple_rnn_1308[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3970 (Dropout)         (None, 32)           0           ['simple_rnn_1309[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3973 (Dropout)         (None, 32)           0           ['simple_rnn_1310[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3976 (Dropout)         (None, 32)           0           ['simple_rnn_1311[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3979 (Dropout)         (None, 32)           0           ['simple_rnn_1312[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3982 (Dropout)         (None, 32)           0           ['simple_rnn_1313[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3985 (Dropout)         (None, 32)           0           ['simple_rnn_1314[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3988 (Dropout)         (None, 32)           0           ['simple_rnn_1315[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3991 (Dropout)         (None, 32)           0           ['simple_rnn_1316[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3994 (Dropout)         (None, 32)           0           ['simple_rnn_1317[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_3997 (Dropout)         (None, 32)           0           ['simple_rnn_1318[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4000 (Dropout)         (None, 32)           0           ['simple_rnn_1319[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4003 (Dropout)         (None, 32)           0           ['simple_rnn_1320[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4006 (Dropout)         (None, 32)           0           ['simple_rnn_1321[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4009 (Dropout)         (None, 32)           0           ['simple_rnn_1322[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4012 (Dropout)         (None, 32)           0           ['simple_rnn_1323[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4015 (Dropout)         (None, 32)           0           ['simple_rnn_1324[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4018 (Dropout)         (None, 32)           0           ['simple_rnn_1325[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4021 (Dropout)         (None, 32)           0           ['simple_rnn_1326[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4024 (Dropout)         (None, 32)           0           ['simple_rnn_1327[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4027 (Dropout)         (None, 32)           0           ['simple_rnn_1328[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4030 (Dropout)         (None, 32)           0           ['simple_rnn_1329[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_4033 (Dropout)         (None, 32)           0           ['simple_rnn_1330[0][0]']        \n",
      "                                                                                                  \n",
      " input_1262 (InputLayer)        [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_2544 (Dense)             (None, 16)           528         ['dropout_3739[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2546 (Dense)             (None, 16)           528         ['dropout_3742[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2548 (Dense)             (None, 16)           528         ['dropout_3745[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2550 (Dense)             (None, 16)           528         ['dropout_3748[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2552 (Dense)             (None, 16)           528         ['dropout_3751[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2554 (Dense)             (None, 16)           528         ['dropout_3754[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2556 (Dense)             (None, 16)           528         ['dropout_3757[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2558 (Dense)             (None, 16)           528         ['dropout_3760[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2560 (Dense)             (None, 16)           528         ['dropout_3763[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2562 (Dense)             (None, 16)           528         ['dropout_3766[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2564 (Dense)             (None, 16)           528         ['dropout_3769[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2566 (Dense)             (None, 16)           528         ['dropout_3772[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2568 (Dense)             (None, 16)           528         ['dropout_3775[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2570 (Dense)             (None, 16)           528         ['dropout_3778[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2572 (Dense)             (None, 16)           528         ['dropout_3781[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2574 (Dense)             (None, 16)           528         ['dropout_3784[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2576 (Dense)             (None, 16)           528         ['dropout_3787[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2578 (Dense)             (None, 16)           528         ['dropout_3790[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2580 (Dense)             (None, 16)           528         ['dropout_3793[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2582 (Dense)             (None, 16)           528         ['dropout_3796[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2584 (Dense)             (None, 16)           528         ['dropout_3799[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2586 (Dense)             (None, 16)           528         ['dropout_3802[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2588 (Dense)             (None, 16)           528         ['dropout_3805[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2590 (Dense)             (None, 16)           528         ['dropout_3808[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2592 (Dense)             (None, 16)           528         ['dropout_3811[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2594 (Dense)             (None, 16)           528         ['dropout_3814[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2596 (Dense)             (None, 16)           528         ['dropout_3817[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2598 (Dense)             (None, 16)           528         ['dropout_3820[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2600 (Dense)             (None, 16)           528         ['dropout_3823[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2602 (Dense)             (None, 16)           528         ['dropout_3826[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2604 (Dense)             (None, 16)           528         ['dropout_3829[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2606 (Dense)             (None, 16)           528         ['dropout_3832[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2608 (Dense)             (None, 16)           528         ['dropout_3835[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2610 (Dense)             (None, 16)           528         ['dropout_3838[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2612 (Dense)             (None, 16)           528         ['dropout_3841[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2614 (Dense)             (None, 16)           528         ['dropout_3844[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2616 (Dense)             (None, 16)           528         ['dropout_3847[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2618 (Dense)             (None, 16)           528         ['dropout_3850[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2620 (Dense)             (None, 16)           528         ['dropout_3853[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2622 (Dense)             (None, 16)           528         ['dropout_3856[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2624 (Dense)             (None, 16)           528         ['dropout_3859[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2626 (Dense)             (None, 16)           528         ['dropout_3862[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2628 (Dense)             (None, 16)           528         ['dropout_3865[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2630 (Dense)             (None, 16)           528         ['dropout_3868[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2632 (Dense)             (None, 16)           528         ['dropout_3871[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2634 (Dense)             (None, 16)           528         ['dropout_3874[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2636 (Dense)             (None, 16)           528         ['dropout_3877[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2638 (Dense)             (None, 16)           528         ['dropout_3880[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2640 (Dense)             (None, 16)           528         ['dropout_3883[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2642 (Dense)             (None, 16)           528         ['dropout_3886[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2644 (Dense)             (None, 16)           528         ['dropout_3889[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2646 (Dense)             (None, 16)           528         ['dropout_3892[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2648 (Dense)             (None, 16)           528         ['dropout_3895[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2650 (Dense)             (None, 16)           528         ['dropout_3898[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2652 (Dense)             (None, 16)           528         ['dropout_3901[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2654 (Dense)             (None, 16)           528         ['dropout_3904[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2656 (Dense)             (None, 16)           528         ['dropout_3907[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2658 (Dense)             (None, 16)           528         ['dropout_3910[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2660 (Dense)             (None, 16)           528         ['dropout_3913[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2662 (Dense)             (None, 16)           528         ['dropout_3916[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2664 (Dense)             (None, 16)           528         ['dropout_3919[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2666 (Dense)             (None, 16)           528         ['dropout_3922[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2668 (Dense)             (None, 16)           528         ['dropout_3925[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2670 (Dense)             (None, 16)           528         ['dropout_3928[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2672 (Dense)             (None, 16)           528         ['dropout_3931[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2674 (Dense)             (None, 16)           528         ['dropout_3934[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2676 (Dense)             (None, 16)           528         ['dropout_3937[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2678 (Dense)             (None, 16)           528         ['dropout_3940[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2680 (Dense)             (None, 16)           528         ['dropout_3943[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2682 (Dense)             (None, 16)           528         ['dropout_3946[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2684 (Dense)             (None, 16)           528         ['dropout_3949[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2686 (Dense)             (None, 16)           528         ['dropout_3952[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2688 (Dense)             (None, 16)           528         ['dropout_3955[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2690 (Dense)             (None, 16)           528         ['dropout_3958[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2692 (Dense)             (None, 16)           528         ['dropout_3961[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2694 (Dense)             (None, 16)           528         ['dropout_3964[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2696 (Dense)             (None, 16)           528         ['dropout_3967[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2698 (Dense)             (None, 16)           528         ['dropout_3970[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2700 (Dense)             (None, 16)           528         ['dropout_3973[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2702 (Dense)             (None, 16)           528         ['dropout_3976[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2704 (Dense)             (None, 16)           528         ['dropout_3979[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2706 (Dense)             (None, 16)           528         ['dropout_3982[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2708 (Dense)             (None, 16)           528         ['dropout_3985[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2710 (Dense)             (None, 16)           528         ['dropout_3988[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2712 (Dense)             (None, 16)           528         ['dropout_3991[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2714 (Dense)             (None, 16)           528         ['dropout_3994[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2716 (Dense)             (None, 16)           528         ['dropout_3997[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2718 (Dense)             (None, 16)           528         ['dropout_4000[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2720 (Dense)             (None, 16)           528         ['dropout_4003[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2722 (Dense)             (None, 16)           528         ['dropout_4006[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2724 (Dense)             (None, 16)           528         ['dropout_4009[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2726 (Dense)             (None, 16)           528         ['dropout_4012[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2728 (Dense)             (None, 16)           528         ['dropout_4015[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2730 (Dense)             (None, 16)           528         ['dropout_4018[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2732 (Dense)             (None, 16)           528         ['dropout_4021[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2734 (Dense)             (None, 16)           528         ['dropout_4024[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2736 (Dense)             (None, 16)           528         ['dropout_4027[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2738 (Dense)             (None, 16)           528         ['dropout_4030[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2740 (Dense)             (None, 16)           528         ['dropout_4033[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2542 (Dense)             (None, 16)           80          ['input_1262[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3740 (Dropout)         (None, 16)           0           ['dense_2544[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3743 (Dropout)         (None, 16)           0           ['dense_2546[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3746 (Dropout)         (None, 16)           0           ['dense_2548[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3749 (Dropout)         (None, 16)           0           ['dense_2550[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3752 (Dropout)         (None, 16)           0           ['dense_2552[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3755 (Dropout)         (None, 16)           0           ['dense_2554[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3758 (Dropout)         (None, 16)           0           ['dense_2556[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3761 (Dropout)         (None, 16)           0           ['dense_2558[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3764 (Dropout)         (None, 16)           0           ['dense_2560[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3767 (Dropout)         (None, 16)           0           ['dense_2562[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3770 (Dropout)         (None, 16)           0           ['dense_2564[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3773 (Dropout)         (None, 16)           0           ['dense_2566[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3776 (Dropout)         (None, 16)           0           ['dense_2568[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3779 (Dropout)         (None, 16)           0           ['dense_2570[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3782 (Dropout)         (None, 16)           0           ['dense_2572[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3785 (Dropout)         (None, 16)           0           ['dense_2574[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3788 (Dropout)         (None, 16)           0           ['dense_2576[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3791 (Dropout)         (None, 16)           0           ['dense_2578[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3794 (Dropout)         (None, 16)           0           ['dense_2580[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3797 (Dropout)         (None, 16)           0           ['dense_2582[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3800 (Dropout)         (None, 16)           0           ['dense_2584[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3803 (Dropout)         (None, 16)           0           ['dense_2586[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3806 (Dropout)         (None, 16)           0           ['dense_2588[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3809 (Dropout)         (None, 16)           0           ['dense_2590[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3812 (Dropout)         (None, 16)           0           ['dense_2592[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3815 (Dropout)         (None, 16)           0           ['dense_2594[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3818 (Dropout)         (None, 16)           0           ['dense_2596[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3821 (Dropout)         (None, 16)           0           ['dense_2598[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3824 (Dropout)         (None, 16)           0           ['dense_2600[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3827 (Dropout)         (None, 16)           0           ['dense_2602[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3830 (Dropout)         (None, 16)           0           ['dense_2604[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3833 (Dropout)         (None, 16)           0           ['dense_2606[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3836 (Dropout)         (None, 16)           0           ['dense_2608[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3839 (Dropout)         (None, 16)           0           ['dense_2610[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3842 (Dropout)         (None, 16)           0           ['dense_2612[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3845 (Dropout)         (None, 16)           0           ['dense_2614[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3848 (Dropout)         (None, 16)           0           ['dense_2616[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3851 (Dropout)         (None, 16)           0           ['dense_2618[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3854 (Dropout)         (None, 16)           0           ['dense_2620[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3857 (Dropout)         (None, 16)           0           ['dense_2622[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3860 (Dropout)         (None, 16)           0           ['dense_2624[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3863 (Dropout)         (None, 16)           0           ['dense_2626[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3866 (Dropout)         (None, 16)           0           ['dense_2628[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3869 (Dropout)         (None, 16)           0           ['dense_2630[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3872 (Dropout)         (None, 16)           0           ['dense_2632[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3875 (Dropout)         (None, 16)           0           ['dense_2634[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3878 (Dropout)         (None, 16)           0           ['dense_2636[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3881 (Dropout)         (None, 16)           0           ['dense_2638[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3884 (Dropout)         (None, 16)           0           ['dense_2640[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3887 (Dropout)         (None, 16)           0           ['dense_2642[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3890 (Dropout)         (None, 16)           0           ['dense_2644[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3893 (Dropout)         (None, 16)           0           ['dense_2646[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3896 (Dropout)         (None, 16)           0           ['dense_2648[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3899 (Dropout)         (None, 16)           0           ['dense_2650[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3902 (Dropout)         (None, 16)           0           ['dense_2652[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3905 (Dropout)         (None, 16)           0           ['dense_2654[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3908 (Dropout)         (None, 16)           0           ['dense_2656[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3911 (Dropout)         (None, 16)           0           ['dense_2658[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3914 (Dropout)         (None, 16)           0           ['dense_2660[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3917 (Dropout)         (None, 16)           0           ['dense_2662[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3920 (Dropout)         (None, 16)           0           ['dense_2664[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3923 (Dropout)         (None, 16)           0           ['dense_2666[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3926 (Dropout)         (None, 16)           0           ['dense_2668[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3929 (Dropout)         (None, 16)           0           ['dense_2670[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3932 (Dropout)         (None, 16)           0           ['dense_2672[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3935 (Dropout)         (None, 16)           0           ['dense_2674[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3938 (Dropout)         (None, 16)           0           ['dense_2676[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3941 (Dropout)         (None, 16)           0           ['dense_2678[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3944 (Dropout)         (None, 16)           0           ['dense_2680[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3947 (Dropout)         (None, 16)           0           ['dense_2682[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3950 (Dropout)         (None, 16)           0           ['dense_2684[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3953 (Dropout)         (None, 16)           0           ['dense_2686[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3956 (Dropout)         (None, 16)           0           ['dense_2688[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3959 (Dropout)         (None, 16)           0           ['dense_2690[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3962 (Dropout)         (None, 16)           0           ['dense_2692[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3965 (Dropout)         (None, 16)           0           ['dense_2694[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3968 (Dropout)         (None, 16)           0           ['dense_2696[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3971 (Dropout)         (None, 16)           0           ['dense_2698[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3974 (Dropout)         (None, 16)           0           ['dense_2700[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3977 (Dropout)         (None, 16)           0           ['dense_2702[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3980 (Dropout)         (None, 16)           0           ['dense_2704[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3983 (Dropout)         (None, 16)           0           ['dense_2706[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3986 (Dropout)         (None, 16)           0           ['dense_2708[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3989 (Dropout)         (None, 16)           0           ['dense_2710[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3992 (Dropout)         (None, 16)           0           ['dense_2712[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3995 (Dropout)         (None, 16)           0           ['dense_2714[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3998 (Dropout)         (None, 16)           0           ['dense_2716[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4001 (Dropout)         (None, 16)           0           ['dense_2718[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4004 (Dropout)         (None, 16)           0           ['dense_2720[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4007 (Dropout)         (None, 16)           0           ['dense_2722[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4010 (Dropout)         (None, 16)           0           ['dense_2724[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4013 (Dropout)         (None, 16)           0           ['dense_2726[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4016 (Dropout)         (None, 16)           0           ['dense_2728[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4019 (Dropout)         (None, 16)           0           ['dense_2730[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4022 (Dropout)         (None, 16)           0           ['dense_2732[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4025 (Dropout)         (None, 16)           0           ['dense_2734[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4028 (Dropout)         (None, 16)           0           ['dense_2736[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4031 (Dropout)         (None, 16)           0           ['dense_2738[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4034 (Dropout)         (None, 16)           0           ['dense_2740[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3737 (Dropout)         (None, 16)           0           ['dense_2542[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2545 (Dense)             (None, 8)            136         ['dropout_3740[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2547 (Dense)             (None, 8)            136         ['dropout_3743[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2549 (Dense)             (None, 8)            136         ['dropout_3746[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2551 (Dense)             (None, 8)            136         ['dropout_3749[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2553 (Dense)             (None, 8)            136         ['dropout_3752[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2555 (Dense)             (None, 8)            136         ['dropout_3755[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2557 (Dense)             (None, 8)            136         ['dropout_3758[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2559 (Dense)             (None, 8)            136         ['dropout_3761[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2561 (Dense)             (None, 8)            136         ['dropout_3764[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2563 (Dense)             (None, 8)            136         ['dropout_3767[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2565 (Dense)             (None, 8)            136         ['dropout_3770[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2567 (Dense)             (None, 8)            136         ['dropout_3773[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2569 (Dense)             (None, 8)            136         ['dropout_3776[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2571 (Dense)             (None, 8)            136         ['dropout_3779[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2573 (Dense)             (None, 8)            136         ['dropout_3782[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2575 (Dense)             (None, 8)            136         ['dropout_3785[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2577 (Dense)             (None, 8)            136         ['dropout_3788[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2579 (Dense)             (None, 8)            136         ['dropout_3791[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2581 (Dense)             (None, 8)            136         ['dropout_3794[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2583 (Dense)             (None, 8)            136         ['dropout_3797[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2585 (Dense)             (None, 8)            136         ['dropout_3800[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2587 (Dense)             (None, 8)            136         ['dropout_3803[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2589 (Dense)             (None, 8)            136         ['dropout_3806[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2591 (Dense)             (None, 8)            136         ['dropout_3809[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2593 (Dense)             (None, 8)            136         ['dropout_3812[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2595 (Dense)             (None, 8)            136         ['dropout_3815[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2597 (Dense)             (None, 8)            136         ['dropout_3818[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2599 (Dense)             (None, 8)            136         ['dropout_3821[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2601 (Dense)             (None, 8)            136         ['dropout_3824[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2603 (Dense)             (None, 8)            136         ['dropout_3827[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2605 (Dense)             (None, 8)            136         ['dropout_3830[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2607 (Dense)             (None, 8)            136         ['dropout_3833[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2609 (Dense)             (None, 8)            136         ['dropout_3836[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2611 (Dense)             (None, 8)            136         ['dropout_3839[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2613 (Dense)             (None, 8)            136         ['dropout_3842[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2615 (Dense)             (None, 8)            136         ['dropout_3845[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2617 (Dense)             (None, 8)            136         ['dropout_3848[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2619 (Dense)             (None, 8)            136         ['dropout_3851[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2621 (Dense)             (None, 8)            136         ['dropout_3854[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2623 (Dense)             (None, 8)            136         ['dropout_3857[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2625 (Dense)             (None, 8)            136         ['dropout_3860[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2627 (Dense)             (None, 8)            136         ['dropout_3863[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2629 (Dense)             (None, 8)            136         ['dropout_3866[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2631 (Dense)             (None, 8)            136         ['dropout_3869[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2633 (Dense)             (None, 8)            136         ['dropout_3872[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2635 (Dense)             (None, 8)            136         ['dropout_3875[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2637 (Dense)             (None, 8)            136         ['dropout_3878[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2639 (Dense)             (None, 8)            136         ['dropout_3881[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2641 (Dense)             (None, 8)            136         ['dropout_3884[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2643 (Dense)             (None, 8)            136         ['dropout_3887[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2645 (Dense)             (None, 8)            136         ['dropout_3890[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2647 (Dense)             (None, 8)            136         ['dropout_3893[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2649 (Dense)             (None, 8)            136         ['dropout_3896[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2651 (Dense)             (None, 8)            136         ['dropout_3899[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2653 (Dense)             (None, 8)            136         ['dropout_3902[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2655 (Dense)             (None, 8)            136         ['dropout_3905[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2657 (Dense)             (None, 8)            136         ['dropout_3908[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2659 (Dense)             (None, 8)            136         ['dropout_3911[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2661 (Dense)             (None, 8)            136         ['dropout_3914[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2663 (Dense)             (None, 8)            136         ['dropout_3917[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2665 (Dense)             (None, 8)            136         ['dropout_3920[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2667 (Dense)             (None, 8)            136         ['dropout_3923[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2669 (Dense)             (None, 8)            136         ['dropout_3926[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2671 (Dense)             (None, 8)            136         ['dropout_3929[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2673 (Dense)             (None, 8)            136         ['dropout_3932[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2675 (Dense)             (None, 8)            136         ['dropout_3935[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2677 (Dense)             (None, 8)            136         ['dropout_3938[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2679 (Dense)             (None, 8)            136         ['dropout_3941[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2681 (Dense)             (None, 8)            136         ['dropout_3944[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2683 (Dense)             (None, 8)            136         ['dropout_3947[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2685 (Dense)             (None, 8)            136         ['dropout_3950[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2687 (Dense)             (None, 8)            136         ['dropout_3953[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2689 (Dense)             (None, 8)            136         ['dropout_3956[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2691 (Dense)             (None, 8)            136         ['dropout_3959[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2693 (Dense)             (None, 8)            136         ['dropout_3962[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2695 (Dense)             (None, 8)            136         ['dropout_3965[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2697 (Dense)             (None, 8)            136         ['dropout_3968[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2699 (Dense)             (None, 8)            136         ['dropout_3971[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2701 (Dense)             (None, 8)            136         ['dropout_3974[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2703 (Dense)             (None, 8)            136         ['dropout_3977[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2705 (Dense)             (None, 8)            136         ['dropout_3980[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2707 (Dense)             (None, 8)            136         ['dropout_3983[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2709 (Dense)             (None, 8)            136         ['dropout_3986[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2711 (Dense)             (None, 8)            136         ['dropout_3989[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2713 (Dense)             (None, 8)            136         ['dropout_3992[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2715 (Dense)             (None, 8)            136         ['dropout_3995[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2717 (Dense)             (None, 8)            136         ['dropout_3998[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2719 (Dense)             (None, 8)            136         ['dropout_4001[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2721 (Dense)             (None, 8)            136         ['dropout_4004[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2723 (Dense)             (None, 8)            136         ['dropout_4007[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2725 (Dense)             (None, 8)            136         ['dropout_4010[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2727 (Dense)             (None, 8)            136         ['dropout_4013[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2729 (Dense)             (None, 8)            136         ['dropout_4016[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2731 (Dense)             (None, 8)            136         ['dropout_4019[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2733 (Dense)             (None, 8)            136         ['dropout_4022[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2735 (Dense)             (None, 8)            136         ['dropout_4025[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2737 (Dense)             (None, 8)            136         ['dropout_4028[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2739 (Dense)             (None, 8)            136         ['dropout_4031[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2741 (Dense)             (None, 8)            136         ['dropout_4034[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2543 (Dense)             (None, 8)            136         ['dropout_3737[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_3741 (Dropout)         (None, 8)            0           ['dense_2545[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3744 (Dropout)         (None, 8)            0           ['dense_2547[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3747 (Dropout)         (None, 8)            0           ['dense_2549[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3750 (Dropout)         (None, 8)            0           ['dense_2551[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3753 (Dropout)         (None, 8)            0           ['dense_2553[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3756 (Dropout)         (None, 8)            0           ['dense_2555[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3759 (Dropout)         (None, 8)            0           ['dense_2557[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3762 (Dropout)         (None, 8)            0           ['dense_2559[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3765 (Dropout)         (None, 8)            0           ['dense_2561[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3768 (Dropout)         (None, 8)            0           ['dense_2563[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3771 (Dropout)         (None, 8)            0           ['dense_2565[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3774 (Dropout)         (None, 8)            0           ['dense_2567[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3777 (Dropout)         (None, 8)            0           ['dense_2569[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3780 (Dropout)         (None, 8)            0           ['dense_2571[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3783 (Dropout)         (None, 8)            0           ['dense_2573[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3786 (Dropout)         (None, 8)            0           ['dense_2575[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3789 (Dropout)         (None, 8)            0           ['dense_2577[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3792 (Dropout)         (None, 8)            0           ['dense_2579[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3795 (Dropout)         (None, 8)            0           ['dense_2581[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3798 (Dropout)         (None, 8)            0           ['dense_2583[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3801 (Dropout)         (None, 8)            0           ['dense_2585[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3804 (Dropout)         (None, 8)            0           ['dense_2587[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3807 (Dropout)         (None, 8)            0           ['dense_2589[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3810 (Dropout)         (None, 8)            0           ['dense_2591[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3813 (Dropout)         (None, 8)            0           ['dense_2593[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3816 (Dropout)         (None, 8)            0           ['dense_2595[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3819 (Dropout)         (None, 8)            0           ['dense_2597[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3822 (Dropout)         (None, 8)            0           ['dense_2599[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3825 (Dropout)         (None, 8)            0           ['dense_2601[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3828 (Dropout)         (None, 8)            0           ['dense_2603[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3831 (Dropout)         (None, 8)            0           ['dense_2605[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3834 (Dropout)         (None, 8)            0           ['dense_2607[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3837 (Dropout)         (None, 8)            0           ['dense_2609[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3840 (Dropout)         (None, 8)            0           ['dense_2611[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3843 (Dropout)         (None, 8)            0           ['dense_2613[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3846 (Dropout)         (None, 8)            0           ['dense_2615[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3849 (Dropout)         (None, 8)            0           ['dense_2617[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3852 (Dropout)         (None, 8)            0           ['dense_2619[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3855 (Dropout)         (None, 8)            0           ['dense_2621[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3858 (Dropout)         (None, 8)            0           ['dense_2623[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3861 (Dropout)         (None, 8)            0           ['dense_2625[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3864 (Dropout)         (None, 8)            0           ['dense_2627[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3867 (Dropout)         (None, 8)            0           ['dense_2629[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3870 (Dropout)         (None, 8)            0           ['dense_2631[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3873 (Dropout)         (None, 8)            0           ['dense_2633[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3876 (Dropout)         (None, 8)            0           ['dense_2635[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3879 (Dropout)         (None, 8)            0           ['dense_2637[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3882 (Dropout)         (None, 8)            0           ['dense_2639[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3885 (Dropout)         (None, 8)            0           ['dense_2641[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3888 (Dropout)         (None, 8)            0           ['dense_2643[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3891 (Dropout)         (None, 8)            0           ['dense_2645[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3894 (Dropout)         (None, 8)            0           ['dense_2647[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3897 (Dropout)         (None, 8)            0           ['dense_2649[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3900 (Dropout)         (None, 8)            0           ['dense_2651[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3903 (Dropout)         (None, 8)            0           ['dense_2653[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3906 (Dropout)         (None, 8)            0           ['dense_2655[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3909 (Dropout)         (None, 8)            0           ['dense_2657[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3912 (Dropout)         (None, 8)            0           ['dense_2659[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3915 (Dropout)         (None, 8)            0           ['dense_2661[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3918 (Dropout)         (None, 8)            0           ['dense_2663[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3921 (Dropout)         (None, 8)            0           ['dense_2665[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3924 (Dropout)         (None, 8)            0           ['dense_2667[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3927 (Dropout)         (None, 8)            0           ['dense_2669[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3930 (Dropout)         (None, 8)            0           ['dense_2671[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3933 (Dropout)         (None, 8)            0           ['dense_2673[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3936 (Dropout)         (None, 8)            0           ['dense_2675[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3939 (Dropout)         (None, 8)            0           ['dense_2677[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3942 (Dropout)         (None, 8)            0           ['dense_2679[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3945 (Dropout)         (None, 8)            0           ['dense_2681[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3948 (Dropout)         (None, 8)            0           ['dense_2683[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3951 (Dropout)         (None, 8)            0           ['dense_2685[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3954 (Dropout)         (None, 8)            0           ['dense_2687[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3957 (Dropout)         (None, 8)            0           ['dense_2689[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3960 (Dropout)         (None, 8)            0           ['dense_2691[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3963 (Dropout)         (None, 8)            0           ['dense_2693[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3966 (Dropout)         (None, 8)            0           ['dense_2695[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3969 (Dropout)         (None, 8)            0           ['dense_2697[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3972 (Dropout)         (None, 8)            0           ['dense_2699[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3975 (Dropout)         (None, 8)            0           ['dense_2701[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3978 (Dropout)         (None, 8)            0           ['dense_2703[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3981 (Dropout)         (None, 8)            0           ['dense_2705[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3984 (Dropout)         (None, 8)            0           ['dense_2707[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3987 (Dropout)         (None, 8)            0           ['dense_2709[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3990 (Dropout)         (None, 8)            0           ['dense_2711[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3993 (Dropout)         (None, 8)            0           ['dense_2713[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3996 (Dropout)         (None, 8)            0           ['dense_2715[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3999 (Dropout)         (None, 8)            0           ['dense_2717[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4002 (Dropout)         (None, 8)            0           ['dense_2719[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4005 (Dropout)         (None, 8)            0           ['dense_2721[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4008 (Dropout)         (None, 8)            0           ['dense_2723[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4011 (Dropout)         (None, 8)            0           ['dense_2725[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4014 (Dropout)         (None, 8)            0           ['dense_2727[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4017 (Dropout)         (None, 8)            0           ['dense_2729[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4020 (Dropout)         (None, 8)            0           ['dense_2731[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4023 (Dropout)         (None, 8)            0           ['dense_2733[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4026 (Dropout)         (None, 8)            0           ['dense_2735[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4029 (Dropout)         (None, 8)            0           ['dense_2737[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4032 (Dropout)         (None, 8)            0           ['dense_2739[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4035 (Dropout)         (None, 8)            0           ['dense_2741[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3738 (Dropout)         (None, 8)            0           ['dense_2543[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_1236 (Flatten)         (None, 8)            0           ['dropout_3741[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1237 (Flatten)         (None, 8)            0           ['dropout_3744[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1238 (Flatten)         (None, 8)            0           ['dropout_3747[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1239 (Flatten)         (None, 8)            0           ['dropout_3750[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1240 (Flatten)         (None, 8)            0           ['dropout_3753[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1241 (Flatten)         (None, 8)            0           ['dropout_3756[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1242 (Flatten)         (None, 8)            0           ['dropout_3759[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1243 (Flatten)         (None, 8)            0           ['dropout_3762[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1244 (Flatten)         (None, 8)            0           ['dropout_3765[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1245 (Flatten)         (None, 8)            0           ['dropout_3768[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1246 (Flatten)         (None, 8)            0           ['dropout_3771[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1247 (Flatten)         (None, 8)            0           ['dropout_3774[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1248 (Flatten)         (None, 8)            0           ['dropout_3777[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1249 (Flatten)         (None, 8)            0           ['dropout_3780[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1250 (Flatten)         (None, 8)            0           ['dropout_3783[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1251 (Flatten)         (None, 8)            0           ['dropout_3786[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1252 (Flatten)         (None, 8)            0           ['dropout_3789[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1253 (Flatten)         (None, 8)            0           ['dropout_3792[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1254 (Flatten)         (None, 8)            0           ['dropout_3795[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1255 (Flatten)         (None, 8)            0           ['dropout_3798[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1256 (Flatten)         (None, 8)            0           ['dropout_3801[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1257 (Flatten)         (None, 8)            0           ['dropout_3804[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1258 (Flatten)         (None, 8)            0           ['dropout_3807[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1259 (Flatten)         (None, 8)            0           ['dropout_3810[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1260 (Flatten)         (None, 8)            0           ['dropout_3813[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1261 (Flatten)         (None, 8)            0           ['dropout_3816[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1262 (Flatten)         (None, 8)            0           ['dropout_3819[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1263 (Flatten)         (None, 8)            0           ['dropout_3822[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1264 (Flatten)         (None, 8)            0           ['dropout_3825[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1265 (Flatten)         (None, 8)            0           ['dropout_3828[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1266 (Flatten)         (None, 8)            0           ['dropout_3831[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1267 (Flatten)         (None, 8)            0           ['dropout_3834[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1268 (Flatten)         (None, 8)            0           ['dropout_3837[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1269 (Flatten)         (None, 8)            0           ['dropout_3840[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1270 (Flatten)         (None, 8)            0           ['dropout_3843[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1271 (Flatten)         (None, 8)            0           ['dropout_3846[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1272 (Flatten)         (None, 8)            0           ['dropout_3849[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1273 (Flatten)         (None, 8)            0           ['dropout_3852[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1274 (Flatten)         (None, 8)            0           ['dropout_3855[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1275 (Flatten)         (None, 8)            0           ['dropout_3858[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1276 (Flatten)         (None, 8)            0           ['dropout_3861[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1277 (Flatten)         (None, 8)            0           ['dropout_3864[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1278 (Flatten)         (None, 8)            0           ['dropout_3867[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1279 (Flatten)         (None, 8)            0           ['dropout_3870[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1280 (Flatten)         (None, 8)            0           ['dropout_3873[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1281 (Flatten)         (None, 8)            0           ['dropout_3876[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1282 (Flatten)         (None, 8)            0           ['dropout_3879[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1283 (Flatten)         (None, 8)            0           ['dropout_3882[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1284 (Flatten)         (None, 8)            0           ['dropout_3885[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1285 (Flatten)         (None, 8)            0           ['dropout_3888[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1286 (Flatten)         (None, 8)            0           ['dropout_3891[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1287 (Flatten)         (None, 8)            0           ['dropout_3894[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1288 (Flatten)         (None, 8)            0           ['dropout_3897[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1289 (Flatten)         (None, 8)            0           ['dropout_3900[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1290 (Flatten)         (None, 8)            0           ['dropout_3903[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1291 (Flatten)         (None, 8)            0           ['dropout_3906[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1292 (Flatten)         (None, 8)            0           ['dropout_3909[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1293 (Flatten)         (None, 8)            0           ['dropout_3912[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1294 (Flatten)         (None, 8)            0           ['dropout_3915[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1295 (Flatten)         (None, 8)            0           ['dropout_3918[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1296 (Flatten)         (None, 8)            0           ['dropout_3921[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1297 (Flatten)         (None, 8)            0           ['dropout_3924[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1298 (Flatten)         (None, 8)            0           ['dropout_3927[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1299 (Flatten)         (None, 8)            0           ['dropout_3930[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1300 (Flatten)         (None, 8)            0           ['dropout_3933[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1301 (Flatten)         (None, 8)            0           ['dropout_3936[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1302 (Flatten)         (None, 8)            0           ['dropout_3939[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1303 (Flatten)         (None, 8)            0           ['dropout_3942[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1304 (Flatten)         (None, 8)            0           ['dropout_3945[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1305 (Flatten)         (None, 8)            0           ['dropout_3948[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1306 (Flatten)         (None, 8)            0           ['dropout_3951[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1307 (Flatten)         (None, 8)            0           ['dropout_3954[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1308 (Flatten)         (None, 8)            0           ['dropout_3957[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1309 (Flatten)         (None, 8)            0           ['dropout_3960[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1310 (Flatten)         (None, 8)            0           ['dropout_3963[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1311 (Flatten)         (None, 8)            0           ['dropout_3966[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1312 (Flatten)         (None, 8)            0           ['dropout_3969[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1313 (Flatten)         (None, 8)            0           ['dropout_3972[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1314 (Flatten)         (None, 8)            0           ['dropout_3975[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1315 (Flatten)         (None, 8)            0           ['dropout_3978[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1316 (Flatten)         (None, 8)            0           ['dropout_3981[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1317 (Flatten)         (None, 8)            0           ['dropout_3984[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1318 (Flatten)         (None, 8)            0           ['dropout_3987[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1319 (Flatten)         (None, 8)            0           ['dropout_3990[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1320 (Flatten)         (None, 8)            0           ['dropout_3993[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1321 (Flatten)         (None, 8)            0           ['dropout_3996[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1322 (Flatten)         (None, 8)            0           ['dropout_3999[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1323 (Flatten)         (None, 8)            0           ['dropout_4002[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1324 (Flatten)         (None, 8)            0           ['dropout_4005[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1325 (Flatten)         (None, 8)            0           ['dropout_4008[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1326 (Flatten)         (None, 8)            0           ['dropout_4011[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1327 (Flatten)         (None, 8)            0           ['dropout_4014[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1328 (Flatten)         (None, 8)            0           ['dropout_4017[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1329 (Flatten)         (None, 8)            0           ['dropout_4020[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1330 (Flatten)         (None, 8)            0           ['dropout_4023[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1331 (Flatten)         (None, 8)            0           ['dropout_4026[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1332 (Flatten)         (None, 8)            0           ['dropout_4029[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1333 (Flatten)         (None, 8)            0           ['dropout_4032[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1334 (Flatten)         (None, 8)            0           ['dropout_4035[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_12 (Concatenate)   (None, 800)          0           ['dropout_3738[0][0]',           \n",
      "                                                                  'flatten_1236[0][0]',           \n",
      "                                                                  'flatten_1237[0][0]',           \n",
      "                                                                  'flatten_1238[0][0]',           \n",
      "                                                                  'flatten_1239[0][0]',           \n",
      "                                                                  'flatten_1240[0][0]',           \n",
      "                                                                  'flatten_1241[0][0]',           \n",
      "                                                                  'flatten_1242[0][0]',           \n",
      "                                                                  'flatten_1243[0][0]',           \n",
      "                                                                  'flatten_1244[0][0]',           \n",
      "                                                                  'flatten_1245[0][0]',           \n",
      "                                                                  'flatten_1246[0][0]',           \n",
      "                                                                  'flatten_1247[0][0]',           \n",
      "                                                                  'flatten_1248[0][0]',           \n",
      "                                                                  'flatten_1249[0][0]',           \n",
      "                                                                  'flatten_1250[0][0]',           \n",
      "                                                                  'flatten_1251[0][0]',           \n",
      "                                                                  'flatten_1252[0][0]',           \n",
      "                                                                  'flatten_1253[0][0]',           \n",
      "                                                                  'flatten_1254[0][0]',           \n",
      "                                                                  'flatten_1255[0][0]',           \n",
      "                                                                  'flatten_1256[0][0]',           \n",
      "                                                                  'flatten_1257[0][0]',           \n",
      "                                                                  'flatten_1258[0][0]',           \n",
      "                                                                  'flatten_1259[0][0]',           \n",
      "                                                                  'flatten_1260[0][0]',           \n",
      "                                                                  'flatten_1261[0][0]',           \n",
      "                                                                  'flatten_1262[0][0]',           \n",
      "                                                                  'flatten_1263[0][0]',           \n",
      "                                                                  'flatten_1264[0][0]',           \n",
      "                                                                  'flatten_1265[0][0]',           \n",
      "                                                                  'flatten_1266[0][0]',           \n",
      "                                                                  'flatten_1267[0][0]',           \n",
      "                                                                  'flatten_1268[0][0]',           \n",
      "                                                                  'flatten_1269[0][0]',           \n",
      "                                                                  'flatten_1270[0][0]',           \n",
      "                                                                  'flatten_1271[0][0]',           \n",
      "                                                                  'flatten_1272[0][0]',           \n",
      "                                                                  'flatten_1273[0][0]',           \n",
      "                                                                  'flatten_1274[0][0]',           \n",
      "                                                                  'flatten_1275[0][0]',           \n",
      "                                                                  'flatten_1276[0][0]',           \n",
      "                                                                  'flatten_1277[0][0]',           \n",
      "                                                                  'flatten_1278[0][0]',           \n",
      "                                                                  'flatten_1279[0][0]',           \n",
      "                                                                  'flatten_1280[0][0]',           \n",
      "                                                                  'flatten_1281[0][0]',           \n",
      "                                                                  'flatten_1282[0][0]',           \n",
      "                                                                  'flatten_1283[0][0]',           \n",
      "                                                                  'flatten_1284[0][0]',           \n",
      "                                                                  'flatten_1285[0][0]',           \n",
      "                                                                  'flatten_1286[0][0]',           \n",
      "                                                                  'flatten_1287[0][0]',           \n",
      "                                                                  'flatten_1288[0][0]',           \n",
      "                                                                  'flatten_1289[0][0]',           \n",
      "                                                                  'flatten_1290[0][0]',           \n",
      "                                                                  'flatten_1291[0][0]',           \n",
      "                                                                  'flatten_1292[0][0]',           \n",
      "                                                                  'flatten_1293[0][0]',           \n",
      "                                                                  'flatten_1294[0][0]',           \n",
      "                                                                  'flatten_1295[0][0]',           \n",
      "                                                                  'flatten_1296[0][0]',           \n",
      "                                                                  'flatten_1297[0][0]',           \n",
      "                                                                  'flatten_1298[0][0]',           \n",
      "                                                                  'flatten_1299[0][0]',           \n",
      "                                                                  'flatten_1300[0][0]',           \n",
      "                                                                  'flatten_1301[0][0]',           \n",
      "                                                                  'flatten_1302[0][0]',           \n",
      "                                                                  'flatten_1303[0][0]',           \n",
      "                                                                  'flatten_1304[0][0]',           \n",
      "                                                                  'flatten_1305[0][0]',           \n",
      "                                                                  'flatten_1306[0][0]',           \n",
      "                                                                  'flatten_1307[0][0]',           \n",
      "                                                                  'flatten_1308[0][0]',           \n",
      "                                                                  'flatten_1309[0][0]',           \n",
      "                                                                  'flatten_1310[0][0]',           \n",
      "                                                                  'flatten_1311[0][0]',           \n",
      "                                                                  'flatten_1312[0][0]',           \n",
      "                                                                  'flatten_1313[0][0]',           \n",
      "                                                                  'flatten_1314[0][0]',           \n",
      "                                                                  'flatten_1315[0][0]',           \n",
      "                                                                  'flatten_1316[0][0]',           \n",
      "                                                                  'flatten_1317[0][0]',           \n",
      "                                                                  'flatten_1318[0][0]',           \n",
      "                                                                  'flatten_1319[0][0]',           \n",
      "                                                                  'flatten_1320[0][0]',           \n",
      "                                                                  'flatten_1321[0][0]',           \n",
      "                                                                  'flatten_1322[0][0]',           \n",
      "                                                                  'flatten_1323[0][0]',           \n",
      "                                                                  'flatten_1324[0][0]',           \n",
      "                                                                  'flatten_1325[0][0]',           \n",
      "                                                                  'flatten_1326[0][0]',           \n",
      "                                                                  'flatten_1327[0][0]',           \n",
      "                                                                  'flatten_1328[0][0]',           \n",
      "                                                                  'flatten_1329[0][0]',           \n",
      "                                                                  'flatten_1330[0][0]',           \n",
      "                                                                  'flatten_1331[0][0]',           \n",
      "                                                                  'flatten_1332[0][0]',           \n",
      "                                                                  'flatten_1333[0][0]',           \n",
      "                                                                  'flatten_1334[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2742 (Dense)             (None, 4)            3204        ['concatenate_12[0][0]']         \n",
      "                                                                                                  \n",
      " dense_2743 (Dense)             (None, 2)            10          ['dense_2742[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2744 (Dense)             (None, 1)            3           ['dense_2743[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 180,049\n",
      "Trainable params: 180,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_ab.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ab = model_ab.fit(x=X_train_2, y=y_train_ab_2, epochs=10000, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "y_pred_ab_2 = model_ab.predict(X_test_2)\n",
    "\n",
    "print(mean_absolute_error(y_pred_ab_2, y_test_ab_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]\n",
      " [0.5140859]]\n",
      "[0.83418987 0.98828817 0.68353739 0.74081079 0.89140379 0.69613153\n",
      " 0.4844527  0.53566795 0.59601383 0.63599096]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_ab_2[0:10])\n",
    "print(y_test_ab_2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_ab, 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ab = np.zeros((n_sim, nb-1, 2, 2))\n",
    "\n",
    "for k1 in range(n_sim):\n",
    "    for k2 in range(nb-1):\n",
    "        dataset_ab[k1, k2, 0, 0] = dataset[k1, k2, 0]\n",
    "        dataset_ab[k1, k2, 1, 0] = dataset[k1, k2+1, 0]\n",
    "        dataset_ab[k1, k2, 0, 1] = dataset[k1, k2, 1]\n",
    "        dataset_ab[k1, k2, 1, 1] = dataset[k1, k2+1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*nb+3* entres (tat initial a, tat initial b, bruit a, bruit b et les observations 2  2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dataset_ab_3 = [0]*n_sim\n",
    "for s in range(n_sim):\n",
    "    param_1 = np.zeros((1))\n",
    "    param_2 = np.zeros((1))\n",
    "    param_3 = np.zeros((1))\n",
    "    param_4 = np.zeros((1))\n",
    "    param_1[0] = param[s, 0] # tat initial a \n",
    "    param_2[0] = param[s, 1] # tat initial b\n",
    "    param_3[0] = param[s, 3] # bruit a \n",
    "    param_4[0] = param[s, 4] # bruit b\n",
    "    liste_dataset_ab_3[s] = [param_1, param_2, param_3, param_4]\n",
    "    liste_dataset_ab_3[s] += [dataset_ab[s, :, :, :]]\n",
    "       \n",
    "X_train_ab_3, X_test_ab_3, y_train_ab_3, y_test_ab_3 = train_test_split(liste_dataset_ab_3, y[:, 1], train_size = 0.7, shuffle = False)\n",
    "\n",
    "X_train_3 = [0]*(nb+3)\n",
    "X_test_3 = [0]*(nb+3)\n",
    "\n",
    "X_train_3[0] = np.zeros((len(X_train_ab_3), 1))\n",
    "X_test_3[0] = np.zeros((len(X_test_ab_3), 1))\n",
    "\n",
    "X_train_3[1] = np.zeros((len(X_train_ab_3), 1))\n",
    "X_test_3[1] = np.zeros((len(X_test_ab_3), 1))\n",
    "\n",
    "X_train_3[2] = np.zeros((len(X_train_ab_3), 1))\n",
    "X_test_3[2] = np.zeros((len(X_test_ab_3), 1))\n",
    "\n",
    "X_train_3[3] = np.zeros((len(X_train_ab_3), 1))\n",
    "X_test_3[3] = np.zeros((len(X_test_ab_3), 1))\n",
    "\n",
    "for s in range(len(X_train_ab_3)):\n",
    "    X_train_3[0][s] = X_train_ab_3[s][0]\n",
    "    X_train_3[1][s] = X_train_ab_3[s][1]\n",
    "    X_train_3[2][s] = X_train_ab_3[s][2]\n",
    "    X_train_3[3][s] = X_train_ab_3[s][3]\n",
    "    \n",
    "for s in range(len(X_test_ab_3)):\n",
    "    X_test_3[0][s] = X_test_ab_3[s][0]\n",
    "    X_test_3[1][s] = X_test_ab_3[s][1]\n",
    "    X_test_3[2][s] = X_test_ab_3[s][2]\n",
    "    X_test_3[3][s] = X_test_ab_3[s][3]\n",
    "\n",
    "for k in range(nb-1):\n",
    "    array_k = np.zeros((len(X_train_ab_3), 2, 2))\n",
    "    for s in range(len(X_train_ab_3)):\n",
    "        array_k[s, :, :] = X_train_ab_3[s][4][k]\n",
    "    X_train_3[k+4] = array_k\n",
    "\n",
    "for k in range(nb-1):\n",
    "    array_k = np.zeros((len(X_test_ab_3), 2, 2))\n",
    "    for s in range(len(X_test_ab_3)):\n",
    "        array_k[s, :, :] = X_test_ab_3[s][4][k]\n",
    "    X_test_3[k+4] = array_k      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 108s 960ms/step - loss: 0.3908 - mean_absolute_error: 0.3837 - val_loss: 0.2006 - val_mean_absolute_error: 0.2001\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 0.2787 - mean_absolute_error: 0.2756 - val_loss: 0.2244 - val_mean_absolute_error: 0.2257\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 1s 74ms/step - loss: 0.2474 - mean_absolute_error: 0.2483 - val_loss: 0.2114 - val_mean_absolute_error: 0.2125\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 2s 99ms/step - loss: 0.2298 - mean_absolute_error: 0.2308 - val_loss: 0.2394 - val_mean_absolute_error: 0.2411\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 1s 88ms/step - loss: 0.2233 - mean_absolute_error: 0.2199 - val_loss: 0.2256 - val_mean_absolute_error: 0.2273\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 1s 85ms/step - loss: 0.2181 - mean_absolute_error: 0.2181 - val_loss: 0.2101 - val_mean_absolute_error: 0.2115\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 2s 96ms/step - loss: 0.2111 - mean_absolute_error: 0.2111 - val_loss: 0.2166 - val_mean_absolute_error: 0.2182\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 2s 102ms/step - loss: 0.2091 - mean_absolute_error: 0.2082 - val_loss: 0.2219 - val_mean_absolute_error: 0.2235\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 2s 95ms/step - loss: 0.2040 - mean_absolute_error: 0.2029 - val_loss: 0.2057 - val_mean_absolute_error: 0.2070\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 1s 90ms/step - loss: 0.1994 - mean_absolute_error: 0.1991 - val_loss: 0.2325 - val_mean_absolute_error: 0.2342\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 2s 98ms/step - loss: 0.1935 - mean_absolute_error: 0.1936 - val_loss: 0.2240 - val_mean_absolute_error: 0.2255\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 1s 94ms/step - loss: 0.1907 - mean_absolute_error: 0.1913 - val_loss: 0.2208 - val_mean_absolute_error: 0.2223\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 2s 104ms/step - loss: 0.1828 - mean_absolute_error: 0.1835 - val_loss: 0.2158 - val_mean_absolute_error: 0.2172\n",
      "Epoch 14/200\n",
      " 1/16 [>.............................] - ETA: 1s - loss: 0.1887 - mean_absolute_error: 0.1887"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-309-12feebd81574>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMeanAbsoluteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mMeanAbsoluteError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mhistory_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_ab_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0my_pred_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_input = []\n",
    "list_output = []\n",
    "input_1 = Input(shape = (1,)) # tat initial a \n",
    "input_2 = Input(shape = (1,)) # tat initial b\n",
    "input_3 = Input(shape = (1,)) # bruit a \n",
    "input_4 = Input(shape = (1,)) # bruit b \n",
    "\n",
    "x = Dense(16, activation=\"relu\")(input_1)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Model(inputs=input_1, outputs=x)\n",
    "list_output += [x.output]\n",
    "list_input += [x.input]\n",
    "\n",
    "x = Dense(16, activation=\"relu\")(input_2)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Model(inputs=input_2, outputs=x)\n",
    "list_output += [x.output]\n",
    "list_input += [x.input]\n",
    "\n",
    "x = Dense(16, activation=\"relu\")(input_3)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Model(inputs=input_3, outputs=x)\n",
    "list_output += [x.output]\n",
    "list_input += [x.input]\n",
    "\n",
    "x = Dense(16, activation=\"relu\")(input_4)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Model(inputs=input_4, outputs=x)\n",
    "list_output += [x.output]\n",
    "list_input += [x.input]\n",
    "\n",
    "for k in range (nb-1):\n",
    "    input_k = Input(shape = (2, 2,))\n",
    "    x = SimpleRNN(32)(input_k)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Model(inputs=input_k, outputs=x)\n",
    "    list_output += [x.output]\n",
    "    list_input += [x.input]\n",
    "\n",
    "output_N1 = concatenate(list_output)\n",
    "\n",
    "z = Dense(4, activation=\"relu\")(output_N1)\n",
    "z = Dense(2, activation=\"relu\")(z)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])\n",
    "\n",
    "history_ab = model_ab.fit(x=X_train_3, y=y_train_ab_3, epochs=200, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "y_pred_ab = model_ab.predict(X_test_3)\n",
    "\n",
    "print(mean_absolute_error(y_pred_ab, y_test_ab_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2269531 ]\n",
      " [0.22026718]\n",
      " [0.22501764]\n",
      " [0.6226822 ]\n",
      " [0.57925713]\n",
      " [0.7985209 ]\n",
      " [0.44359633]\n",
      " [0.32877216]\n",
      " [0.22483027]\n",
      " [0.16590303]]\n",
      "[0.09397579 0.2507343  0.49005176 0.60613818 0.2564541  0.23934314\n",
      " 0.15400659 0.11174209 0.20201491 0.74254792]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_ab[0:10])\n",
    "print(y_test_ab_3[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history_ab, 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rseau avec la score map en entre et les observations 2  2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.1\n",
    "score_maps = np.zeros((n_sim, int(1/step), int(1/step)))\n",
    "\n",
    "for s in range(n_sim):\n",
    "    for i in range(int(1/step)):\n",
    "        for j in range(int(1/step)):\n",
    "            score_maps[s, i, j] = random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_dataset_ab_maps = [0]*n_sim\n",
    "for s in range(n_sim):\n",
    "    liste_dataset_ab_maps[s] = [score_maps[s]]\n",
    "    liste_dataset_ab_maps[s] += [dataset_ab[s, :, :, :]]\n",
    "       \n",
    "X_train_ab_maps, X_test_ab_maps, y_train_ab_maps, y_test_ab_maps = train_test_split(liste_dataset_ab_maps, y[:, 1], train_size = 0.7, shuffle = False)  \n",
    "\n",
    "X_train_ab_maps_2 = [0]*nb\n",
    "X_train_ab_maps_2[0] = np.zeros((len(X_train_ab_maps), int(1/step), int(1/step)))\n",
    "for s in range(len(X_train_ab_maps)):\n",
    "    X_train_ab_maps_2[0][s] = X_train_ab_maps[s][0]\n",
    "    \n",
    "for k in range(1, nb):\n",
    "    X_train_ab_maps_2[k] = np.zeros((len(X_train_ab_maps), 2, 2))\n",
    "    for s in range(len(X_train_ab_maps)):\n",
    "        X_train_ab_maps_2[k][s] = X_train_ab_maps[s][1][k-1]\n",
    "\n",
    "X_test_ab_maps_2 = [0]*nb\n",
    "X_test_ab_maps_2[0] = np.zeros((len(X_test_ab_maps), int(1/step), int(1/step)))\n",
    "for s in range(len(X_test_ab_maps)):\n",
    "    X_test_ab_maps_2[0][s] = X_test_ab_maps[s][0]\n",
    "    \n",
    "for k in range(1, nb):\n",
    "    X_test_ab_maps_2[k] = np.zeros((len(X_test_ab_maps), 2, 2))\n",
    "    for s in range(len(X_test_ab_maps)):\n",
    "        X_test_ab_maps_2[k][s] = X_test_ab_maps[s][1][k-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_input = []\n",
    "list_output = []\n",
    "\n",
    "input_param = Input(shape = (int(1/step), int(1/step),)) # score map\n",
    "x = Dense(16, activation=\"relu\")(input_param)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(8, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Flatten()(x)\n",
    "x = Model(inputs=input_param, outputs=x)\n",
    "\n",
    "list_output += [x.output]\n",
    "list_input += [x.input]\n",
    "\n",
    "for k in range (nb-1):\n",
    "    input_k = Input(shape = (2, 2,))\n",
    "    x = SimpleRNN(32)(input_k)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(8, activation=\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Model(inputs=input_k, outputs=x)\n",
    "    list_output += [x.output]\n",
    "    list_input += [x.input]\n",
    "\n",
    "output_N1 = concatenate(list_output)\n",
    "\n",
    "z = Dense(4, activation=\"relu\")(output_N1)\n",
    "z = Dense(2, activation=\"relu\")(z)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "model_ab = Model(inputs=list_input, outputs=z)\n",
    "\n",
    "model_ab.compile(loss=MeanAbsoluteError(), optimizer=\"adam\", metrics=[MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 135s 135s/step - loss: 0.5792 - mean_absolute_error: 0.5792 - val_loss: 0.4837 - val_mean_absolute_error: 0.4837\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5719 - mean_absolute_error: 0.5719 - val_loss: 0.4827 - val_mean_absolute_error: 0.4827\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 0.5680 - mean_absolute_error: 0.5680 - val_loss: 0.4817 - val_mean_absolute_error: 0.4817\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.5670 - mean_absolute_error: 0.5670 - val_loss: 0.4807 - val_mean_absolute_error: 0.4807\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.5660 - mean_absolute_error: 0.5660 - val_loss: 0.4797 - val_mean_absolute_error: 0.4797\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 0.5650 - mean_absolute_error: 0.5650 - val_loss: 0.4787 - val_mean_absolute_error: 0.4787\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5640 - mean_absolute_error: 0.5640 - val_loss: 0.4777 - val_mean_absolute_error: 0.4777\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 0.5630 - mean_absolute_error: 0.5630 - val_loss: 0.4767 - val_mean_absolute_error: 0.4767\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 0.5620 - mean_absolute_error: 0.5620 - val_loss: 0.4757 - val_mean_absolute_error: 0.4757\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 0.5610 - mean_absolute_error: 0.5610 - val_loss: 0.4747 - val_mean_absolute_error: 0.4747\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 0.5600 - mean_absolute_error: 0.5600 - val_loss: 0.4737 - val_mean_absolute_error: 0.4737\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 308ms/step - loss: 0.5590 - mean_absolute_error: 0.5590 - val_loss: 0.4727 - val_mean_absolute_error: 0.4727\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 1s 504ms/step - loss: 0.5580 - mean_absolute_error: 0.5580 - val_loss: 0.4717 - val_mean_absolute_error: 0.4717\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.5570 - mean_absolute_error: 0.5570 - val_loss: 0.4707 - val_mean_absolute_error: 0.4707\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5560 - mean_absolute_error: 0.5560 - val_loss: 0.4697 - val_mean_absolute_error: 0.4697\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 0.5550 - mean_absolute_error: 0.5550 - val_loss: 0.4687 - val_mean_absolute_error: 0.4687\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 0.5540 - mean_absolute_error: 0.5540 - val_loss: 0.4678 - val_mean_absolute_error: 0.4678\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.5530 - mean_absolute_error: 0.5530 - val_loss: 0.4669 - val_mean_absolute_error: 0.4669\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 0.5520 - mean_absolute_error: 0.5520 - val_loss: 0.4660 - val_mean_absolute_error: 0.4660\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 427ms/step - loss: 0.5510 - mean_absolute_error: 0.5510 - val_loss: 0.4651 - val_mean_absolute_error: 0.4651\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5500 - mean_absolute_error: 0.5500 - val_loss: 0.4642 - val_mean_absolute_error: 0.4642\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 0.5490 - mean_absolute_error: 0.5490 - val_loss: 0.4632 - val_mean_absolute_error: 0.4632\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 0.5480 - mean_absolute_error: 0.5480 - val_loss: 0.4623 - val_mean_absolute_error: 0.4623\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5470 - mean_absolute_error: 0.5470 - val_loss: 0.4614 - val_mean_absolute_error: 0.4614\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 0.5460 - mean_absolute_error: 0.5460 - val_loss: 0.4605 - val_mean_absolute_error: 0.4605\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 0.5450 - mean_absolute_error: 0.5450 - val_loss: 0.4596 - val_mean_absolute_error: 0.4596\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 0.5440 - mean_absolute_error: 0.5440 - val_loss: 0.4587 - val_mean_absolute_error: 0.4587\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 0.5430 - mean_absolute_error: 0.5430 - val_loss: 0.4578 - val_mean_absolute_error: 0.4578\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5420 - mean_absolute_error: 0.5420 - val_loss: 0.4569 - val_mean_absolute_error: 0.4569\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 0.5410 - mean_absolute_error: 0.5410 - val_loss: 0.4560 - val_mean_absolute_error: 0.4560\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 0.5400 - mean_absolute_error: 0.5400 - val_loss: 0.4551 - val_mean_absolute_error: 0.4551\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.5390 - mean_absolute_error: 0.5390 - val_loss: 0.4543 - val_mean_absolute_error: 0.4543\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 0.5380 - mean_absolute_error: 0.5380 - val_loss: 0.4535 - val_mean_absolute_error: 0.4535\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 0.5370 - mean_absolute_error: 0.5370 - val_loss: 0.4527 - val_mean_absolute_error: 0.4527\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 0.5360 - mean_absolute_error: 0.5360 - val_loss: 0.4519 - val_mean_absolute_error: 0.4519\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 0.5350 - mean_absolute_error: 0.5350 - val_loss: 0.4511 - val_mean_absolute_error: 0.4511\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.5340 - mean_absolute_error: 0.5340 - val_loss: 0.4502 - val_mean_absolute_error: 0.4502\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5330 - mean_absolute_error: 0.5330"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-508-382dd879cef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_ab_maps_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_ab_maps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_ab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_ab_maps_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1252\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_test_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 726\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    749\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 751\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3235\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3237\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3238\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3239\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history_ab = model_ab.fit(x=X_train_ab_maps_2, y=y_train_ab_maps, epochs=200, batch_size = 64, validation_split=0.3)\n",
    "\n",
    "y_pred_ab = model_ab.predict(X_test_ab_maps_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "232.727px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
